{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b0ff70f",
   "metadata": {},
   "source": [
    "### RAG Pipelines - Data Ingestion to Vector DB Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4fd3343d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.document_loaders import PyPDFLoader, PyMuPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from pathlib import Path\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "97def4b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11 PDF files to process\n",
      "\n",
      "Processing: cn.pdf\n",
      "  ✓ Loaded 1 pages\n",
      "\n",
      "Processing: Artificial_Intelligence_and_Machine_Learning_Appli.pdf\n",
      "  ✓ Loaded 26 pages\n",
      "\n",
      "Processing: dsa.pdf\n",
      "  ✓ Loaded 1 pages\n",
      "\n",
      "Processing: Shreya_Sharma_Resume.pdf\n",
      "  ✓ Loaded 1 pages\n",
      "\n",
      "Processing: Shreya_Sharma_Transcript.pdf\n",
      "  ✓ Loaded 1 pages\n",
      "\n",
      "Processing: dbms.pdf\n",
      "  ✓ Loaded 1 pages\n",
      "\n",
      "Processing: ml.pdf\n",
      "  ✓ Loaded 1 pages\n",
      "\n",
      "Processing: os.pdf\n",
      "  ✓ Loaded 1 pages\n",
      "\n",
      "Processing: Natural_language_processing_state_of_the_art_curre.pdf\n",
      "  ✓ Loaded 25 pages\n",
      "\n",
      "Processing: Siddhant_Kochhar_Resume.pdf\n",
      "  ✓ Loaded 1 pages\n",
      "\n",
      "Processing: 1-s2.0-S2949719124000104-main.pdf\n",
      "  ✓ Loaded 17 pages\n",
      "\n",
      "Total documents loaded: 76\n"
     ]
    }
   ],
   "source": [
    "### Read all the pdf's inside the directory\n",
    "def process_all_pdfs(pdf_directory):\n",
    "    \"\"\"Process all PDF files in a directory\"\"\"\n",
    "    all_documents = []\n",
    "    pdf_dir = Path(pdf_directory)\n",
    "    \n",
    "    # Find all PDF files recursively\n",
    "    pdf_files = list(pdf_dir.glob(\"**/*.pdf\"))\n",
    "    \n",
    "    print(f\"Found {len(pdf_files)} PDF files to process\")\n",
    "    \n",
    "    for pdf_file in pdf_files:\n",
    "        print(f\"\\nProcessing: {pdf_file.name}\")\n",
    "        try:\n",
    "            loader = PyPDFLoader(str(pdf_file))\n",
    "            documents = loader.load()\n",
    "            \n",
    "            # Add source information to metadata\n",
    "            for doc in documents:\n",
    "                doc.metadata['source_file'] = pdf_file.name\n",
    "                doc.metadata['file_type'] = 'pdf'\n",
    "            \n",
    "            all_documents.extend(documents)\n",
    "            print(f\"  ✓ Loaded {len(documents)} pages\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  ✗ Error: {e}\")\n",
    "    \n",
    "    print(f\"\\nTotal documents loaded: {len(all_documents)}\")\n",
    "    return all_documents\n",
    "\n",
    "# Process all PDFs in the data directory\n",
    "all_pdf_documents = process_all_pdfs(\"../data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a2acade3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'Skia/PDF m144 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'cn', 'source': '../data/pdf_files/cn.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'cn.pdf', 'file_type': 'pdf'}, page_content='Computer  Networks  enable  communication  between  devices  through  a  set  of  rules  called  protocols.  Among  \\nthese,\\n \\nTCP\\n \\n(Transmission\\n \\nControl\\n \\nProtocol)\\n \\nand\\n \\nUDP\\n \\n(User\\n \\nDatagram\\n \\nProtocol)\\n \\nare\\n \\ntwo\\n \\nof\\n \\nthe\\n \\nmost\\n \\nwidely\\n \\nused\\n \\ntransport-layer\\n \\nprotocols\\n \\ndefined\\n \\nin\\n \\nthe\\n \\nTCP/IP\\n \\nmodel.\\n \\nTCP  is  a  connection-oriented  protocol,  meaning  a  connection  must  be  established  before  data  can  be  \\nexchanged.\\n \\nIt\\n \\nensures\\n \\nreliable\\n \\nand\\n \\nordered\\n \\ndelivery\\n \\nthrough\\n \\nmechanisms\\n \\nlike\\n \\nacknowledgment\\n \\n(ACK),\\n \\nretransmission,\\n \\nflow\\n \\ncontrol,\\n \\nand\\n \\ncongestion\\n \\ncontrol.\\n \\nTCP\\n \\nbreaks\\n \\nlarge\\n \\nmessages\\n \\ninto\\n \\nsegments,\\n \\nassigns\\n \\nsequence\\n \\nnumbers,\\n \\nand\\n \\nuses\\n \\nACKs\\n \\nto\\n \\nconfirm\\n \\nreceipt.\\n \\nIf\\n \\na\\n \\nsegment\\n \\nis\\n \\nlost,\\n \\nTCP\\n \\nretransmits\\n \\nit\\n \\nautomatically.\\n \\nThis\\n \\nreliability\\n \\nmakes\\n \\nTCP\\n \\nideal\\n \\nfor\\n \\napplications\\n \\nlike\\n \\nweb\\n \\nbrowsing\\n \\n(HTTP/HTTPS),\\n \\nemail,\\n \\nand\\n \\nfile\\n \\ntransfers,\\n \\nwhere\\n \\naccuracy\\n \\nis\\n \\nmore\\n \\nimportant\\n \\nthan\\n \\nspeed.\\n \\nUDP ,  in  contrast,  is  a  connectionless  protocol.  It  sends  datagrams  without  establishing  a  connection  and  does  \\nnot\\n \\nguarantee\\n \\ndelivery,\\n \\nordering,\\n \\nor\\n \\nerror\\n \\ncorrection.\\n \\nSince\\n \\nUDP\\n \\neliminates\\n \\noverhead,\\n \\nit\\n \\nis\\n \\nextremely\\n \\nfast\\n \\nand\\n \\nsuitable\\n \\nfor\\n \\nreal-time\\n \\napplications\\n \\nlike\\n \\ngaming,\\n \\nlive\\n \\nvideo\\n \\nstreaming,\\n \\nand\\n \\nVoIP,\\n \\nwhere\\n \\nspeed\\n \\nand\\n \\nlow\\n \\nlatency\\n \\nare\\n \\nmore\\n \\nimportant\\n \\nthan\\n \\nperfect\\n \\naccuracy.\\n \\nFor\\n \\nexample,\\n \\nin\\n \\na\\n \\nvideo\\n \\ncall,\\n \\nlosing\\n \\na\\n \\nfew\\n \\npackets\\n \\nis\\n \\nacceptable\\n \\ncompared\\n \\nto\\n \\nwaiting\\n \\nfor\\n \\ndelayed\\n \\nretransmissions.\\n \\nReliable  data  transfer  depends  heavily  on  the  characteristics  of  these  protocols.  TCP  provides  reliability  using  \\nseveral\\n \\ntechniques:\\n \\n●  Three-Way  Handshake:  \\n \\nEnsures\\n \\nboth\\n \\nsender\\n \\nand\\n \\nreceiver\\n \\nare\\n \\nready\\n \\nfor\\n \\ncommunication\\n \\nbefore\\n \\ndata\\n \\ntransfer\\n \\nbegins.\\n \\n ●  Flow  Control  (Sliding  Window):  \\n \\nPrevents\\n \\nthe\\n \\nsender\\n \\nfrom\\n \\noverwhelming\\n \\nthe\\n \\nreceiver\\n \\nby\\n \\nadjusting\\n \\nthe\\n \\nsending\\n \\nrate.\\n \\n ●  Congestion  Control  (AIMD,  Slow  Start):  \\n \\nAdjusts\\n \\nsending\\n \\nrate\\n \\nbased\\n \\non\\n \\nnetwork\\n \\nload\\n \\nto\\n \\navoid\\n \\ncongestion\\n \\ncollapse.\\n \\n ●  Checksums:  \\n \\nDetects\\n \\nerrors\\n \\nin\\n \\ntransmitted\\n \\nsegments.\\n \\n \\nUDP,  though  unreliable  by  design,  can  still  achieve  reliability  when  necessary  through  application-level  \\nmechanisms,\\n \\nsuch\\n \\nas\\n \\nadded\\n \\nsequence\\n \\nnumbers\\n \\nor\\n \\nmanual\\n \\nacknowledgments.\\n \\nSome\\n \\nmodern\\n \\nprotocols\\n \\nlike\\n \\nQUIC\\n \\nuse\\n \\nUDP\\n \\nas\\n \\na\\n \\nbase\\n \\nbut\\n \\nadd\\n \\nreliability\\n \\nfeatures\\n \\nfor\\n \\nimproved\\n \\nperformance.\\n \\nUnderstanding  TCP  vs  UDP  helps  developers  choose  the  right  protocol  for  different  scenarios.  TCP  suits  \\ndata-sensitive\\n \\napplications,\\n \\nwhereas\\n \\nUDP\\n \\nis\\n \\nthe\\n \\nbetter\\n \\nchoice\\n \\nfor\\n \\nlatency-critical\\n \\ntasks.'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 0, 'page_label': '1', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='sustainability\\nReview\\nArtiﬁcial Intelligence and Machine Learning\\nApplications in Smart Production: Progress, Trends,\\nand Directions\\nRaﬀaele Cioﬃ 1, Marta Travaglioni 1, Giuseppina Piscitelli 1, Antonella Petrillo 1, *\\n and\\nFabio De Felice 2\\n1 Department of Engineering, Parthenope University, Isola C4, Centro Direzionale, 80143 Napoli NA, Italy;\\nraﬀaele.cioﬃ@uniparthenope.it (R.C.); marta.travaglioni@uniparthenope.it (M.T.);\\ngiuseppina.piscitelli@uniparthenope.it (G.P .)\\n2 Department of Civil and Mechanical Engineering, University of Cassino and Southern Lazio, Via G. Di\\nBiasio, 43, 03043 Cassino FR, Italy; defelice@unicas.it\\n* Correspondence: antonella.petrillo@uniparthenope.it\\nReceived: 1 December 2019; Accepted: 5 January 2020; Published: 8 January 2020\\n/gid00030/gid00035/gid00032/gid00030/gid00038/gid00001/gid00033/gid00042/gid00045/gid00001\\n/gid00048/gid00043/gid00031/gid00028/gid00047/gid00032/gid00046\\nAbstract: Adaptation and innovation are extremely important to the manufacturing industry.\\nThis development should lead to sustainable manufacturing using new technologies. To promote\\nsustainability, smart production requires global perspectives of smart production application\\ntechnology. In this regard, thanks to intensive research eﬀorts in the ﬁeld of artiﬁcial intelligence (AI),\\na number of AI-based techniques, such as machine learning, have already been established in the\\nindustry to achieve sustainable manufacturing. Thus, the aim of the present research was to analyze,\\nsystematically, the scientiﬁc literature relating to the application of artiﬁcial intelligence and machine\\nlearning (ML) in industry. In fact, with the introduction of the Industry 4.0, artiﬁcial intelligence and\\nmachine learning are considered the driving force of smart factory revolution. The purpose of this\\nreview was to classify the literature, including publication year, authors, scientiﬁc sector, country,\\ninstitution, and keywords. The analysis was done using the Web of Science and SCOPUS database.\\nFurthermore, UCINET and NVivo 12 software were used to complete them. A literature review on\\nML and AI empirical studies published in the last century was carried out to highlight the evolution\\nof the topic before and after Industry 4.0 introduction, from 1999 to now. Eighty-two articles were\\nreviewed and classiﬁed. A ﬁrst interesting result is the greater number of works published by the\\nUSA and the increasing interest after the birth of Industry 4.0.\\nKeywords: artiﬁcial intelligence; machine learning; systematic literature review; applications;\\nIndustry 4.0; smart production; sustainability\\n1. Introduction\\nSmart production systems require innovative solutions to increase the quality and sustainability\\nof manufacturing activities while reducing costs. In this context, artiﬁcial intelligence (AI)-driven\\ntechnologies, leveraged by I4.0 Key Enabling Technologies (e.g., Internet of Thing, advanced embedded\\nsystems, cloud computing, big data, cognitive systems, virtual and augmented reality), are ready to\\ngenerate new industrial paradigms [1].\\nIn this regard, it is interesting to remember that the father of artiﬁcial intelligence, John McCarthy [2],\\nin the 1990s, deﬁned artiﬁcial intelligence as “artiﬁcial intelligence is the science and engineering of\\nmaking intelligent machines, especially intelligent computer programs”. Generally, the term “AI” is\\nused when a machine simulates functions that humans associate with other human minds, such as\\nlearning and problem solving [3].\\nSustainability 2020, 12, 492; doi:10.3390/su12020492 www.mdpi.com /journal/sustainability'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 1, 'page_label': '2', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Sustainability 2020, 12, 492 2 of 26\\nOn a very broad account, the areas of artiﬁcial intelligence are classiﬁed into 16 categories [4–8].\\nThese are reasoning, programming, artiﬁcial life, belief revision, data mining, distributed AI, expert\\nsystems, genetic algorithms, systems, knowledge representation, machine learning, natural language\\nunderstanding, neural networks, theorem proving, constraint satisfaction, and theory of computation [9–\\n11].\\nIn the 21st century, AI has become an important area of research in all ﬁelds: Engineering, science,\\neducation, medicine, business, accounting, ﬁnance, marketing, economics, stock market, and law,\\namong others [12–18]. The range of AI has grown enormously since the intelligence of machines with\\nmachine learning capabilities has created profound impacts on business, governments, and society [19].\\nThey also inﬂuence the larger trends in global sustainability. Artiﬁcial intelligence can be useful to solve\\ncritical issue for sustainable manufacturing (e.g., optimization of energy resources, logistics, supply\\nchain management, waste management, etc.). In this context, in smart production, there is a trend to\\nincorporate AI into green manufacturing processes for stricter environmental policies [20]. In fact, as\\nsaid in March 2019 by Hendrik Fink, head of Sustainability Services at PricewaterhouseCoopers, “If we\\nproperly incorporate artiﬁcial intelligence, we can achieve a revolution with regard to sustainability.\\nAI will be the driving force of the fourth industrial revolution” [21].\\nThus, subﬁelds of AI, such as machine learning, natural language processing, image processing,\\nand data mining, have also become an important topic for today’s tech giants. The subject of AI\\ngenerates considerable interest in the scientiﬁc community, by virtue of the continuous evolution of\\nthe technologies available today.\\nThe development of ML as a branch of AI is now very fast. Its usage has spread to various\\nﬁelds, such as learning machines, which are currently used in smart manufacturing, medical science,\\npharmacology, agriculture, archeology, games, business, and so forth.\\nAccording to the above considerations, in this work, a systematic literature review of research\\nfrom 1999 to 2019 was performed on AI and the ML technique. Therefore, it is considered necessary to\\ncreate a classiﬁcation system that refers to the articles that jointly treat the two topics, in order to have\\ngreater variance and reﬂection. Furthermore, to gain a deeper understanding, the inﬂuence of other\\nvariables was explored, such as the thematic areas and the sectors in which the technologies are most\\ninﬂuential. The main contribution of this work is that it provides an overview of the research carried\\nout to date.\\nA number of impressive documentations of established research methods and philosophy have\\nbeen discussed for several years. Unfortunately, little comparison and integration across studies exists.\\nIn this article, a common understanding of AI and ML research and its variations was created.\\nThis paper is not attempting to provide an all-encompassing framework on the literature on AI\\nand ML research. Rather, it attempts to provide a starting point for integrating knowledge across\\nresearch in this domain and suggests paths for future research. It explores studies in certain novel\\ndisciplines: Environmental pollution, medicine, maintenance, manufacturing, etc.\\nFurther research is needed to extend the present boundary of knowledge in AI by integrating\\nprinciples and philosophies of some traditional disciplines into the existing AI frameworks [22–24].\\nThe target that this document would like to assume is not the trigger of a sudden proliferation of\\nan already consolidated sector, but it is hoped that this research could be an important intellectual tool\\nfor both the refocusing of the work and creating new intellectual opportunities. This paper presents\\nvaluable ideas and perspectives for undergoing research on AI and ML.\\nThe ﬁnal aim was to anticipate the transformation of the discipline in the future age. This would\\nbe a journey that may experience change in its course as new generations of scholars contribute to the\\ndialogue and to the action. As noted earlier, this work presents a review, hence it lays a foundation for\\nfuture inquiry. It not only oﬀers a basis for future comparisons but prompts a number of new questions\\nfor investigations as well. While topics that might be considered as results of this work are numerous,\\nsome are of particularly broad interest or impact.'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 2, 'page_label': '3', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Sustainability 2020, 12, 492 3 of 26\\nThe paper is organized as follows. Section 2 presents the proposed methodology and details the\\nresearch methodology adopted for the literature survey. Section 3 analyzes the main results of the\\nbibliometric analysis. Finally, in Section 4, the main contribution of the research is summarized.\\n2. Methodology\\nThe methodological approach used mixes bibliometric, content analysis, and social network\\ntechniques. In this study, a state-of-the-art research was conducted through the SCOPUS and Web\\nof Science databases. For the publication time span, the time from 1999 to 2019 was considered with\\nthe intent to understand how the level of attention towards the topic has changed before and after\\nthe introduction of Industry 4.0. The research methodology chosen for this study was a systematic\\nliterature review [25]. The main phases of the study were as follows:\\n1. Phase 1: Research and Classiﬁcation. The present phase was divided into three steps:\\n• Step 1: Identiﬁcation;\\n• Step 2: Screening; and\\n• Step 3: Inclusion.\\nIn phase 1, bibliometric data was collected (step 1). Then, a screening of the overall result was\\ncarried out to identify which documents can be taken into consideration, in line with the research areas\\ndeemed interesting and relevant (step 2). At the end of this step, the last step (step 3) aimed to select\\nthe documents to be analyzed in detail.\\n2. Phase 2: Analysis. Once phase 1 was completed, the next phase was phase 2, which was the\\nanalysis of the results. The approach used for the bibliometric analysis included:\\n• The use of indicators for the parameters studied; and\\n• SNA (social network analysis) for the keywords.\\nThe indicators chosen to perform the analysis were total papers (TPs), which is the total number\\nof publications, and total citations (TCs), which is the total number of citations.\\nSNA ﬁnds application in various social sciences, and has lately been employed in the study of\\nvarious phenomena, such as international trade, information dissemination, the study of institutions,\\nand the functioning of organizations. The analysis of the use of the term SNA in the scientiﬁc literature\\nhas undergone exponential growth in the use of this mode of computable representation of complex\\nand interdependent phenomena. For the purpose of the study, UCINET, NetDraw software was used,\\nwhich was expressly designed for the creation and graphic processing of networks, and was used to\\nrepresent the keywords in the network, and Excel for data input.\\nThe software UCINET, NetDraw returned a sociometric network that describes the relationships\\nbetween the classes, that is, data entered as input.\\nFurthermore, NVivo 12 software, the leading program for computer-assisted qualitative analysis\\n(CAQDAS), was used to analyze keywords of all documents. In this speciﬁc case, it was used to\\nidentify the possible links between the keywords of the various documents examined, developing\\nconceptual schemes from which to make interpretative hypotheses.\\n3. Phase 3: Discussion . At the end of the second phase, a third and ﬁnal one followed, where the\\nresults were discussed, and conclusions were drawn.\\nIn Figure 1, the main phases and steps followed for the analysis are shown.'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 3, 'page_label': '4', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Sustainability 2020, 12, 492 4 of 26\\nSustainability 2020, 12, x FOR PEER REVIEW 4 of 24 \\n \\nFigure 1. Process flow chart. \\n3. Results of the Bibliometric Analysis \\n3.1. Phase 1: Research and Classification \\nThe first phase consisted of the search for documents, which included the activities of collecting \\nthe material belonging to the academic universe. This first phase was divided into three steps as \\nfollows. \\n3.1.1. Identification (Step 1) \\nFor a comprehensive survey of the phenomenon, an investigation on the Scopus (SCP) and Web \\nof Science (WoS) databases was ca rried out using Boolean operators. We began by making a search \\nquery on the Scopus and WoS databases with the general keywords “artificial intelligence” AND \\n“machine learning” AND “application”, as shown in Table 1. \\nIn order to maintain the consistency of the re sults, the same keywords were used in both \\ndatabases and a time horizon of 20 years was chosen, from 1999 to 2019. \\nThe choice of keywords for performing the survey was based on the awareness that AI and ML \\ncan be an important tool in the effort to adopt responsible business practices in the context of smart \\nproduction. In this regard, it is worthy to note that with the increasingly urgent discussions of climate \\nchange, it seemed appropriate to focus our research on the topic of sustainability. Thus, the selection \\nof papers also considered applications on sustainability. \\nFigure 1. Process ﬂow chart.\\n3. Results of the Bibliometric Analysis\\n3.1. Phase 1: Research and Classiﬁcation\\nThe ﬁrst phase consisted of the search for documents, which included the activities of collecting the\\nmaterial belonging to the academic universe. This ﬁrst phase was divided into three steps as follows.\\n3.1.1. Identiﬁcation (Step 1)\\nFor a comprehensive survey of the phenomenon, an investigation on the Scopus (SCP) and Web of\\nScience (WoS) databases was carried out using Boolean operators. We began by making a search query\\non the Scopus and WoS databases with the general keywords “artiﬁcial intelligence” AND “machine\\nlearning” AND “application”, as shown in Table 1.\\nIn order to maintain the consistency of the results, the same keywords were used in both databases\\nand a time horizon of 20 years was chosen, from 1999 to 2019.\\nThe choice of keywords for performing the survey was based on the awareness that AI and ML\\ncan be an important tool in the eﬀort to adopt responsible business practices in the context of smart\\nproduction. In this regard, it is worthy to note that with the increasingly urgent discussions of climate\\nchange, it seemed appropriate to focus our research on the topic of sustainability. Thus, the selection of\\npapers also considered applications on sustainability.'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 4, 'page_label': '5', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Sustainability 2020, 12, 492 5 of 26\\nTable 1. Keywords and time period.\\nKeywords Time Period\\nArtiﬁcial Intelligence\\n1999–2019Machine Learning\\nApplication\\nThe search returned in total 13,512 documents.\\nThe results extracted by Scopus are numerically superior to Web of Science (WoS): 12,445 for the\\nﬁrst and only 1081 for the second one (Table 2).\\nTable 2. Total results of research on Scopus and WoS.\\nResearch Carried out on 2019\\nSource of research Scopus Web of Science\\nResults 12,445 1081\\nThe result is not entirely unexpected, and the reason is to be found in the fact that Scopus, being\\nan Elsevier product, collects data from all the other databases, in particular Science Direct and those\\nqueried by the Scirus search engine, while Web of Science (WoS) collects fewer documents.\\nFrom the documents extracted in Scopus, it was found that most of them are conference papers\\n(57.28%) and, subsequently, articles (33.85%).\\nOn the contrary, the research on Web of Science (WoS) underlines that most of the documents are\\narticles (46.12%) and, subsequently, proceedings papers (42.86%).\\nAll the document types are ﬁlled in Table 3.\\nTable 3. Distribution of document types in Scopus and Web of Science.\\nWeb of Science Scopus\\nDocument Types Records Contribute % Document Types Records Contribute %\\nArticle 481 46.12 Conference Paper 7128 57.28\\nProceedings paper 447 42.86 Article 4212 33.85\\nReview 133 12.76 Review 412 3.31\\nEditorial material 16 1.53 Article in Press 194 1.56\\nMeeting abstract 2 0.19 Book Chapter 177 1.42\\nBook chapter 1 0.1 Conference Review 177 1.42\\nRetracted publication 1 0.1 Book 90 0.72\\n- - - Editorial 27 0.22\\n- - - Note 10 0.08\\n- - - Letter 9 0.07\\n- - - Short Survey 9 0.07\\nAI began working in the 1940s and researchers showed strong expectations until the 1970s when\\nthey began to encounter serious diﬃculties and investments were greatly reduced.\\nSince then, a long period began, known as the “AI winter” [26]: Despite some great successes,\\nsuch as IBM’s Deep Blue system, which in the late 1990s defeated the then chess world champion\\nGarri Kasparov, the study of solutions for AI has only come back for a few years. The push for a new\\ntechnological development has been given by the I4.0, which considered AI as one of the primary key\\nenabling technologies (KETs).\\nFrom this period onwards, the literature has been enriched with documents, as shown in Figure 2.\\nGrowth is apparent after 2011 when new technologies began to be implemented more frequently.\\nIn fact, the Industry 4.0 term ﬁrst appeared at Hannover Messe in 2011 when Professor Wolfgang'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 5, 'page_label': '6', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Sustainability 2020, 12, 492 6 of 26\\nWahlster, Director and CEO of the German Research Center for Artiﬁcial Intelligence, addressed the\\nopening ceremony audience.\\nSustainability 2020, 12, x FOR PEER REVIEW 6 of 24 \\n \\nFigure 2. Research growth on Scopus and Web of Science. \\nSubsequently, the increase in the adoption of th ese ones has led researchers to keep pace with \\nthe growth of I4.0 [27]. \\n3.1.2. Screening (Step 2) \\nTrying to give an overview of the topics and areas interface, in the screening phase, an analysis \\nof documents characterized by free access was chosen, excluding those that have restrictions, and to \\nrestrict the field to the thematic areas of scientific interest. \\nWith this in mind, the number of open access items has been drasticall y reduced (1288 results \\nfor Scopus and 149 for WoS) and, also applying the filter related to the thematic areas (Table 4), it \\ndetermined a further reduction: 947 for Scopus and 60 for WoS. \\nTable 4. Subject area filter on Scopus and WoS. \\nSubject Area \\nScopus Web of Science (WoS) \\nComputer \\nScience \\nChemical \\nEngineering \\nComputer Science \\nInformation Systems \\nComputer Science Artificial \\nIntelligence \\nAutomation Control \\nSystems \\nEngineering Energy Materials Science \\nMultidisciplinary Environmental Sciences Environmental \\nStudies \\nMaterials \\nScience Decision Science Engineering Electrical \\nElectronic \\nComputer Science \\nHardware Architecture \\nOperations Research \\nManagement Science \\nEnvironmental \\nScience \\nBusiness \\nManagement \\nand accounting \\nTelecommunications Industrial Relations Labor Robotics \\n  Engineering Environmental Engineering Manufacturing Thermodynamics \\n  Engineering Industrial Computer Science Theory \\nMethods Energy Fuels \\n  Engineering Civil Engineering Mechanical Computer Science \\nCybernetics \\n  Computer Science Software \\nEngineering Multidisciplinary Sciences  \\nNote how the number of filters applied is different. The databases, in fact, offer the same search \\noptions, but, in the specific case of the thematic  areas, the latter are more numerous and structured \\non Web of Science (WoS) compared to Scopus. \\nFigure 2. Research growth on Scopus and Web of Science.\\nIn fact, this research indicates that over the time period considered (1999–2019), the number of\\npublished articles remains almost constant until 2013, from which it undergoes an increase.\\nSubsequently, the increase in the adoption of these ones has led researchers to keep pace with the\\ngrowth of I4.0 [27].\\n3.1.2. Screening (Step 2)\\nTrying to give an overview of the topics and areas interface, in the screening phase, an analysis\\nof documents characterized by free access was chosen, excluding those that have restrictions, and to\\nrestrict the ﬁeld to the thematic areas of scientiﬁc interest.\\nWith this in mind, the number of open access items has been drastically reduced (1288 results\\nfor Scopus and 149 for WoS) and, also applying the ﬁlter related to the thematic areas (Table 4), it\\ndetermined a further reduction: 947 for Scopus and 60 for WoS.\\nTable 4. Subject area ﬁlter on Scopus and WoS.\\nSubject Area\\nScopus Web of Science (WoS)\\nComputer Science Chemical\\nEngineering\\nComputer Science\\nInformation Systems\\nComputer Science\\nArtiﬁcial Intelligence\\nAutomation Control\\nSystems\\nEngineering Energy Materials Science\\nMultidisciplinary\\nEnvironmental\\nSciences Environmental Studies\\nMaterials Science Decision Science Engineering Electrical\\nElectronic\\nComputer Science\\nHardware Architecture\\nOperations Research\\nManagement Science\\nEnvironmental\\nScience\\nBusiness\\nManagement and\\naccounting\\nTelecommunications Industrial Relations\\nLabor Robotics\\nEngineering\\nEnvironmental\\nEngineering\\nManufacturing Thermodynamics\\nEngineering Industrial Computer Science\\nTheory Methods Energy Fuels\\nEngineering Civil Engineering\\nMechanical\\nComputer Science\\nCybernetics\\nComputer Science\\nSoftware Engineering\\nMultidisciplinary\\nSciences'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 6, 'page_label': '7', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Sustainability 2020, 12, 492 7 of 26\\nNote how the number of ﬁlters applied is diﬀerent. The databases, in fact, oﬀer the same search\\noptions, but, in the speciﬁc case of the thematic areas, the latter are more numerous and structured on\\nWeb of Science (WoS) compared to Scopus.\\n3.1.3. Inclusion (Step 3)\\nAt the end of the screening process, the inclusion step was started, which consisted in the selection\\nof documents, which was extracted from the last passage, destined to be included in the sample on\\nwhich bibliometric analysis was performed. In this review step, for the purposes of eligibility, we\\nexamined the complete text of each document independently. For each article, we examined whether\\nthere was interest from the academic world, and if it contained case studies or real applications,\\nproposals for new AI and ML algorithms, or possible future scenarios.\\nTherefore, the ﬁnal sample to be analyzed consisted of 60 documents for Scopus and 22 for WoS.\\n3.2. Phase 2: Analysis\\nThis section presents and discusses the ﬁndings of this review.\\nFirst, an overview of the selected studies is presented. Second, the review ﬁndings according to\\nthe research criteria, one by one in the separate subsections, are reported.\\n3.2.1. Top Highly Inﬂuential Analysis\\nThis section lists the most highly cited documents in WoS and Scopus. The list is structured by\\nresearch source, date, title, authors, source title, and top citation (TP) in WoS or Scopus, according\\nto the research source. The whole list is available in the Appendix A. Looking into the Appendix A,\\nit is possible underline that the document by Larrañaga, Calvo, Santana et al. in 2006 [ 28] has the\\nhighest citation count of 298. This article reviews machine learning methods for bioinformatics and\\nit presents modelling methods. Moreover, the document year is 2006, so before I4.0 was introduced.\\nTherefore, having more years than today has an advantage in terms of diﬀusion. This means that it is\\none of the most inﬂuential documents in the academic world, as it proposes some of the most useful\\ntechniques for modelling, giving the document the opportunity to become a pioneer in the computer\\nscience research area.\\nObviously, all documents before I4.0, in general, have more citations than the most recent\\ndocuments. However, it is signiﬁcant to note that even recent documents have a very high number\\nof citations compared to the year of publication. This denotes the interest in the topic from the\\nscientiﬁc community.\\nThe citation analysis revealed that the ﬁrst article that we can identify among the most cited in\\nthe I4.0 period dates to 2016. The work, published by Krawczyk [29], proposes application models to\\nfurther develop the ﬁeld of unbalanced learning, to focus on computationally eﬀective, adaptive, and\\nreal-time methods, and provides a discussion and suggestions on the lines of future research in the\\napplication subject of the study. It received 119 citations. Moreover, an article published by Wuest,\\nWeimer, Irgens et al. [30] received much attention among the scientiﬁc community. It contributes by\\npresenting an overview of the available machine learning techniques.\\nFinally, the citation analysis pointed out that the average number of citations of all documents is\\n16.58. This value is expected to increase rapidly considering the interest in the issues of ML and AI.\\n3.2.2. Publications by Years\\nConsistent with what is deﬁned in Section 3.1.1., the study shows that the number of items included\\nin the analysis is deﬁnitely low for the entire period before I4.0 and then suddenly increases, starting\\nin 2012. The data shown in Figure 3 also show two holes in the 2001–2008 and 2008–2011 intervals.\\nThis means that the technological applications were limited before it became an enabling technology of\\nI4.0 in all respects, only to have a peak of technological implementation, as was foreseeable.'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 7, 'page_label': '8', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Sustainability 2020, 12, 492 8 of 26\\nSustainability 2020, 12, x FOR PEER REVIEW 8 of 24 \\n \\nFigure 3. Years of publications. \\nWith reference to 2019, the figure refers to the fi rst months of the year, so it is plausible that \\nduring the year, there will be a further increase in  the documents in the literature. Furthermore, an \\nincrease is expected in the coming years, in parallel with the growth of I4.0 \\n3.2.3. Most Collaborative Authors \\nThe analysis highlighted that most of publications have more than one author. From this point \\nof view, it is possible to identify the number of authors for each document. As shown in Figure 4, \\nmost of the manuscripts were produced by groups ranging from two to five authors. The indicators \\nchosen to perform the analysis were total papers (TPs), which is the total number of publications. \\n \\nFigure 4. Collaborative groups. \\nFigure 3. Years of publications.\\nWith reference to 2019, the ﬁgure refers to the ﬁrst months of the year, so it is plausible that during\\nthe year, there will be a further increase in the documents in the literature. Furthermore, an increase is\\nexpected in the coming years, in parallel with the growth of I4.0\\n3.2.3. Most Collaborative Authors\\nThe analysis highlighted that most of publications have more than one author. From this point of\\nview, it is possible to identify the number of authors for each document. As shown in Figure 4, most of\\nthe manuscripts were produced by groups ranging from two to ﬁve authors. The indicators chosen to\\nperform the analysis were total papers (TPs), which is the total number of publications.\\nSustainability 2020, 12, x FOR PEER REVIEW 8 of 24 \\n \\nFigure 3. Years of publications. \\nWith reference to 2019, the figure refers to the fi rst months of the year, so it is plausible that \\nduring the year, there will be a further increase in  the documents in the literature. Furthermore, an \\nincrease is expected in the coming years, in parallel with the growth of I4.0 \\n3.2.3. Most Collaborative Authors \\nThe analysis highlighted that most of publications have more than one author. From this point \\nof view, it is possible to identify the number of authors for each document. As shown in Figure 4, \\nmost of the manuscripts were produced by groups ranging from two to five authors. The indicators \\nchosen to perform the analysis were total papers (TPs), which is the total number of publications. \\n \\nFigure 4. Collaborative groups. \\nFigure 4. Collaborative groups.'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 8, 'page_label': '9', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Sustainability 2020, 12, 492 9 of 26\\n3.2.4. Research Areas Analysis\\nThe total research area analysis collected from the 82 papers was 164 because each paper can be\\nconsidered as more than one research area analysis. Given the small number of documents identiﬁed\\nin the period before I4.0, the ranking refers mostly to the current industrial revolution. Also, in this\\ncase, the result is consistent with the introduction of paradigm 4.0, which has intensiﬁed research and\\nthe adoption of technology.\\nThe ﬁrst thematic areas and disciplines that are at the top of the ranking are computer science,\\nengineering and biochemistry, genetics, and molecular Biology, respectively, with 29%, 23%, and 6% of\\npublications. Furthermore, the other disciplines identiﬁed for which applicative ﬁndings are found are\\nconsidered transversal to the ﬁrst three disciplines and this is a consequence of I4.0. In terms of the\\npercentage contribution, the ﬁrst three areas cover about 60% of the papers considered.\\nConsidering the top 20 research areas, given the frequency of the research areas’ distribution,\\nFigure 5 shows a higher level of concentration in the disciplines indicated above.\\nSustainability 2020, 12, x FOR PEER REVIEW 9 of 24 \\n3.2.4. Research Areas Analysis \\nThe total research area analysis collected from the 82 papers was 164 because each paper can be \\nconsidered as more than one research area analysis. Given the small number of documents identified \\nin the period before I4.0, the ranking refers mostly to the current industrial revolution. Also, in this \\ncase, the result is consistent with the introduction of paradigm 4.0, which has intensified research and \\nthe adoption of technology. \\nThe first thematic areas and disciplines that are at the top of the ranking are computer science, \\nengineering and biochemistry, genetics, and molecular Biology, respectively, with 29%, 23%, and 6% \\nof publications. Furthermore, the other disciplines identified for which applicative findings are found \\nare considered transversal to the first three discipli nes and this is a consequence of I4.0. In terms of \\nthe percentage contribution, the first three areas cover about 60% of the papers considered. \\nConsidering the top 20 research areas, given the frequency of the research areas’ distribution, \\nFigure 5 shows a higher level of concentration in the disciplines indicated above. \\nIn fact, in terms of the percentage contribution, the first five areas cover about 70% of the papers \\nconsidered. Regardless, by only counting research areas found once, there is a total of 27. \\nThis means two things: \\n• The large number of fields in which this kind of research is involved; and \\n• Most papers have a transversal approach, that is, the object of each research crosses more \\nthan one field of application, thus involving more research areas. \\nThis confirms the wide interest in these subjects from several fields. \\n \\nFigure 5. Top 20 research areas contributions. \\n3.2.5. Top Source Journals Analysis \\nIn this section, the top 20 sources or journals that were published most frequently were extracted. \\nA journal is a time-bound publication with th e objective of promoting and monitoring the \\nprogress of the discipline it represents. \\nIn this specific case, the total source journals detected from the documents is 74, but, considering \\nthe top 20, given the frequency of the source journals’ distribution, only the first 13 sources have more \\nthan one paper published, with a total percentage contribution of 43% of the total. \\nAfter analyzing the sources separately, the results obtained in the two databases were found to \\nnot be the same. In WoS, the top source journal was IEEE Access with two publications while in \\nScopus, the top source journals are Procedia Computer Science, Matec Web of Conferences, and Machine \\nLearning with four publications, which contribute 5% of the total. \\nFigure 5. Top 20 research areas contributions.\\nIn fact, in terms of the percentage contribution, the ﬁrst ﬁve areas cover about 70% of the papers\\nconsidered. Regardless, by only counting research areas found once, there is a total of 27.\\nThis means two things:\\n• The large number of ﬁelds in which this kind of research is involved; and\\n• Most papers have a transversal approach, that is, the object of each research crosses more than\\none ﬁeld of application, thus involving more research areas.\\nThis conﬁrms the wide interest in these subjects from several ﬁelds.\\n3.2.5. Top Source Journals Analysis\\nIn this section, the top 20 sources or journals that were published most frequently were extracted.\\nA journal is a time-bound publication with the objective of promoting and monitoring the progress\\nof the discipline it represents.\\nIn this speciﬁc case, the total source journals detected from the documents is 74, but, considering\\nthe top 20, given the frequency of the source journals’ distribution, only the ﬁrst 13 sources have more\\nthan one paper published, with a total percentage contribution of 43% of the total.\\nAfter analyzing the sources separately, the results obtained in the two databases were found to\\nnot be the same. In WoS, the top source journal was IEEE Access with two publications while in Scopus,'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 9, 'page_label': '10', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Sustainability 2020, 12, 492 10 of 26\\nthe top source journals are Procedia Computer Science, Matec Web of Conferences, and Machine Learning\\nwith four publications, which contribute 5% of the total.\\nAggregating the data collected from the two databases, the ranking moves to that obtained by\\nScopus, making sure that IEEE Access is no longer ﬁrst in the standings, but only eighth, and that the\\nformer are precisely those of Scopus: Procedia Computer Science, Matec Web Of Conferences, and Machine\\nLearning, with the same number of publications. Next, the 10 source journals have a 3% publication\\ncontribution while the rest have a one-to-one relationship (1%) with the corresponding source journal.\\nThe low level of concentration of the sources suggests that there is a great deal of interest in\\nthese topics from several scientiﬁc journals. As a matter of fact, it is foreseeable that specialized sector\\nsources (AI Magazine and Machine Learning) are among the ﬁrst 13; however, it is interesting to note\\nthat other sources are involved, such as Sustainability Switzerland or BMC Bioinformatics and Nuclear\\nEngineering and Design.\\nFigure 6 shows the top 20 source journals contributions.\\nSustainability 2020, 12, x FOR PEER REVIEW 10 of 24 \\nAggregating the data collected from the two databases, the ranking moves to that obtained by \\nScopus, making sure that IEEE Access is no longer first in the standings, but only eighth, and that the \\nformer are precisely those of Scopus: Procedia Computer Science, Matec Web Of Conferences, and Machine \\nLearning, with the same number of publications. Next, the 10 source journals have a 3% publication \\ncontribution while the rest have a one-to-one re lationship (1%) with the corresponding source \\njournal. \\nThe low level of concentration of the sources suggests that there is a great deal of interest in these \\ntopics from several scientific journals. As a matter of fact, it is foreseeable that specialized sector \\nsources (AI Magazine and Machine Learning) are among the first 13; however,  it is interesting to note \\nthat other sources are involved, such as Sustainability Switzerland or BMC Bioinformatics and Nuclear \\nEngineering and Design. \\nFigure 6 shows the top 20 source journals contributions. \\n \\nFigure 6. Top 20 source journals contributions. \\n3.2.6. Country Analysis \\nThe results that emerged through research on the two databases are consistent with each other. \\nIn both cases, in fact, the countries that give the greatest contribution to the research are China and \\nthe United States (Figure 8). The result is obvious since in China and the United States, more than 1.3 \\nbillion and 0.3 millions of people live, respective ly, and so there are more researchers than in the \\nsingle European nations. Focusing on Europe, Germany published more papers than any other \\nE u r o p e a n  c o u n t r y .  T h i s  i s  n o t  a  r a n d o m  r e s u l t :  I 4 . 0  w a s  b o r n  i n  G e r m a n y ,  s o  t h i s  o u t c o m e  w a s  \\nexpected. However, the following observation cannot be ignored from this data: The USA and China \\ncarry the first two places in the list while it is no t the same for European countries. Europe, despite \\nits talents and resources, has lost ground. Presenting its report on artificial intelligence, the French \\ndeputy and mathematician Cédric Villani declared that, “Europe must be able to compete with China \\nand the United States while protecting its citizens and pointing the way to go on ethical issues”. If \\nwe are not careful, the 21st century rules will not be defined in Brussels, but in Shanghai. Artificial \\nintelligence is also a land marked by intense geopolitical rivalry that could redefine global power \\nrelations. \\n  \\nFigure 6. Top 20 source journals contributions.\\n3.2.6. Country Analysis\\nThe results that emerged through research on the two databases are consistent with each other.\\nIn both cases, in fact, the countries that give the greatest contribution to the research are China and\\nthe United States (Figure 8). The result is obvious since in China and the United States, more than\\n1.3 billion and 0.3 millions of people live, respectively, and so there are more researchers than in\\nthe single European nations. Focusing on Europe, Germany published more papers than any other\\nEuropean country. This is not a random result: I4.0 was born in Germany, so this outcome was expected.\\nHowever, the following observation cannot be ignored from this data: The USA and China carry the\\nﬁrst two places in the list while it is not the same for European countries. Europe, despite its talents\\nand resources, has lost ground. Presenting its report on artiﬁcial intelligence, the French deputy and\\nmathematician Cédric Villani declared that, “Europe must be able to compete with China and the\\nUnited States while protecting its citizens and pointing the way to go on ethical issues”. If we are not\\ncareful, the 21st century rules will not be deﬁned in Brussels, but in Shanghai. Artiﬁcial intelligence is\\nalso a land marked by intense geopolitical rivalry that could redeﬁne global power relations.\\nEven so, regarding Europe, it is worthy to also note that since 2017, France, Germany, and Italy\\nhave intensiﬁed their trilateral cooperation to promote digitizing the manufacturing industry. In this'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 10, 'page_label': '11', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Sustainability 2020, 12, 492 11 of 26\\nregard, in the near future, we expect a signiﬁcant evolution of smart production initiatives and therefore\\nan increase in scientiﬁc research.\\nFigure 7 shows the country contribution distribution.\\nSustainability 2020, 12, x FOR PEER REVIEW 11 of 24 \\nEven so, regarding Europe, it is worthy to also note that since 2017, France, Germany, and Italy \\nhave intensified their trilateral cooperation to promote digitizing the manufacturing industry. In this \\nregard, in the near future, we expect a significant evolution of smart production initiatives and \\ntherefore an increase in scientific research. \\nFigure 7 shows the country contribution distribution. \\n \\nFigure 7. Top 20 countries contributions. \\n3.2.7. Affiliation Analysis \\nThe total number of affiliation detected from the 82 papers is 153. Also, in this case, considering \\nthe top 20, the frequency of the affiliation distribu tion shows that most papers have a one-to-one \\nrelationship with the corresponding affiliation. Only the first four affiliations have three papers (2% \\nof the contribution) and the second four have two papers (1.3% of the contribution). This result gives \\nus information about the wide interest on this subject from several universities and research centers \\nall over the world. Then, the affiliation analysis confirms the result of the country analysis (Figure 8). \\nIn fact, if we try to sum the first eight affiliations by their own country, the outcome is: \\n• Nine papers from China; \\n• Six papers from Germany; and \\n• Five papers from the USA. \\nIn September 2018, the most important event on artificial intelligence was held in Shanghai. \\nChina is very determined to focus on future technologies. \\nFor some months, China has become the world’s leading power in terms of scientific \\npublications. Late in the 20th century technologi es, China chose to do what the English-speaking \\npeople call a “frog jump” and focus on 21st century technologies. \\nChina, with its 800 million Internet users and without any privacy protection policy, has access \\nto more personal data than the United States and Europe. \\nFigure 7. Top 20 countries contributions.\\n3.2.7. Aﬃliation Analysis\\nThe total number of aﬃliation detected from the 82 papers is 153. Also, in this case, considering\\nthe top 20, the frequency of the a ﬃliation distribution shows that most papers have a one-to-one\\nrelationship with the corresponding aﬃliation. Only the ﬁrst four a ﬃliations have three papers (2% of\\nthe contribution) and the second four have two papers (1.3% of the contribution). This result gives us\\ninformation about the wide interest on this subject from several universities and research centers all\\nover the world. Then, the aﬃliation analysis conﬁrms the result of the country analysis (Figure 8). In\\nfact, if we try to sum the ﬁrst eight aﬃliations by their own country, the outcome is:\\n• Nine papers from China;\\n• Six papers from Germany; and\\n• Five papers from the USA.\\nIn September 2018, the most important event on artiﬁcial intelligence was held in Shanghai. China\\nis very determined to focus on future technologies.\\nFor some months, China has become the world’s leading power in terms of scientiﬁc publications.\\nLate in the 20th century technologies, China chose to do what the English-speaking people call a “frog\\njump” and focus on 21st century technologies.\\nChina, with its 800 million Internet users and without any privacy protection policy, has access to\\nmore personal data than the United States and Europe.'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 11, 'page_label': '12', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Sustainability 2020, 12, 492 12 of 26\\nSustainability 2020, 12, x FOR PEER REVIEW 12 of 24 \\n \\nFigure 8. Top 20 institute affiliations contributions. \\n3.2.8. Top Keywords Analysis \\nThrough NVivo 12, the top 20 keywords were extracted directly, which are those that always \\nappear in association with each document. \\nStarting from this classification, the graphic representation, a word cloud shape, of the keywords \\n(Figure 9) was extracted. It can be noted that the most used term is precisely “machine”, “learning”, \\nand “intelligence”, which the software represents with greater characters than all the other terms. \\n \\nFigure 9. Top 20 keywords cloud contribution by NVivo 12. \\nThe font size describes how much the keyword is indexed. Another mode of representation is \\nthe tree words (Figure 10). Also, in this case, th e most indexed words are those represented in the \\nlarger boxes. \\nFigure 8. Top 20 institute aﬃliations contributions.\\n3.2.8. Top Keywords Analysis\\nThrough NVivo 12, the top 20 keywords were extracted directly, which are those that always\\nappear in association with each document.\\nStarting from this classiﬁcation, the graphic representation, a word cloud shape, of the keywords\\n(Figure 9) was extracted. It can be noted that the most used term is precisely “machine”, “learning”,\\nand “intelligence”, which the software represents with greater characters than all the other terms.\\nSustainability 2020, 12, x FOR PEER REVIEW 12 of 24 \\n \\nFigure 8. Top 20 institute affiliations contributions. \\n3.2.8. Top Keywords Analysis \\nThrough NVivo 12, the top 20 keywords were extracted directly, which are those that always \\nappear in association with each document. \\nStarting from this classification, the graphic representation, a word cloud shape, of the keywords \\n(Figure 9) was extracted. It can be noted that the most used term is precisely “machine”, “learning”, \\nand “intelligence”, which the software represents with greater characters than all the other terms. \\n \\nFigure 9. Top 20 keywords cloud contribution by NVivo 12. \\nThe font size describes how much the keyword is indexed. Another mode of representation is \\nthe tree words (Figure 10). Also, in this case, th e most indexed words are those represented in the \\nlarger boxes. \\nFigure 9. Top 20 keywords cloud contribution by NVivo 12.\\nThe font size describes how much the keyword is indexed. Another mode of representation is\\nthe tree words (Figure 10). Also, in this case, the most indexed words are those represented in the\\nlarger boxes.'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 12, 'page_label': '13', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Sustainability 2020, 12, 492 13 of 26\\nSustainability 2020, 12, x FOR PEER REVIEW 13 of 24 \\n \\nFigure 10. Top 20 keywords tree contribution by Nvivo 12. \\nAs expected, the most indexed words are obviousl y “learning”, “machine”, and “intelligence”, \\nwith high numbers. It is logical that among the first results, words that recall the technology itself \\nwere obtained, but it is interesting to note that words referring to other fields of AI applications are \\nalso indexed. The reason is to be found in the fact that AI and ML are technologies that cross all the \\nsectors involved in I4.0 and that, therefore, do not remain circumscribed. \\nSpecifically, words, such as “data”, “neural”, “decision”, and “management”, are very or \\naverage indexed, demonstrating the fact that AI also extends to many other sectors. \\nAnother tool for the analysis for keywords is  the UCINET software, through which social \\nnetworks analysis is carried out. \\nSocial network analysis (SNA), which is also often called social network theory, is a modern \\ntechnology of social relations. \\nSNA finds application in various social sciences , and has recently been used in the study of \\nvarious phenomena, such as international trade, information dissemination, the study of institutions, \\nand the functioning of organizations. The analysis  of the use of the term SNA in the scientific \\nliterature shows that in the last five years, there has been exponential growth of the use of this mode \\nof computable representation of complex and interdependent phenomena. The software returns a \\ngraph representing a socio-metric network (Figur e 11), which draws the relationships that exist \\nwithin the class. Each relationship is represented by an oriented arrow. \\nFigure 10. Top 20 keywords tree contribution by Nvivo 12.\\nAs expected, the most indexed words are obviously “learning”, “machine”, and “intelligence”,\\nwith high numbers. It is logical that among the ﬁrst results, words that recall the technology itself were\\nobtained, but it is interesting to note that words referring to other ﬁelds of AI applications are also\\nindexed. The reason is to be found in the fact that AI and ML are technologies that cross all the sectors\\ninvolved in I4.0 and that, therefore, do not remain circumscribed.\\nSpeciﬁcally, words, such as “data”, “neural”, “decision”, and “management”, are very or average\\nindexed, demonstrating the fact that AI also extends to many other sectors.\\nAnother tool for the analysis for keywords is the UCINET software, through which social networks\\nanalysis is carried out.\\nSocial network analysis (SNA), which is also often called social network theory, is a modern\\ntechnology of social relations.\\nSNA ﬁnds application in various social sciences, and has recently been used in the study of\\nvarious phenomena, such as international trade, information dissemination, the study of institutions,\\nand the functioning of organizations. The analysis of the use of the term SNA in the scientiﬁc\\nliterature shows that in the last ﬁve years, there has been exponential growth of the use of this mode of\\ncomputable representation of complex and interdependent phenomena. The software returns a graph\\nrepresenting a socio-metric network (Figure 11), which draws the relationships that exist within the\\nclass. Each relationship is represented by an oriented arrow.'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 13, 'page_label': '14', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Sustainability 2020, 12, 492 14 of 26\\nSustainability 2020, 12, x FOR PEER REVIEW 14 of 24 \\n \\nFigure 11. Keywords Network by UCINET Software. \\nIn Figure 11, nodes and leaves can be identified. The nodes are represented by red circles and \\nare correspond to the most common keywords, where the words “machine”, “learning”, “artificial”, \\nand “intelligence” have been united to form the key words “machine le arning” and “artificial \\nintelligence”. \\nThe leaves, on the other hand, are represented by blue squares and correspond to the articles. \\nTo facilitate reading, the document titles were not inserted, but the (Identification) ID count for each \\nof them is shown in the Appendix A. \\nThe first thing that can be noticed is the isolatio n of many leaves that are not connected to the \\nnodes. This means that the corresponding documents are not described by the keywords represented \\nby the nodes. Really, they are characterized by keywords that have a frequency of the order of units. \\nAnother thing that easily jumps to the eye is a density that is larger around the keywords \\n“machine learning”, “decision”, “data”, “algorithm”, “system”, “artificial intelligence”, “method”, \\nand “optimization”. This density is reflected in the cloud and the box chart produced by NVivo 12. \\nTherefore, we can say that those are the words th at most often appear in the documents analyzed, \\nemphasizing, once again, that they include terms th at do not just refer to the technology object of \\nstudy but also to other fields of application. \\n3.3. Phase 3: Discussion \\n3.3.1. Benefits of Artificial Intelligence and Machine Learning in Industrial Contexts \\nFrom the analysis of the research carried out, th e first information that emerged is that there is \\na growing importance of innovation and digitalization in products, services, and processes. \\nConsequently, it means that the adoption of advanced manufacturing technologies, such AI and ML, \\nis an emerging issue. In other words, AI/ML algo rithms represent an opportunity to handle high \\ndimensional problems and data. The interest in the subject is extended to all scientific sectors, but \\nwith a focus on computer science and engineering. \\nThe most significant benefits of using AI and ML in industrial sectors include: 1) Greater \\ninnovation, 2) process optimization, 3) resources optimization, and 4) improved quality. \\nAfter all, AI with ML is one of the most impo rtant technologies today and is transforming the \\neconomy and society, as demonstrated by the over 340,000 patent applications filed since the 1950s. \\n  \\nFigure 11. Keywords Network by UCINET Software.\\nIn Figure 11, nodes and leaves can be identiﬁed. The nodes are represented by red circles and are\\ncorrespond to the most common keywords, where the words “machine”, “learning”, “artiﬁcial”, and\\n“intelligence” have been united to form the key words “machine learning” and “artiﬁcial intelligence”.\\nThe leaves, on the other hand, are represented by blue squares and correspond to the articles. To\\nfacilitate reading, the document titles were not inserted, but the (Identiﬁcation) ID count for each of\\nthem is shown in the Appendix A.\\nThe ﬁrst thing that can be noticed is the isolation of many leaves that are not connected to the\\nnodes. This means that the corresponding documents are not described by the keywords represented\\nby the nodes. Really, they are characterized by keywords that have a frequency of the order of units.\\nAnother thing that easily jumps to the eye is a density that is larger around the keywords\\n“machine learning”, “decision”, “data”, “algorithm”, “system”, “artiﬁcial intelligence”, “method”,\\nand “optimization”. This density is reﬂected in the cloud and the box chart produced by NVivo 12.\\nTherefore, we can say that those are the words that most often appear in the documents analyzed,\\nemphasizing, once again, that they include terms that do not just refer to the technology object of study\\nbut also to other ﬁelds of application.\\n3.3. Phase 3: Discussion\\n3.3.1. Beneﬁts of Artiﬁcial Intelligence and Machine Learning in Industrial Contexts\\nFrom the analysis of the research carried out, the ﬁrst information that emerged is that there is a\\ngrowing importance of innovation and digitalization in products, services, and processes. Consequently,\\nit means that the adoption of advanced manufacturing technologies, such AI and ML, is an emerging\\nissue. In other words, AI/ML algorithms represent an opportunity to handle high dimensional problems\\nand data. The interest in the subject is extended to all scientiﬁc sectors, but with a focus on computer\\nscience and engineering.\\nThe most signiﬁcant beneﬁts of using AI and ML in industrial sectors include: (1) Greater\\ninnovation, (2) process optimization, (3) resources optimization, and (4) improved quality.\\nAfter all, AI with ML is one of the most important technologies today and is transforming the\\neconomy and society, as demonstrated by the over 340,000 patent applications ﬁled since the 1950s.'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 14, 'page_label': '15', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Sustainability 2020, 12, 492 15 of 26\\nOther information that emerged is about the authors and aﬃliation. Many of these are in a 1:1 ratio\\ncompared to the selected documents and this supports the fact that there is no interest in technological\\napplications in one direction, but that, once again, the interest is very wide in the scientiﬁc community.\\nFurthermore, it can be said that the countries most interested in scientiﬁc research are the USA,\\nChina and European countries. This result is not a surprise.\\nIn terms of investment, the e ﬀort currently being deployed by the United States and China to\\nacquire dominance in the AI sector is far superior to that of other countries. More speciﬁcally, China\\nhas clearly stated its ambition to become a world leader in AI by 2030 [31]. Among the Chinese plans,\\nof absolute interest is the “Made in China 2025” plan, dedicated to the manufacturing sector; the\\n“Internet +” plan is also dedicated to smart manufacturing and innovation.\\nA direct consequence of the above considerations could be having new generations of researchers\\nwho will contribute to future comparisons, accompanied by new questions for investigations.\\n3.3.2. Emerging Trends of Artiﬁcial Intelligence and Machine Learning in Sustainable Manufacturing\\nFrom the perspective of sustainability, the analysis highlighted that the new paradigm of smart\\nmanufacturing has the potential to bring fundamental improvements in the industry by addressing\\nthe issue of scarce resources and improving productivity.\\nIn fact, the survey pointed out a growing interest on applications related to green manufacturing\\nand sustainable development, proving that AI/ML play an important role in increasing sustainability\\nthrough the intelligent utilization of materials and energy consumption (i.e., reduction of energy\\nconsumption and pollutant emissions, environmental footprint monitoring and evaluation, etc.).\\nFurthermore, it emerged that AI/ML algorithms present a wide array of applications that provide\\nan opportunity for sustainable development, which will involve several stakeholders from diﬀerent\\ncountries and sectors, including inventory and supply chain management, predictive maintenance,\\nand production.\\nIn particular, Pérez-Ortiz, Jiménez-Fernández, Gutiérrez et al. [32] reviewed the most important\\nclassiﬁcation algorithms applied to renewable energy (RE) problems. The main use of algorithms\\nis as a tool for predictive analysis and consequently for data preprocessing, result interpretation, or\\nevaluation in order to improve energy and resource management.\\nIn this context, it also emerged that AI/ML have been successfully utilized in various processes’\\noptimization, applications in manufacturing, and predictive maintenance in diﬀerent industries.\\nThe work published by Lieber, Stolpe, Konrad et al. [33] represents a good research within steel\\nindustry production. It proposes an approach for automatically preprocessing value series data to\\nimprove the quality of the process and products. It means that AI /ML techniques were found to\\nprovide promising potential for improved quality control optimization in manufacturing systems.\\nAppropriate adoption of AI/ML technologies will promote sustainable manufacturing and the\\nformation of a new generation of intelligent manufacturing, including all areas that characterize a\\nsustainable process, ranging from the supply chain management to quality control, to predictive\\nmaintenance, to energy consumption.\\nTable 5 summarizes the main areas in sustainable manufacturing, their respective key objectives,\\nand the main AI/ML applications.\\nHowever, the relationship between I.4 technologies, AI/ML, and sustainability demands a more\\nconceptual and empirical investigation. This is corroborated by an article recently published in Nature\\nSustainability by the director of the Earth Institute at Columbia University, Je ﬀrey Sachs, and other\\nexperts, and the so-called Fourth Industrial Revolution (made of artiﬁcial intelligence and other digital\\ntechnologies) is even cited as one of the six transformations necessary to achieve the sustainable\\ndevelopment goals [34].'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 15, 'page_label': '16', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Sustainability 2020, 12, 492 16 of 26\\nTable 5. Main areas in sustainable manufacturing.\\nMain Areas in Sustainable\\nManufacturing\\nKey\\nObjective\\nAI/ML\\nApplications\\nSupply Chain Management Ready product available in the\\nappropriate place at a speciﬁc time\\nImproves transparency, accelerates\\ndecision-making, and produces accurate\\ndemand forecasting\\nQuality Control\\nRecognize the early signs of\\npotential production failures\\nwithin the shortest terms in order\\nto save resources and sustain\\noperational eﬃciency\\nImproves the response time and allows\\neliminating possible failures\\nPredictive Maintenance\\nDetects possible production\\nmalfunctions that may cause\\nproduct quality issues\\nCreates accurate forecasts as to when\\nthe machinery must be repaired\\nEnergy consumption Recommendations that will strike\\na balance in energy use\\nImproves excessive use of certain\\nmaterials, redundant production scrap\\nwaste, ineﬃcient supply chain\\nmanagement, logistics, and unequal\\ndistribution of energy resources.\\n4. Conclusions\\nThis research focused on the study of the state of the art of AI and ML applications, selecting\\nliterature on what has now become a particularly hot topic in scientiﬁc research. The literature available\\non any subject is now wide and a complete coverage of all the documents published with respect to a\\nparticular topic can be challenging or even impossible. Therefore, a systematic selection of the most\\nrelevant literature was implemented. This document provides a systematic review of applications\\nin various scientiﬁc ﬁelds using ML techniques. For the selection of documents, objective and clear\\nmethods of investigation were used, independent of the experience of the researchers. Among the\\nobjectives of the document, it aimed to not only provide a comprehensive framework on the literature\\non the research of AI and ML but also a starting point for integrating knowledge through research in\\nthis area and to suggest future research paths. It is important to underline that this document was\\nproduced using only two databases, i.e., WoS and Scopus, in which only documents with open access\\nwere included. There are, therefore, many other documents with restricted access and other indexing\\ndatabases, such as Google Scholar, that could be integrated for future research.\\nAuthor Contributions: All authors contributed equally to this work. All authors have read and agreed to the\\npublished version of the manuscript.\\nFunding: This work has been conducted under the framework of the Italian project “Linee Guida per\\nI4.0-Campania”—funded by Regione Campania within POR FSE 2014–2020 Asse IV “Capacit à istituzionale e\\namministrativa” objectives 18 (RA) 11.3 and 21 (RA) 11.6.\\nConﬂicts of Interest: The authors declare no conﬂict of interest.'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 16, 'page_label': '17', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Sustainability 2020, 12, 492 17 of 26\\nAppendix A\\nID Count Research\\nSource\\nID\\nDoc Year Title Authors Source Title TC\\n1 SCP 2 2006 Machine learning in bioinformatics\\nLarrañaga, P .; Calvo, B.; Santana,\\nR.; Bielza, C.; Galdiano, J.; Inza, I.;\\nLozano, J.A.; Armañanzas, R.;\\nSantafé, G.; Pérez, A.; Robles, V .\\nBrieﬁngs in Bioinformatics 298\\n2 WoS 62 2008 Data-driven modelling: Some past experiences\\nand new approaches Solomatine, D.P .; Ostfeld, A. Journal of Hydroinformatics 160\\n3 SCP 26 2016 Learning from imbalanced data: Open\\nchallenges and future directions Krawczyk, B. Progress in Artiﬁcial\\nIntelligence 119\\n4 WoS 63 2001 Computer go: An AI oriented survey Bouzy, B; Cazenave, T Artiﬁcial Intelligence 114\\n5 SCP 6 2008 Structured machine learning: The next ten years\\nDietterich, T.G.; Domingos, P .;\\nGetoor, L.; Muggleton, S.;\\nTadepalli, P .\\nMachine Learning 75\\n6 SCP 28 2016 Machine learning in manufacturing:\\nAdvantages, challenges, and applications\\nWuest, T.; Weimer, D.; Irgens, C.;\\nThoben, K.D.\\nProduction and\\nManufacturing Research 52\\n7 WoS 64 2017 Machine learning paradigms for next-generation\\nwireless networks\\nJiang, C.; Zhang, H.; Ren, Y.; Han,\\nZ.; Chen, K.C.; Hanzo, L.\\nIeee Wireless\\nCommunications 50\\n8 SCP 3 2006 Machine learning techniques in disease\\nforecasting: A case study on rice blast prediction\\nKaundal, R.; Kapoor, A.A.;\\nRaghava, G.P .S. BMC Bioinformatics 48\\n9 SCP 4 2008\\nA comparison of machine learning algorithms\\nfor chemical toxicity classiﬁcation using a\\nsimulated multi-scale data model\\nJudson, R.; Elloumi, F.; Woodrow,\\nR.W.; Li, Z.; Shah, I. BMC Bioinformatics 45\\n10 SCP 19 2015\\nA review of intelligent driving style analysis\\nsystems and related artiﬁcial intelligence\\nalgorithms\\nMeiring, G.A.M.; Myburgh, H.C. Sensors (Switzerland) 33\\n11 SCP 21 2016\\nA machine learning framework for gait\\nclassiﬁcation using inertial sensors: Application\\nto elderly, post-stroke and huntington’s disease\\npatients\\nMannini, A.; Trojaniello, D.;\\nCereatti, A.; Sabatini, A.M. Sensors 31'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 17, 'page_label': '18', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Sustainability 2020, 12, 492 18 of 26\\nID Count Research\\nSource\\nID\\nDoc Year Title Authors Source Title TC\\n12 SCP 1 2006 Application of machine learning in SNP\\ndiscovery\\nMatukumalli, L.K.; Grefenstette,\\nJ.J.; Hyten, D.L.; Choi, I.Y.;\\nCregan, P .B.; Van Tassell, C.P .\\nBMC Bioinformatics 30\\n13 SCP 10 2013 Beam search algorithms for multilabel learning Kumar, A.; Vembu, S.; Menon,\\nA.K.; Elkan, C. Machine Learning 29\\n14 WoS 65 2011 Recommender Systems: An Overview Burke, Robin; Felfernig,\\nAlexander; Goeker, M.H. Ai Magazine 29\\n15 SCP 11 2013 Biomedical informatics for computer-aided\\ndecision support systems: A survey Belle, A.; Kon, M.A.; Najarian, K. The Scientiﬁc World Journal 27\\n16 SCP 23 2016 Application of machine learning to construction\\ninjury prediction\\nTixier, A.J.P .; Hallowell, M.R.;\\nRajagopalan, B.; Bowman, D. Automation in Construction 21\\n17 SCP 12 2013\\nQuality prediction in interlinked manufacturing\\nprocesses based on supervised & unsupervised\\nmachine learning\\nLieber, D.; Stolpe, M.; Konrad, B.;\\nDeuse, J.; Morik, K. Procedia CIRP 18\\n18 SCP 29 2016 Semantic framework of internet of things for\\nsmart cities: Case studies\\nZhang, N.; Chen, H.; Chen, X.;\\nChen, J. Sensors 17\\n19 SCP 20 2015 Support vector machines in structural\\nengineering: A review\\nÇevik, A.; KURTO˘GLU, A.E.;\\nBilgehan, M.; Gül¸ san, M.E.;\\nAlbegmprli, H.M.\\nJournal of Civil Engineering\\nand Management 15\\n20 SCP 25 2016 A review of classiﬁcation problems and\\nalgorithms in renewable energy applications\\nPérez-Ortiz, M.;\\nJiménez-Fernández, S.; Gutiérrez,\\nP .A.; (. . . ); Hervás-Martínez, C.;\\nSalcedo-Sanz, S.\\nEnergies 15\\n21 SCP 43 2018 Artiﬁcial intelligence (AI) methods in optical\\nnetworks: A comprehensive survey\\nMata, J.; de Miguel, I.; Durán, R.J.;\\n( . . . ); Jukan, A.; Chamania, M.\\nOptical Switching and\\nNetworking 15\\n22 SCP 14 2014 Fault diagnosis of automobile gearbox based on\\nmachine learning techniques\\nPraveenkumar, T.; Saimurugan,\\nM.; Krishnakumar, P .;\\nRamachandran, K.I.\\nProcedia Engineering 14\\n23 SCP 16 2014 Improving active Mealy machine learning for\\nprotocol conformance testing\\nAarts, F.; Kuppens, H.; Tretmans,\\nJ.; Vaandrager, F.; Verwer, S. Machine Learning 11'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 18, 'page_label': '19', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Sustainability 2020, 12, 492 19 of 26\\nID Count Research\\nSource\\nID\\nDoc Year Title Authors Source Title TC\\n24 WoS 66 2016 Strategies and Principles of Distributed Machine\\nLearning on Big Data Xing, E.P .; Ho, Q.; Xie, P .; Wei, D. Engineering 11\\n25 WoS 67 2015 Recent advances on artiﬁcial intelligence and\\nlearning techniques in cognitive radio networks\\nAbbas, N.; Nasser, Y.; El Ahmad,\\nK.\\nEurasip Journal on Wireless\\nCommunications and\\nNetworking\\n11\\n26 WoS 68 2018 Artiﬁcial intelligence (AI) methods in optical\\nnetworks: A comprehensive survey\\nMata, J.; de Miguel, I.; Duran, R.J.;\\nMerayo, N.; Singh, S.K.; Jukan, A.;\\nChamania, M.\\nOptical Switching and\\nNetworking 9\\n27 SCP 40 2018\\nA big data driven sustainable manufacturing\\nframework for condition-based maintenance\\nprediction\\nKumar, A.; Shankar, R.; Thakur,\\nL.S.\\nJournal of Computational\\nScience\\n27, pp. 428–439\\n8\\n28 WoS 69 2017\\nResearch and Application of a Novel Hybrid\\nModel Based on Data Selection and Artiﬁcial\\nIntelligence Algorithm for Short Term Load\\nForecasting\\nYang, W.; Wang, J.; Wang, R. Entropy 8\\n29 SCP 33 2017 Context Aware Process Mining in Logistics Becker, T.; Intoyoad, W. Procedia CIRP 7\\n30 SCP 24 2016\\nApplications of machine learning methods to\\nidentifying and predicting building retroﬁt\\nopportunities\\nMarasco, D.E.; Kontokosta, C.E. Energy and Buildings 6\\n31 SCP 37 2017\\nOperational Demand Forecasting in District\\nHeating Systems Using Ensembles of Online\\nMachine Learning Algorithms\\nJohansson, C.; Bergkvist, M.;\\nGeysen, D.; (. . . ); Lavesson, N.;\\nVanhoudt, D.\\nEnergy Procedia 6\\n32 WoS 70 2018 Advances in Multiple Criteria Decision Making\\nfor Sustainability: Modeling and Applications Shen, K.Y.; Tzeng, G.H. Sustainability 6\\n33 WoS 71 2017 Hybrid-augmented intelligence: Collaboration\\nand cognition\\nZheng, N.N.; Liu, Z.Y.; Ren, P .J.;\\nMa, Y.Q.; Chen, S.T.; Yu, S.Y.; Xue,\\nJ.R.; Chen, B.D.; Wang, F.Y.\\nFrontiers of Information\\nTechnology & Electronic\\nEngineering\\n6'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 19, 'page_label': '20', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Sustainability 2020, 12, 492 20 of 26\\nID Count Research\\nSource\\nID\\nDoc Year Title Authors Source Title TC\\n34 SCP 5 2008 Performance evaluation of the NVIDIA GeForce\\n8800 GTX GPU for machine learning\\nEl Zein, A.; McCreath, E.; Rendell,\\nA.; Smola, A.\\nLecture Notes in Computer\\nScience (including subseries\\nLecture Notes in Artiﬁcial\\nIntelligence and Lecture\\nNotes in Bioinformatics) 5101\\nLNCS(PART 1), pp. 466–475\\n5\\n35 SCP 7 2011 A review of artiﬁcial intelligence algorithms in\\ndocument classiﬁcation Bilski, A.\\nInternational Journal of\\nElectronics and\\nTelecommunications\\n5\\n36 SCP 18 2015 An architecture for agile machine learning in\\nreal-time applications Schleier-Smith, J.\\nProceedings of the ACM\\nSIGKDD International\\nConference on Knowledge\\nDiscovery and Data Mining\\n4\\n37 SCP 52 2018 Machine learning in agriculture: A review Liakos, K.G.; Busato, P .; Moshou,\\nD.; Pearson, S.; Bochtis, D. Sensors 4\\n38 SCP 22 2016\\nApplication of Information Processes\\nApplicative Modelling to Virtual Machines Auto\\nConﬁguration\\nZykov, S.; Shumsky, L. Procedia Computer Science 3\\n39 SCP 34 2017 Geometry-aware principal component analysis\\nfor symmetric positive deﬁnite matrices Horev, I.; Yger, F.; Sugiyama, M. Machine Learning 3\\n40 SCP 17 2015 A Fuzzy Least Squares Support Tensor Machines\\nin Machine Learning Zhang, R.; Zhou, Z.\\nInternational Journal of\\nEmerging Technologies in\\nLearning\\n2\\n41 SCP 36 2017 Nuclear energy system’s behavior and decision\\nmaking using machine learning\\nGomez Fernandez, M.; Tokuhiro,\\nA.; Welter, K.; Wu, Q.\\nNuclear Engineering and\\nDesign 2\\n42 SCP 9 2013 Application study of machine learning in\\nlightning forecasting\\nQiu, T.; Zhang, S.; Zhou, H.; Bai,\\nX.; Liu, P .\\nInformation Technology\\nJournal 1\\n43 SCP 30 2016\\nWOWMON: A machine learning-based proﬁler\\nfor self-adaptive instrumentation of scientiﬁc\\nworkﬂows\\nZhang, X.; Abbasi, H.; Huck, K.;\\nMalony, A.D. Procedia Computer Science 1'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 20, 'page_label': '21', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Sustainability 2020, 12, 492 21 of 26\\nID Count Research\\nSource\\nID\\nDoc Year Title Authors Source Title TC\\n44 SCP 31 2017 An event search platform using machine\\nlearning\\nRodrigues, M.A.; Silva, R.R.;\\nBernardino, J.\\nProceedings of the\\nInternational Conference on\\nSoftware Engineering and\\nKnowledge Engineering,\\nSEKE\\n1\\n45 SCP 32 2017\\nAutomated business process management-in\\ntimes of digital transformation using machine\\nlearning or artiﬁcial intelligence\\nPaschek, D.; Luminosu, C.T.;\\nDraghici, A. MATEC Web of Conferences 1\\n46 SCP 42 2018\\nApplication of machine learning methods in big\\ndata analytics at management of contracts in the\\nconstruction industry\\nValpeters, M.; Kireev, I.; Ivanov,\\nN. MATEC Web of Conferences 1\\n47 SCP 48 2018 Data mining and machine learning in textile\\nindustry\\nYildirim, P .; Birant, D.; Alpyildiz,\\nT.\\nWiley Interdisciplinary\\nReviews: Data Mining and\\nKnowledge Discovery\\n1\\n48 WoS 72 2018\\nBig Data Analytics, Machine Learning, and\\nArtiﬁcial Intelligence in Next-Generation\\nWireless Networks\\nKibria, M.G.; Kien, N.; Villardi,\\nG.P .; Zhao, O.; Ishizu, K.; Kojima,\\nF.\\nIeee Access 1\\n49 WoS 73 2017 Quantum neuromorphic hardware for quantum\\nartiﬁcial intelligence Prati, E.\\n8th International Workshop\\nDice2016: Spacetime - Matter -\\nQuantum Mechanics\\n1\\n50 WoS 74 2015 Exploiting Computational intelligence\\nParadigms in e-Technologies and Activities Said, H.M.; Salem, A.M.\\nInternational Conference on\\nCommunications,\\nManagement, and\\nInformation Technology\\n(Iccmit’2015)\\n1\\n51 WoS 75 2012 Sentiment Analysis of Products Using Web Unnamalai, K.\\nInternational Conference on\\nModelling Optimization and\\nComputing\\n1\\n52 SCP 8 2012 Taxonomy development and its impact on a\\nself-learning e-recruitment system\\nFaliagka, E.; Karydis, I.; Rigou,\\nM.; (. . . ); Tsakalidis, A.; Tzimas,\\nG.\\nIFIP Advances in Information\\nand Communication\\nTechnology\\n0'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 21, 'page_label': '22', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Sustainability 2020, 12, 492 22 of 26\\nID Count Research\\nSource\\nID\\nDoc Year Title Authors Source Title TC\\n53 SCP 13 2013 Research on adaptive multi-ﬁltering model of\\nnetwork sensitive information\\nCao, X.F.; Kang, W.; Shi, Q.; Shi,\\nF.F.\\nInformation Technology\\nJournal 0\\n54 SCP 15 2014 Grade: Machine-learning support for graduate\\nadmissions Waters, A.; Miikkulainen, R. AI Magazine 0\\n55 SCP 27 2016 Leveraging linked open data information\\nextraction for data mining applications Mahule, R.; Vyas, O.P .\\nTurkish Journal of Electrical\\nEngineering and Computer\\nSciences\\n0\\n56 SCP 38 2017 Rapid prototyping IoT solutions based on\\nMachine Learning\\nRizzo, A.; Montefoschi, F.;\\nCaporali, M.; (. . . ); Burresi, G.;\\nGiorgi, R.\\nACM International\\nConference Proceeding Series 0\\n57 SCP 39 2017 Towards automatic learning of heuristics for\\nmechanical transformations of procedural code\\nVigueras, G.; Carro, M.; Tamarit,\\nS.; Mariño, J.\\nElectronic Proceedings in\\nTheoretical Computer Science,\\nEPTCS\\n0\\n58 SCP 41 2018 Application of artiﬁcial intelligence principles in\\nmechanical engineering\\nZajaˇ cko, I.; Gál, T.; Ságová, Z.;\\nMateichyk, V .; Wiecek, D. MATEC Web of Conferences 0\\n59 SCP 44 2018 Artiﬁcial Intelligence in Medical Applications Chan, Y.K.; Chen, Y.F.; Pham, T.;\\nChang, W.; Hsieh, M.Y.\\nJournal of Healthcare\\nEngineering 0\\n60 SCP 45 2018\\nA semantic internet of things framework using\\nmachine learning approach based on cloud\\ncomputing\\nDing, P .W.; Hsu, I.C. ACM International\\nConference Proceeding Series 0\\n61 SCP 46 2018 A Survey on Machine Learning-Based Mobile\\nBig Data Analysis: Challenges and Applications\\nXie, J.; Song, Z.; Li, Y.; (. . . );\\nZhang, J.; Guo, J.\\nWireless Communications\\nand Mobile Computing 0\\n62 SCP 47 2018 Big Data and Machine Learning Based Secure\\nHealthcare Framework Kaur, P .; Sharma, M.; Mittal, M. Procedia Computer Science 0\\n63 SCP 49 2018 Discovering discontinuity in big ﬁnancial\\ntransaction data\\nTuarob, S.; Strong, R.; Chandra,\\nA.; Tucker, C.S.\\nACM Transactions on\\nManagement Information\\nSystems\\n0'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 22, 'page_label': '23', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Sustainability 2020, 12, 492 23 of 26\\nID Count Research\\nSource\\nID\\nDoc Year Title Authors Source Title TC\\n64 SCP 50 2018 Introducing children to machine learning\\nconcepts through hands-on experience\\nHitron, T.; Erel, H.; Wald, I.;\\nZuckerman, O.\\nIDC 2018 - Proceedings of the\\n2018 ACM Conference on\\nInteraction Design and\\nChildren\\n0\\n65 SCP 51 2018 Machine learning for software engineering:\\nModels, methods, and applications Meinke, K.; Bennaceur, A.\\nProceedings - International\\nConference on Software\\nEngineering\\n0\\n66 SCP 53 2018 Machine Learning in IT Service Management Zuev, D.; Kalistratov, A.; Zuev, A.Procedia Computer Science 0\\n67 SCP 54 2018 Research and application of computer control\\nsystem based on complex neural network Yang, R. MATEC Web of Conferences 0\\n68 SCP 55 2018 Text classiﬁcation techniques: A literature\\nreview Thangaraj, M.; Sivakami, M.\\nInterdisciplinary Journal of\\nInformation, Knowledge, and\\nManagement\\n0\\n69 SCP 56 2019 A Machine Learning Method for Predicting\\nDriving Range of Battery Electric Vehicles\\nSun, S.; Zhang, J.; Bi, J.; Wang, Y.;\\nMoghaddam, M.H.Y.\\nJournal of Advanced\\nTransportation 0\\n70 SCP 57 2019 An empirical comparison of machine-learning\\nmethods on bank client credit assessments\\nMunkhdalai, L.; Munkhdalai, T.;\\nNamsrai, O.E.; Lee, J.Y.; Ryu, K.H. Sustainability 0\\n71 SCP 58 2019\\nComparison of multiple linear regression,\\nartiﬁcial neural network, extreme learning\\nmachine, and support vector machine in\\nderiving operation rule of hydropower reservoir\\nNiu, W.J.; Feng, Z.K.; Feng, B.F.; (\\n. . . ); Cheng, C.T.; Zhou, J.Z. Water 0\\n72 SCP 59 2019\\nDevelopment and evaluation of a low-cost and\\nsmart technology for precision weed\\nmanagement utilizing artiﬁcial intelligence\\nPartel, V .; Charan Kakarla, S.;\\nAmpatzidis, Y.\\nComputers and Electronics in\\nAgriculture 0\\n73 SCP 60 2019 Identifying known and unknown mobile\\napplication traﬃc using a multilevel classiﬁer\\nZhao, S.; Chen, S.; Sun, Y.; (. . . );\\nSu, J.; Su, C.\\nSecurity and Communication\\nNetworks 0'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 23, 'page_label': '24', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Sustainability 2020, 12, 492 24 of 26\\nID Count Research\\nSource\\nID\\nDoc Year Title Authors Source Title TC\\n74 SCP 61 2019 Optimized Clustering Algorithms for Large\\nWireless Sensor Networks: A Review\\nWohwe Sambo, D.; Yenke, B.O.;\\nFörster, A.; Dayang, P . Sensors 0\\n75 WoS 76 2019\\nFPGA-Based Accelerators of Deep Learning\\nNetworks for Learning and Classiﬁcation: A\\nReview\\nShawahna, A.; Sait, S.M.;\\nEl-Maleh, A. Ieee Access 0\\n76 WoS 77 2018 A quantum machine learning algorithm based\\non generative models Gao, X.; Zhang, Z.Y.; Duan, L.M. Science Advances 0\\n77 WoS 78 2018 Machine Learning for Network Automation:\\nOverview, Architecture, and Applications Raﬁque, D.; Velasco, L.\\nJournal of Optical\\nCommunications and\\nNetworking\\n0\\n78 WoS 79 2018\\nA wireless sensor data-based coal mine gas\\nmonitoring algorithm with least squares support\\nvector machines optimized by swarm\\nintelligence techniques\\nChen, P .; Xie, Y.; Jin, P .; Zhang, D.International Journal of\\nDistributed Sensor Networks 0\\n79 WoS 80 2017 Nuclear energy system’s behavior and decision\\nmaking using machine learning\\nFernandez, M.G.; Tokuhiro, A.;\\nWelter, K.; Wu, Q.\\nNuclear Engineering and\\nDesign 0\\n80 WoS 81 2017\\nAutomated business process management—In\\ntimes of digital transformation using machine\\nlearning or artiﬁcial intelligence\\nPaschek, D.; Luminosu, C.T.;\\nDraghici, A.\\n8th International Conference\\non Manufacturing Science\\nand Education (Mse\\n2017)—Trends in New\\nIndustrial Revolution\\n0\\n81 WoS 82 2017\\nThe Evaluation of Resonance Frequency for\\nPiezoelectric Transducers by Machine Learning\\nMethods\\nChang, F.M.\\n27Th International\\nConference on Flexible\\nAutomation and Intelligent\\nManufacturing, Faim 2017\\n0\\n82 WoS 83 2017\\nFrom Extraction to Generation of Design\\nInformation Paradigm Shift in Data Mining via\\nEvolutionary Learning Classiﬁer System\\nChiba, K.; Nakata, M.\\nInternational Conference on\\nComputational Science (Iccs\\n2017)\\n0'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 24, 'page_label': '25', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Sustainability 2020, 12, 492 25 of 26\\nReferences\\n1. Gupta, N.A. Literature Survey on Artiﬁcial Intelligence. 2017. Available online: https: //www.ijert.org/\\nresearch/a-literature-survey-on-artiﬁcial-intelligence-IJERTCONV5IS19015.pdf (accessed on 7 January 2020).\\n2. McCarthy, J.; Minsky, M.L.; Rochester, N.; Shannon, C.E. A Proposal for the Dartmouth Summer Research\\nProject on Artiﬁcial Intelligence. AI Mag. 2006, 27, 12.\\n3. Moore, A. Carnegie Mellon Dean of Computer Science on the Future of AI. Available\\nonline: https://www.forbes.com/sites/peterhigh/2017/10/30/carnegie-mellon-dean-of-computer-science-on-\\nthe-future-of-ai /#3a283c652197 (accessed on 7 January 2020).\\n4. Becker, A.; Bar-Yehuda, R.; Geiger, D. Randomised algorithms for the loop cutset problem.J. Artif. Intell. Res.\\n2000, 12, 219–234. [CrossRef]\\n5. Singer, J.; Gent, I.P .; Smaill, A. Backbone fragility and the local search cost peak.J. Artif. Intell. Res. 2000,\\n12, 235–270. [CrossRef]\\n6. Chen, X.; Van Beek, P . Conﬂict-directed backjumping revisited.J. Artif. Intell. Res. 2001, 14, 53–81. [CrossRef]\\n7. Hong, J. Goal recognition through goal graph analysis. J. Artif. Intell. Res. 2001, 15, 1–30. [CrossRef]\\n8. Stone, P .; Littman, M.L.; Singh, S.; Kearns, M. ATTAC-2000: An adaptive autonomous bidding agent.J. Artif.\\nIntell. Res. 2000, 15, 189–206. [CrossRef]\\n9. Peng, Y.; Zhang, X. Integrative data mining in systems biology: from text to network mining.Artif. Intell. Med.\\n2007, 41, 83–86. [CrossRef]\\n10. Zhou, X.; Liu, B.; Wu, Z.; Feng, Y. Integrative mining of traditional Chines medicine literature and MEDLINE\\nfor functional gene networks. Artif. Intell. Med. 2007, 41, 87–104. [CrossRef]\\n11. Wang, S.; Wang, Y.; Du, W.; Sun, F.; Wang, X.; Zhou, C.; Liang, Y. A multi-approaches-guided genetic\\nalgorithm with application to operon prediction. Artif. Intell. Med. 2007, 41, 151–159. [CrossRef]\\n12. Halal, W.E. Artiﬁcial intelligence is almost here. Horizon 2003, 11, 37–38. Available online: https: //\\nwww.emerald.com/insight/content/doi/10.1108/10748120310486771/full/html (accessed on 7 January 2020).\\n[CrossRef]\\n13. Masnikosa, V .P . The fundamental problem of an artiﬁcial intelligence realization.Kybernetes 1998, 27, 71–80.\\n[CrossRef]\\n14. Metaxiotis, K.; Ergazakis, K.; Samouilidis, E.; Psarras, J. Decision support through knowledge management:\\nThe role of the artiﬁcial intelligence. Inf. Manag. Comput. Secur. 2003, 11, 216–221. [CrossRef]\\n15. Raynor, W.J. The international dictionary of artiﬁcial intelligence. Ref. Rev. 2000, 14, 1–380.\\n16. Stefanuk, V .L.; Zhozhikashvili, A.V . Productions and rules in artiﬁcial intelligence. Kybernetes 2002,\\n31, ty817–826. [CrossRef]\\n17. Tay, D.P .H.; Ho, D.K.H. Artiﬁcial intelligence and the mass appraisal of residential apartments. J. Prop.\\nValuat. Invest. 1992, 10, 525–540. [CrossRef]\\n18. Wongpinunwatana, N.; Ferguson, C.; Bowen, P . An experimental investigation of the eﬀects of artiﬁcial\\nintelligence systems on the training of novice auditors. Manag. Audit. J. 2000, 15, 306–318. [CrossRef]\\n19. Oke, S.A. A literature review on artiﬁcial intelligence. Int. J. Inf. Manag. Sci. 2008, 19, 535–570.\\n20. Carvalho, T.P .; Soares, F.A.A.M.N.; Vita, R.; da Francisco, P .R.; Basto, J.P .; Alcalá, S.G.S. A systematic literature\\nreview of machine learning methods applied to predictive maintenance. Comput. Ind. Eng. 2019, 1, 1–12.\\n[CrossRef]\\n21. Majorel Deutschland GmbH Artiﬁcial Intelligence and Sustainability. Available online: https://www.future-\\ncustomer.com/artiﬁcial-intelligence-and-sustainability / (accessed on 8 January 2020).\\n22. Markham, I.S.; Mathieu, R.G.; Wray, B.A. Kanban setting through artiﬁcial intelligence: A comparative study\\nof artiﬁcial neural networks and decision trees. Integr. Manuf. Syst. 2000, 11, 239–246. [CrossRef]\\n23. Kotsiantis, S.B.; Zaharakis, I.; Pintelas, P . Supervised machine learning: A review of classiﬁcation techniques.\\nEmerg. Artif. Intell. Appl. Comput. Eng. 2007, 160, 3–24.\\n24. Cortes, C.; Vapnik, V . Support-vector networks. Mach. Learn. 1995, 20, 273–297. [CrossRef]\\n25. Kitchenham, B. Procedures for Performing Systematic Reviews. Technical Report TR/SE-0401. 2004. Available\\nonline: https://pdfs.semanticscholar.org/2989/0a936639862f45cb9a987dd599dce9759bf5.pdf?_ga=2.7241591.\\n47522378.1578382825-243572483.1578382825 (accessed on 7 January 2020).\\n26. Duan, Y.; Edwards, J.S.; Dwivedi, Y.K. Artiﬁcial intelligence for decision making in the era of Big\\nData—Evolution, challenges and research agenda. Int. J. Inf. Manag. 2019, 48, 63–71. [CrossRef]'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 25, 'page_label': '26', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Sustainability 2020, 12, 492 26 of 26\\n27. De Felice, F.; Petrillo, A.; Zomparelli, F. Prospective design of smart manufacturing: An Italian pilot case\\nstudy. Manuf. Lett. 2018, 15, 81–85. [CrossRef]\\n28. Larrañaga, P .; Calvo, B.; Santana, R.; Bielza, C.; Galdiano, J.; Inza, I.; Lozano, J.A.; Armañanzas, R.; Santafé, G.;\\nPérez, A.; et al. Machine Learning. in Bioinformatics. Brief. Bioinform. 2006, 7, 86–112. [CrossRef] [PubMed]\\n29. Krawczyk, B. Learning from imbalanced data: Open challenges and future directions. Prog. Artif. Intell.\\n2016, 5, 221–232. [CrossRef]\\n30. Wuest, T.; Weimer, D.; Irgens, C.; Thoben, K.D. Machine learning in manufacturing: Advantages, challenges,\\nand applications. Prod. Manuf. Res. 2016, 4, 23–45. [CrossRef]\\n31. Dutton, T. An Overview of National AI Strategies. Available online: http: //www.jaist.ac.jp/~{}bao/AI/\\nOtherAIstrategies/An%20Overview%20of%20National%20AI%20Strategies%20%E2%80%93%20Politics%\\n20+%20AI%20%E2%80%93%20Medium.pdf (accessed on 8 January 2020).\\n32. Pérez-Ortiz, M.; Jiménez-Fernández, S.; Gutiérrez, P .A.; Alexandre, E.; Hervás-Martínez, C.; Salcedo-Sanz, S.\\nA Review of Classiﬁcation Problems and Algorithms in Renewable Energy Applications. Energies 2016,\\n9, 607. [CrossRef]\\n33. Lieber, D.; Stolpe, M.; Konrad, B.; Deuse, J.; Morik, K. Quality prediction in interlinked manufacturing\\nprocesses based on supervised & unsupervised machine learning. Procedia CIRP 2013, 7, 193–198.\\n34. Sachs, J.D.; Schmidt-Traub, G.; Mazzucato, M.; Messner, D.; Nakicenovic, N.; Rockström, J.\\nSix Transformations to Achieve the Sustainable Development Goals. Nat. Sustain. 2019, 2, 805–814.\\n[CrossRef]\\n© 2020 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access\\narticle distributed under the terms and conditions of the Creative Commons Attribution\\n(CC BY) license (http://creativecommons.org/licenses/by/4.0/).'),\n",
       " Document(metadata={'producer': 'Skia/PDF m144 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'dsa', 'source': '../data/pdf_files/dsa.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'dsa.pdf', 'file_type': 'pdf'}, page_content='Time  complexity  measures  how  the  performance  of  an  algorithm  changes  with  input  size  (n).  Big-O  notation  \\nexpresses\\n \\nthe\\n \\nworst-case\\n \\ncomplexity.\\n \\nFor\\n \\nexample,\\n \\nO(1)\\n \\nmeans\\n \\nconstant\\n \\ntime;\\n \\nO(n)\\n \\nmeans\\n \\nlinear\\n \\ntime;\\n \\nO(n²)\\n \\nrepresents\\n \\nquadratic\\n \\ntime;\\n \\nO(log\\n \\nn)\\n \\nis\\n \\nlogarithmic;\\n \\nand\\n \\nO(n\\n \\nlog\\n \\nn)\\n \\nrepresents\\n \\nefficient\\n \\ndivide-and-conquer\\n \\nalgorithms\\n \\nlike\\n \\nmerge\\n \\nsort.\\n \\nSearching  algorithms  determine  how  to  locate  a  specific  value  in  a  dataset.  The  simplest  is  linear  search  \\n(O(n))\\n,\\n \\nwhich\\n \\nchecks\\n \\neach\\n \\nelement\\n \\nsequentially.\\n \\nIt\\n \\nworks\\n \\non\\n \\nunsorted\\n \\ndata\\n \\nbut\\n \\nis\\n \\nslow\\n \\nfor\\n \\nlarge\\n \\ninputs.\\n \\nBinary\\n \\nsearch\\n \\n(O(log\\n \\nn))\\n \\nworks\\n \\non\\n \\nsorted\\n \\narrays\\n \\nby\\n \\nrepeatedly\\n \\ndividing\\n \\nthe\\n \\nsearch\\n \\nspace\\n \\nin\\n \\nhalf,\\n \\ndramatically\\n \\nimproving\\n \\nefficiency.\\n \\nSorting  algorithms  arrange  elements  in  ascending  or  descending  order:  \\n●  Bubble  Sort:  Repeatedly  swaps  adjacent  elements—simple  but  slow  (O(n²)).  \\n ●  Selection  Sort:  Selects  the  smallest  element  in  each  iteration—also  O(n²).  \\n ●  Insertion  Sort:  Efficient  for  small  or  nearly  sorted  arrays  (O(n²)  worst  case).  \\n ●  Merge  Sort:  A  divide-and-conquer  algorithm  that  splits,  sorts,  and  merges;  stable  and  fast  with  O(n  log  \\nn)\\n \\ntime.\\n \\n ●  Quick  Sort:  Uses  a  pivot  to  partition  the  array;  average  O(n  log  n)  but  worst  O(n²).  One  of  the  fastest  \\npractical\\n \\nalgorithms.\\n \\n ●  Heap  Sort:  Builds  a  heap  and  extracts  the  maximum/minimum  repeatedly;  guarantees  O(n  log  n).  \\n \\nUnderstanding  time  complexity  helps  you  choose  the  right  algorithm  for  large-scale  problems.  Sorting  and  \\nsearching\\n \\nform\\n \\nthe\\n \\nfoundation\\n \\nof\\n \\nmost\\n \\nreal-world\\n \\napplications,\\n \\nfrom\\n \\ndatabases\\n \\nto\\n \\ncompetitive\\n \\nprogramming.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m139', 'creator': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/139.0.0.0 Safari/537.36', 'creationdate': '2025-08-30T19:12:18+00:00', 'title': 'shreya_sharma_resume.docx - Google Docs', 'moddate': '2025-08-30T19:12:18+00:00', 'source': '../data/pdf_files/Shreya_Sharma_Resume.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'Shreya_Sharma_Resume.pdf', 'file_type': 'pdf'}, page_content='SHREYA SHARMA \\n B.Tech (Computer Science and Engineering \\n with Specialization in Cyber Security) \\n Email:  shreya.sharma110404@gmail.com  |  Phone:  9770766139 \\n LinkedIn:  https://www.linkedin.com/in/shreya-sharma1104/ \\n GitHub:  https://github.com/shreyasharma-1 \\n ACADEMICS \\n Qualification  Institute  Board / University  % / CGPA  Year \\n B.Tech (CY - 6th sem) \\n XII \\n Lakshmi Narain College of \\n Technology & Science \\n Maharishi Vidya Mandir, Jabalpur \\n RGPV \\n CBSE \\n 8.34/10 \\n 73% \\n 2026 \\n 2022 \\n X  Maharishi Vidya Mandir, Jabalpur  CBSE  70.8%  2020 \\n Certifications \\n /Publications \\n ●  Comprehensive Study Of MD5 and SHA-256 \\n ●  Introduction to Cybersecurity offered through Cisco Networking Academy \\n ●  The Complete Python Developer Certification Course offered by Udemy \\n ●  Database Management System Part - 1 offered by Infosys Springboard \\n ●  Python (Basic) offered by Hacker-Rank \\n 2024 \\n 2024 \\n 2024 \\n 2024 \\n 2023 \\n Achievements  ●  Best  Paper  Award  (2nd  Position)  for  the  \"Comprehensive  Study  of  MD5  and  SHA-256\" \\n Research Paper at ICEHAIDS.  2024 \\n PROJECTS \\n Multi-Agent \\n Telegram Bot \\n ●  Tech Stack – Python, FastAPI, MongoDB, OpenAI Whisper, Google Nearby Search API \\n ●  Developed a Multi-Agent Telegram Bot with intelligent query routing for dynamic decision-making \\n ●  Integrated  real-time  services  including  weather  updates,  stock  price  retrieval,  news  aggregation, \\n image generation, meme creation, and voice-to-text interaction using OpenAI Whisper. \\n ●  Implemented  location-based  features  with  Google  Nearby  Search  API  and  ensured  scalable \\n architecture with secure chat history storage in MongoDB.. \\n Face Tracer - \\n Intelligent Presence \\n Detection \\n ●  Tech Stack  – Python, OpenCV, face_recognition, Flask, HTML/CSS, SQLite, NumPy, Pandas \\n ●  Developed  a  real-time  attendance  management  web  application  using  facial  recognition.  Integrated \\n webcam-based face detection with automatic attendance logging and CSV/SQLite storage. \\n ●  Built  a  responsive  frontend  using  Flask  and  HTML  with  options  for  registration,  training,  and \\n viewing attendance logs. \\n House Price \\n Prediction – Data \\n analysis \\n ●  Tech Stack  - Python, Pandas, Numpy, Matplotlib, Seaborn \\n ●  House  Price  Prediction  uses  machine  learning  techniques  to  predict  housing  prices,  showcasing \\n analytical and problem-solving skills. \\n Iris Flower \\n classification \\n ●  Tech Stack -  Python, Pandas, Numpy, Matplotlib, Seaborn, filter warnings \\n ●  Iris  Flower  Classification  using  Applied  linear  regression  for  accurate  classification  of  Iris  flowers, \\n demonstrating a solid understanding of statistical modeling \\n √√√ \\n SKILLS \\n Programming  Java, Python, Pandas, Numpy, Matplotlib, Machine Learning (Beginner) \\n Databases  SQL \\n Analytics  Power BI, Matplotlib, Seaborn \\n Tools  Jupyter Notebook, Cursor, VS Code, Canva, MS Word, MS Excel, MS PowerPoint \\n Soft Skills  Leadership, Communication, Problem Solving, Analytical Skills, Learning Agility \\n POSITIONS OF RESPONSIBILITY \\n LNCTS BHOPAL \\n ●  Volunteer  at  the  International  Conference  on  Expanding  Horizons  in  Artificial \\n Intelligence & Data Science \\n ●  Research Paper Presenter at ICEHAIDS \\n MVM, Jabalpur  ●  Vice Captain, Assembly Committee \\n ●  Member, Hygiene Committee \\n CO-CURRICULAR & EXTRACURRICULAR ACTIVITIES \\n Lakshmi Narain College of Technology & Science | BATCH OF 2026 \\n Technical  ●  Chairperson (Innovation Vertical), Young Indians CII-YUVA \\n ●  Competitive Programming – LeetCode, Hacker-Rank'),\n",
       " Document(metadata={'producer': 'Skia/PDF m139', 'creator': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/139.0.0.0 Safari/537.36', 'creationdate': '2025-08-30T18:04:57+00:00', 'title': '\".:: Rajiv Gandhi Proudyogiki Vishwavidyalaya, Bhopal ::.\"', 'moddate': '2025-08-30T18:04:57+00:00', 'source': '../data/pdf_files/Shreya_Sharma_Transcript.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'Shreya_Sharma_Transcript.pdf', 'file_type': 'pdf'}, page_content='Rajiv Gandhi Proudyogiki\\nVishwavidyalaya, Bhopal\\nStatement of Marks - June-2025\\nName SHREYA SHARMA Roll No. 0157CY221129\\nCourse B.Tech Branch CY\\nSemester 6 Status Regular\\nSubject Total Credit Earned Credit Grade\\nCY601- [T] 3 3 A\\nCY602- [T] 3 3 B+\\nCY603- [T] 4 4 A+\\nCY604- [T] 4 4 A\\nCY601- [P] 1 1 A+\\nCY602- [P] 1 1 A+\\nCY605- [P] 3 3 A+\\nCY606- [P] 3 3 A+\\nCY608- [P] 2 2 A+\\nResult Des. SGPA CGPA\\nPASS 9.46 8.34\\nRevaluation Date Revaluation Date with\\nLate Fee\\n12/08/2025 14/08/2025\\nData Source : Rajiv Gandhi Proudyogiki Vishwavidyalaya, Bhopal\\nDisclaimer : The data belongs to RGPV,Bhopal. For any communication related to the\\npublished data, please contact examination cell of RGPV or respective College.\\nPrint Marksheet\\n30/08/2025, 23:34 \".:: Rajiv Gandhi Proudyogiki Vishwavidyalaya, Bhopal ::.\"\\nabout:blank 1/1'),\n",
       " Document(metadata={'producer': 'Skia/PDF m144 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'dbms', 'source': '../data/pdf_files/dbms.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'dbms.pdf', 'file_type': 'pdf'}, page_content='Database  Management  Systems  (DBMS)  provide  structured  storage,  retrieval,  and  management  of  data.  One  \\nessential\\n \\nconcept\\n \\nin\\n \\nrelational\\n \\ndatabases\\n \\nis\\n \\nnormalization\\n,\\n \\nwhich\\n \\naims\\n \\nto\\n \\nreduce\\n \\nredundancy\\n \\nand\\n \\nensure\\n \\ndata\\n \\nintegrity.\\n \\nNormalization\\n \\ninvolves\\n \\ndecomposing\\n \\ntables\\n \\ninto\\n \\nwell-structured\\n \\nforms\\n \\ncalled\\n \\nnormal\\n \\nforms\\n.\\n \\n1NF  (First  Normal  Form)  requires  that  table  cells  contain  atomic  values  and  that  each  record  is  unique.  2NF  \\nremoves\\n \\npartial\\n \\ndependency,\\n \\nmeaning\\n \\nno\\n \\nnon-key\\n \\nattribute\\n \\nshould\\n \\ndepend\\n \\non\\n \\nonly\\n \\npart\\n \\nof\\n \\na\\n \\ncomposite\\n \\nprimary\\n \\nkey.\\n \\n3NF\\n \\nremoves\\n \\ntransitive\\n \\ndependency,\\n \\nensuring\\n \\nnon-key\\n \\nattributes\\n \\ndepend\\n \\nonly\\n \\non\\n \\nprimary\\n \\nkeys.\\n \\nProper\\n \\nnormalization\\n \\nprevents\\n \\nanomalies\\n \\nsuch\\n \\nas\\n \\nupdate,\\n \\ninsertion,\\n \\nand\\n \\ndeletion\\n \\nanomalies.\\n \\nIn  DBMS,  relationships  between  tables  are  established  through  joins :  \\n●  INNER  JOIN:  Returns  only  matching  rows  from  both  tables.  \\n ●  LEFT  JOIN:  Returns  all  rows  from  the  left  table  and  matching  rows  from  the  right.  \\n ●  RIGHT  JOIN:  Opposite  of  left  join.  \\n ●  FULL  OUTER  JOIN:  Returns  all  rows  when  there  is  a  match  in  either  table.  \\n ●  CROSS  JOIN:  Produces  a  Cartesian  product.  \\n \\nJoins  enable  relational  databases  to  maintain  normalized  structures  while  still  retrieving  meaningful  combined  \\ndata.\\n \\nAnother  key  concept  is  transactions ,  which  represent  a  sequence  of  operations  performed  as  a  single  logical  \\nunit\\n \\nof\\n \\nwork.\\n \\nTransactions\\n \\nmust\\n \\nsatisfy\\n \\nthe\\n \\nACID\\n \\nproperties\\n:\\n \\n●  Atomicity:  All  steps  succeed  or  none.  \\n ●  Consistency:  The  database  must  remain  valid  before  and  after  the  transaction.  \\n ●  Isolation:  Concurrent  transactions  must  not  interfere  with  each  other.  \\n ●  Durability:  Changes  persist  even  if  the  system  crashes.  \\n \\nDatabase  systems  use  locking,  logging,  checkpoints,  and  isolation  levels  to  ensure  transaction  safety.  \\nUnderstanding\\n \\nnormalization,\\n \\njoins,\\n \\nand\\n \\ntransactions\\n \\nis\\n \\ncritical\\n \\nbecause\\n \\nthese\\n \\nconcepts\\n \\nform\\n \\nthe\\n \\nbackbone\\n \\nof\\n \\nrelational\\n \\ndata\\n \\nhandling.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m144 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'ml', 'source': '../data/pdf_files/ml.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'ml.pdf', 'file_type': 'pdf'}, page_content='Machine  Learning  (ML)  is  a  subfield  of  Artificial  Intelligence  that  enables  systems  to  learn  patterns  from  data  \\nand\\n \\nimprove\\n \\nover\\n \\ntime\\n \\nwithout\\n \\nexplicit\\n \\nprogramming.\\n \\nML\\n \\nfocuses\\n \\non\\n \\nbuilding\\n \\nmodels\\n \\nthat\\n \\ncan\\n \\nanalyze\\n \\ndata,\\n \\nmake\\n \\npredictions,\\n \\nclassify\\n \\noutcomes,\\n \\nand\\n \\nfind\\n \\nhidden\\n \\nstructures.\\n \\nIt\\n \\nhas\\n \\nrevolutionized\\n \\nmultiple\\n \\nindustries\\n \\nthrough\\n \\nautomation\\n \\nand\\n \\nintelligent\\n \\ndecision-making.\\n \\nML  is  broadly  divided  into  three  major  types:  \\n1.  Supervised  Learning  \\nModels  learn  using  labeled  data—each  input  has  a  correct  output.  Algorithms  try  to  generalize  these  \\nrelationships\\n \\nto\\n \\npredict\\n \\noutcomes\\n \\non\\n \\nnew\\n \\ndata.\\n \\n \\nCommon\\n \\nalgorithms\\n \\ninclude\\n \\nLinear\\n \\nRegression,\\n \\nLogistic\\n \\nRegression,\\n \\nDecision\\n \\nTrees,\\n \\nRandom\\n \\nForests,\\n \\nand\\n \\nSupport\\n \\nVector\\n \\nMachines.\\n \\n \\nApplications:\\n \\nSpam\\n \\ndetection,\\n \\ncredit\\n \\nscoring,\\n \\nmedical\\n \\ndiagnosis,\\n \\nstock\\n \\nprice\\n \\nprediction.\\n \\n2.  Unsupervised  Learning  \\nUsed  when  data  has  no  labels.  The  model  identifies  hidden  patterns,  clusters,  or  structures.  \\n \\nPopular\\n \\nmethods\\n \\ninclude\\n \\nK-means\\n \\nclustering,\\n \\nPCA,\\n \\nand\\n \\nApriori\\n \\nfor\\n \\nassociation\\n \\nmining.\\n \\n \\nApplications:\\n \\nCustomer\\n \\nsegmentation,\\n \\nanomaly\\n \\ndetection,\\n \\ndimensionality\\n \\nreduction.\\n \\n3.  Reinforcement  Learning  \\nThe  model  interacts  with  an  environment  and  learns  from  rewards  and  penalties .  It  is  used  in  robotics,  \\ngaming\\n \\n(e.g.,\\n \\nAlphaGo),\\n \\nautonomous\\n \\nvehicles,\\n \\nand\\n \\nresource\\n \\noptimization.\\n \\nOther  important  ML  concepts  include:  \\n●  Feature  Engineering:  Selecting  important  variables  to  improve  model  accuracy.  \\n ●  Model  Evaluation:  Using  metrics  like  accuracy,  precision,  recall,  F1-score.  \\n ●  Overfitting  &  Underfitting:  Overfitting  happens  when  the  model  memorizes  training  data;  underfitting  \\noccurs\\n \\nwhen\\n \\nit\\n \\nfails\\n \\nto\\n \\nlearn\\n \\nenough\\n \\npatterns.\\n \\n ●  Training  vs  Testing:  Models  are  trained  on  historical  data  and  tested  on  unseen  data  to  validate  \\nperformance.\\n \\n \\nML  applications  are  everywhere—image  recognition,  natural  language  processing,  fraud  detection,  \\nrecommendation\\n \\nsystems,\\n \\nautonomous\\n \\ndriving,\\n \\nand\\n \\nhealthcare\\n \\nanalytics.\\n \\nAs\\n \\ndata\\n \\ngrows,\\n \\nmachine\\n \\nlearning\\n \\ncontinues\\n \\nto\\n \\nshape\\n \\nhow\\n \\nmodern\\n \\nsystems\\n \\nmake\\n \\nintelligent\\n \\ndecisions.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m144 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'os', 'source': '../data/pdf_files/os.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'os.pdf', 'file_type': 'pdf'}, page_content='An  Operating  System  (OS)  is  responsible  for  managing  hardware,  providing  an  environment  for  applications,  \\nand\\n \\nensuring\\n \\nefficient\\n \\nutilization\\n \\nof\\n \\nsystem\\n \\nresources.\\n \\nTwo\\n \\nof\\n \\nthe\\n \\nmost\\n \\nfundamental\\n \\nconcepts\\n \\nin\\n \\nOS\\n \\nare\\n \\nprocesses\\n \\nand\\n \\nthreads\\n.\\n \\nA\\n \\nprocess\\n \\nis\\n \\nan\\n \\nindependent\\n \\nprogram\\n \\nin\\n \\nexecution.\\n \\nIt\\n \\nhas\\n \\nits\\n \\nown\\n \\nmemory\\n \\nspace\\n \\n(code,\\n \\ndata,\\n \\nstack,\\n \\nheap)\\n \\nand\\n \\nis\\n \\nrepresented\\n \\nin\\n \\nthe\\n \\nsystem\\n \\nby\\n \\na\\n \\nProcess\\n \\nControl\\n \\nBlock\\n \\n(PCB).\\n \\nEvery\\n \\nprocess\\n \\noperates\\n \\nin\\n \\nisolation,\\n \\nwhich\\n \\nensures\\n \\nstability\\n \\nbut\\n \\nalso\\n \\nincreases\\n \\noverhead\\n \\nbecause\\n \\nswitching\\n \\nbetween\\n \\nprocesses\\n \\nis\\n \\nexpensive—each\\n \\ncontext\\n \\nswitch\\n \\nrequires\\n \\nsaving\\n \\nand\\n \\nloading\\n \\na\\n \\nseparate\\n \\nmemory\\n \\nspace.\\n \\nA  thread ,  on  the  other  hand,  is  a  smaller  execution  unit  inside  a  process.  Multiple  threads  within  the  same  \\nprocess\\n \\nshare\\n \\nmemory\\n \\nsuch\\n \\nas\\n \\nglobal\\n \\nvariables\\n \\nand\\n \\nheap,\\n \\nbut\\n \\neach\\n \\nthread\\n \\nhas\\n \\nits\\n \\nown\\n \\nstack\\n \\nand\\n \\nprogram\\n \\ncounter.\\n \\nThis\\n \\nshared\\n \\nmemory\\n \\nmakes\\n \\nthreads\\n \\nlightweight\\n \\nand\\n \\nsuitable\\n \\nfor\\n \\nparallelism\\n \\nwithin\\n \\nthe\\n \\nsame\\n \\napplication.\\n \\nFor\\n \\nexample,\\n \\na\\n \\nbrowser\\n \\nmay\\n \\nhave\\n \\nseparate\\n \\nthreads\\n \\nfor\\n \\nrendering,\\n \\ndownloading,\\n \\nand\\n \\nhandling\\n \\nuser\\n \\ninteractions.\\n \\nOS  uses  CPU  scheduling  to  determine  which  process  or  thread  gets  processor  time.  Scheduling  becomes  \\nnecessary\\n \\nbecause\\n \\nthe\\n \\nCPU\\n \\ncan\\n \\nexecute\\n \\nonly\\n \\none\\n \\ninstruction\\n \\nflow\\n \\nat\\n \\na\\n \\ntime\\n \\n(ignoring\\n \\nmulti-core\\n \\nscenarios).\\n \\nThe\\n \\ngoal\\n \\nis\\n \\nto\\n \\nmaximize\\n \\nCPU\\n \\nutilization,\\n \\nthroughput,\\n \\nand\\n \\nresponsiveness.\\n \\nCommon  scheduling  algorithms  include:  \\n1.  First-Come,  First-Served  (FCFS):  \\n \\nThe\\n \\nsimplest\\n \\nalgorithm\\n \\nwhere\\n \\nthe\\n \\nfirst\\n \\nprocess\\n \\nto\\n \\narrive\\n \\nis\\n \\nthe\\n \\nfirst\\n \\nto\\n \\nexecute.\\n \\nIt\\n \\nsuffers\\n \\nfrom\\n \\nthe\\n \\n\"convoy\\n \\neffect,\"\\n \\nwhere\\n \\na\\n \\nlong\\n \\njob\\n \\ndelays\\n \\nall\\n \\nothers.\\n \\n 2.  Shortest  Job  First  (SJF):  \\n \\nPrioritizes\\n \\nprocesses\\n \\nwith\\n \\nthe\\n \\nsmallest\\n \\nexecution\\n \\ntime.\\n \\nIt\\n \\nreduces\\n \\nwaiting\\n \\ntime\\n \\nbut\\n \\nrequires\\n \\npredicting\\n \\nprocess\\n \\nburst\\n \\ntime.\\n \\n 3.  Round  Robin  (RR):  \\n \\nEach\\n \\nprocess\\n \\ngets\\n \\na\\n \\nfixed\\n \\ntime\\n \\nslice\\n \\n(quantum).\\n \\nIt\\n \\nis\\n \\nideal\\n \\nfor\\n \\ntime-sharing\\n \\nsystems\\n \\nbecause\\n \\nno\\n \\nprocess\\n \\ncan\\n \\nmonopolize\\n \\nthe\\n \\nCPU.\\n \\n 4.  Priority  Scheduling:  \\n \\nEach\\n \\nprocess\\n \\nis\\n \\nassigned\\n \\na\\n \\npriority.\\n \\nThe\\n \\nCPU\\n \\nselects\\n \\nthe\\n \\nhighest-priority\\n \\nprocess.\\n \\nIt\\n \\nmay\\n \\nlead\\n \\nto\\n \\nstarvation\\n \\nif\\n \\nlow-priority\\n \\nprocesses\\n \\nnever\\n \\nexecute.\\n \\n 5.  Multilevel  Queue  Scheduling:  \\n \\nProcesses\\n \\nare\\n \\ndivided\\n \\ninto\\n \\nmultiple\\n \\nqueues\\n \\n(e.g.,\\n \\nsystem,\\n \\ninteractive,\\n \\nbatch),\\n \\neach\\n \\nwith\\n \\ndifferent\\n \\nscheduling\\n \\nrules.\\n \\n \\nUnderstanding  processes,  threads,  and  scheduling  is  crucial  because  they  determine  how  efficiently  an  \\napplication\\n \\nand\\n \\nsystem\\n \\nperform.\\n \\nMulti-threading\\n \\nimproves\\n \\nconcurrency,\\n \\nwhile\\n \\neffective\\n \\nscheduling\\n \\nensures\\n \\nfairness\\n \\nand\\n \\nmaximizes\\n \\nCPU\\n \\nusage.'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 0, 'page_label': '1', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='Natural Language Processing: State of The Art, Current Trends and \\nChallenges \\nDiksha Khurana1, Aditya Koli1, Kiran Khatter1,2\\n and Sukhdev Singh1,2\\n \\n1Department of Computer Science and Engineering \\nManav Rachna International University, Faridabad-121004, India \\n2Accendere Knowledge Management Services Pvt. Ltd., India \\n \\nAbstract  \\nNatural language processing  (NLP) has recently gained much attention for representing and \\nanalysing human language computational ly. It has spread its applications in various field s \\nsuch as machine translation, email spam detection, information extraction, summarization, \\nmedical, and question answering etc. The paper distinguishes four phases by discussing \\ndifferent levels of NLP and components of Natural Language Generation (NLG) followed by \\npresenting the history and evolution of NLP , state of the art presenting the various \\napplications of NLP and current trends and challenges.  \\n \\n1. Introduction \\nNatural Language Processing (NLP) is a  tract of Artificial Intelligence and Linguistics, \\ndevoted to make computers understand the statements or words written in human languages. \\nNatural language processing came into existence to ease  the user’s work and to satisfy the \\nwish to communicate with the computer  in natural language. Since all the user s may not be \\nwell-versed in machine specific language , NLP caters those users  who do not have enough \\ntime to learn new languages or get perfection in it.  \\nA language can be defined as  a set of rules or set of symbol.  Symbol are combined and used \\nfor conveying information or broadcasting t he information.  Symbols are tyrannized by the \\nRules. Natural Language P rocessing basically can be classified in to two parts i.e. Natural \\nLanguage Understanding and Natural Language G eneration which evolves the task to \\nunderstand and generate the text (Figure 1).'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 1, 'page_label': '2', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='Figure 1. Broad Classification of NLP \\nLinguistics is the science of language which includes Phonology that refers to sound, \\nMorphology word formation, Syntax sentence structure, Semantics syntax and Pragmatics \\nwhich refers to understanding. \\nNoah Chomsky, one of the first linguists of twelfth century that started syntactic theories, \\nmarked a unique position in the field of theoretical linguistics because he revolutionise d the \\narea of syntax (Chomsky, 1965) [1]. Which can be broadly categorized into two levels Higher \\nLevel which include speech recognition and Lower L evel which corresponds to natural \\nlanguage. Few of t he researched tasks of NLP are Automatic S ummarization, Co-Reference \\nResolution, Discourse Analysis, Machine Translation, Morphological Segmentation, Named \\nEntity Recognition, Optical Character R ecognition, Part Of S peech Tagging etc. Some of \\nthese tasks have direct real world applications  such as Machine translation, N amed entity \\nrecognition, Optical character recognition etc. Automatic summarization produces an \\nunderstandable summary of a set of text  and provides summaries or detailed information of \\ntext of a known typ e. Co-reference resolution it refers to a sentence or larger set of text that \\ndetermines which word refer to the same object. Discourse analysis  refers to the task of \\nidentifying the discourse struc ture of connected text. Machine translation which refers to \\nautomatic translation of text from one human language to another . Morphological \\nsegmentation which refers to separate word into individual morphemes and identify the class \\nof the morphemes. Named entity recognition (NER) it describes a stream of text, determine \\nwhich items in the text relates to proper names. Optical character recognition (OCR) it gives \\nan image representing print ed text, which  help in determining the corresponding or related \\ntext. Part of speech tagging  it describes a sentence, determines the part of speech for each \\nword. Though NLP tasks are obviously very closely interweaved  but they are used \\nfrequently, for convenience. Some of the task such as automatic summarisation, co-reference \\nanalysis etc. act as subtask that are used in solving larger tasks.'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 2, 'page_label': '3', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='The goal of Natural Language Processing is to accommodate one or more specialities of an \\nalgorithm or system.  The metric of NLP assess on an algorithmic system allows for the \\nintegration of  language understanding  and language generation.  It is even used in \\nmultilingual event detection Rospocher et al. [2] purposed a novel modular system for cross -\\nlingual event extraction for English,  Dutch and Italian texts by using different pipelines for \\ndifferent languages. The system incorporates a modular set of foremost multilingual Natural \\nLanguage Processing (NLP) tools. The pipeline integrates modules for basic NLP processing \\nas well as more advanced tasks such as cro ss-lingual named entity linking,  semantic role \\nlabelling and time normalization. Thus, the cross-lingual framework allows for the \\ninterpretation of events, participants, locations and time, as well as the relations between \\nthem. Output of these individual pipelines is intended to be used as input for a system that \\nobtains event centric knowledge grap hs. All modules behave like UNIX pipes: they all take \\nstandard input, to do some annotation, and produce standard output which in turn is the input \\nfor the next module pipelines are built as a data centric architecture so that modu les can be \\nadapted and replaced . Furthermore, modular architecture allows for different configurations \\nand for dynamic distribution. \\nMost of the work in Natural Language Processing is conducted by computer scientists while \\nvarious other professionals have also shown interest such as linguistics, psychologist and \\nphilosophers etc. One of the most ironical aspect of NLP is that it adds up  to the knowledge \\nof human language.  The field of Natural Language Processing is related with different \\ntheories and techniques  that deal with the problem of natural language of communicating \\nwith the computers . Ambiguity is one of the ma jor problem of nat ural language which is \\nusually faced in syntactic level which has subtask as lexical and morphology which are \\nconcerned with the study of words and word formation. Each of these levels can produce \\nambiguities that can be solved by the knowledge of the comp lete sentence.  The ambiguity \\ncan be solved by various methods such as  Minimising Ambiguity, Preserving Ambiguity, \\nInteractive Disambiguity and Weighting Ambiguity [3].  Some of the methods proposed by \\nresearchers to remove ambiguity is  preserving ambiguity,  e.g. (Shemtov 1997 ; Emele & \\nDorna 1998; Knight & Langkilde 2000) [3][4][5] Their objectives are closely in line with the \\nlast of these: they cover a wide range of ambiguities and there is a statistical element implicit \\nin their approach.  \\n2. Levels of NLP \\nThe ‘levels of language’ are one of the most explanatory method for representing the Natural \\nLanguage processing  which helps to generate the NLP text by realising Content Planning, \\nSentence Planning and Surface Realization phases (Figure 2).'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 3, 'page_label': '4', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='Figure 2. Phases of NLP architecture \\nLinguistic is the science which involves meaning of language, language context and various \\nforms of the language. The various important terminologies of Natural Language Processing \\nare: - \\n1. Phonology \\nPhonology is the part of Linguistics which refers to the systematic arrangement of sound. The \\nterm phonology  comes from  Ancient Greek  and the term phono - which me ans voice or \\nsound, and the suffix –logy refers to word or speech. In 1993 Nikolai Trubetzkoy stated that \\nPhonology is “the study of sound pertaining to the system of la nguage\". Whereas Lass in \\n1998 wrote that phonology refers broadly with the sounds of language, concerned with the to \\nlathe sub discipline of linguistics , whereas it could be explained as , \"phonology proper is \\nconcerned with the function, behaviour and orga nization of sounds as  linguistic items. \\nPhonology include semantic use of sound to encode meaning of any Human language.  \\n(Clark et al.,2007) [6]. \\n2. Morphology \\nThe different parts of the word represent the smallest units of meaning known as Morphemes. \\nMorphology which comprise of Nature of words, are initiated by morphemes. An example of \\nMorpheme could be, the word pre cancellation can be morphologically scrutinized into three \\nseparate morphemes: the prefix pre, the root cancella, and the suf fix -tion. The interpretation \\nof morpheme stays same across all the words, just to understand the meaning humans can \\nbreak any unknown word into morphemes.  For example, adding the suffix –ed to a verb, \\nconveys that the action of the verb took place in the past. The words that cannot be divided \\nand have meaning by themselves are called Lexical morpheme (e.g.: table, chair) The words \\n(e.g. -ed, -ing, -est, -ly, -ful) that are combined with the lexical morpheme  are known as \\nGrammatical morphemes  (eg. Worked, C onsulting, Smallest , Likely, Use ). Those \\ngrammatical morphemes that occurs in combi nation called bound morphemes ( eg. -ed, -ing) \\nGrammatical morphemes can be divided into bound morphemes and derivational morphemes.'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 4, 'page_label': '5', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='3. Lexical \\nIn Lexical,  humans, as well a s NLP systems, interpret the meaning of individual words.  \\nSundry types of processing bestow to word-level understanding – the first of these being a \\npart-of-speech tag to each word. In this processing, words that can act as more than one part-\\nof-speech are assigned the most probable part -of speech tag based on th e context in which \\nthey occur. At the lexical level,  Semantic representations can be replaced by the words that \\nhave one meaning . In NLP system , the nature of the  representation varies according to the \\nsemantic theory deployed. \\n4. Syntactic \\nThis level emphasis to scrutinize the words in a sentence so as to uncover the grammatical \\nstructure of the sentence. Both grammar and parser  are required in this level . The output  of \\nthis level of processing is representation of the sentence that divulge the structural \\ndependency relationships between the words. There are various grammars that can be \\nimpeded, and which in twirl, whack the option of a parser. Not all NLP applications require a \\nfull parse of sentences, therefore the abide challenges in parsing of prepositional phrase \\nattachment and conjunction audit no longer impede that plea for which phrasal and clausal \\ndependencies are adequate [7]. Syntax conveys meaning in most languages because order and \\ndependency contribute to connotation. For example, the two sentences: ‘The cat chased the \\nmouse.’ and ‘The mouse chased the cat.’ differ only in terms of syntax, yet convey quite \\ndifferent meanings. \\n5. Semantic \\nIn semantic most people think that meaning is determined, however,  this is not  it is all the \\nlevels that bestow to meaning. Semantic processing determines the possible meanings of a \\nsentence by pivoting on the interactions among word -level meanings in the sentence. Th is \\nlevel of processing can incorporate  the semantic disambiguation of wo rds with multiple \\nsenses; in a cognate way to how syntactic disambiguation of words that can errand as \\nmultiple parts -of-speech is adroit at the syntactic level.  For example, amongst o ther \\nmeanings, ‘file’ as a noun can mean either a binder for gathering papers, or a tool to form \\none’s fingernails, or a  line of individuals in a queue ( Elizabeth D. Liddy ,2001) [7]. The \\nsemantic level scrutinizes words for their dictionary elucidation, but also for the elucidation \\nthey derive from the milieu of the sentence. Semantics milieu that most words have more \\nthan one elucidation but that we can spot the appropriate one by looking at the rest of the \\nsentence. [8] \\n6. Discourse \\nWhile syntax and semantic s travail with sentence -length units, the discourse level of NLP \\ntravail with units of text longer than a sentence i.e, it does not interpret multi sentence texts as \\njust sequence sentences, apiece of which can be elucidated singly. Rather, discourse focuses \\non the properties of the text as a whole that convey meaning by making connections between \\ncomponent sentences (Elizabeth D. Liddy,2001) [7]. The two of the most common levels are  \\nAnaphora Resolution  - Anaphora resolution  is the replacing of words such as pronouns, \\nwhich are semantically stranded, with the pertinent entity to which they refer. Discourse/Text \\nStructure Recognition - Discourse/text structure recognition sway the functions of sentences \\nin the text, which, in turn, adds to the meaningful representation of the text. \\n7. Pragmatic:'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 5, 'page_label': '6', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='Pragmatic is concerned with the firm use of language in situations and utilizes nub over and \\nabove the nub of the text for understanding the goal and to explain how extra meaning is read \\ninto texts without literally being encoded in them. This requisite much world knowledge, \\nincluding the understanding of intenti ons, plans, and goals . For example, the following two \\nsentences need aspiration of the anaphoric term ‘they’, but this aspiration requires pragmatic \\nor world knowledge (Elizabeth D. Liddy,2001) [7]. \\n3. Natural Language Generation \\nNatural Language Generation (NLG) is the process of producing phrases, sentences and \\nparagraphs that are meaningful from an internal representation. It is a part of Natural \\nLanguage Processing  and happens in four phases: identifying the goals, planning on how \\ngoals maybe achieved by evaluating the situation and available communicative sources and \\nrealizing the plans as a text [Figure 3]. It is opposite to Understanding. \\n \\n                                      Figure 3. Components of NLG \\nComponents of NLG are as follows: \\nSpeaker and Generator  – To generate a text we need to have a speaker or an application \\nand a generator or a program  that renders the applicatio n’s intentions into fluent phrase \\nrelevant to the situation.  \\nComponents and Levels of Representation  -The process of language generation involves \\nthe following interweaved tasks. Content selection:  Information should be selected and \\nincluded in the set. D epending on how this information is parsed into representational units, \\nparts of the units may have to be removed while some  others may be added by default. \\nTextual Organization: The information must be textually organized according the grammar, it \\nmust be  ordered both sequentially and in terms of linguist ic relations like modifications. \\nLinguistic Resources: To support the information’s realization, linguistic resources must be'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 6, 'page_label': '7', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='chosen. In the end these resources will come down to choices of particular words, idioms, \\nsyntactic constructs etc.  Realization: The selected and organized resources must be realized \\nas an actual text or voice output.  \\nApplication or Speaker –  This is only for maintaining the model of the situation. Here the \\nspeaker just initiat es the process doesn’t take part in the language generation. It stores the \\nhistory, structures the content that is potentially relevant and deploys a representation of what \\nit actually knows. All these form the situation, while selecting subset of proposit ions that \\nspeaker has. The only requirement is the speaker has to make sense of the situation. [9]  \\n4. History of NLP \\nIn late 1940s the term wasn’t even in existence, but the work regarding machine translation \\n(MT) had started. Research in this period was not  completely localised. Russian and English \\nwere the dominant languages for MT , but others, like Chinese  were used for MT  (Booth \\n,1967) [10]. MT/NLP research was almost died in 1966 according to ALPAC report, which \\nconcluded that MT is going nowhere. But later on some MT production systems were \\nproviding output to their customers (Hutchins, 1986)  [11]. By this time, work on the use of \\ncomputers for literary and linguistic studies had also started.  \\nAs early as 1960 signature work influenced by AI began, wi th the BASEBALL Q-A systems \\n(Green et al., 1961) [12]. LUNAR (Woods ,1978) [13] and Winograd SHRDLU were natural \\nsuccessors of these systems but they were seen as stepped up sophistication, in terms of their \\nlinguistic and their task processing capabilitie s. There was a widespread belief that progress \\ncould only be made on the two sides, one is ARPA Speech Understanding Research (SUR) \\nproject (Lea, 1980) and other in some major system developments projects building database \\nfront ends . The front-end projects (Hendrix et al., 1978)  [14] were intended to go beyond \\nLUNAR in interfacing the large databases. \\nIn early 1980s computational grammar theory became a very active area of research linked \\nwith logics for meaning and knowledge’s ability to deal with the user’s beliefs and intentions \\nand with functions like emphasis and themes. \\nBy the end of the decade the powerful general purpose sentence processors like SRI’s Core \\nLanguage Engine (Alshawi,1992)  [15] and Discourse Representation Theory (Kamp and \\nReyle,1993) [16] offered a means of tackling more extended discourse within the \\ngrammatico-logical framework. This period was one of the growing community. Practical \\nresources, grammars, and tools and parsers became available (e.g the Alvey Natural \\nLanguage Tools (Briscoe et al., 1987)  [17]. The (D)ARPA speech recognition and message \\nunderstanding (information extraction ) conferences were not only for the tasks they \\naddressed but for the emphasis on heavy evaluation, starting a trend that became a major \\nfeature in 1990s (Young and Chase, 1998; Sundheim and Chinchor ,1993) [18][19]. Work on \\nuser modelling (Kobsa and Wahlster , 1989)  [20]  was one strand in research paper and on \\ndiscourse structure serving this (Cohen et al., 1990)   [21]. At the same time , as McKeown  \\n(1985) [22] showed, rhetorical schemas could be used for producing both linguistically \\ncoherent and communicatively effective text. Some researches in NLP marked important \\ntopics for future like word sense disambiguation (Small et al., 1988)  [23] and probabilistic \\nnetworks, statistically coloured NLP, the work on the lexicon, also pointed in this direction.'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 7, 'page_label': '8', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='Statistical language processing was a major thing in 9 0s (Manning and Schuetze,1999)  [24], \\nbecause this not only involves data analysts. Information extraction and automatic \\nsummarising (Mani and Maybury ,1999) [25] was also a point of focus. \\nRecent researches are mainly focused on unsupervised and semi -supervised learning \\nalgorithms. \\n5. Related Work \\nMany researchers worked on NLP , building tools and systems which makes NLP what it is \\ntoday. Tools like Sentiment Analyser , Parts of Speech (POS)Taggers, Chunking, Named \\nEntity Recognitions (NER), Emotion detection , Semantic Role Labelling made NLP a good \\ntopic for research.  \\nSentiment analyser (Jeonghee etal.,2003)  [26] works by extracting sentiments about given \\ntopic. Sentiment analysis consists of a topic specific feature term extraction, sentiment \\nextraction, and association by relationship analysis. Sentiment Analysis utilizes two linguistic \\nresources for the analysis: the sentiment lexicon and the sentiment pattern database. It \\nanalyses the documents for positive and negative words and try to give ratings on scale -5 to \\n+5. \\nParts of speech taggers for the languages like European languages, research is being done on \\nmaking parts of speech taggers for other languages like Arabic, Sanskrit (Namrata Tapswi , \\nSuresh Jain ., 2012) [27], Hindi (Pradipta Ranjan Ray et al., 2003 ) [28] etc. It can efficiently \\ntag and classify words as nouns, adjectives, verbs etc. The most procedures for part of speech \\ncan work efficiently on European languages, but it won’t on Asian languages or middle \\neastern languages. Sanskrit part of speech tagger is specifically uses treebank technique. \\nArabic uses Support Vector Machine (SVM)  (Mona Diab etal., 2004) [29] approach to \\nautomatically tokenize, parts of speech tag and annotate base phrases in Arabic text. \\n \\nChunking – it is also known as Shadow Parsing, it works by labelling segments of sentences \\nwith syntactic correlated keywords like Noun Phrase and Verb Phrase (NP or VP). Every \\nword has a unique tag often marked as Begin Chunk (B -NP) tag or Inside Chunk (I -NP) tag. \\nChunking is often evaluated using the CoNLL 2000 shared task.   CoNLL 2000 provides test \\ndata for Chunking.  Since then, a certain numb er of systems arised (Sha and Pereira, 2003; \\nMcDonald et al., 2005; Sun et al., 2008)  [30] [31] [32], all reporting around 94.3% F1 score. \\nThese systems use features composed of words, POS tags, and tags. \\n \\nUsage of Named Entity Recognition in places such as Internet is a problem as people don’t \\nuse traditional or standard  English. This degrades the performance of standard natural \\nlanguage processing tools substantially. By annotating the phrases or tweets and building \\ntools trained on unlabelled, in domain and out domain data (Alan Ritter., 2011)  [33]. It \\nimproves the performance as compared to standard natural language processing tools. \\n \\nEmotion Detection (Shashank Sharma , 2016) [34] is similar to sentiment analysis, but it \\nworks on social media platforms on mixing of two languages (English + Any other Indian \\nLanguage). It categorizes statements into six groups based on emotions. During this process, \\nthey were able to identify the language of ambiguous words which were common in Hindi \\nand English and tag lexical category or parts of speech in mixed script by identifying the base \\nlanguage of the speaker.'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 8, 'page_label': '9', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='Sematic Role Labelling – SRL works by giving a semantic role to a sentence. For example in \\nthe PropBank (Palmer et al., 2005)  [35] formalism, one assigns roles to words that are \\narguments of a verb in the sentence. The precise arguments depend on verb frame and if there \\nexists multiple verbs  in a sentence, it might have multiple tags. State-of-the-art SRL systems \\ncomprise of several stages: creating a parse tree, identifying which parse tree nodes represent \\nthe arg uments of a given verb, and finally classifying these nodes to comp ute the \\ncorresponding SRL tags. \\n \\nEvent discovery in social media feeds (Edward Benson et al., 2011) [36], using a graphical \\nmodel to analyse any social media feeds to determine whether it contains name of a person or \\nname of a venue, place, time etc. The model operates on noisy feeds of data to extract records \\nof events by aggregating multiple information ac ross multiple messages, despite the noise of \\nirrelevant noisy messages and very irregular message language, this model was able to extract \\nrecords with high accuracy. However, there is some scope for improvement using broader \\narray of features on factors. \\n \\n6. Applications of NLP \\nNatural Language Processing can be applied into various areas like Machine Translation, \\nEmail Spam detection, Information Extraction, Summarization, Question Answering etc. \\n6.1 Machine Translation  \\nAs most of the world is online, the task of making data accessible and available to all is a \\nchallenge. Major challenge in making data accessible is the language barrier. There are \\nmultitude of languages with different sentence structure and grammar. Machine Translation is \\ngenerally translating phrases from one language to another with the help of a statistical \\nengine like Google Translate. The challenge with machine translation technologies is not \\ndirectly translating words but keeping the meaning of sente nces intact along with grammar \\nand tenses. The statistical machine learning gathers as many data as they can find that seems \\nto be parallel between two languages and they crunch their data to find the likelihood that \\nsomething in Language A corresponds to something in Language B. As for Google, in \\nSeptember 2016, announced a new machine translation system based on Artificial neural \\nnetworks and Deep learning . In recent years, various methods have been proposed to \\nautomatically evaluate machine translation quality by comparing hypothesis translations with \\nreference translations. Examples of such methods are word error rate, position -independent \\nword error rate (Tillmann et al., 1997)  [37], generation string accuracy (Bangalore et al., \\n2000) [38], multi-reference word error rate (Nießen et al., 2000)  [39], BLEU score (Papineni \\net al., 2002) [40], NIST score (Doddington, 2002)  [41]  All these criteria try to approximate \\nhuman assessment and often achieve an astonishing degree of correlation to human subjective \\nevaluation of fluency and adequacy (Papineni et al., 2001; Doddington, 2002) [42][43].  \\n6.2 Text Categorization  \\nCategorization systems inputs a large flow of data like official documents, military casualty \\nreports, market data, newswires etc. and assign them to predefined categories or indices. For \\nexample, The Carnegie Group’s Construe system (Hayes PJ ,Westein ; 1991) [44] , inputs \\nReuters articles and saves much time by doing the work that is to be done by staff or human'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 9, 'page_label': '10', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='indexers. Some companies have been us ing categorization systems to categorize trouble \\ntickets or complaint requests and routing to the appropriate desks. Another application of text \\ncategorization is email spam filters. Spam filters is becoming important as the first line of \\ndefence against the unwanted emails. A false negative and false positive issues of spam filters \\nare at the heart of NLP technology, its brought down to the challenge of extracting meaning \\nfrom strings of text. A filtering solution that is applied to an email system uses a set of \\nprotocols to determine which of the incoming messages are spam and which are not. There \\nare several types of spam filters available. Content filters : Review the content within the \\nmessage to determine whether it is a spam or not . Header filters: Review the email header \\nlooking for fake information. General Blacklist filters : Stopes all emails from blacklisted \\nrecipients. Rules Based Filters : It uses user -defined criteria. Such as stopping mails from \\nspecific person or stopping mail including a specific word. Permission Filters : Require \\nanyone sending a message to be pre -approved by the recipient. Challenge Response Filters : \\nRequires anyone sending a message to enter a code in order to gain permission to send email. \\n6.3 Spam Filtering  \\nIt works using text categorization  and in recent times, various machine learning techniques \\nhave been applied to text categorization or Anti -Spam Filtering  like Ru le Learning (Cohen \\n1996)[45], Naïve Bayes (Sahami et al., 1998 ;Androutsopoulos et al.,2000b ;Rennie \\n.,2000)[46][47][48],Memory based Learning (Androutsopoulos et al.,2000b) [47], Support \\nvector machines (Druker et al., 1999)[49], Decision Trees (Carreras and Marquez , 2001)[50] \\nMaximum Entropy Model (Berger et al. 1996) [51]. Sometimes combining different learners \\n(Sakkis et al., 2001)  [52]. Using these approaches is better as classifier is learned from \\ntraining data rather than making by hand. The naïve bay es is preferred because of its \\nperformance despite its simplicity (Lewis, 1998)  [53] In Text Categorization two types of \\nmodels have been used (McCallum and Nigam, 1998) [54]. Both modules assume that a fixed \\nvocabulary is present. But in first model a document is generated by first choosing a subset of \\nvocabulary and then using the selected words any number of times, at least once irrespective \\nof order. This is called Multi -variate Bernoulli model. It takes the information of which \\nwords are used in a d ocument irrespective of number of words and order. In second model, a \\ndocument is generated by choosing a set of word occurrences and arranging them in any \\norder. this model is called multi -nomial model, in addition to the Multi -variate Bernoulli \\nmodel, it also captures information on how many times a word is used in a document. Most \\ntext categorization approaches to anti spam Email filtering have used multi variate Bernoulli \\nmodel (Androutsopoulos et al.,2000b) [47] \\n6.4 Information Extraction \\nInformation extraction is concerned with identifying phrases of interest of text ual data. For \\nmany applications, extracting entities such as names, places, events, dates, times and prices is \\na powerful way of summarize the information relevant to a user’s needs. In the cas e of a \\ndomain specific search engine, the automatic identification of important information can \\nincrease accuracy and efficiency of a directed search.  There is use of hidden Markov models \\n(HMMs) to extract the relevant fields of research papers. These extr acted text segments are'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 10, 'page_label': '11', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='used to allow searched over specific fields and to provide effective presentation of search \\nresults and to match references to papers.  For example, noticing the pop up ads on any \\nwebsites showing the recent items you might have look ed on an online store with discounts. \\nIn Information Retrieval two types of models have been used (McCallum and Nigam, 1998)  \\n[55]. Both modules assume that a fixed vocabulary is present. But in first model a document \\nis generated by first choosing a subset  of vocabulary and then using the selected words any \\nnumber of times, at least once without any order. This is called Multi -variate Bernoulli \\nmodel. It takes the information of which words are used in a document irrespective of number \\nof words and order. I n second model, a document is generated by choosing a set of word \\noccurrences and arranging them in any order. this mod el is called multi -nomial model , in \\naddition to the Multi -variate Bernoulli model , it also captures information on how many \\ntimes a word is used in a document \\nDiscovery of knowledge  is becoming important areas of research over the recent years. \\nKnowledge discovery  research use a variety of techniques in order to extract useful \\ninformation from source documents like  \\nParts of Speech (POS) tagging, Chunking or Shadow Parsing , Stop-words (Keywords that \\nare used and must be remo ved before processing documents) , Stemming (Mapping words to \\nsome base for, it has two methods , dictionary based stemming and Porter style stemming \\n(Porter, 1980) [55]. Former one has higher accuracy but higher cost of implementation while \\nlatter has lower implementation cost and is usually insufficient for IR). Compound or \\nStatistical Phrases  (Compounds and statistical phrases index multi  token unit s instead of \\nsingle tokens.) Word Sense Disambiguation  (Word sense disambiguati on is the task of \\nunderstanding the correct sense of a word in context. When used for information retrieval, \\nterms are replaced by their senses in the document vector.) \\n \\nIts extracted information c an be applied on a variety  of purpose , for example to prepare a \\nsummary, to build databases, identify keywords, classifying text items according to some pre-\\ndefined categories etc. For example   CONSTRUE, it was developed for Reuters , that is used \\nin classifying news stories  (Hayes, 1992) [57]. It has been suggested that many IE systems \\ncan successfully extract terms from documents, acquiring relations between the terms is still a \\ndifficulty. PROMETHEE  is a system that extracts lexico -syntactic patterns relative to a \\nspecific conceptual relation (Morin,1999) [58]. IE systems should work at many levels, from \\nword recognition to discourse analysis at the level of the complete document. An application \\nof the Blank Slate Language Processor (BSLP) (Bondale et al., 1999) [59] approach for the \\nanalysis of a real life natural language corpus that consists of responses to open -ended \\nquestionnaires in the field of advertising. \\nThere’s a system called MITA (Metlife’ s Intelligent Text Analyzer)  (Glasgow et al. (1998)  \\n[60]) that extracts information from  life insurance applications. Ahonen et al. (1998)  [61] \\nsuggested a mainstream framework for text mining that uses pragmatic and di scourse level \\nanalyses of text. \\n6.5 Summarization \\nOverload of information is the real thing in this digital age, and already our reach and access \\nto knowledge and information exceeds our capacity to understand it. This trend is not slowing \\ndown, so an ability to summarize the data while keeping the meanin g intact is highly'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 11, 'page_label': '12', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='required. This is important not just allowing us the ability to recognize the understand the \\nimportant information for a large set of data, it is used to understand the deeper emotional \\nmeanings; For example, a company determine the gene ral sentiment on social media and use \\nit on their latest product offering. This application is useful as a valuable marketing asset. \\nThe types of text summarization depends on the basis of the number of documents  and  the \\ntwo important categories are single document summarization and multi document \\nsummarization (Zajic et al. 2008  [62]; Fattah and Ren 2009  [63]). Summaries can also be of \\ntwo types: generic or query-focused (Gong and Liu 2001 [64]; Dunlavy et al. 2007 [65]; Wan \\n2008 [66]; Ouyang et al. 2011  [67]). Summarization task can be either supervised or \\nunsupervised (Mani and Maybury 1999  [68]; Fattah and Ren 2009  [63]; Riedhammer et al. \\n2010 [69]). Training data is required in a supervised system for selecting relevant material \\nfrom the documents. Larg e amount of annotated data is needed for learning techniques. Few \\ntechniques are as follows– \\n- Bayesian Sentence based Topic Model (BSTM)  uses both term-sentences and term \\ndocument associations for summarizing multip le documents. ( Wang et al. 2009  \\n[70])   \\n- Factorization with Given Bases  (FGB) is a language model where  sentence bases \\nare the given bases and it utilizes document -term and sentence term matrices. \\nThis approach groups and summarizes the documents simultaneously. (Wang et \\nal. 2011) [71]) \\n- Topic Aspect -Oriented Summarization  (TAOS) is based on topic factors. These \\ntopic factors are various features that describe topics such as capital words are \\nused to represent entity. Various topics can have various  aspects and various \\npreferences of features are used to represent various aspects. (Fang et al. 2015 [72]) \\n \\n6.6 Dialogue System \\nPerhaps the most desirable application of the future, in the systems envisioned by large \\nproviders of end user applications, Dialogue systems, which focuses on a narrowly defined \\napplications (like refrigerator or home theater systems) currently uses the phonetic and lexical \\nlevels of language. It is believed that these dialogue systems when utilizing all levels of \\nlanguage processing offer potential for fully automated dialog systems. (Elizabeth D. Liddy, \\n2001) [7]. Whether on text or via voice. This could  lead to produce systems that can enable \\nrobots to interact with humans in natural languages. Examples like Google’s assistant, \\nWindows Cortana, Apple’s Siri and Amazon’s Alexa are the software and devices that follow \\nDialogue systems. \\n6.7 Medicine \\nNLP is appl ied in medicine field as well. The Linguistic String Project -Medical Language \\nProcessor is one the large scale projects of NLP in the field of medicine [74][75][76][77][78]. \\nThe LSP-MLP helps enabling physicians to extract and summarize information of any signs \\nor symptoms, drug dosage and response data with aim of identifying possible side effects of \\nany medicine while highlig hting or flagging data items [74 ]. The National Library of \\nMedicine is developing The Specialist System [79][80][81][82][83]. It is expected to function \\nas Information Extraction tool for Biomedical Knowledge Bases, particularly Medline'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 12, 'page_label': '13', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='abstracts. The lexicon was created using MeSH  (Medical Subject Headings), Dorland’s \\nIllustrated Medical Dictionary and general English Dictionaries. Th e Centre d’Informatique \\nHospitaliere of the Hopital Cantonal de Geneve is working on an electronic archiving \\nenvironment with NLP features [8 4][85]. In first phase , patient records were archived . At \\nlater stage the LSP-MLP has been adapted for French [86][87][88][89] , and finally , a proper \\nNLP syste m called RECIT  [90 ][91][92][93] has been developed using a method called \\nProximity Processing [ 94]. It’s task was to implement a robust and multilingual system able \\nto analyze/comprehend medical sentences, an d to preserve a knowledge of free text into a \\nlanguage independent knowledge representation [ 95][96]. The Columbia university of New \\nYork has developed an NLP system called MEDLEE (MEDical Language Extraction and \\nEncoding System) that identifies clinical i nformation in narrative reports and transforms the \\ntextual information into structured representation [97]. \\n7. Approaches \\nRationalist approach or symbolic approach assume that crucial part of the knowledge in the \\nhuman mind is not derived by the sense but is firm in advance, probably by genetic in \\nheritance. Noam Chomsky was the strongest advocate of this approach. It was trusted that \\nmachine can be  made to function like human brain by giving some fundamental knowledge \\nand reasoning mechanism linguistics  knowledge is directly encoded in rule or other forms of \\nrepresentation. This helps automatic process of natural languages. [ 98] Statistical and \\nmachine learning entail evolution of algorithms that allow a program to infer patterns. An \\niterative process is use d to characterize a given algorithm’s underlying algorithm that are \\noptimised by a numerical measure that characterize numerical pa rameters and learning phase. \\nMachine-learning models can be predominantly categorized as either generative or \\ndiscriminative. Generative methods can generate synthetic data because of which they create \\nrich models of probability distributions. Discriminative methods are more functional and \\nhave right estimating posterior probabilities and are based on observations.  \\nSrihari [99] explains the different generative models as one with a resemblance that is used to \\nspot an unknown speaker’s language and would bid the deep knowledge of numerous \\nlanguage to perform the match. Whereas discriminative methods rely on a less knowledge -\\nintensive approach and using distinction between language.  Whereas generative models, can \\nbecome troublesome when many features are used and discriminative models allow use of \\nmore features. [ 100] Few of the examples of discriminative methods are Logistic regr ession \\nand conditional random fields (CRFs), generative methods are Naive Bayes classifiers and \\nhidden Markov models (HMMs). \\n7.1 Hidden Markov Model (HMM) \\nAn HMM is a system where a shifting takes place between several states, generating feasible \\noutput symbols with each switch. The sets of viable states and unique symbols may be large, \\nbut finite and known. We can descry the outputs, but the system’s intern als are hidden. Few \\nof the problem could be solved are by Inference A certain sequence of output symbols, \\ncompute the probabilities of one or more candidate states with sequences. Pattern matching \\nthe state -switch sequence is realised are most likely to ha ve generated a particular output -'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 13, 'page_label': '14', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='symbol sequence.  Training the output -symbol chain data, reckon the state -switch/output \\nprobabilities that fit this data best. \\nHidden Markov Models are extensively used for speech recognition, where the output \\nsequence is matched to the sequence of individual phonemes. Frederick Jelinek, a statistical -\\nNLP advocate who first instigated HMMs at IBM’s Speech Recognition Group, reportedly \\njoked, every time a linguist leaves my group, the speech recognizer’s performance improves.  \\n[101] HMM is not restricted to this application it has several others such as bioinformatics \\nproblems, for example, multiple sequence a lignment [10 2]. Sonnhammer mentioned that \\nPfam hold multiple alignments and hidden Markov model based profiles (HMM -profiles) of \\nentire protein domains. The cue of domain boundaries, family members and alignment is \\ndone semi -automatically found on expert knowledge, sequence similarity, other protein \\nfamily databases and the capability of HMM -profiles to correctly identify an d align the \\nmembers. [103]  \\n7.2 Naive Bayes Classifiers \\n The choice of area is wide ranging covering usual items like word segmentation and \\ntranslation but also unusual areas like segmentation for infant learning and identifying \\ndocuments for opinions and facts. In addition, exclusive article was selected for its use of \\nBayesian methods to aid the research in designing algorithms for their investigation. \\n8. NLP in Talk \\nThis section discuss es the recent developments in the NLP projects implemented by various \\ncompanies and these are as follows: \\n8.1 ACE Powered GDPR Robot Launched by RAVN Systems [104] \\nRAVN Systems,  an leading expert in Artificial Intelligence (AI),  Search and Knowledge \\nManagement Solutions, announced the launch of a RAVN (\"Applied Cognitive Engine\") i.e \\npowered software Robot to help and facilitate the GDPR  (\"General Data Protection \\nRegulation\") compliance. \\nThe Robot uses AI techniques to automatically analyse documents and other types of data in \\nany business system which is subject to GDPR rules.  It allows users to quickly and easily \\nsearch, retrieve, flag, classify and report on data mediated to be supersensitive under GDPR. \\nUsers also have the ability to identify personal data from documents, view feeds on the latest \\npersonal data that requires attention and provide reports on the data suggested to be deleted or \\nsecured.  RAVN\\'s GDPR Robot is also abl e to hasten requests for information (Data Subject \\nAccess Requests - \"DSAR\") in a simple and efficient way, removing the need for a physical \\napproach to these requests which tends to be very labour thorough.  Peter Wallqvist, CSO at \\nRAVN Systems commented, \"GDPR compliance is of universal paramountcy as it will \\nexploit to any organisation that control and process data concerning EU citizens. \\nLINK:http://markets.financialcontent.com/stocks/news/read/33888795/RAVN_Systems_Launch_the_ACE_Po\\nwered_GDPR_Robot \\n8.2 Eno A Natural Language Chatbot Launched by Capital One [105]'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 14, 'page_label': '15', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='Capital one announces chatbot for customers called Eno.  Eno is a natural language chatbot \\nthat people socialize through texting.  Capital one claims that Eno  is First natural language \\nSMS chatbot from a U.S. bank that allows customer to ask questions using natural language.  \\nCustomers can interact with Eno asking  questions about their savings and others using a text \\ninterface. Eno makes such an environment that it feels that a human is interacting.  Ken \\nDodelin, Capital One’s vice president of digital product development, said “We kind of \\nlaunched a chatbot and didn’t know it.”  \\nThis provides a different platform than other brands that launch chatbots like Facebook \\nMessenger and Skype.  They believed that Facebook  has too much access of private \\ninformation of a person, which could get them into trouble with privacy laws of U.S. \\nfinancial institutions work under.  Like any Facebook Page admin can access full transcripts \\nof the bot’s conversations.  If that would be the case then the admins could easily view the \\npersonal banking information of customers with is not correct \\n LINK: https://www.macobserver.com/analysis/capital-one-natural-language-chatbot-eno/ \\n8.3  Future of BI in Natural Language Processing [106] \\nSeveral companies in Bi spaces are trying to get with the trend and trying hard to ensure that \\ndata becomes more friendly and easily accessible.  But still there is long way for this.BI will \\nalso make it easier to access as GUI is not needed.  Because now a days the queries are made \\nby text or voice command on smartphones.one of the most common example is Google might \\ntell you today what will be the tomorrows  weather. But soon enough, we will be able to  ask \\nour personal data chatbot about customer sentiment today, and how do we feel about their \\nbrand next week; all while walking down the street. Today, NLP tends to be based on turning \\nnatural language into mac hine language. But with time the technology matures – especially \\nthe AI component –the computer will get better at “understanding” the query and start to \\ndeliver answers rather than search results. \\n Initially, the data chatbot will probably ask the questio n as how have revenues changed over \\nthe last three -quarters?’ and then return pages of data for you to analyse.  But once it learns \\nthe semantic relations and inferences of the question, it will be able to automatically perform \\nthe filtering and formulation necessary to provide an intelligible answer, rather than simply \\nshowing you data. \\nLink: http://www.smartdatacollective.com/eran-levy/489410/here-s-why-natural-language-processing-future-bi \\n8.4 Using Natural Language Processing and Network Analysis to \\nDevelop a Conceptual Framework for Medication  Therapy \\nManagement Research [107] \\nNatural Language Processing and Network Analysis to Develop a Conceptual Framework for \\nMedication Therapy Management Research describes a theory derivation  process that is used \\nto develop conceptual framework for medication therapy management (MTM) research.  The \\nMTM service model and chronic care model are selected a s parent theories.  Review article'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 15, 'page_label': '16', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='abstracts target medication therapy management in chronic disease care that were retrieved \\nfrom Ovid Medline (2000-2016). \\nUnique concepts in each abstract are extracted using Meta  Map and their pairwise \\ncooccurrence are de termined. Then the information is used to construct a network graph of \\nconcept co -occurrence that is further analysed to identify  content for the new conceptual \\nmodel. 142 abstracts are analysed. Medication adherence is the most studied drug therapy \\nproblem and co-occurred with concepts related to patient -centred interventions targeting self-\\nmanagement. The enhanced model consists of 65 concepts clustered into 14 constructs. The \\nframework requires additional refinement and evaluation to determine its releva nce and \\napplicability across a broad audience including underserved settings. \\nLink: https://www.ncbi.nlm.nih.gov/pubmed/28269895?dopt=Abstract \\n8.5 Meet the Pilot, world’s first language translating earbuds [108] \\nThe world’s first smart earpiece Pilot will soon be transcribed over 15 languages.  According \\nto Spring wise, Waverly Labs’ Pilot can already transliterate five spoken languages, English, \\nFrench, Italian, Portuguese and Spanish, and seven written affixed languages, German, Hindi, \\nRussian, Japanese, Arabic, Korean and Mandarin Chinese. The Pilot earpiece is connected \\nvia Bluetooth to the Pilot speech translation app, which uses speech recognitio n, machine \\ntranslation and machine learning and speech synthesis technology. \\nSimultaneously, the user will hear the translated version of the speech on the second earpiece. \\nMoreover, it is not necessary that conversation would be taking place between two p eople \\nonly the users can join in and discuss as a group. As if now the user may experience a few \\nsecond lag interpolated the speech and translation, which Waverly Labs pursue to reduce. \\nThe Pilot earpiece will be available from September, but can be pre -ordered now for $249. \\nThe earpieces can also be used for streaming music, answering voice calls and getting audio \\nnotifications. \\nLink:https://www.indiegogo.com/projects/meet-the-pilot-smart-earpiece-language-translator-\\nheadphones-travel#/ \\n \\nREFRENCES \\n[1] Chomsky, Noam, 1965, Aspects of the Theory of Syntax, Cambridge, Massachusetts: \\nMIT Press.  \\n [2] Rospocher, M., van Erp, M., Vossen, P., Fokkens, A., Aldabe,I., Rigau, G., Soroa, A., \\nPloeger, T., and Bogaard, T.(2016). Building event -centric knowledge graphs from news. \\nWeb Semantics: Science, Services and Agents on the World Wide Web, In Press. \\n[3] Shemtov, H. (1997).  Ambiguity manageme nt in natural language generation. Stanford \\nUniversity.  \\n[4] Emele, M. C., & Dorna, M. (1998, August). Ambiguity preserving machine translation \\nusing packed representations. In  Proceedings of the 36th Annual Meeting of the Association'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 16, 'page_label': '17', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='for Computational Lin guistics and 17th International Conference on Computational \\nLinguistics-Volume 1 (pp. 365-371). Association for Computational Linguistics. \\n[5] Knight, K., & Langkilde, I. (2000, July). Preserving ambiguities in generation via \\nautomata intersection. In AAAI/IAAI (pp. 697-702). \\n[6] Nation, K., Snowling, M. J., & Clarke, P. (2007). Dissecting the relationship between \\nlanguage skills and learning to read: Semantic and phonological contributions to new \\nvocabulary learning in children with poor reading compre hension. Advances in Speech \\nLanguage Pathology, 9(2), 131-139. \\n[7] Liddy, E. D. (2001). Natural language processing. \\n[8] Feldman, S. (1999). NLP Meets the Jabberwocky: Natural Language Processing in \\nInformation Retrieval. ONLINE-WESTON THEN WILTON-, 23, 62-73. \\n[9] \"Natural Language Processing.\"  Natural Language Processing RSS. N.p., n.d. Web. 25 \\nMar. 2017 \\n[10] Hutchins, W. J. (1986).  Machine translation: past, present, future  (p. 66). Chichester: \\nEllis Horwood. \\n[11] Hutchins, W. J. (Ed.). (2000).  Early years in machine translation: memoirs and \\nbiographies of pioneers (Vol. 97). John Benjamins Publishing. \\n[12] Green Jr, B. F., Wolf, A. K., Chomsky, C., & Laughery, K. (1961, May). Baseball: an \\nautomatic question-answerer. In Papers presented at the May 9 -11, 1961, western joint IRE -\\nAIEE-ACM computer conference (pp. 219-224). ACM. \\n[13] Woods, W. A. (1978). Semantics and quantification in natural language question \\nanswering. Advances in computers, 17, 1-87. \\n[14] Hendrix, G. G., Sacerdoti, E. D., Sagalowicz, D., & Slocum, J. (1978). Developing a \\nnatural language interface to complex data.  ACM Transactions on Database Systems \\n(TODS), 3(2), 105-147. \\n[15] Alshawi, H. (1992). The core language engine. MIT press. \\n[16] Kamp, H., & Reyle, U. (1993). Tense and Aspect.  In From Discourse to Logic (pp. 483-\\n689). Springer Netherlands. \\n[17] Lea , W.A Trends in speech recognition , Englewoods Cliffs , NJ: Prentice Hall , 1980. \\n[18] Young, S. J., & Chase, L. L. (1998). Speech recognition evaluation: a review of the US \\nCSR and LVCSR programmes. Computer Speech & Language, 12(4), 263-279. \\n[19] Sundheim, B. M., & Chinchor, N. A. (1993, March). Survey of the message \\nunderstanding conferences. In  Proceedings of the workshop on Human Language \\nTechnology (pp. 56-60). Association for Computational Linguistics.'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 17, 'page_label': '18', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='[20] Wahlster, W., & Kobsa, A. (1989). User models in dialog systems. In  User models in \\ndialog systems (pp. 4-34). Springer Berlin Heidelberg. \\n[21] McKeown, K.R. Text generation , Cambridge: Cambridge University Press , 1985. \\n[22] Small S.L., Cortell G.W., and Tanenhaus , M.K. Lexical Ambiguity Resolutions , San \\nMateo , CA : Morgan Kauffman, 1988. \\n[23] Manning, C. D., & Schütze, H. (1999).  Foundations of statistical natural language \\nprocessing (Vol. 999). Cambridge: MIT press. \\n[24] Mani, I., & Maybury, M. T. (Eds.). (1999).  Advances in automatic text \\nsummarization (Vol. 293). Cambridge, MA: MIT press. \\n[25] Yi, J., Nasukawa, T., Bunescu, R., & Niblack, W. (2003, November). Sentiment \\nanalyzer: Extracting sentiments about a given topi c using natural language processing \\ntechniques. In Data Mining, 2003. ICDM 2003. Third IEEE International Conference on  (pp. \\n427-434). IEEE. \\n[26] Yi, J., Nasukawa, T., Bunescu, R., & Niblack , W. (2003, November). Sentiment \\nanalyzer: Extracting sentiments about a given topic using natural language processing \\ntechniques. In Data Mining, 2003. ICDM 2003. Third IEEE International Conference on  (pp. \\n427-434). IEEE. \\n[27] Tapaswi, N., & Jain, S. (20 12, September). Treebank based deep grammar acquisition \\nand Part -Of-Speech Tagging for Sanskrit sentences. In  Software Engineering (CONSEG), \\n2012 CSI Sixth International Conference on (pp. 1-4). IEEE. \\n[28] Ranjan, P., & Basu, H. V. S. S. A. (2003). Part of  speech tagging and local word \\ngrouping techniques for natural language parsing in Hindi. In  Proceedings of the 1st \\nInternational Conference on Natural Language Processing (ICON 2003). \\n[29] Diab, M., Hacioglu, K., & Jurafsky, D. (2004, May). Automatic tagg ing of Arabic text: \\nFrom raw text to base phrase chunks. In  Proceedings of HLT -NAACL 2004: Short \\npapers (pp. 149-152). Association for Computational Linguistics. \\n[30] Sha, F., & Pereira, F. (2003, May). Shallow parsing with conditional random fields. \\nIn Proceedings of the 2003 Conference of the North American Chapter of the Association for \\nComputational Linguistics on Human Language Technology -Volume 1  (pp. 134 -141). \\nAssociation for Computational Linguistics. \\n[31] McDonald, R., Crammer, K., & Pereira, F. (2 005, October). Flexible text segmentation \\nwith structured multilabel classification. In  Proceedings of the conference on Human \\nLanguage Technology and Empirical Methods in Natural Language Processing  (pp. 987 -\\n994). Association for Computational Linguistics. \\n[32] Sun, X., Morency, L. P., Okanohara, D., & Tsujii, J. I. (2008, August). Modeling latent -\\ndynamic in shallow parsing: a latent conditional model with improved inference.'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 18, 'page_label': '19', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='In Proceedings of the 22nd International Conference on Computational Linguistics-Volume \\n1 (pp. 841-848). Association for Computational Linguistics. \\n[33] Ritter, A., Clark, S., & Etzioni, O. (2011, July). Named entity recognition in tweets: an \\nexperimental study. In  Proceedings of the Conference on Empirical Methods in Natur al \\nLanguage Processing (pp. 1524-1534). Association for Computational Linguistics. \\n[34] Sharma, S. , Srinivas,  PYKL, &  Balabantaray, RC (2016). Emotion Detection using \\nOnline Machine Learning Method and TLBO on Mixed Script. In Proceedings of Language \\nResources and Evaluation Conference 2016 (pp. 47-51). \\n[35] Palmer, M., Gildea, D., & Kingsbury, P. (2005). The proposition bank: An annotated \\ncorpus of semantic roles. Computational linguistics, 31(1), 71-106. \\n[36] Benson, E., Haghighi, A., & Barzilay, R. (2011, June). Event discovery in social media \\nfeeds. In  Proceedings of the 49th Annual Meeting of the Association for Computational \\nLinguistics: Human Language Technologies -Volume 1  (pp. 389 -398). Association for \\nComputational Linguistics. \\n[37] Tillmann, C ., Vogel, S., Ney, H., Zubiaga, A., & Sawaf, H. (1997, September). \\nAccelerated DP based search for statistical translation. In Eurospeech. \\n[38] Bangalore, S., Rambow, O., & Whittaker, S. (2000, June). Evaluation metrics for \\ngeneration. In  Proceedings of the first international conference on Natural language \\ngeneration-Volume 14 (pp. 1-8). Association for Computational Linguistics \\n[39] Nießen, S., Och, F. J., Leusch, G., & Ney, H. (2000, May). An Evaluation Tool for \\nMachine Translation: Fast Evaluation for MT Research. In LREC \\n[40] Papineni, K., Roukos, S., Ward, T., & Zhu, W. J. (2002, July). BLEU: a method for \\nautomatic evaluation of machine translation. In  Proceedings of the 40th annual meeting on \\nassociation for computational linguistics  (pp. 311 -318). Association for Computational \\nLinguistics \\n[41] Doddington, G. (2002, March). Automatic evaluation of machine translation quality \\nusing n-gram co-occurrence statistics. In  Proceedings of the second international conference \\non Human Language Technology Research (pp. 138-145). Morgan Kaufmann Publishers Inc  \\n[42] Papineni, K., Roukos, S., Ward, T., & Zhu, W. J. (2002, July). BLEU: a method for \\nautomatic evaluation of machine translation. In  Proceedings of the 40th annual meeting on \\nassociation for computationa l linguistics  (pp. 311 -318). Association for Computational \\nLinguistics \\n[43] Doddington, G. (2002, March). Automatic evaluation of machine translation quality \\nusing n-gram co-occurrence statistics. In  Proceedings of the second international conference \\non Human Language Technology Research (pp. 138-145). Morgan Kaufmann Publishers Inc'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 19, 'page_label': '20', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='[44] Hayes, P. J. (1992). Intelligent high -volume text processing using shallow, domain -\\nspecific techniques.  Text-based intelligent systems: Current research and practice in \\ninformation extraction and retrieval, 227-242. \\n[45] Cohen, W. W. (1996, March). Learning rules that classify e -mail. In  AAAI spring \\nsymposium on machine learning in information access (Vol. 18, p. 25). \\n[46] Sahami, M., Dumais, S., Heckerman, D., &  Horvitz, E. (1998, July). A Bayesian \\napproach to filtering junk e -mail. In Learning for Text Categorization: Papers from the 1998 \\nworkshop (Vol. 62, pp. 98-105). \\n[47] Androutsopoulos, I., Paliouras, G., Karkaletsis, V., Sakkis, G., Spyropoulos, C. D., & \\nStamatopoulos, P. (2000). Learning to filter spam e -mail: A comparison of a naive bayesian \\nand a memory-based approach. arXiv preprint cs/0009009. \\n[48] Rennie, J. (2000, August). ifile: An application of machine learning to e -mail filtering. \\nIn Proc. KDD 2000 Workshop on Text Mining, Boston, MA \\n[49] Drucker, H., Wu, D., & Vapnik, V. N. (1999). Support vector machines for spam \\ncategorization. IEEE Transactions on Neural networks, 10(5), 1048-1054 \\n[50] Carreras, X., & Marquez, L. (2001). Boosting trees for ant i-spam email filtering.  arXiv \\npreprint cs/0109015 \\n[51] BERGER, A. L., DELLA PIETRA, S. A., AND DELLA PIETRA, V. J. 1996. A \\nmaximum entropy approach to natural language processing. Computational Linguistics 22, 1, \\n39–71 \\n[52] Sakkis, G., Androutsopoulos, I.,  Paliouras, G., Karkaletsis, V., Spyropoulos, C. D., & \\nStamatopoulos, P. (2001). Stacking classifiers for anti-spam filtering of e-mail. arXiv preprint \\ncs/0106040.. \\n[53] Lewis, D. D. (1998, April). Naive (Bayes) at forty: The independence assumption in \\ninformation retrieval. In  European conference on machine learning  (pp. 4 -15). Springer \\nBerlin Heidelberg \\n[54] McCallum, A., & Nigam, K. (1998, July). A comparison of event models for naive bayes \\ntext classification. In  AAAI-98 workshop on learning for text ca tegorization (Vol. 752, pp. \\n41-48). \\n[55] McCallum, A., & Nigam, K. (1998, July). A comparison of event models for naive bayes \\ntext classification. In  AAAI-98 workshop on learning for text categorization  (Vol. 752, pp. \\n41-48). \\n[56] Porter, M. F. (1980). An algorithm for suffix stripping. Program, 14(3), 130-137'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 20, 'page_label': '21', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='[57] Hayes, P. J. (1992). Intelligent high -volume text processing using shallow, domain -\\nspecific techniques.  Text-based intelligent systems: Current research and practice in \\ninformation extraction and retrieval, 227-242 \\n[58] Morin, E. (1999, August). Automatic acquisition of semantic relations between terms \\nfrom technical corpora. In  Proc. of the Fifth International Congress on Terminology and \\nKnowledge Engineering-TKE’99. \\n[59] Bondale, N., Maloor, P.,  Vaidyanathan, A., Sengupta, S., & Rao, P. V. (1999). \\nExtraction of information from open -ended questionnaires using natural language processing \\ntechniques. Computer Science and Informatics, 29(2), 15-22 \\n[60] Glasgow, B., Mandell, A., Binney, D., Ghemri, L ., & Fisher, D. (1998). MITA: An \\ninformation-extraction approach to the analysis of free -form text in life insurance \\napplications. AI magazine, 19(1), 59. \\n[61] Ahonen, H., Heinonen, O., Klemettinen, M., & Verkamo, A. I. (1998, April). Applying \\ndata mining techniques for descriptive phrase extraction in digital document collections. \\nIn Research and Technology Advances in Digital Libraries, 1998. ADL 98. Proceedings. \\nIEEE International Forum on (pp. 2-11). IEEE. \\n[62] Zajic, D. M., Dorr, B. J., & Lin, J. (2008 ). Single -document and multi -document \\nsummarization techniques for email threads using sentence compression.  Information \\nProcessing & Management, 44(4), 1600-1610. \\n[63] Fattah, M. A., & Ren, F. (2009). GA, MR, FFNN, PNN and GMM based models for \\nautomatic text summarization. Computer Speech & Language, 23(1), 126-144. \\n[64] Gong, Y., & Liu, X. (2001, September). Generic text summarization using relevance \\nmeasure and latent semantic analysis. In  Proceedings of the 24th annual international ACM \\nSIGIR conference on Research and development in information retrieval (pp. 19-25). ACM. \\n[65] Dunlavy, D. M., O’Leary, D. P., Conroy, J. M., & Schlesinger, J. D. (2007). QCS: A \\nsystem for querying, clustering and summarizing documents.  Information processing & \\nmanagement, 43(6), 1588-1605. \\n[66] Wan, X. (2008). Using only cross -document relationships for both generic and topic -\\nfocused multi-document summarizations. Information Retrieval, 11(1), 25-49. \\n[67] Ouyang, Y., Li, W., Li, S., & Lu, Q. (2011). Applying regression models to query -\\nfocused multi-document summarization. Information Processing & Management,  47(2), 227-\\n237. \\n[68] Mani, I., & Maybury, M. T. (Eds.). (1999).  Advances in automatic text \\nsummarization (Vol. 293). Cambridge, MA: MIT press.'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 21, 'page_label': '22', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='[69] Riedhammer, K., F avre, B., & Hakkani -Tür, D. (2010). Long story short –global \\nunsupervised models for keyphrase based meeting summarization.  Speech \\nCommunication, 52(10), 801-815. \\n[70] Wang, D., Zhu, S., Li, T., & Gong, Y. (2009, August). Multi -document summarization \\nusing sentence-based topic models. In  Proceedings of the ACL -IJCNLP 2009 Conference \\nShort Papers (pp. 297-300). Association for Computational Linguistics. \\n[71] Wang, D., Zhu, S., Li, T., Chi, Y., & Gong, Y. (2011). Integrating document clustering \\nand multidocument summarization. ACM Transactions on Knowledge Discovery from Data \\n(TKDD), 5(3), 14. \\n[72] Fang, H., Lu, W., Wu, F., Zhang, Y., Shang, X., Shao, J., & Zhuang, Y. (2015). Topic \\naspect-oriented summarization via group selection. Neurocomputing, 149, 1613-1619. \\n[73] Sager, N., Lyman, M., Nhan, N. T., & Tick, L. J. (1995). Medical language processing: \\napplications to patient data representation and automatic encoding. Methods of information in \\nmedicine, 34(1-2), 140-146. \\n[74] Chi, E. C., Lyman, M. S. , Sager, N., Friedman, C., & Macleod, C. (1985, November). A \\ndatabase of computer -structured narrative: methods of computing complex relations. \\nIn Proceedings of the Annual Symposium on Computer Application in Medical Care (p. 221). \\nAmerican Medical Informatics Association. \\n[75] Grishman, R., Sager, N., Raze, C., & Bookchin, B. (1973, June). The linguistic string \\nparser. In  Proceedings of the June 4 -8, 1973, national computer conference and \\nexposition (pp. 427-434). ACM. \\n[76] Hirschman, L., Grishman, R., & Sager, N. (1976, June). From text to structured \\ninformation: automatic processing of medical reports. In  Proceedings of the June 7 -10, 1976, \\nnational computer conference and exposition (pp. 267-275). ACM. \\n[77] Sager, N. (1981). Natural language information processing. Addison-Wesley Publishing \\nCompany, Advanced Book Program. \\n[78] Lyman, M., Sager, N., Friedman, C., & Chi, E. (1985, November). Computer -structured \\nnarrative in ambulatory care: its use in longitudinal review of clinical data. In  Proceedings of \\nthe Annual Symposium on Computer Application in Medical Care (p. 82). American Medical \\nInformatics Association. \\n[79] McCray, A. T., & Nelson, S. J. (1995). The representation of meaning in the \\nUMLS. Methods of information in medicine, 34(1-2), 193-201. \\n[80] McGray, A. T., Sponsler, J. L., Brylawski, B., & Browne, A. C. (1987, November). The \\nrole of lexical knowledge in biomedical text understanding. In  Proceedings of the Annual \\nSymposium on Computer Application in Medical Care  (p. 103). American Medical \\nInformatics Association.'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 22, 'page_label': '23', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content=\"[81] McCray, A. T. (1991). Natural language processing for intelligent information retrieval. \\nIn Engineering in Medicine and Biology Society, 1991. Vol. 13: 1991., Proceedings of the \\nAnnual International Conference of the IEEE (pp. 1160-1161). IEEE. \\n[82] McCray, A. T. (1991). Extending a natural language parser with UMLS knowledge. \\nIn Proceedings of the Annual Symposium on Computer Application in Medical Care (p. 194). \\nAmerican Medical Informatics Association. \\n[83] McCray, A. T., Srin ivasan, S., & Browne, A. C. (1994). Lexical methods for managing \\nvariation in biomedical terminologies. In  Proceedings of the Annual Symposium on \\nComputer Application in Medical Care (p. 235). American Medical Informatics Association. \\n[84] McCray, A. T., &  Razi, A. (1994). The UMLS Knowledge Source server.  Medinfo. \\nMEDINFO, 8, 144-147. \\n[85] Scherrer, J. R., Revillard, C., Borst, F., Berthoud, M., & Lovis, C. (1994). Medical office \\nautomation integrated into the distributed architecture of a hospital informa tion \\nsystem. Methods of information in medicine, 33(2), 174-179. \\n[86] Baud, R. H., Rassinoux, A. M., & Scherrer, J. R. (1992). Natural language processing \\nand semantical representation of medical texts.  Methods of information in medicine,  31(2), \\n117-125. \\n[87] Lyman, M., Sager, N., Chi, E. C., Tick, L. J., Nhan, N. T., Su, Y., ... & Scherrer, J. \\n(1989, November). Medical Language Processing for Knowledge Representation and \\nRetrievals. In Proceedings. Symposium on Computer Applications in Medical Care  (pp. 548-\\n553). American Medical Informatics Association. \\n[88] Nhàn, N. T., Sager, N., Lyman, M., Tick, L. J., Borst, F., & Su, Y. (1989, November). A \\nMedical Language Processor for Two Indo -European Languages. In  Proceedings. \\nSymposium on Computer Applications i n Medical Care  (pp. 554 -558). American Medical \\nInformatics Association. \\n[89] Sager, N., Lyman, M., Tick, L. J., Borst, F., Nhan, N. T., Revillard, C., ... & Scherrer, J. \\nR. (1989). Adapting a medical language processor from English to French.  Medinfo, 89, 795-\\n799. \\n[90] Borst, F., Sager, N., Nhàn, N. T., Su, Y., Lyman, M., Tick, L. J., ... & Scherrer, J. R. \\n(1989). Analyse automatique de comptes rendus d'hospitalisation. In  Degoulet P, Stephan JC, \\nVenot A, Yvon PJ, rédacteurs. Informatique et Santé, Informat ique et Gestion des Unités de \\nSoins, Comptes Rendus du Colloque AIM-IF, Paris (pp. 246-56). [5] \\n[91] Baud, R. H., Rassinoux, A. M., & Scherrer, J. R. (1991). Knowledge representation of \\ndischarge summaries. In AIME 91 (pp. 173-182). Springer Berlin Heidelberg. \\n[92] Baud, R. H., Alpay, L., & Lovis, C. (1994). Let’s Meet the Users with Natural Language \\nUnderstanding. Knowledge and Decisions in Health Telematics: The Next Decade, 12, 103.\"),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 23, 'page_label': '24', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='[93] Rassinoux, A. M., Baud, R. H., & Scherrer, J. R. (1992). Conceptual  graphs model \\nextension for knowledge representation of medical texts. MEDINFO, 92, 1368-1374. \\n[94] Morel-Guillemaz, A. M., Baud, R. H., & Scherrer, J. R. (1990). Proximity Processing of \\nMedical Text. In Medical Informatics Europe’90 (pp. 625-630). Springer Berlin Heidelberg. \\n[95] Rassinoux, A. M., Michel, P. A., Juge, C., Baud, R., & Scherrer, J. R. (1994). Natural \\nlanguage processing of medical texts within the HELIOS environment.  Computer methods \\nand programs in biomedicine, 45, S79-96. \\n[96] Rassinoux, A. M., Juge, C., Michel, P. A., Baud, R. H., Lemaitre, D., Jean, F. C., ... & \\nScherrer, J. R. (1995, June). Analysis of medical jargon: The RECIT system. In  Conference \\non Artificial Intelligence in Medicine in Europe (pp. 42-52). Springer Berlin Heidelberg. \\n[97] Friedman, C., Cimino, J. J., & Johnson, S. B. (1993). A conceptual model for clinical \\nradiology reports. In  Proceedings of the Annual Symposium on Computer Application in \\nMedical Care (p. 829). American Medical Informatics Association. \\n[98] \"Natural Language Processing.\"  Natural Language Processing RSS. N.p., n.d. Web. 23 \\nMar. 2017.   \\n[99] [Srihari S. Machine Learning: Generative and Discriminative Models. 2010. http:// \\nwww.cedar.buffalo.edu/wsrihari/CSE574/Discriminative-Generative.pdf (access ed 31 May \\n2011).] \\n[100] [Elkan C. Log -Linear Models and Conditional Random Fields. 2008. http://cseweb. \\nucsd.edu/welkan/250B/cikmtutorial.pdf (accessed 28 Jun 2011). 62. Hearst MA, Dumais ST, \\nOsman E, et al. Support vector machines] \\n[101] [Jurafsky D, Martin JH. Speech and Language Processing. 2nd edn. Englewood Cliffs, \\nNJ: Prentice-Hall, 2008.] \\n[102] [Sonnhammer ELL, Eddy SR, Birney E, et al. Pfam: Multiple sequence alignments and \\nHMM-profiles of protein domains. Nucleic Acids Res 1998;26:320] \\n[103] [Sonnhammer, E. L., Eddy, S. R., Birney, E., Bateman, A., & Durbin, R. (1998). Pfam: \\nmultiple sequence alignments and HMM -profiles of protein domains.  Nucleic acids \\nresearch, 26(1), 320-322] \\n[104] Systems, RAVN. \"RAVN Systems Launch the ACE Powered GDPR Rob ot - Artificial \\nIntelligence to Expedite GDPR Compliance.\"  Stock Market. PR Newswire, n.d. Web. 19 \\nMar. 2017. \\n [105] \"Here\\'s Why Natural Language Processing is the Future of BI.\"  SmartData Collective. \\nN.p., n.d. Web. 19 Mar. 2017'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 24, 'page_label': '25', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='[106] \"Using Natural Langu age Processing and Network Analysis to Develop a Conceptual \\nFramework for Medication Therapy Management Research.\"  AMIA ... Annual Symposium \\nproceedings. AMIA Symposium. U.S. National Library of Medicine, n.d. Web. 19 Mar. 2017 \\n[107] Ogallo, W., & Kanter , A. S. (2017, February 10). Using Natural Language Processing \\nand Network Analysis to Develop a Conceptual Framework for Medication Therapy \\nManagement Research. Retrieved April 10, 2017, from \\nhttps://www.ncbi.nlm.nih.gov/pubmed/28269895?dopt=Abstract \\n[108] Ochoa, A. (2016, May 25). Meet the Pilot: Smart Earpiece Language Translator. \\nRetrieved April 10, 2017, from https://www.indiegogo.com/projects/meet -the-pilot-smart-\\nearpiece-language-translator-headphones-travel'),\n",
       " Document(metadata={'producer': 'Skia/PDF m144 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'Siddhant_Kochhar_Resume', 'source': '../data/pdf_files/Siddhant_Kochhar_Resume.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'Siddhant_Kochhar_Resume.pdf', 'file_type': 'pdf'}, page_content='SIDDHANT  KOCHHAR  (22BCE11684)  B.Tech  (Computer  Science  and  Engineering)   Email:  siddhantkochhar2022@vitbhopal.ac.in  |  Phone:  8965897560  LinkedIn:  https://www.linkedin.com/in/siddhant-kochhar/ LeetCode:   https://leetcode.com/u/Siddhant_Kochhar/  GitHub:  https://github.com/Siddhant-kochhar  \\n  \\n \\nACADEMICS  \\n \\nQualification  Institute  Board  /  University  %  /  CGPA  Year  B.Tech  (CSE  -  7th  sem)  XII  \\nVellore  Institute  of  Technology  Maharishi  Vidya  Mandir,  Jabalpur  \\nVIT  University  CBSE  \\n8.81/10  78.6%  \\n2026  2022  X  Maharishi  Vidya  Mandir,  Jabalpur  CBSE  79.2%  2020  \\n \\nCertifications   \\n●  AWS  Academy  Graduate  -  AWS  Academy  Cloud  Architecting ●  Cloud  Computing  by  IIT  Kharagpur  offered  through  NPTEL  ●  The  Bits  and  Bytes  of  Computer  Networks  by  Google  offered  through  Coursera  ●  Python  A-Z™:  Python  For  Data  Science offered  by  Udemy  \\n2025  2024  2023  2023  \\n \\nAchievements  \\n●  Selected  among  top  500  students  globally  for  the  Ericsson  Academic  Training  Program  ●  Awarded  a  scholarship  under  Deen  Dayal  SPARSH  Yojana  by  India  Post  \\n2024  2017  \\n  \\nINTERNSHIP                                                                                                                                                              2  MONTHS  \\n  \\nMagicPin  (Hybrid)  Gen  AI  Intern   May  2025  -  June  2025  \\nRoles  and  Responsibilities  \\nGen  AI  &  Conversational  Interfaces  ●  Developed  a  WhatsApp-based  GenAI  chatbot  enabling  users  to  search  for  food,  fashion,  etc.  ●  Integrated  personalised  food  recommendation  engine  using  user  context  and  historical  data  ●  Enhanced  Magicpin’s  personal  support  bot  with  conversational  AI  capabilities  ●  Collaborated  with  tech  and  product  teams  to  ensure  scalable  integration  across  key  user  workflows   \\n \\n \\nPROJECTS  \\n \\nGet.Fit  \\n●  Tech  Stack  -  Python,  FastAPI,  Google  Gemini,  Google  Fit,  MongoDB,  HTML,  CSS  ●  Developed  a  smart  health  tracking  app  integrated  with  Google  Fit  for  vitals  monitoring  ●  Added  a  feature  to  send  regular  summaries  and  real-time  alerts  for  proactive  health  management  \\nAI  Tutor  \\n●  Tech  Stack  -  Python,  FastAPI,  MongoDB,  OpenAI  ●  Developed  an  AI  tutor  that  assesses  the  user’s  proficiency  to  generate  personalized  responses  ●  Developed  a  YouTube  video  summarizer,  transforming  lengthy  video  content  into  concise  notes  \\nEventGenie \\n●  Tech  Stack  -  Python,  FastAPI,  Google  Gemini,  MongoDB,  MCP,  Redis,  Google  Places,  HTML   ●  Developed  EventGenie,  an  AI  event  planner  with  venues,  budgeting,  restaurants,  and  activities.  ●  Integrated  Google  Gemini  and  Google  Places  API  for  intelligent  venues,  budgeting,  and  scheduling.  \\nNote-Taking  App  \\n●  Tech  Stack  -  Python,  FastAPI,  MongoDB,  Bootstrap  ●  Developed  a  basic  note-taking  application  using  CRUD  APIs  to  learn  the  FastAPI  framework  \\n \\nCORE  COMPETENCIES  \\n \\nData  Structure  and  Algorithm,  Operating  Systems,  Database  Management,  GenAI,  Cloud  Computing,  Computer  Networking  Programming  Python,  FastAPI,  Flask,  Pandas,  Numpy,  HTML,  CSS,  Bootstrap,  Java  Databases/Cache  MongoDB,  SQL,  Redis  Cloud  AWS,  GCP  AI/Tools  OpenAI  APIs,  Gemini,  MCP  server,  GitHub,  Cursor,  Postman,  MS  Office,  Canva  Soft  Skills  Leadership,  Communication,  Teamwork,  Problem  Solving,  Analytical  Skills,  Learning  Agility  \\n \\nPOSITIONS  OF  RESPONSIBILITY  \\n \\nMVM,  Jabalpur  \\n●  Vice  Captain,  Assembly  Committee  ●  Junior  Prefect  of  Parashar  House  \\n \\n \\nCO-CURRICULAR  &  EXTRACURRICULAR  ACTIVITIES  \\n \\nTechnical  \\n●  Member,  Google  Developers  Group  ●  Competitive  Programming  -  LeetCode,  HackerRank,  Code  Chef  \\n \\nSocial/Sports  \\n●  Karate  -  Yellow  belt   Interests  /  Hobbies  ●  Travelling,  Cooking,  Gaming     VIT  UNIVERSITY  |  BATCH  OF  2026'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 0, 'page_label': '1', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='Natural Language Processing Journal 7 (2024) 100062\\nContents lists available at ScienceDirect\\nNatural Language Processing Journal\\njournal homepage: www.elsevier.com/locate/nlp\\nUnderstanding latent affective bias in large pre-trained neural language\\nmodels\\nAnoop Kadana,∗, Deepak P.b, Sahely Bhadrac, Manjary P. Gangand, Lajish V.L.d\\na School of Psychology, Queen’s University Belfast, UK\\nb School of Electronics, Electrical Engineering and Computer Science, Queen’s University Belfast, UK\\nc Computer Science and Engineering, IIT Palakkad, India\\nd Department of Computer Science, University of Calicut, India\\nA R T I C L E I N F O\\nKeywords:\\nAffective bias in NLP\\nFairness in NLP\\nPre-trained language models\\nTextual emotion detection\\nDeep learning\\nA B S T R A C T\\nGroundbreaking inventions and highly significant performance improvements in deep learning based Natural\\nLanguage Processing are witnessed through the development of transformer based large Pre-trained Language\\nModels (PLMs). The wide availability of unlabeled data within human generated data deluge along with self-\\nsupervised learning strategy helps to accelerate the success of large PLMs in language generation, language\\nunderstanding, etc. But at the same time, latent historical bias/unfairness in human minds towards a particular\\ngender, race, etc., encoded unintentionally/intentionally into the corpora harms and questions the utility and\\nefficacy of large PLMs in many real-world applications, particularly for the protected groups. In this paper,\\nwe present an extensive investigation towards understanding the existence of ‘‘Affective Bias’’ in large PLMs\\nto unveil any biased association of emotions such as anger, fear, joy, etc., towards a particular gender, race\\nor religion with respect to the downstream task of textual emotion detection. We conduct our exploration of\\naffective bias from the very initial stage of corpus level affective bias analysis by searching for imbalanced\\ndistribution of affective words within a domain, in large scale corpora that are used to pre-train and fine-tune\\nPLMs. Later, to quantify affective bias in model predictions, we perform an extensive set of class-based and\\nintensity-based evaluations using various bias evaluation corpora. Our results show the existence of statistically\\nsignificant affective bias in the PLM based emotion detection systems, indicating biased association of certain\\nemotions towards a particular gender, race, and religion.\\n1. Introduction\\nRecently, large scale Natural Language Processing (NLP) models are\\nbeing increasingly deployed in many real-world applications within\\nalmost all domains such as health-care, business, legal systems, etc.,\\nVelupillai et al. (2018), Soni and Roberts (2020), Mishev et al. (2020),\\nDale (2019), Rahman and Siddiqui (2019) and Rahman and Siddiqui\\n(2021) due to its efficacy to make data-driven decisions and capability\\nof natural language understanding even better than humans1 (He et al.,\\n2021). Transformer based large Pre-trained Language Models (PLMs)\\nhave been hugely influential in NLP due to their capability to gener-\\nate powerful contextual representations. PLMs are mostly built based\\non a self-supervised learning strategy that highly relies on unlabeled\\ndata abundantly available from the human generated data deluge (He\\net al., 2021). But, since this historical data of textual write-ups has its\\nroots within human thought, they often reflect latent social stereotypes\\n(Suresh and Guttag, 2021; Garg et al., 2018). For example, the Social\\n∗ Correspondence to: School of Psychology, Queen’s University Belfast, Northern Ireland, UK.\\nE-mail addresses: a.kadan@qub.ac.uk (A. Kadan), deepaksp@acm.org (Deepak P.), sahely@iitpkd.ac.in (S. Bhadra), manjaryp_dcs@uoc.ac.in\\n(M. P. Gangan), lajish@uoc.ac.in (Lajish V.L.).\\n1 https://www.infoq.com/news/2021/01/google-microsoft-superhuman/.\\nRole Theory by Eagly and Steffen (1984) demonstrates that the idea of\\ngender stereotype develops from perceivers’ observations, associating\\nthe capabilities and personality attributes of different genders with the\\nactivities in which they engage in their day-to-day lives over time,\\nbuilding rigid stereotypes in human minds and their writings, on how\\nthese genders behave (e.g. women are highly emotional), where they\\nwork (e.g. women preferred in children’s daycare), etc. Hence the data\\nfrom such human generated data repositories eventually convey these\\nstereotypes as linguistic biases through the NLP algorithms (Raza et al.,\\n2024), especially those built on large PLMs that utilize huge amounts\\nof data (Suresh and Guttag, 2021).\\nIn this direction, investigation of ‘‘Affective Bias’’ in NLP is a re-\\ncent stream of research to study the existence of any unfair/biased\\nassociation of emotions (anger, fear, joy, etc.) or sentiments (positive,\\nnegative, etc.) towards underrepresented or protected groups in a\\ndomain, that may lead affective computing systems such as sentiment\\nor emotion detection systems to deliver unfavorable outcomes for these\\nhttps://doi.org/10.1016/j.nlp.2024.100062\\nReceived 5 November 2023; Received in revised form 6 January 2024; Accepted 1 March 2024\\n2949-7191/© 2024 The Author(s). Published by Elsevier B.V. This is an open access article under the CC BY-NC license\\n(http://creativecommons.org/licenses/by-nc/4.0/).'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 1, 'page_label': '2', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='A. Kadan, Deepak P., S. Bhadra et al. Natural Language Processing Journal 7 (2024) 100062\\nTable 1\\nDifferences in predicted emotion classes/intensities between sentences that differ only on a target term\\nrepresenting various social groups, indicating existence of ‘Affective Bias’.\\nSentence Emotion prediction\\nMen know how to drive Joy\\nWomen know how to drive Fear\\nWhite people are very ambitious as a whole Joy\\nBlack people are very ambitious as a whole Anger\\nTasha fell in love with the Christian man’s looks Joy\\nTasha fell in love with the Muslim man’s looks Fear\\nHe eventually wants to become a doctor Joy: 0.700\\nShe eventually wants to become a doctor Joy: 0.506\\nMy man friend made me feel alarmed Fear: 0.694\\nMy woman friend made me feel alarmed Fear: 0.750\\nMy queer friend made me feel alarmed Fear: 0.940\\nBlack people can dance very well Joy: 0.491\\nWhite people can dance very well Joy: 0.746\\nIt is always the Christian people who think their films are the best Joy: 0.996\\nIt is always the Muslim people who think their films are the best Joy: 0.488\\nprotected groups (Anoop et al., 2022). For instance, a model consis-\\ntently associating women with a different class of emotion or same\\nemotion differing in emotion intensities vis-a-vis predictions for male\\n(Shields, 2002) could be seen as a manifestation of affective bias.\\nSimilarly, association of a particular religion always with a specific\\nemotion (Abid et al., 2021a) represents affective bias too. A real world\\nscenario of affective bias is the case of Google sentiment analyzer\\njudging that being gay is bad by assigning high negative sentiments\\nto sentences such as ‘ I’m a gay black woman’, ‘I’m a homosexual’, etc.,.2\\nFor better understandability of affective bias, we illustrate in Table 1,\\na sample set of affectively biased emotion predictions from PLM based\\ntextual emotion detection models constructed in this study for affective\\nbias analysis (detailed explanation of the models are provided in Sec-\\ntion 4.1). The first set in the table demonstrates affective bias due to\\ndifferences in predicted emotion classes, whereas the second set shows\\naffective bias due to differences in predicted emotion intensities.\\nSimilar to other general algorithmic biases like gender bias, racial\\nbias, etc., a possible stimuli to affective biases are the latent emotion\\nbased stereotypes about different social groups in the data. Studies\\nreport that such emotion based stereotyping influence socialization\\nof emotions leading to propagation of stereotypes such as associating\\nwomen’s (or men’s) experiences and expressions being aligned with\\nfear and sadness (or anger and pride) (Plant et al., 2000). Similarly,\\naffective bias within systems could facilitate a higher association of\\nblack women to the emotion anger when considering emotions with\\nthe domains race and gender (Ashley, 2014). In addition to biased\\ndata, another reason for bias is based on how the model/algorithmic\\ndesign considers or treats the underrepresented or protected attributes\\nconcerning a domain (Hooker, 2021). Similar to any other general\\nsocial biases, the existence of these affective biases make textual af-\\nfective computing systems generate unfair or biased decisions that can\\nharm its utility towards socially marginalized populations by denying\\nopportunities/resources or by false portrayal of these groups when\\ndeployed in the real-world. Hence, understanding affective bias in NLP\\n2 https://www.vice.com/en/article/j5jmj8/google-artificial-intelligence-\\nbias.\\nplays a vital role in achieving algorithmic fairness, by protecting the\\nsocio-political and moral equality of marginalized groups.\\nIn this context, we present an extensive experimental analysis to\\nunderstand and illustrate the existence of latent ‘‘Affective Bias’’ in\\ntransformer based large PLMs 3 with respect to the downstream task\\nof textual emotion detection. Hence, we set our research question: Do\\npredictions made by large PLM based textual emotion detection sys-\\ntems systematically or consistently exemplify ‘Affective Bias’ towards\\ndemographic groups?Our investigation of affective bias in large PLMs\\nprimarily aims to identify the existence of gender, racial, and religious\\naffective biases and set aside the task of affective bias mitigation in\\nthe scope for future work. We start with an exploration of corpus level\\naffective bias or affect imbalance in corpus to find out any biased emo-\\ntion associations in the large scale corpora that are used to pre-train and\\nfine-tune the PLMs, by analyzing the distribution of emotions or their\\nassociations with demographic target terms (e.g., Islam, Quran) related\\nto a social group (e.g., Muslim) concerning a domain (e.g., Religion).\\nLater, we explore the prediction level affective bias in four popular\\ntransformer based PLMs, BERT (Bidirectional Encoder Representation\\nfrom Transformers) (Devlin et al., 2019), OpenAI GPT-2 (Generative\\nPre-trained Transformer) (Radford et al., 2019), XLNet (Yang et al.,\\n2019), and T5 (Text-to-Text Transfer Transformer) (Raffel et al., 2020),\\nthat are fine-tuned using a popular corpora SemEval-2018 EI-oc (Mo-\\nhammad et al., 2018) for the task of textual emotion detection. To\\nquantify prediction level affective bias, we subject the PLMs to an\\nextensive set of class-based and intensity-based evaluations using three\\ndifferent evaluation corpora EEC (Kiritchenko and Mohammad, 2018),\\nBITS (Venkit and Wilson, 2021) and CSP (Nangia et al., 2020). A\\ndetailed sketch of the overall analysis is shown in Fig. 1.\\nThe rest of the paper is organized as follows. Section 2 presents\\nthe relevant related works. Section 3 presents corpus level affective\\n3 Even though, the current interpretation of large language models seems to\\nbe changing to billions of parameters (for e.g., LLaMA (Touvron et al., 2023),\\nFLAN-T5 XXL (Chung et al., 2022), etc.), there are works that utilize the term\\n‘large PLMs’ to indicate PLMs trained on millions of parameters (e.g., Navigli\\net al. (2023)). In this study also, we use the term ‘large PLMs’ in the context\\nof having a PLM trained on millions of parameters.\\n2'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 2, 'page_label': '3', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='A. Kadan, Deepak P., S. Bhadra et al. Natural Language Processing Journal 7 (2024) 100062\\nFig. 1. Workflow of Affective bias analysis.\\nbias analysis with corresponding methodology and results. Section 4\\npresents the exploration towards prediction level affective bias with\\ndetails of constructing PLM based textual emotion detection model,\\nmethodology of analysis, and the corresponding results. Section 5\\npresents a discussion based on the entire results and finally, Section 6\\ndraws the conclusions.\\n2. Related works\\nHere we review two categories of algorithmic bias analysis pertinent\\nto our work, i.e., the general affect-agnostic bias analysis and affect-\\noriented bias analysis, and demarcate our work from these related\\nworks.\\n2.1. General affect agnostic bias analysis\\nRecent works in the literature have focused on several approaches\\nto identify the existence of latent biases in PLMs by inspecting at\\nvarious levels, commencing from bias analysis at the corpus level to the\\ndownstream-task level (Anoop et al., 2022; Suresh and Guttag, 2021).\\nWorks addressing bias at the corpus level analyze the terms relating\\na domain and their associations with key terms against which bias\\nis examined, e.g., the association between gender and stereotypically\\ngendered occupation terms (Bordia and Bowman, 2019; Tan and Celis,\\n2019). In model level analysis, bias are quantified using various metrics\\ndepending on the tasks, where evaluating geometry of the word vector\\nspace (Bolukbasi et al., 2016), performing association tests such as\\nWord Embedding Association Test (Caliskan et al., 2017) and Sentence\\nEncoder Association Test (May et al., 2019), measuring bias of classifi-\\ncation tasks using demographic parity and equal opportunity (Du et al.,\\n2021), etc., are popular approaches in the literature. At the downstream\\ntask level, bias is quantified by comparing the performance scores of a\\nmodel for a set of sentence pairs in an evaluation corpus that differs\\nonly on target terms in which the domain of bias is being studied.\\nFor example, comparing performances of a model for gender-swapped\\nsentences like ‘She is here’ versus ‘He is here’, where the model exhibits\\ngender bias if it produces different performance scores for both sets\\nof sentence pairs. Bias identification at the downstream task level is\\nexplored for a variety of tasks like identification of toxic comments\\n(Dixon et al., 2018), text generation (Nadeem et al., 2021), coreference\\nresolution (Zhao et al., 2018; Lu et al., 2020), etc.\\n2.2. Affect-oriented bias analysis\\nMost affect-oriented bias analysis studies in the literature predom-\\ninantly focus on the coarse-grained sentiment perspective of these\\nbiases (i.e. positive, negative, and neutral sentiments), and that too\\nmostly specific to gender domain (Yang et al., 2021; Bhaskaran and\\nBhallamudi, 2019; Rozado, 2020; Shen et al., 2018; Sweeney and\\nNajafian, 2020). But, affective bias in context of fine-grained emotion\\nclasses like anger, fear, joy, etc., and the variability of these biases\\nin diverse domains such as religion, politics, race, or intersectional\\nbiases, are not well explored (Anoop et al., 2022), except in Kiritchenko\\nand Mohammad (2018) and Venkit and Wilson (2021). In Kiritchenko\\nand Mohammad (2018) Kiritchenko and Mohammad identify affective\\nbias in the emotion prediction systems developed for the shared task\\nSemEval-2018 Task 1 Affect in Tweets, and in Venkit and Wilson (2021)\\nVenkit et al. identifies affective bias in the domain of persons with\\ndisabilities in sentiment analysis and toxicity classification models; both\\nthese works use a synthetics evaluation corpus to identify affective bias.\\nAffect-oriented bias analysis are seen to be conducted in lexicon\\nand deep learning based sentiment analysis systems (Shen et al., 2018;\\nZhiltsova et al., 2019), and in non-contextual word embeddings such as\\nFastText, GloVe, and Word2Vec to address bias in sentiment analysis\\nand toxicity classification (Sweeney and Najafian, 2020), age-related\\nbias (Díaz et al., 2018) and other underreported bias types (Rozado,\\n2020). Recently several works also address bias in contextual repre-\\nsentations of large PLMs. But most of these works in PLMs address\\ngeneral affect-agnostic biases (Liang et al., 2021; Nadeem et al., 2021;\\nTan and Celis, 2019; Zhao et al., 2019), very few works address affect-\\noriented biases in PLMs through sentiment perspective (Bhaskaran and\\nBhallamudi, 2019; Yang et al., 2021; Huang et al., 2020), and to our\\nbest knowledge only the work in Mao et al. (2022) investigates affective\\nbias in large PLMs through the perspective of fine-grained emotions, so\\nfar, and that too specifically in prompt-based sentiment and emotion\\ndetection tasks.\\n2.3. Our work in context\\nTo put our work in context, we conduct experiments to identify\\naffective bias in large PLMs through the perspective of fine-grained\\nemotions. Hence, as a natural first step, we consider textual emotion\\ndetection systems, unlike the considerable amount of bias analysis\\nworks in large PLMs relying on text generation, coreference resolution,\\n3'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 3, 'page_label': '4', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='A. Kadan, Deepak P., S. Bhadra et al. Natural Language Processing Journal 7 (2024) 100062\\nprompt-based classification, etc., Mao et al. (2022), Liang et al. (2021),\\nNadeem et al. (2021) and Huang et al. (2020). Our work, in particular,\\nconsiders investigating affective bias in transformer based large PLMs\\ndue to their wide applicability in developing textual emotion detection\\nsystems (Acheampong et al., 2021). Distinct from the recent work (Mao\\net al., 2022) that addresses affective bias in PLMs with respect to label-\\nword, prompt template, etc., specifically focusing on prompt-based\\nsentiment and emotion detection, our work investigates affective bias\\nin four different PLMs with respect to the domains gender, race, and\\nreligion, focusing on fine-tuning based emotion classification. Unlike\\nthe works (Venkit and Wilson, 2021; Kiritchenko and Mohammad,\\n2018) addressing affective bias, we start our investigation from the very\\ninitial stage of corpus level affective bias analysis, inspired by the works\\n(Bordia and Bowman, 2019; Tan and Celis, 2019) that address corpus\\nlevel general affect-agnostic biases, and later we progress towards\\nanalyzing affective bias in predictions of the PLM based textual emotion\\ndetection models. We conduct a much broader intensity based and class\\nbased affective bias analysis using a set of synthetic (template based)\\nevaluation corpora as well as non-synthetic (crowdsourced) evaluation\\ncorpus that much more suits the real-world scenario.\\n3. Corpus level affective bias\\nThe existence of bias in PLM based language processing systems are\\nobserved due to many sources such as data, annotation, representa-\\ntions, model, etc. (Anoop et al., 2022; Hovy and Prabhumoye, 2021).\\nA substantial amount of works that address general social biases on\\ngender and race lines report the existence of data bias from innate\\nhistorical biases as the most primeval source of bias (Corbett-Davies\\net al., 2017; Bordia and Bowman, 2019; Tan and Celis, 2019; Zhao\\net al., 2019). To the best of our knowledge, this is the first attempt\\nthat explore affective bias in large scale textual corpora utilized by\\nPLMs. Hence, as an initial step to explore the affective bias, we conduct\\nexperiments to understand the existence of affective bias if any, in the\\npre-training corpora that are integral ingredients of large PLMs and\\nfine-tuning corpora used to build the textual emotion detection systems.\\nData quality issues, uneven distributions of data, and class imbal-\\nances that target marginalized groups, etc., are the root factors that\\ncontribute towards data bias (Navigli et al., 2023; Hovy and Prab-\\nhumoye, 2021; Subramanian et al., 2021; Anoop et al., 2022). Many\\nworks that address affect agnostic biases focus on exploring data bias by\\nunderstanding any uneven distributions of the target terms associated\\nwithin the domain of interest (Tan and Celis, 2019; Zhao et al., 2019).\\nMotivated by these lines of works, as an initial attempt to unveil the\\ncorpus level affective bias, we follow this simple approach of analyzing\\nthe distributions of affective target terms. A detailed description of pre-\\ntraining and fine-tuning corpora, the method to measure corpus level\\naffective bias, and the analysis of corpus level affective bias are given\\nbelow.\\n3.1. Training corpora\\nOur choice of large scale datasets for corpus level affective bias\\nanalysis hinges on the large PLMs, BERT (Devlin et al., 2019), GPT-2\\n(Radford et al., 2019), XLNet (Yang et al., 2019), and T5 (Raffel et al.,\\n2020). BERT is trained on Wikipedia dump (WikiEn)4 and BookCorpus\\n(Zhu et al., 2015), GPT-2 is trained on WebText (Radford et al., 2019),\\nXLNet is trained on WikiEn, BookCorpus, Giga5, 5 ClueWeb6 and Com-\\nmon Crawl,7 and T5 is trained on Colossal Clean Crawled Corpus (C4).8\\n4 https://dumps.wikimedia.org/enwiki/.\\n5 https://catalog.ldc.upenn.edu/LDC2011T07.\\n6 https://lemurproject.org/clueweb12/index.php.\\n7 http://commoncrawl.org/.\\n8 https://www.tensorflow.org/datasets/catalog/c4.\\nTable 2\\nDetails of training corpora used for corpus level affective bias analysis.\\nCorpus Size Number of PLM\\nsentences BERT GPT-2 XLNet a T5\\nPre-training corpora\\nWikiEn 19.8 GB 95 917 189 ✓ ✓\\nBookCorpus 6.19 GB 91 025 872 ✓ ✓\\nWebText-250 620 MB 5 314 965 ✓\\nC4-Val 731 MB 4 959 563 ✓\\nFine-tuning corpora\\nSemEval-2018 925 KB 10 030\\na Giga5, ClueWeb, & Common Crawl used to pre-train XLNet are omitted.\\nFrom these set of large-scale pre-training datasets, we chose WikiEn, 9\\nBookCorpus, WebText, and C4, for our study. The details regarding size\\nof these corpora and number of sentences are shown in Table 2. We\\nomit Giga5 and ClueWeb due to their unavailability as open-source\\ncorpora and Common Crawl as it is reported to have significant data\\nquality issues due to a large number of unintelligible document content\\n(Trinh and Le, 2018; Radford et al., 2019). Since BookCorpus 10 is no\\nlonger hosted by the authors, we choose its open version available in\\nHugging Face.11 We make use of the partially released 250K documents\\nfrom WebText test set, similar to Tan and Celis (2019), since WebText\\ncorpora has not been fully released and call it WebText-250. 12 As\\nthe train split of C4 corpus is very large (305 GB with 364868892\\ndocuments) and cumbersome to process, we use only a part of the\\ncorpus, i.e., the validation split, and call it C4-Val. Apart from the above\\nmentioned pre-training datasets, we also consider SemEval-2018 EI-oc\\n(Mohammad et al., 2018) that is used to fine-tune the textual emotion\\ndetection model, for our analysis.\\n3.2. Measuring corpus level affective bias\\nInspired by the recent methods to identify gender bias in datasets\\nwith respect to occupations (Tan and Celis, 2019; Zhao et al., 2019), we\\nidentify the existence of affective bias in the large scale corpora used to\\ntrain large PLMs with respect to various domains such as gender, race,\\nand religion. That is, for a corpus, we identify any imbalances in the\\ndistribution of emotions, or any imbalanced association of the emotions\\ntowards social groups within a domain. Accordingly, for each corpus,\\nwe measure the occurrence of emotion terms representing or related\\nto an emotion and their co-occurrence or association with target terms\\nrepresenting a social group in a domain.\\nAlgorithm 1 illustrates the method of computing occurrence and\\nco-occurrence for a training corpora 𝐷 that is considered as a set of\\nsentences [𝑆1,𝑆2,𝑆3,…] derived from documents in the corpus, where\\neach sentence consists of a sequence of words[𝑤1,𝑤2,𝑤3,…]. The algo-\\nrithm sifts through each word in the sentences of the corpus 𝐷. Once\\na word belonging to the set of emotion terms related to an emotion\\n𝐸 (i.e., 𝐸𝑡𝑒𝑟𝑚𝑠) is encountered in a sentence, the algorithm increments\\nthe occurrence of that emotion 𝑜𝑐𝑐𝐸, for that corpus. Similarly in a\\nsentence, once a word related to the emotion 𝐸 co-occurs with a\\nterm belonging to the set of target terms related to a social group 𝑇\\nin a domain (i.e., 𝑇𝑡𝑒𝑟𝑚𝑠), the algorithm increments the co-occurrence\\nof that emotion with the corresponding social group 𝑐𝑜𝑜𝑐𝑐𝑇\\n𝐸, for that\\ncorpus. For example, we increment the occurrence of the emotion Joy\\n(i.e., 𝑜𝑐𝑐𝑗𝑜𝑦), for a corpus, once an emotion term related to Joy like\\n‘happy’, ‘bliss’, ‘cheer’, etc., is encountered in a sentence of the corpus.\\nWe increment the co-occurrence of Joy-Male (i.e., 𝑐𝑜𝑜𝑐𝑐𝑚𝑎𝑙𝑒\\n𝑗𝑜𝑦 ), for the\\n9 Latest Wikipedia dump (date: 02/June/2022), extracted using https://\\ngithub.com/attardi/wikiextractor.\\n10 https://yknzhu.wixsite.com/mbweb.\\n11 https://huggingface.co/datasets/bookcorpus.\\n12 https://github.com/openai/gpt-2-output-dataset.\\n4'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 4, 'page_label': '5', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='A. Kadan, Deepak P., S. Bhadra et al. Natural Language Processing Journal 7 (2024) 100062\\ncorpus, if an emotion term related to Joy co-occurs with target terms\\nrelated to the social group Male like ‘husband’, ‘boy’, ‘brother’, etc.,\\nand increment the co-occurrence of Joy-Female (i.e., 𝑐𝑜𝑜𝑐𝑐𝑓𝑒𝑚𝑎𝑙𝑒\\n𝑗𝑜𝑦 ) if an\\nemotion term related to Joy co-occurs with target terms related to the\\nsocial group Female like ‘wife’, ‘girl’, ‘sister’, etc., in a sentence of the\\ncorpus. Finally, for each social group in a domain, the co-occurrence\\nvalues with respect to each emotion are expressed in percentages.\\nAlgorithm 1:Occurrence and Co-occurrence\\ninput : Corpus 𝐷\\nEmotion terms for emotion 𝐸 (𝐸𝑡𝑒𝑟𝑚𝑠)\\nTarget terms for social group 𝑇 (𝑇𝑡𝑒𝑟𝑚𝑠)\\noutput : Emotion occurrence 𝑜𝑐𝑐𝐸\\nEmotion and Social group co-occurrence 𝑐𝑜𝑜𝑐𝑐𝑇\\n𝐸\\n1 Let 𝐷= [𝑆1,𝑆2,… ,𝑆𝑚] and 𝑆 = [𝑤1,𝑤2,… ,𝑤𝑛] ;\\n2 initialize 𝑜𝑐𝑐𝐸 = 0; 𝑐𝑜𝑜𝑐𝑐𝑇\\n𝐸 = 0; 𝑓𝑙𝑎𝑔 = 𝐹𝑎𝑙𝑠𝑒 ;\\n3 for (𝑗 = 1; 𝑗 ≤ 𝑚; 𝑗+ +)do\\n4 for (𝑖= 1; 𝑖≤ 𝑛; 𝑖+ +)do\\n5 if (𝑤𝑖 ∈ 𝐸𝑡𝑒𝑟𝑚𝑠) then\\n6 𝑓𝑙𝑎𝑔 = 𝑇𝑟𝑢𝑒;\\n7 𝑜𝑐𝑐𝐸 = 𝑜𝑐𝑐𝐸 + 1;\\n8 break;\\n9 end\\n10 end\\n11 for (𝑖= 1; 𝑖≤ 𝑛; 𝑖+ +)do\\n12 if (𝑤𝑖 ∈ 𝑇𝑡𝑒𝑟𝑚𝑠 and 𝑓𝑙𝑎𝑔 = 𝑇𝑟𝑢𝑒) then\\n13 𝑐𝑜𝑜𝑐𝑐𝑇\\n𝐸 = 𝑐𝑜𝑜𝑐𝑐𝑇\\n𝐸 + 1;\\n14 break;\\n15 end\\n16 end\\n17 end\\n18 output 𝑜𝑐𝑐𝐸, 𝑐𝑜𝑜𝑐𝑐𝑇\\n𝐸\\nTo conduct this study on corpus level affective bias, we maintain\\na list of emotion terms (or affective terms) for the basic emotions\\n𝐸 = {𝑎𝑛𝑔𝑒𝑟,𝑓𝑒𝑎𝑟,𝑗𝑜𝑦,𝑠𝑎𝑑𝑛𝑒𝑠𝑠 }, because our emotion prediction models\\n(discussed in Section 4.1, to identify affective bias in model predic-\\ntions) relies on these categories of basic emotions. Hence, initially, we\\nprocure a list of affective terms collectively from Parrott’s primary,\\nsecondary, and tertiary emotions,13 and refer the works Kiritchenko and\\nMohammad (2018) and Venkit and Wilson (2021), to represent these\\nbasic emotions. Later, we extend this list of affective terms by including\\nlinguistic inflections of each word in the list using Merriam-Webster 14\\ndictionary and an automated python package pyinflect. 15 As a result\\nthe entire list contains 735 affective terms (given in supplementary\\nmaterial), where 162 represent anger, 143 fear, 222 joy, and 208\\nsadness.\\nA similar procedure is carried out to procure target terms related to\\na social group within gender, race, and religion, the domains that are\\nconsidered in this study. In domain gender, the target terms considered\\nrepresent three social groups 𝑇 = {𝑀,𝐹,𝑁𝑏 } for Male, Female, and\\nNon-binary groups. Similarly in domain race, we consider European\\nAmerican and African American social groups i.e., 𝑇 = {𝐸𝐴,𝐴𝐴}, and\\nfor religion, we consider Christian, Muslim, and Jewish social groups\\ni.e., 𝑇 = { 𝐶ℎ,𝑀𝑢,𝐽𝑤 }. An initial list of target terms representing\\nthese social groups is prepared collectively by referring to the works\\n(Bolukbasi et al., 2016; Lu et al., 2020; Guo and Caliskan, 2021;\\nNadeem et al., 2021; Liang et al., 2021; Kaneko and Bollegala, 2022),\\nwhich is later expanded by adding linguistic inflections. As these works\\ndo not consider target terms related to the non-binary social group\\nin the gender domain, we manually curated the corresponding target\\n13 https://en.wikipedia.org/wiki/Emotion_classification#Parrott’s_emotions_\\nby_groups.\\n14 https://www.merriam-webster.com/.\\n15 https://pypi.org/project/pyinflect/.\\nterms from various articles and web resources (e.g. Center (2022)) and\\nverified these terms with the help of an expert in gender studies. The\\nentire list contains 507, 167, and 332 target terms in the domains\\nof gender, race, and religion, respectively (given in supplementary\\nmaterial), with 199 male, 211 female, and 97 non-binary target terms\\nfor the gender domain, 82 African American and 85 European American\\ntarget terms for the racial domain, and 122 Muslim, 111 Jewish, and\\n99 Christian target terms for the religious domain.\\n3.3. Results and analysis of corpus level affective bias\\nIn this section, we present the results of occurrence of emotions\\nin the corpora and their co-occurrence with social groups in various\\ndomains of gender, race, and religion to analyze corpus level affective\\nbias.\\n3.3.1. Occurrence of emotions in the corpora\\nResults of the occurrence statistics of emotions for our corpus level\\naffective bias analysis are shown in Table 3. The trends of emotion\\noccurrence illustrate that, for all the corpora, the occurrence of affective\\nterms related to joy is consistently higher than all other emotions;\\nescalating joy from the next highest occurring emotionsfear and sadness\\nminimally by a factor of 1.1 in SemEval-2018 EI-oc and maximum by\\na factor of 5.6 in C4-Val, respectively. The predominance of joy in\\ntextual corpora can be possibly due to the reason that, psychologically\\npeople are inclined towards expressing more positive emotions on the\\nweb (Vittengl and Holt, 1998; De Choudhury et al., 2012; Staiano and\\nGuerini, 2014; Waterloo et al., 2018). On the other side, for all the\\ncorpora, the instances of anger are consistently very low in count. The\\nstandard deviation computed to measure the dispersion between the\\noccurrence of various emotions within a corpus shows that there exists\\na large disparity between the occurrence of emotions within a corpus,\\nparticularly in the large scale corpora used to pre-train PLMs. In total,\\nthe occurrence statistics over the four basic emotions anger, fear, joy\\nand sadness, clearly affirms the existence of emotion imbalances in both\\nPLM pre-training and fine-tuning corpora.\\nBookCorpus contains the highest number of total affective words\\namong all other corpora considered. This brings to another observation\\nthat despite BookCorpus being almost one-third of the size of WikiEn,\\nthe number of affective words in BookCorpus exceeds WikiEn by a\\nfactor of 1.3. We presume this is because BookCorpus being a large\\ncorpus curated from books in the web, contains more affective words\\nthan WikiEn curated from Wikipedia articles in the web.\\n3.3.2. Co-occurrence of emotions with social groups\\nThe co-occurrence statistics of basic emotions with various social\\ngroups in gender, racial and religious domains for each corpus is\\nillustrated in Table 4, where the domains are separated column wise\\nand emotions are grouped across the rows. We look into each domain\\nseparately, (in the order of gender, race, and religion) and analyze the\\nassociation of emotion categories (in the order of anger, fear, joy, and\\nsadness) with social groups in these domains.\\n(A) Emotion Co-occurrence with Gender Domain: In the gender do-\\nmain, anger mostly co-occurs with the non-binary and female\\nsocial groups than male. Fear is always highly associated with\\nthe non-binary group, followed secondly by female. The positive\\nemotion joy is found to mostly co-occur with male, but, it has\\nthe least co-occurrence with non-binary gender. Sadness mostly\\nco-occurs with non-binary and female groups, similar to anger.\\nFor the fine-tuning corpus SemEval-2018, in particular, there\\nis no instance of co-occurrence between any of the emotions\\nand non-binary gender, this is due to the lack of non-binary\\ngender terms in the corpus; also, for this corpus, negative emo-\\ntions such as, anger, fear, and sadness are always found to have\\nhigh co-occurrence with female gender and the positive emotion\\n5'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 5, 'page_label': '6', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='A. Kadan, Deepak P., S. Bhadra et al. Natural Language Processing Journal 7 (2024) 100062\\nTable 3\\nOccurrence statistics of emotions in the corpora.\\nCorpus Anger Fear Joy Sadness Total affective words Standard deviation\\nWikiEn 533 111 745 221 2 479 326 1 802 466 5 560 124 914 103.94\\nBookCorpus 1 049 407 1 647 267 3 143 907 1 400 423 7 241 004 922 324.00\\nWebText-250k 50 207 85 325 220 354 88 749 444 635 74 851.63\\nC4-Val 33 182 66 239 394 413 69 686 563 520 169 821.19\\nSemEval-2018 984 1 472 1 579 1 131 5 166 280.21\\nTable 4\\nCo-occurrence statistics of basic emotions with various domains in corpora (in\\npercentage).\\nCorpus Co-occurrence with\\nGender Race Religion\\nM F Nb EA AA Ch Mu Jw\\nAnger\\nWikiEn 12.12 13.41 14.25 10.44 10.68 8.55 11.69 13.93\\nBookCorpus 17.61 16.15 19.02 15.09 17.06 12.20 13.74 18.64\\nWebText-250k 14.13 14.24 11.46 15.05 16.53 12.86 15.05 19.55\\nC4-Val 9.32 9.08 6.02 7.06 7.71 6.22 11.19 13.49\\nSemEval-2018 22.36 24.56 0 22.55 52.17 15.79 15.06 0\\nFear\\nWikiEn 12.61 15.09 21.01 14.73 14.62 9.81 17.03 16.05\\nBookCorpus 22.03 24.00 25.05 23.09 23.52 14.65 21.42 16.44\\nWebText-250k 19.56 21.80 23.02 21.11 21.02 16.66 36.00 28.39\\nC4-Val 13.95 13.79 16.87 13.56 13.46 9.33 23.09 19.70\\nSemEval-2018 25.36 26.06 0 31.37 10.87 36.84 62.16 75.00\\nJoy\\nWikiEn 40.81 40.81 39.18 45.46 45.31 51.94 36.47 41.93\\nBookCorpus 41.09 40.01 38.40 44.01 41.07 51.12 44.53 40.77\\nWebText-250k 44.25 40.01 42.79 43.69 42.44 47.54 25.06 27.53\\nC4-Val 57.76 61.28 55.42 63.49 63.95 68.05 44.28 45.75\\nSemEval-2018 33.53 30.83 0 34.31 13.04 27.02 12.16 25.00\\nSadness\\nWikiEn 34.46 30.70 25.56 29.37 29.38 29.70 34.81 28.09\\nBookCorpus 19.76 19.84 21.02 18.11 18.55 22.03 20.30 24.14\\nWebText-250k 24.05 25.25 20.83 20.75 20.51 22.94 24.09 24.52\\nC4-Val 18.96 16.95 21.69 15.89 14.88 16.40 21.44 21.05\\nSemEval-2018 17.75 19.05 0 11.76 23.91 21.05 10.81 0\\njoy is found to have high co-occurrence with male. The over-\\nall co-occurrence statistics of the gender domain illustrate that\\nnegative emotions mostly co-occur with the non-binary gender\\ngroup, followed by female, and conversely, positive emotions\\nco-occur mostly with the male group. The observations thus\\nclearly dictate imbalanced associations between affective terms\\nand social groups of gender domain, in both pre-training and\\nfine-tuning corpora.\\n(B) Emotion Co-occurrence with Racial Domain: Evaluation results\\nover the racial domain illustrate that the negative emotions\\nanger and sadness mostly co-occur with African American race\\ngroup, whereas negative emotion fear and the positive emotion\\njoy mostly co-occur with European American. But, for all the\\npre-training corpora, the imbalance of co-occurrence values in\\nthe racial domain is comparatively less than the previously\\ndiscussed gender domain; for example, imbalance in the co-\\noccurrence of all emotions with the racial groups is negligible\\nin the case of WikiEn corpus. Contrary to the observations of\\npre-training corpora, in fine-tuning corpus SemEval-2018, there\\nexists a large difference in co-occurrence values between African\\nand European American groups. That is, in SemEval-2018, the\\nnegative emotions anger and sadness co-occur with the African\\nAmerican race double the times than European American, indi-\\ncating highly imbalanced association of anger and sadness with\\nAfrican American race. Whereas, the co-occurrence of negative\\nemotion fear and positive emotion joy with European American\\ngroup is almost thrice African American, again indicating a\\nhighly imbalanced association, that of fear and joy emotions in\\nSemEval-2018 with European American group.\\n(C) Emotion Co-occurrence with Religious Domain:Analysis in the do-\\nmain of religion shows that anger mostly co-occurs with Jewish\\nand fear mostly co-occurs with Muslim. Whereas, joy is always\\nfound to have maximum co-occurrence with Christian.Sadness is\\nfound to mostly co-occur with Muslim and Jew religious groups\\nthan Christian. The results thus shows existence of high co-\\noccurrence between negative emotions anger, fear, and sadness\\nwith Muslim and Jew, whereas the positive emotion joy with\\nChristian. Moreover, when considering previous observations\\nof gender and racial domains, the imbalance in the religious\\ndomain is comparatively higher.\\nThe entire occurrence and co-occurrence analysis over gender, race\\nand religious domains thus consolidate the existence of corpus level\\naffective bias in pre-training and fine-tuning corpora. The extensions of\\nsuch corpora holding latent affect imbalances, to build computational\\nmodels may eventually trigger chances of bias in learning models,\\nespecially when building large scale contextual pre-trained language\\nmodels that extract all possible properties of a language.\\n4. Prediction level affective bias\\nTo identify the existence of prediction level affective bias, if any,\\nin the perspective of large PLMs, we utilize textual emotion detection\\nsystems built using popular large PLMs that are fine-tuned using an\\nemotion detection corpus. We evaluate the existence of affective bias\\nin the context of domains gender, race, and religion via different\\nsynthetic and non-synthetic paired evaluation sentence corpora and\\nan extensive set of evaluation measures. Details of our investigation,\\nincluding description and settings of textual emotion detection models\\nbased on large PLMs, the method to measure prediction level affective\\nbias with the details of evaluation corpora and measures, and the\\nresults and analysis of prediction level affective bias, are given below.\\n4.1. Textual emotion detection using large PLMs\\nWe formulate the task of textual emotion detection as a four-class\\nclassification system with classes being the basic emotions anger, fear,\\njoy, and sadness. For this classification task, we utilize pre-trained lan-\\nguage models and fine-tune them with an aim to find the best-fit map-\\nping function 𝑓 ∶ 𝑦 = 𝑓(𝑥) for the fine-tuning data (𝑥1,𝑦1),(𝑥2,𝑦2),… ,\\n(𝑥𝑁,𝑦𝑁) with 𝑁 documents, where 𝑥𝑖 indicates ith document in the\\nfine-tuning corpus and 𝑦𝑖 indicates the corresponding ground-truth\\nemotion.\\nThe choice of PLMs, GPT-2 (Radford et al., 2019), BERT (De-\\nvlin et al., 2019), XLNet (Yang et al., 2019), and T5 (Raffel et al.,\\n2020), that are utilized in this study to identify affective bias, is\\nmotivated by considering their acceptance as relevant and neoteric\\ncontextualized models with high performance efficacy towards textual\\nemotion detection (Adoma et al., 2020; Acheampong et al., 2021)\\nand the much related task of sentiment analysis (Zhang et al., 2020;\\nTabinda Kokab et al., 2022) within the area of affective computing.\\nGPT and BERT are the very popular PLMs that follow the most ef-\\nfective auto-regressive and auto-encoding self-supervised pre-training\\nobjectives, respectively, where GPT uses transformer decoder blocks,\\nwhereas BERT uses transformer encoder blocks. The autoregressive\\n6'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 6, 'page_label': '7', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='A. Kadan, Deepak P., S. Bhadra et al. Natural Language Processing Journal 7 (2024) 100062\\nTable 5\\nFine-tuning corpus statistics.\\nEmotions Number of documents\\nTraining Validation\\nAnger 2089 388\\nFear 2641 389\\nJoy 1906 290\\nSadness 1930 397\\nnature of GPT helps to effectively encode sequential knowledge and\\nachieve good results (Radford et al., 2019). On the other hand, by\\neliminating the autoregressive objective and alleviating unidirectional\\nconstraints through the masked language model pre-training objective,\\nBERT attains powerful bi-directional representations. This ability of\\nBERT to learn context from both sides of a word makes it an empirically\\npowerful state-of-the-art model (Devlin et al., 2019). XLNet brings back\\nthe auto-regressive pre-training objective with alternate ways to extract\\ncontext from both sides of a word and overcome the pretrain-finetune\\ndiscrepancy of BERT outperforming it in several downstream NLP tasks\\n(Yang et al., 2019). The development of T5 explores the landscape of\\nNLP transfer learning and proposes a unified framework that converts\\nall textual language related problems into the text-to-text format and\\nachieves improved performance (Raffel et al., 2020).\\nEach pre-trained language model (PLM) after fine-tuning and appli-\\ncation of softmax function at the final layer forms the textual emotion\\ndetection model (i.e., softmax(PLM)). For each textual document 𝑑, the\\nfine-tuned textual emotion detection models predict an emotion class\\n̂ 𝑒𝑐𝑙𝑎𝑠𝑠 by finding the highest prediction intensity score ̂ 𝑒𝑠𝑐𝑜𝑟𝑒 among 𝐸\\nclasses of emotions (namely anger, fear, joy, and sadness, for our task)\\nrepresented as,\\n̂ 𝑒𝑐𝑙𝑎𝑠𝑠(𝑑) = argmax\\n𝑘∈1,2,…,𝐸\\n𝑠𝑜𝑓𝑡𝑚𝑎𝑥(𝑃𝐿𝑀(𝑑)) (1)\\n̂ 𝑒𝑠𝑐𝑜𝑟𝑒(𝑑) = max\\n𝑘∈1,2,…,𝐸\\n𝑠𝑜𝑓𝑡𝑚𝑎𝑥(𝑃𝐿𝑀(𝑑)) (2)\\nTo fine-tune PLMs and build emotion detection models, we use\\n24-layered version of the pre-trained BERT, GPT-2, XLNet, and T5\\navailable at HuggingFace, 16 i.e., bert-large-uncased,17 gpt2-medium,18\\nxlnet-large-cased,19 and t5-large, 20 respectively, and update these ar-\\nchitectures by adding a final dense layer of four neurons with softmax\\nactivation function on top of the base models to suit our four class\\nclassification task. For our study, the choice of GPT-2 instead of the\\nlatest version GPT-3 (Brown et al., 2020) is due to its unavailability as\\nan open-source pre-trained model. All four models are fine-tuned using\\na popular affect detection corpus SemEval-2018 EI-oc (Mohammad\\net al., 2018) that consists a total of 10 030 data instances for the\\nemotions anger, fear, joy, and sadness. The fine-tuning corpus is split as\\n8566 data instances for training and 1464 data instances for validation;\\ndetails of the number of data instances belonging to each emotion\\ncategory in the train and validation splits are shown in Table 5.\\nThe hyperparameters that can aid the reproducibility of our emotion\\ndetection models are, for GPT-2, XLNet, and T5 we useAdam optimizer\\nwith learning rate 0.000001, categorical crossentropy loss function,\\nand 100 epochs, whereas for BERT the learning rate is 0.00001 and\\nrest of the above mentioned parameters are the same. The batch size\\nis set to 80 for BERT, XLNet, and T5, whereas 64 for GPT-2. The\\ntotal number of trainable parameters for our BERT, GPT-2, XLNet,\\nand T5 textual emotion detection models come out as 335145988,\\n354827268, 360272900, and 334943748, respectively. All experiments\\nwere conducted on a deep learning workstation equipped with Intel\\n16 https://huggingface.co/.\\n17 https://huggingface.co/docs/transformers/model_doc/bert.\\n18 https://huggingface.co/docs/transformers/model_doc/gpt2.\\n19 https://huggingface.co/docs/transformers/model_doc/xlnet.\\n20 https://huggingface.co/docs/transformers/model_doc/t5.\\nXeon Silver 4208 CPU at 2.10 GHz, 256 GB RAM, and two GPUs\\nof NVIDIA Quadro RTX 5000 (16 GB for each), using the libraries\\nTensorflow (version 2.8.0), Keras (version 2.8.0), Transformer (version\\n4.17.0), and NLTK (version 3.6.5).\\n4.2. Measuring prediction level affective bias\\nThe textual emotion detection models, when supplied with a docu-\\nment/sentence, predict as output the emotion class and corresponding\\nemotion intensity of the document/sentence. To identify prediction\\nlevel affective bias in textual emotion detection models, we input into\\nthese models a sentence pair that differs only in key terms representing\\ndifferent social groups, with an aim to compare and contrast between\\nemotion predictions of sentences in that pair. For instance, sentence\\npairs such as ‘ She made me feel angry’ versus ‘ He made me feel angry’\\nthat only differ in key terms representing female and male social groups\\nconcerning gender domain, or ‘ African American people can dance very\\nwell’ versus ‘ European American people can dance very well’ that only\\ndiffer in key terms representing African American and European Amer-\\nican social groups concerning racial domain, are input to the models\\nto compare and contrast between emotion predictions of sentences in\\nthese pairs. Comparing emotion predictions using such sentence pairs\\nhelps to pair-wise analyze and understand whether algorithmic deci-\\nsions of emotion classification are similar (or different) across different\\nsocial groups within a domain. Accordingly, to identify prediction level\\naffective bias, we use evaluation corpora that consist of sentence pairs\\ndiffering only in key terms representing various social groups.\\nThe prediction of emotion class for a sentence is decided by the\\nintensity of emotions predicted by the textual emotion detection model\\nfor that sentence. For example, for a prediction ̂𝐸𝑠𝑐𝑜𝑟𝑒(𝑑) = {0.5,0.2,\\n0.1,0.2}, the choice of emotion class from the set 𝐸 = {𝑎𝑛𝑔𝑒𝑟,𝑓𝑒𝑎𝑟,\\n𝑗𝑜𝑦,𝑠𝑎𝑑𝑛𝑒𝑠𝑠}, would be anger. Differences in the intensities of emotion\\npredictions between sentences in a pair show existence of affective bias\\nat the intensity level, which when higher enough can alter the predic-\\ntion of emotion class and thereby cause affective bias at the class level.\\nThat is, an unbiased model is expected to predict the same emotion\\nclass and intensities for the sentence pairs that only differ in key terms\\nrepresenting different social groups. Hence, to analyze affective bias in\\nthe predictions, we utilize class based and intensity based evaluation\\nmeasures capable of comparing predictions of these sentence pairs. The\\nevaluation corpora and measures are detailed below.\\n4.2.1. Evaluation corpora\\nOur choice of bias evaluation corpora is based on the objective\\nto identify affective bias in textual emotion detection models using\\nsentence pairs that only differ in key terms representing social groups,\\nconcerning either gender, racial, or religious domain. Suitably, we\\nutilize three different evaluation corpora, Equity Evaluation Corpus\\n(EEC) (Kiritchenko and Mohammad, 2018), Bias Identification Test\\nin Sentiments (BITS) corpus (Venkit and Wilson, 2021), and Crowd-\\nsourced Stereotype Pairs (CSP) corpus (Nangia et al., 2020). Similar\\nto most bias evaluation corpora, EEC and BITS contain template based\\nsynthetically created sentences along with ground truth emotions. On\\nthe contrary, CSP is a crowd sourced non-synthetic bias evaluation\\ncorpus that possesses greater diversity within data in the perspective\\nof context expressed and structure of sentence pairs, but it does not\\ncontain ground truth emotions.\\nEEC consists of a total of 8640 sentences capable of evaluating\\ngender and racial domains, from which we select 8400 sentences for\\nour study after excluding 240 sentences with no emotion words. For\\nthe gender domain, the sentence pairs in EEC represent only two social\\ngroups, female and male. To tease out affective bias towards the gender\\ndomain, we select 1400 sentence pairs. For the racial domain, the\\nsentence pairs represent African American and European American\\nsocial groups, and we select 2800 sentence pairs to analyze affective\\nbias in racial domain.\\n7'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 7, 'page_label': '8', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='A. Kadan, Deepak P., S. Bhadra et al. Natural Language Processing Journal 7 (2024) 100062\\nBITS consists of a total of 720 sentences capable of evaluating\\ngender and racial domains. In BITS, the sentence pairs for gender\\ndomain also include the non-binary social group besides female and\\nmale groups. For this study, we select the available 120 sentences\\nfor each non-binary, female, and male social group in the gender\\ndomain. The racial domain includes social groups such as American\\nIndian, Asian, and Latino, apart from African American and European\\nAmerican groups. For this study, we only select the available small\\nset of 72 sentence pairs representing African American and European\\nAmerican social groups, as we limit our investigation only to these two\\nracial groups.\\nCSP contains 1508 sentence pairs that cover nine domains, includ-\\ning gender, race, religion, age, nationality, etc., that, unlike EEC and\\nBITS, do not differ ‘only’ on a single key term. A sample sentence pair in\\nCSP for the racial domain is ‘African Americanpeople are notvery ambi-\\ntious as a whole’ versus ‘European Americanpeople arevery ambitious as a\\nwhole’. Such sentence pairs violate our evaluation setting of considering\\nsentence pairs that ‘only’ differ in key terms representing certain social\\ngroups, an evaluation strategy to identify bias. But considering the\\nusefulness of such a non-synthetic corpus that suits the real-world con-\\ntext, we manually evaluate all sentence pairs in CSP and modify them\\n(if required) to suit our evaluation settings. An example of modified\\nversions for the above mentioned sentence pair is, ‘ African American\\npeople are not very ambitious as a whole’ versus ‘European Americanpeople\\nare not very ambitious as a whole’, and ‘ African American people are\\nvery ambitious as a whole’ versus ‘ European American people are very\\nambitious as a whole’. Finally, after such modifications and exclusion\\nof pairs belonging to domains other than gender, race, and religion,\\nwe gather 1970 sentences, where the gender domain consists of 263\\nsentence pairs representing female and male, the racial domain consists\\nof 566 sentence pairs representing African Americans and European\\nAmericans, and religious domain consists of 104 sentences each for\\nChristian, Jew, and Muslim social groups.\\nEven though in some evaluation corpora, certain domains consist\\nof three social groups (e.g. in BITS, the gender domain consists of\\nmale, female, and non-binary social groups, in CSP, the religious do-\\nmain consists of Christian, Jew, and Muslim groups), our evaluation\\nstrategies are limited to pair-wise evaluations, to maintain commonality\\namong all the domains. That is, for all the evaluation corpora, from the\\navailable set of social groups, we conduct pair-wise evaluations for the\\npairs, Male versus Female (M × F), Male versus Non-binary (M × Nb),\\nor Female versus Non-binary (F × Nb) in gender domain, European\\nAmerican versus African American (EA × AA) in the racial domain, and\\nChristian versus Muslim (Ch × Mu), Christian versus Jew (Ch × Jw) or\\nMuslim versus Jew (Mu × Jw) in the religious domain.\\n4.2.2. Evaluation measures\\nFor an evaluation corpus with 𝑁 sentence pairs, we denote 𝑠𝑝𝑔1\\n𝑖 and\\n𝑠𝑝𝑔2\\n𝑖 as the ith sentence pair representing two social groups 𝑔1 and 𝑔2\\n(e.g. Male versus Female), respectively, in a domain (e.g. gender). We\\nevaluate the existence of prediction level affective bias using different\\nmeasures that rely on class ( ̂ 𝑒𝑐𝑙𝑎𝑠𝑠) and intensity ( ̂ 𝑒𝑠𝑐𝑜𝑟𝑒) predictions of\\nthe textual emotion detection models, details follow.\\n• Demographic Parity (DP): A popular class based measure to quan-\\ntify group fairness/bias of a classifier system, commonly used\\nto address general affect-agnostic biases like gender bias, racial\\nbias, etc. Du et al. (2021). We utilize this measure to identify\\nthe existence of affective bias and check whether the model’s\\nemotion classifications are similar (or different) across different\\nsocial groups within a domain. Accordingly, we say that a textual\\nemotion detection model satisfies demographic parity if,\\nDP = 𝑃(̂ 𝑒𝑐𝑙𝑎𝑠𝑠(𝑠𝑝𝑔1 ) =𝑒|𝑧= 𝑔1)\\n𝑃(̂ 𝑒𝑐𝑙𝑎𝑠𝑠(𝑠𝑝𝑔2 ) =𝑒|𝑧= 𝑔2) , 𝑒 ∈ 𝐸 and 𝑔1,𝑔2 ∈ 𝑇 (3)\\nwhere, 𝑃(̂ 𝑒𝑐𝑙𝑎𝑠𝑠(𝑠𝑝𝑔1 ) = 𝑒|𝑧 = 𝑔1) and 𝑃(̂ 𝑒𝑐𝑙𝑎𝑠𝑠(𝑠𝑝𝑔2 ) = 𝑒|𝑧 = 𝑔2)\\nindicates the probabilities of the two social groups 𝑔1 and 𝑔2,\\nrespectively, to predict an emotion 𝑒; 𝑔2 is taken as the group\\nwith higher probability (Feldman et al., 2015). 𝐸 is the set of\\nall emotions, and 𝑇 is the set of social groups in a domain.\\nDemographic parity advocates the likelihood of emotion predic-\\ntion outcomes of sentence pairs that differ only in key terms\\ndenoting a certain social group should be the same; as a result,\\nDP=1 indicates an ideal unbiased scenario, whereas, lower the\\nvalues higher the existence of bias. Therefore, we use the general\\nthreshold 𝜏 = 0.80, lower than which indicates biased predictions\\n(Feldman et al., 2015).\\n• Average Difference of Prediction Intensity Scores ( 𝑎𝑣𝑔.𝛥): An\\nintensity based measure that computes the average difference of\\nemotion prediction intensity scores between the sentence pairs\\nof two social groups in a domain (Kiritchenko and Mohammad,\\n2018).\\n𝑎𝑣𝑔.𝛥= 1\\n𝑁\\n𝑁∑\\n𝑖=1\\n|̂ 𝑒𝑠𝑐𝑜𝑟𝑒(𝑠𝑝𝑔1\\n𝑖 ) −̂ 𝑒𝑠𝑐𝑜𝑟𝑒(𝑠𝑝𝑔2\\n𝑖 )| (4)\\nwhere, ̂ 𝑒𝑠𝑐𝑜𝑟𝑒(𝑠𝑝𝑔1\\n𝑖 ) and ̂ 𝑒𝑠𝑐𝑜𝑟𝑒(𝑠𝑝𝑔2\\n𝑖 ) indicates emotion prediction\\nintensity scores corresponding to the social groups 𝑔1 and 𝑔2,\\nrespectively, for the ith sentence pair concerning a domain, and\\n𝑁 denotes the total number of sentence pairs. That is, 𝑎𝑣𝑔.𝛥\\nindicates the average dissimilarity in prediction scores between\\na pair of sentences; 0 indicates perfect similarity, and higher the\\nvalues more the dissimilarity.\\n• Prediction Score Significance ( 𝑝-value): A measure that shows\\nwhether dissimilarity in prediction scores between the sentence\\npairs is statistically significant or not. To compute prediction\\nscore significance, we perform a paired statistical significance\\ntest, 𝑡-Test (Kiritchenko and Mohammad, 2018) over the predic-\\ntion scores of sentence pairs, ̂ 𝑒𝑠𝑐𝑜𝑟𝑒(𝑠𝑝𝑔1\\n𝑖 ) and ̂ 𝑒𝑠𝑐𝑜𝑟𝑒(𝑠𝑝𝑔2\\n𝑖 ), using the\\nconventional significance level, i.e., a 𝑝-value of 0.05.\\n• Average Confidence Score (ACS): A measure that illustrates model\\nbias towards a particular social group using the average ratio\\nbetween prediction intensity scores of sentence pairs (Nangia\\net al., 2020), computed as,\\nACS = 1\\n𝑁\\n𝑁∑\\n𝑖=1\\n1 −\\n̂ 𝑒𝑠𝑐𝑜𝑟𝑒(𝑠𝑝𝑔1\\n𝑖 )\\n̂ 𝑒𝑠𝑐𝑜𝑟𝑒(𝑠𝑝𝑔2\\n𝑖 )\\n(5)\\nACS value of an unbiased model will peak around zero, but if\\nit tends to negative values, then the measure indicates that the\\nmodel prediction intensities of the social group𝑔1 are higher than\\n𝑔2, and if it tends to positive values, it indicates that prediction\\nintensities of the social group 𝑔2 are higher than 𝑔1.\\n4.3. Results and analysis of prediction level affective bias\\nWe examine emotion predictions of each PLM based textual emotion\\ndetection system and could observe the existence of affective bias in\\nthe predicted emotion classes, as well as their intensities, for gender,\\nrace, and religious domains. The sample set of predictions presented in\\nTable 1 is a small subset of these affectively biased emotion predictions\\nfrom the emotion detection models that employ BERT and T5. More sets\\nof affectively biased predictions from the PLM based textual emotion\\ndetection systems, are provided in the supplementary material. In the\\nfollowing subsections, we evaluate the results of each PLM separately.\\n4.3.1. Affective bias in BERT\\nTable 6 shows evaluation results observed for the textual emotion\\ndetection model built using BERT, analyzing gender, racial and re-\\nligious domains using three different evaluation corpora EEC, BITS,\\nand CSP, and various evaluation measures. The pairs of social groups\\naddressed by the evaluation corpora within each domain are presented\\ncolumn wise, the measures are presented row wise, and the emotions\\nare grouped across the rows.\\n8'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 8, 'page_label': '9', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='A. Kadan, Deepak P., S. Bhadra et al. Natural Language Processing Journal 7 (2024) 100062\\nTable 6\\nResults of BERT (Boldface is used to highlight the values of DP < threshold 𝜏 = 0.80 and p-values <0.05).\\nEvaluation Gender Race Religion\\nmeasures EEC\\nM × F\\nBITS\\nM × F\\nCSP\\nM × F\\nBITS\\nM × Nb\\nBITS\\nF × Nb\\nEEC\\nEA × AA\\nBITS\\nEA × AA\\nCSP\\nEA × AA\\nCSP\\nCh × Mu\\nCSP\\nCh × Jw\\nCSP\\nMu × Jw\\nAnger\\nDP 0.964 1.000 0.836 0.866 0.867 0.996 0.948 1.000 0.923 0.923 1.000\\navg.𝛥 0.018 0.016 0.049 0.038 0.030 0.031 0.012 0.052 0.076 0.078 0.100\\np-value 0.003 0.036 0.037 0.047 0.132 0.417 0.431 0.730 0.038 0.042 2e −04\\nACS 0.010 0.017 0.025 0.036 0.020 −0.005 −0.008 −0.001 0.050 −0.084 −0.148\\nFear\\nDP 0.954 1.000 1.000 0.938 0.938 0.961 1.000 0.743 0.857 0.885 0.968\\navg.𝛥 0.019 0.049 0.086 0.085 0.086 0.049 0.058 0.109 0.076 0.089 0.073\\np-value 9.2e−12 0.864 0.767 0.043 0.063 5.3e−27 0.748 1.2e−6 0.044 0.439 0.001\\nACS 0.019 −0.010 −0.015 −0.094 −0.088 −0.055 −0.016 −0.123 0.031 −0.041 −0.082\\nJoy\\nDP 0.994 1.000 0.971 1.000 1.000 1.000 1.000 0.797 0.455 0.637 0.713\\navg.𝛥 0.002 9.9e −5 0.072 0.001 0.001 0.005 0.001 0.076 0.148 0.031 0.130\\np-value 0.400 0.061 0.014 0.360 0.394 0.002 0.611 0.001 0.033 0.425 0.021\\nACS −0.001 −5.8e−5 0.064 −0.001 −0.001 −0.004 −1e−4 −0.080 −0.240 −0.022 0.169\\nSadness\\nDP 0.953 1.000 0.872 0.938 0.938 0.977 0.950 0.724 0.666 0.666 1.000\\navg.𝛥 0.027 0.013 0.076 0.024 0.033 0.056 0.012 0.116 0.124 0.100 0.051\\np-value 1.8e−4 0.045 0.019 0.461 0.156 0.600 0.924 1e−12 0.065 0.201 0.146\\nACS −0.020 −0.019 −0.064 0.006 0.022 −0.010 −0.002 0.100 −0.279 −0.169 0.064\\n(A) Affective Gender Bias:Initially, looking into the gender domain,\\nfor class based measure DP, throughout all the emotions, we can\\nobserve that there is almost no affective bias in the predictions\\nmade by BERT between male and female groups when evaluated\\nusing the EEC corpus (since, DP > 0.8 in all cases), and ideally\\nno affective bias when evaluated using BITS corpus (since, DP =\\n1 in all cases). This ideal scenario in BITS might be because\\nBITS is a small corpus containing short-length synthetically cre-\\nated sentences with explicit emotion terms that do not suit the\\nreal-world context. When compared to synthetic corpora (EEC\\nand BITS), evaluations using the real-world context and non-\\nsynthetic corpus CSP shows more disparity (lower values of DP)\\nbetween male and female groups for all the emotions except\\nfear. For pairs involving non-binary genders, the values of DP\\nare much less than those involving male and female groups of\\nsynthetic corpora EEC and BITS, for all emotions except joy.\\nThis indicate more disparity of male and female groups with\\nnon-binary gender, with respect to anger, fear and sadness. Since\\nthe evaluation of affective bias in non-binary social groups is\\nonly possible with BITS corpus, it may limit the exploration\\nof affective bias towards this group and also the magnitude of\\naffective bias. For the measure DP, when looking across each\\nemotion, the most disparity (lowest value for DP) is observed\\nfor anger between male versus female when evaluated using CSP\\ncorpus, followed by male versus non-binary, and female versus\\nnon-binary, for the same emotion, when evaluated using BITS\\ncorpus. Whereas, for joy, very less disparity is observed across\\nthe gender groups. In total, even though disparities are shown\\nby DP, any of the gender pairs do not have values of DP less than\\nthe threshold 𝜏 = 0.80. Hence DP does not establish the existence\\nof gender affective bias in the predictions of BERT using these\\nevaluation corpora.\\nComing to the intensity based measure avg. 𝛥 in the gender\\ndomain, similar to DP, more disparity is observed for male\\nversus female pairs when evaluated using CSP corpus and also\\nfor the pairs involving non-binary social groups in BITS, across\\nall the emotions. Different from the measure DP, avg. 𝛥 reports\\nhighest disparity for fear, but similar to DP, avg. 𝛥 shows very\\nless disparity for joy. For the next measure 𝑝-value, at least one\\nof the evaluation corpora reports values less than 0.05 or statisti-\\ncally significant difference between male and female predictions\\nacross the emotions, indicating the existence of affective bias.\\nThe 𝑝-value also shows that difference between male and non-\\nbinary predictions for anger and fear are statistically significant.\\nAnalyzing the prediction intensity plots of pairs with statistically\\nsignificant differences (e.g. Figs. 2(a) and 2(b)), shows that their\\nintensity plots also depict more dispersion between data points\\nas well as more disparity between the corresponding mean val-\\nues. Conversely, in the plots of sentence pairs with statistically\\ninsignificant differences in prediction intensities (e.g. Fig. 2(c)),\\nthere is very less dispersion between data points and less dispar-\\nity between the mean values. Therefore𝑝-value evidently reports\\nthe existence of affective bias in emotion prediction intensities\\nof male and female groups with respect to all emotions, and for\\nmale and non-binary groups with respect to anger and fear.\\nIn the case of intensity based measure ACS, for emotion anger,\\nthe positive values in Male versus Female sentence pairs of EEC,\\nBITS, and CSP indicates that prediction intensities for anger are\\nhigher for the Female when compared to Male, and positive\\nvalues in Male versus Non-binary and Female versus Non-binary\\nsentence pairs of BITS indicates that anger prediction intensities\\nare higher for the Non-binary group when compared to Male and\\nFemale. Similarly, when examining across evaluation corpora,\\nprediction intensities of fear and joy are higher for Male and\\nFemale genders, and prediction intensities of sadness are higher\\nfor Male and Non-binary genders. Therefore in the gender do-\\nmain, the measure ACS also indicates affective bias in prediction\\nintensities.\\n(B) Affective Racial Bias:The European and African American racial\\ngroups when evaluated using CSP corpus, for the measure DP,\\nshows the presence of affective bias for all emotions except\\nanger, where EEC and BITS fail to identify it. Similarly, the avg.𝛥\\ndisparities among intensity predictions of these racial groups\\nare also much more visible when evaluated using CSP corpus.\\nEither or both, EEC and CSP corpora shows that the difference\\nin intensity predictions of these racial groups are statistically\\n9'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 9, 'page_label': '10', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='A. Kadan, Deepak P., S. Bhadra et al. Natural Language Processing Journal 7 (2024) 100062\\nFig. 2. Intensity plots of emotion predictions from BERT.\\nsignificant with p-values less than 0.05, for all emotions ex-\\ncept anger, similar to the observations of the measure DP. The\\nmeasure ACS also shows disparities in prediction intensities\\nbetween the racial groups, where, for all emotions, prediction\\nintensities of European American race are mostly higher than\\nAfrican American.\\n(C) Affective Religious Bias: In the religious domain, the measure\\nDP evidently shows affective bias in the emotion joy with very\\nlow values for all three religious pairs and also in sadness for\\nChristian versus Muslim and Christian versus Jew pairs. For\\nall the emotions, the values of DP indicate more bias in the\\nChristian versus Muslim and Christian versus Jew sentence pairs\\nthan in the Muslim versus Jew pairs. The measure avg. 𝛥 shows\\nthat there exist disparities between prediction intensities of reli-\\ngious pairs, and these disparities are found to be comparatively\\nhigher than the pairs of gender and racial domains. The 𝑝-value\\nindicates statistically significant differences in intensity predic-\\ntions of anger between all three religious pairs. Also, Christian\\nversus Muslim and Muslim versus Jew pairs show statistically\\nsignificant differences in intensity predictions of all emotions\\nexcept sadness. The measure ACS shows that for BERT anger and\\nfear prediction intensities are higher for Muslim followed by\\nChristian, and joy and sadness prediction intensities are higher\\nfor Christian followed by Jew.\\n4.3.2. Affective bias in GPT-2\\n(A) Affective Gender Bias:Table 7 shows evaluation results observed\\nfor GPT-2 where similar to BERT, no gender affective bias is\\nobserved with the measure DP for any of the emotion class\\npredictions. Whereas intensity based disparities are shown by\\nthe measure avg.𝛥, which is highly visible when evaluated using\\nCSP corpus. The difference in prediction intensities between\\nMale versus Female when evaluated using EEC corpus for all\\nemotions except joy, and Male versus Non-binary and Female\\nversus Non-binary when evaluated using BITS corpus for all\\nemotions except fear, are statistically significant with p-values\\n< 0.05, indicating the existence of affective bias in emotion\\nprediction intensities. The measure ACS indicates that, in GPT-\\n2, anger and joy prediction intensities are higher for Male and\\nFemale genders, fear prediction intensities are higher mainly for\\nFemale, and sadness prediction intensities are higher mainly for\\nMale gender.\\n(B) Affective Racial Bias: In the racial domain, similar to gender,\\nDP does not show racial affective bias for any of the emotion\\nclass predictions, whereas intensity based disparities are shown\\nby the measure avg. 𝛥. Here also, the disparities for class based\\nmeasure DP and intensity based measure avg.𝛥, are more visible\\nwhen evaluated using CSP corpus. Whereas BITS reports an ideal\\nunbiased scenario for DP and very low disparity for avg. 𝛥. The\\nmeasure 𝑝-value reports that the difference in prediction inten-\\nsities of European and African American races are statistically\\nsignificant for all emotions except sadness. The measure ACS\\nshows that, in GPT-2, prediction intensities of anger and sadness\\nare mostly higher for African American race, whereas predic-\\ntion intensities of fear and joy are mostly higher for European\\nAmerican race.\\n(C) Affective Religious Bias:Unlike gender and race, in the religious\\ndomain the class based measure DP reports affective bias (with\\nvalues of DP < 0.8) in the predictions of all emotions except\\nfear. The measure avg. 𝛥 also shows disparities in prediction\\nintensities of religious pairs. The p-values indicate that differ-\\nence in fear prediction intensities for the pairs Christian versus\\nMuslim and Muslim versus Jew are statistically significant. The\\n10'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 10, 'page_label': '11', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='A. Kadan, Deepak P., S. Bhadra et al. Natural Language Processing Journal 7 (2024) 100062\\nTable 7\\nResults of GPT-2 (Boldface is used to highlight the values of DP < threshold 𝜏 = 0.80 and p-values <0.05).\\nEvaluation Gender Race Religion\\nmeasures EEC\\nM × F\\nBITS\\nM × F\\nCSP\\nM × F\\nBITS\\nM × Nb\\nBITS\\nF × Nb\\nEEC\\nEA × AA\\nBITS\\nEA × AA\\nCSP\\nEA × AA\\nCSP\\nCh × Mu\\nCSP\\nCh × Jw\\nCSP\\nMu × Jw\\nAnger\\nDP 0.992 0.926 0.954 0.960 0.889 0.980 1.000 0.920 0.600 0.867 0.692\\navg.𝛥 0.023 0.006 0.039 0.008 0.008 0.038 0.010 0.050 0.059 0.048 0.021\\np-value 2.5e−05 0.103 0.772 0.031 0.004 3.4e −5 0.015 0.037 0.580 0.788 0.626\\nACS 0.013 0.007 −0.005 −0.006 −0.008 0.011 0.012 0.015 −0.044 −0.018 0.010\\nFear\\nDP 1.000 1.000 0.991 0.960 0.960 0.996 1.000 0.901 0.883 0.985 0.870\\navg.𝛥 0.016 0.007 0.058 0.017 0.015 0.030 0.010 0.063 0.139 0.069 0.158\\np-value 0.048 0.372 0.505 0.917 0.787 0.012 0.101 0.183 6.9e−13 0.262 7e−13\\nACS −0.003 0.002 0.001 3.7e −4 −0.001 −0.011 −0.014 0.005 0.159 −0.040 −0.277\\nJoy\\nDP 0.985 1.000 0.914 1.000 1.000 0.995 1.000 0.936 0.545 0.600 0.909\\navg.𝛥 0.008 3.3e −5 0.073 0.001 0.001 0.017 2e −4 0.101 0.114 0.100 0.089\\np-value 0.640 0.713 0.761 0.018 0.017 0.872 0.204 6.1e−5 0.110 0.944 0.069\\nACS −7.3e−5 5.3e −6 −0.023 −0.001 −0.001 −0.003 −2e−4 −0.108 0.135 −0.011 −0.129\\nSadness\\nDP 0.985 0.951 0.927 1.000 0.951 0.996 1.000 0.938 0.467 0.933 0.502\\navg.𝛥 0.011 0.002 0.047 0.014 0.014 0.018 0.010 0.055 0.039 0.045 0.045\\np-value 4.5e−29 0.262 0.313 0.042 0.042 0.178 0.725 0.283 0.310 0.429 0.343\\nACS −0.012 −0.001 −0.020 −0.013 −0.011 −0.002 0.001 0.006 −0.058 0.028 0.060\\nmeasure ACS shows that for GPT-2 anger prediction intensities\\nare mostly higher for Christian, fear and joy prediction intensi-\\nties are higher for Muslim and Christian, and sadness prediction\\nintensities are mostly higher for Jew groups.\\n4.3.3. Affective bias in XLNet\\n(A) Affective Gender Bias:Table 8 shows evaluation results of XLNet,\\nwhere the class based measure DP shows negligible affective bias\\n(values of DP is almost one) in emotion predictions of gender\\npairs, whereas avg. 𝛥 shows disparities in emotion prediction\\nintensities of these pairs. The p-values report that differences be-\\ntween intensity predictions are statistically significant for Male\\nversus Female pairs for all emotions, and also for pairs involving\\nthe Non-binary group for emotion anger. The measure ACS indi-\\ncates high anger and fear prediction intensities for Female and\\nMale genders, and high joy and sadness prediction intensities for\\nMale and Non-binary genders.\\n(B) Affective Racial Bias: Similar to the gender domain, the mea-\\nsure DP does not confirm class based affective racial bias in\\nXLNet, but avg. 𝛥 shows disparity in intensities of predictions\\nwith 𝑝-value indicating statistically significant differences be-\\ntween prediction intensities of both races, for all emotions. The\\nmeasure ACS shows that anger and sadness prediction intensities\\nare higher for African American, whereasfear and joy prediction\\nintensities are higher for European American race.\\n(C) Affective Religious Bias:In the religious domain, even though the\\nvalues of DP are less compared to gender and racial domains,\\nit is not sufficient to confirm class based affective religious bias\\nin the emotions except sadness whose values are very low and\\nreporting bias. The measure avg.𝛥shows disparity in prediction\\nintensities, with 𝑝-value indicating statistically significant differ-\\nences between Christian versus Muslim and Muslim versus Jew\\nreligious pairs, for anger and sadness. The measure ACS indicates\\nthat anger prediction intensities are mostly higher for Muslim\\nreligion followed by Christian, fear mostly higher for Christian\\nfollowed by Muslim, andjoy and sadness higher for Christian and\\nJew.\\n4.3.4. Affective bias in T5\\n(A) Affective Gender Bias: Table 9 shows evaluation results of T5.\\nIn the gender domain, class based measure DP shows affective\\nbias in the predictions of Male versus Female pair for anger and\\nfear when evaluated using CSP corpus. The avg.𝛥measure shows\\ndisparities in prediction intensities, and p-values indicate that\\ndifferences in prediction intensities of Male versus Female pair\\nfor all emotions except fear and in pairs involving Non-binary\\ngender for emotions anger and fear are statistically significant.\\nThe measure ACS indicates high prediction intensities for anger,\\njoy and sadness mostly by Male gender and high prediction\\nintensities for fear mostly by Female and Non-binary genders.\\n(B) Affective Racial Bias: The measure DP does not confirm class\\nbased affective racial bias in T5 predictions, whereas avg. 𝛥\\nshows intensity based affective racial bias, with statistically\\nsignificant differences in intensity predictions of the racial pairs\\nfor all the emotions. ACS indicates prediction intensities of\\nAfrican American race are higher for anger, whereas prediction\\nintensities of European American are higher for fear, joy and\\nsadness.\\n(C) Affective Religious Bias: In the religious pairs, the measure DP\\nindicates affective bias in Muslim versus Jew pairs for all emo-\\ntions, in Muslim versus Christian pairs for all emotions except\\nanger, and in Christian versus Jew pairs for joy. The avg.𝛥shows\\nintensity based disparities in all emotions, and p-values indicate\\nthat the differences in prediction intensities are statistically sig-\\nnificant in the case of Muslim versus Jew pair for all emotions\\nexcept joy and in Christian versus Jew pair for the emotion\\nfear. ACS indicates that anger and joy prediction intensities are\\nhigher for Jew religion followed by Christian, fear prediction\\nintensities are higher for Christian followed by Muslim, and\\nsadness prediction intensities are higher for Christian followed\\nby Jew.\\n5. Discussion\\n5.1. Affective bias - Across the PLMs\\nThis study analyzes affective bias in the predictions of textual\\nemotion detection models at class level and intensity level. In most\\n11'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 11, 'page_label': '12', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='A. Kadan, Deepak P., S. Bhadra et al. Natural Language Processing Journal 7 (2024) 100062\\nTable 8\\nResults of XLNet (Boldface is used to highlight the values of DP < threshold 𝜏 = 0.80 and p-values <0.05).\\nEvaluation Gender Race Religion\\nmeasures EEC\\nM × F\\nBITS\\nM × F\\nCSP\\nM × F\\nBITS\\nM × Nb\\nBITS\\nF × Nb\\nEEC\\nEA × AA\\nBITS\\nEA × AA\\nCSP\\nEA × AA\\nCSP\\nCh × Mu\\nCSP\\nCh × Jw\\nCSP\\nMu × Jw\\nAnger\\nDP 0.983 1.000 1.000 1.000 1.000 0.976 1.000 0.974 0.825 0.869 0.950\\navg.𝛥 0.017 0.005 0.053 0.017 0.019 0.048 0.004 0.061 0.115 0.083 0.110\\np-value 1.7e−6 0.002 0.226 0.035 0.014 0.041 0.561 0.063 0.008 0.842 0.001\\nACS 0.015 0.005 −0.028 −0.015 −0.020 −0.021 0.002 0.015 0.077 −0.032 −0.153\\nFear\\nDP 0.991 1.000 0.989 1.000 1.000 0.988 1.000 0.938 0.810 1.000 0.810\\navg.𝛥 0.012 0.030 0.080 0.060 0.071 0.038 0.036 0.067 0.054 0.070 0.047\\np-value 0.032 0.809 0.680 0.667 0.642 0.228 0.004 0.003 0.561 0.807 0.703\\nACS 0.004 −0.001 −0.003 −0.008 −0.013 −0.007 −0.050 −0.062 −0.029 −0.005 −0.019\\nJoy\\nDP 0.993 1.000 0.974 1.000 1.000 0.970 1.000 0.804 0.856 1.000 0.857\\navg.𝛥 0.010 0.013 0.084 0.006 0.018 0.022 0.009 0.084 0.027 0.077 0.086\\np-value 0.457 0.118 0.028 0.158 0.125 0.011 0.573 0.024 0.357 0.410 0.397\\nACS −0.003 −0.018 0.056 0.006 0.019 −0.012 0.004 −0.073 −0.055 0.073 0.133\\nSadness\\nDP 0.998 1.000 0.989 1.000 1.000 0.997 1.000 0.902 0.533 0.833 0.640\\navg.𝛥 0.009 0.003 0.050 0.007 0.008 0.028 0.007 0.083 0.094 0.065 0.104\\np-value 0.013 0.010 0.553 0.203 0.061 0.253 0.075 5.1e−6 0.048 0.637 0.010\\nACS −0.003 −0.003 −0.031 0.002 0.005 −0.004 0.009 0.046 −0.131 0.007 0.124\\nTable 9\\nResults of T5 (Boldface is used to highlight the values of DP < threshold 𝜏 = 0.80 and p-values <0.05).\\nEvaluation Gender Race Religion\\nmeasures EEC\\nM × F\\nBIT\\nM × F\\nCSP\\nM × F\\nBITS\\nM × Nb\\nBITS\\nF × Nb\\nEEC\\nEA × AA\\nBITS\\nEA × AA\\nCSP\\nEA × AA\\nCSP\\nCh × Mu\\nCSP\\nCh × Jw\\nCSP\\nMu × Jw\\nAnger\\nDP 0.983 0.966 0.765 0.897 0.866 0.933 0.952 0.903 0.968 0.816 0.790\\navg.𝛥 0.039 0.016 0.077 0.021 0.022 0.101 0.004 0.106 0.082 0.113 0.097\\np-value 3.6e−20 0.530 0.385 0.017 0.043 0.001 0.458 6.8e−8 0.118 0.491 0.041\\nACS −0.044 0.006 −0.037 −0.029 −0.032 0.005 0.002 0.070 −0.086 0.014 0.064\\nFear\\nDP 0.994 1.000 0.778 0.897 1.000 0.966 1.000 0.867 0.783 0.915 0.717\\navg.𝛥 0.017 0.029 0.079 0.079 0.068 0.039 0.067 0.099 0.079 0.148 0.145\\np-value 0.309 0.318 0.662 0.003 0.004 3.1e −7 0.022 9.2e −5 0.602 0.001 2.8e −5\\nACS 0.002 0.008 −0.025 0.071 0.063 −0.035 −0.087 −0.111 −0.005 −0.242 −0.263\\nJoy\\nDP 0.990 1.000 0.848 1.000 1.000 0.961 1.000 0.971 0.624 0.375 0.600\\navg.𝛥 0.009 2e −4 0.062 1e −4 2.8e −4 0.029 0.009 0.068 0.183 0.001 0.075\\np-value 0.003 0.025 0.885 0.605 0.115 0.122 0.332 0.001 0.122 0.468 0.423\\nACS −0.009 −2e−4 −0.025 −1.6e−5 1.8e −4 −0.014 −0.014 −0.078 −0.320 0.001 0.075\\nSadness\\nDP 0.998 0.973 0.952 0.925 0.900 0.998 0.955 0.972 0.500 0.900 0.450\\navg.𝛥 0.023 0.006 0.082 0.009 0.014 0.074 0.007 0.103 0.095 0.118 0.085\\np-value 8.6e−15 0.035 0.689 0.223 0.871 0.002 0.048 0.957 0.121 0.751 0.020\\nACS −0.026 −0.006 −0.027 −0.008 −0.002 −0.040 −0.007 −0.030 −0.150 −0.002 0.099\\ncases, class based measures that are capable of identifying differences\\nin emotion classes predicted for two different social groups, do not\\nshow affective bias, whereas intensity based measures mostly identify\\nthe existence of affective bias in predicted emotion intensities. This\\nis because the differences in predicted emotion intensities between\\nthe social groups might not be that very high to alter the choice of\\nemotion class predictions, but even then there exists affective bias due\\nto differences in the predicted emotion intensities. When comparing\\nacross the PLMs, class based affective gender bias is only observed in\\nT5, whereas intensity based affective gender bias is observed in all\\nthe PLMs. Similarly, class based affective racial bias is only observed\\nin BERT, whereas intensity based affective racial bias is observed in\\nall the PLMs. But, in the domain of religion, all four PLMs show\\nhigh magnitudes of class based and intensity based affective bias,\\ni.e., compared to gender and race, the religious domain is observed to have\\nhigh existence of affective bias. We believe this could be a reflection\\nof comparatively high affect imbalance with respect to the religious\\ndomain in the pre-training corpora (from Table 4).\\nXLNet is observed to have the least class based affective bias, with\\nbias only observed in the case of the religious domain for the emo-\\ntion sadness. XLNet is also observed to have the least intensity based\\naffective bias among all the PLMs when considering the measures avg.𝛥\\n(i.e., the top five values of avg. 𝛥 do not have any instance of XLNet)\\nand 𝑝-value (i.e., the number of instances in XLNet with statistically\\nsignificant differences are also low). Whereas T5 has the maximum\\nclass based biased instances, and also high intensity based affective bias\\namong all the PLMs when considering the measures avg.𝛥(i.e., top five\\nvalues of avg.𝛥have three instances of T5) and𝑝-value (i.e., the number\\nof instances in T5 with statistically significant differences are also high).\\nBERT also shows class based and intensity based affective bias, nearly\\nsimilar but comparatively less than T5, followed by GPT-2.\\n12'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 12, 'page_label': '13', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='A. Kadan, Deepak P., S. Bhadra et al. Natural Language Processing Journal 7 (2024) 100062\\nThis study explores affective bias in large PLMs that are trained on\\nmillions of parameters. However, rapid growth in the data processing\\ntechnology and plenty availability of data has recently, very quickly\\nevolved the category of large PLMs to being trained on billions of\\nparameters, the PLMs such as LLaMA (Touvron et al., 2023), Flan-T5\\nXXL (Chung et al., 2022), PaLM (Chowdhery et al., 2023), LaMDA\\n(Thoppilan et al., 2022), etc. All these PLMs have the benefits of\\nhuge improvements in their performance, capable of performing several\\ndownstream tasks, and supporting multi-lingual and multi-modal data\\nprocessing. All such large PLMs highly rely on the large availability\\nof massive amounts of textual data especially collected from the web,\\nWikipedia, Book Corpus, etc. In most cases, which proportion of data\\nis extracted from a source to train a PLM is not fully transparent.\\nFor example, LLaMA uses different data proportions from different\\ncommonly available data deluges such as CommonCrawl (67.0%), C4\\n(15.0%), Wikipedia (4.5%), etc., where which data proportions are\\nextracted from each of the sources is not fully transparent. Also, the\\ntraining data quality is unmanageable and unverifiable by even a large\\ngroup of human crowd (Navigli et al., 2023), where there are chances\\nof the existence of affective biases in these recent large PLMs. For\\nexample, LLaMA is trained on data proportions from several corpora in-\\ncluding C4 and Wikipedia, which are already investigated in this study\\nand identified with the affect imbalances. The large PLMs PaLM and\\nLaMDA are also trained on billions of tokens extracted from web pages,\\nbooks, Wikipedia, and news articles, indicating chances of existence of\\naffective bias. Similarly, Flan-T5 is a variant of the T5, and in this study\\nwe observed that T5 has the highest affective bias amongst the PLMs\\nXLNet, BERT, and GPT-2.\\n5.2. Affect imbalance in corpora and affective bias in predictions\\nWhen revisiting the analysis of corpora involved in training PLMs,\\nwe have already observed (in Table 4) that these corpora have imbal-\\nanced co-occurrences of emotions with certain social groups in gender,\\nracial and religious domains. Further at the prediction level, PLMs that\\nutilize these corpora seems to reflect some of these imbalances hinting\\nat the propagation of affect imbalance in data towards affective bias\\nin predictions. For example, in pre-training and fine-tuning corpora\\nof BERT (i.e., WikiEn, BookCorpus, and SemEval-2018), the emotion\\nanger has high co-occurrence with Non-binary and Female groups than\\nMale. This seems to reflect in the predictions of BERT, i.e., the measure\\nACS shows that prediction intensities of anger are higher for Non-\\nbinary and Female groups than Male. Some other imbalanced emotion\\nassociations that exist in these corpora like sadness more associated\\nwith Male and Non-binary groups in the gender domain, joy more\\nassociated with European American racial group, fear more associated\\nwith Muslim, joy more associated with Christian, etc., are also seen\\nto be reflected in the predictions of BERT when evaluated using the\\nmeasure ACS. Similar to BERT, we can also observe the reflection of\\ncorpus level affective bias from pre-training and fine-tuning corpora\\nof GPT-2 (i.e., WebText-250k and SemEval-2018) to the predictions\\nof GPT-2, e.g., (1) high co-occurrence of fear with Female and Non-\\nbinary genders in the corpora, and high prediction intensities offear for\\nFemale and Non-binary genders, (2) high co-occurrence of anger with\\nAfrican American race in the corpora, and high prediction intensities\\nof anger for African American, (3) high co-occurrence of fear with\\nMuslim religion in the corpora, and high prediction intensities of fear\\nfor Muslim, etc. Such examples of reflection of corpus level affective\\nbias in the predictions of PLMs are also visible in XLNet and T5. These\\ninstances give hints that affect imbalances in the large scale corpora of\\nPLMs may lead to affective bias in the predictions of the models that utilize\\nthese PLMs. Hence, this study further opens the scope for much more\\nnuanced explorations in the direction of affective bias propagation from\\nthe corpus to model prediction.\\n5.3. Societal stereotypes and affective bias\\nThe imbalanced/biased association of emotions with certain so-\\ncial groups within a domain, either at the corpus level or prediction\\nlevel, reflects several affect-oriented societal stereotypes. Patterns in\\nthe training corpora and predictions of PLM based textual emotion\\ndetection models showing high association of African American race\\nwith anger (an example plot of high anger prediction intensities for\\nAfrican American race is presented in Fig. 3(a)) reflect the ‘‘Angry\\nBlack’’ stereotype that misrepresents and victimizes blacks as hostile\\nin mainstream American culture and suppress their emotions (Lozada\\net al., 2022). Another pattern of high association of European American\\nrace with fear (an example plot of high fear prediction intensities for\\nEuropean American is presented in Fig. 3(b)) reflects the existence of\\nstereotypes such as fear of crime, residential integration, and racial\\nprejudice among the whites (Skogan, 1995). The high association of\\nNon-binary genders with negative emotions especially fear, and very\\nrarely associating with positive emotionjoy, reflects the societal stigmas\\nlike homo-negativity and homophobia against these gender minorities\\n(Hahn et al., 2020). Similarly, the high association of Muslim religion\\nwith fear (an example plot of highfear prediction intensities for Muslim\\nis presented in Fig. 3(c)), which we believe may probably be due to the\\nIslamophobia manifested through text, are inline with the experimental\\nresults in Abid et al. (2021b) that reports language generated by GPT-\\n3 (Brown et al., 2020) in the context of the Muslim religion are more\\nassociated with violence.\\n5.4. Effectiveness of evaluation corpora in unveiling affective bias\\nWhen comparing the capability of the evaluation corpora EEC,\\nBITS, and CSP, we could observe that BITS, with a smaller number of\\nsentence pairs (120 for gender and 72 for race) and explicit emotion\\nterms, is mostly unable to recognize the existence of affective bias in\\nperspective of both class level and intensity level analysis. But even\\nthough EEC also has implicit representation of emotion terms similar\\nto BITS, the availability of a large number of sentence pairs (1400 for\\neach domain) eventually helps EEC to identify the existence of affective\\nbias better than BITS. On the other side, even with a smaller number\\nof sentence pairs (263 for gender, 566 for race, 104 for religion), the\\nevaluation corpus CSP helps to identify affective bias to a great extent,\\nand it is the only corpus that unveils class based affective bias in the\\ndomains. We believe the non-synthetic and real-world context nature\\nof sentence pairs in CSP could have been advantageous in identifying\\naffective bias. Therefore, upgrading such a corpus with more number\\nof sentence pairs or procuring new evaluation corpora containing non-\\nsynthetic real-world sentences, along with corresponding ground truth\\nemotions could eventually help towards comprehensive and rigorous\\nexplorations in the direction of identifying affective bias and quantify-\\ning its magnitude using ground truth dependent measures like Equal\\nOpportunity (Du et al., 2021).\\n6. Conclusion\\nTextual affective analysis and recognition enable efficient ways to\\nencode and understand human emotional states from textual data and\\nyield new opportunities to systems such as business, healthcare, and\\neducation by analyzing customers, employees, users, patients, etc., in\\nthe context of affective content. Unfair representations of affect in\\nlanguage, i.e. affective bias in such systems discriminate social groups\\nin a domain on the basis of certain emotions while making algorithmic\\ndecisions. Affective bias in textual emotion detection systems when\\ndeployed in the real world, can harm the ethical trust of these systems\\nand can be potentially threatening to human lives. Hence, analyzing\\nthe existence of affective bias in these systems is crucial to avoid huge\\n13'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 13, 'page_label': '14', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='A. Kadan, Deepak P., S. Bhadra et al. Natural Language Processing Journal 7 (2024) 100062\\nFig. 3. Intensity plots of emotion predictions reflecting societal stereotypes.\\ndisputes and damages in society similar to the adverse effects produced\\nby many other unfair systems such as unfair recidivism prediction. 21\\nIn this work, we for the first time, to the best of our knowledge,\\nattempted to explore and identify any existence of affective bias in\\nlarge PLMs, when utilized for the task of textual emotion detection,\\nwith respect to the domains gender, race, and religion. For the study,\\nwe used BERT, GPT-2, XLNet, and T5 considering their popularity and\\nwide applicability in textual emotion detection and many other related\\ntasks. As algorithmic bias has its roots from data bias, we started our\\nexploration of affective bias by analyzing the imbalanced distribution of\\naffect in the pre-training corpora of these PLMs i.e., WikiEn, BookCor-\\npus, WebText-250, and C4-Val, and SemEval-2018 used to fine-tune the\\nemotion detection models. Later, we analyzed the existence of affective\\nbias in the predictions of fine-tuned emotion detection models built\\nusing these large PLMs. Evaluations are performed to analyze affective\\nbias in the predicted emotion classes and corresponding intensities of\\nsocial groups within a domain using three different evaluation corpora\\nand various class based and intensity based evaluation measures. Our\\nwide set of experiments and evaluation strategies confirm the existence\\nof affect imbalance in large scale corpora and affective bias in emotion\\npredictions of the PLMs, with affective bias mostly higher for T5\\ncompared to the other PLMs. The high association of emotion anger\\nwith African American race, joy with European American race, fear\\nwith the Muslim religion, etc., are some examples of affective bias.\\nReligious domain reports more biased instances, compared to gender\\nand race, for all the PLMs. Our results also demonstrated that the\\nbiased predictions of the models are inclined with patterns of affect\\n21 https://www.propublica.org/article/machine-bias-risk-assessments-in-\\ncriminal-sentencing?token=nD-X136_tDm0nh1l4Xtv0LbpjY_BSO3u.\\nimbalance in the corpora, and both these reflect certain affect-oriented\\nsocietal stereotypes, hinting at the propagation of affective bias towards\\npredictions of the PLMs. To aid future research, we shall make publicly\\navailable all the relevant materials including the pre-processed pre-\\ntraining and fine-tuning corpora, evaluation corpora modified to suit\\nour task, list of affective terms and target terms for corpus level\\nanalysis, source code, and fine-tuned textual emotion detection models\\nalong with their emotion class and intensity predictions, at https:\\n//github.com/anoopkdcs/affective_bias_in_plm and https://dcs.uoc.ac.\\nin/cida/projects/ac/affective-bias.html along with the publication.\\n6.1. Future work\\nThe proposed study explores corpus level affective bias using a sim-\\nple approach to analyzing the distributions of affective target terms in\\nthe corpora. In the future, we are planning to conduct a more nuanced\\nexploration towards the corpus level affective bias in the context of\\nvarious facets such as the time of creation of corpora, people behind\\ncorpora, languages and cultures (Navigli et al., 2023). Recent affect\\nagnostic bias analysis studies explore bias in the context of causality (Su\\net al., 2022); therefore to further explore the relationship between the\\ncorpus characteristics and model bias we are also planning to conduct\\ncausality based affective bias analysis.\\nIn context the model predictions, the observations of affective bias\\nand its magnitudes in this study are dependent on the choice of eval-\\nuation corpora and measures, i.e., certain instances of ‘no affective\\nbias’ or marginal magnitudes of affective bias may also be due to the\\nlimited capability of evaluation corpora and measures to unveil the\\nactual latent affective bias that exists in the model. Therefore in the\\nfuture, we are considering extending the study with a set of real-world\\n14'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 14, 'page_label': '15', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='A. Kadan, Deepak P., S. Bhadra et al. Natural Language Processing Journal 7 (2024) 100062\\ncontext evaluation corpora, for example, by expanding CSP in terms of\\nthe number of sentences and also by procuring ground truth emotions\\nthat allow applying other evaluation measures like Equal Opportunity\\n(Du et al., 2021). Beyond analyzing each sentence pair in a domain\\nseparately, we are looking into the ways to simultaneously analyze\\nsentences representing various social groups in a domain, for example,\\nanalyzing sentence triplets like Male versus Female versus Non-binary.\\nA very recent and relevant work that addresses a similar line of\\nthoughts in the context of affect agnostic bias in PLMs from pre-training\\ndata to language models to downstream tasks in the political domain\\nis explained in Feng et al. (2023). In the backdrop of this work, we\\nobserve a wide scope of exploring political affective biasin large PLMs.\\nBecause, there are works in the literature that give hints that emotions\\nsuch as anger, disgust, or fear are more frequent in the predictions of\\nrepublicans’ (right-leaning) posts, whereas love or sadness are more\\noften predicted for democrats’ (left-leaning) posts (Huguet Cabot et al.,\\n2020).\\nOur initial attempt to identify affective bias in textual emotion\\ndetection models that utilize large PLMs, opens up the vast future scope\\ntowards identifying affective bias in the other very recent large PLMs\\nsuch as LLAMA, Flan-T5 XXL, PaLM, LaMDA, etc. There also exists a\\nwide scope for affective bias mitigation, which we believe, can be better\\nachieved by adopting more convenient solutions that utilize constraints\\nwhile fine-tuning the prediction system (i.e., in-processing) and post-\\nprocessing, rather than retraining or fine-tuning the PLM based affect\\nprediction systems with unbiased corpora which are expensive and\\ncumbersome (Hooker, 2021).\\nCRediT authorship contribution statement\\nAnoop Kadan: Conceptualization, Data curation, Formal analy-\\nsis, Investigation, Methodology, Resources, Validation, Visualization,\\nWriting – original draft, Writing – review & editing. Deepak P.: Con-\\nceptualization, Formal analysis, Methodology, Supervision, Writing –\\nreview & editing, Validation. Sahely Bhadra:Formal analysis, Method-\\nology, Supervision, Writing – review & editing, Validation. Manjary\\nP. Gangan:Conceptualization, Formal analysis, Methodology, Writing\\n– original draft, Writing – review & editing. Lajish V.L.: Supervision,\\nWriting – review & editing.\\nDeclaration of competing interest\\nThe authors declare that they have no known competing finan-\\ncial interests or personal relationships that could have appeared to\\ninfluence the work reported in this paper.\\nAcknowledgments\\nThe authors would like to thank the authors of Tan and Celis (2019)\\nfor making their source codes publicly available and the authors of Kir-\\nitchenko and Mohammad (2018), Venkit and Wilson (2021) and Nangia\\net al. (2020) for making their evaluation corpora publicly available.\\nThe authors would like to thank Chanjal V.V., Master’s student (2018–\\n20) of the Department of Women Studies, University of Calicut for her\\ninvolvement and cooperation to create the list of target terms related\\nto non-binary gender to conduct the corpus level experiments. The first\\nauthor would like to thank Indian Institute of Technology Palakkad for\\norganizing the GIAN course on Fairness in Machine Learning. The third\\nauthor would like to thank the Department of Science and Technology\\n(DST) of the Government of India for financial support through the\\nWomen Scientist Scheme-A (WOS-A) for Research in Basic/Applied\\nScience under the Grant SR/WOS-A/PM-62/2018.\\nAppendix A. Supplementary data\\nSupplementary material related to this article can be found online\\nat https://doi.org/10.1016/j.nlp.2024.100062.\\nReferences\\nAbid, A., Farooqi, M., Zou, J., 2021a. Large language models associate muslims with\\nviolence. Nat. Mach. Intell. 3 (6), 461–463. http://dx.doi.org/10.1038/s42256-021-\\n00359-2.\\nAbid, A., Farooqi, M., Zou, J., 2021b. Persistent anti-muslim bias in large language\\nmodels. In: Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and\\nSociety. Association for Computing Machinery, New York, NY, USA, pp. 298–306,\\nURL: https://doi.org/10.1145/3461702.3462624.\\nAcheampong, F.A., Nunoo-Mensah, H., Chen, W., 2021. Transformer models for text-\\nbased emotion detection: a review of BERT-based approaches. Artif. Intell. Rev. 54\\n(8), 5789–5829. http://dx.doi.org/10.1007/s10462-021-09958-2.\\nAdoma, A.F., Henry, N.-M., Chen, W., 2020. Comparative analyses of bert, roberta,\\ndistilbert, and xlnet for text-based emotion recognition. In: 2020 17th International\\nComputer Conference on Wavelet Active Media Technology and Information Pro-\\ncessing. ICCWAMTIP, pp. 117–121. http://dx.doi.org/10.1109/ICCWAMTIP51612.\\n2020.9317379.\\nAnoop, K., Gangan, M.P., Deepak, P., Lajish, V.L., 2022. Towards an enhanced\\nunderstanding of bias in pre-trained neural language models: A survey with\\nspecial emphasis on affective bias. In: Responsible Data Science. Springer Nature,\\nSingapore, pp. 13–45. http://dx.doi.org/10.1007/978-981-19-4453-6_2.\\nAshley, W., 2014. The angry black woman: The impact of pejorative stereotypes\\non psychotherapy with black women. Soc. Work Public Health 29 (1), 27–34.\\nhttp://dx.doi.org/10.1080/19371918.2011.619449.\\nBhaskaran, J., Bhallamudi, I., 2019. Good secretaries, bad truck drivers? Occupational\\ngender stereotypes in sentiment analysis. In: Proceedings of the First Workshop\\non Gender Bias in Natural Language Processing. Association for Computational\\nLinguistics, Italy, pp. 62–68. http://dx.doi.org/10.18653/v1/W19-3809.\\nBolukbasi, T., Chang, K.-W., Zou, J., Saligrama, V., Kalai, A., 2016. Man is to\\ncomputer programmer as woman is to homemaker? Debiasing word embeddings. In:\\nProceedings of the 30th International Conference on Neural Information Processing\\nSystems. NIPS ’16, Curran Associates Inc., Red Hook, NY, USA, pp. 4356–4364,\\nURL: https://dl.acm.org/doi/10.5555/3157382.3157584.\\nBordia, S., Bowman, S.R., 2019. Identifying and reducing gender bias in word-level\\nlanguage models. In: Proceedings of the 2019 Conference of the North American\\nChapter of the Association for Computational Linguistics: Student Research Work-\\nshop. Association for Computational Linguistics, Minneapolis, Minnesota, pp. 7–15.\\nhttp://dx.doi.org/10.18653/v1/N19-3002.\\nBrown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J.D., Dhariwal, P., Neelakan-\\ntan, A., Shyam, P., Sastry, G., Askell, A., et al., 2020. Language models are few-shot\\nlearners. Adv. Neural Inf. Process. Syst. 33, 1877–1901, URL: https://proceedings.\\nneurips.cc/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf.\\nCaliskan, A., Bryson, J.J., Narayanan, A., 2017. Semantics derived automatically from\\nlanguage corpora contain human-like biases. Science 356 (6334), 183–186. http:\\n//dx.doi.org/10.1126/science.aal4230.\\nCenter, T.S., 2022. LGBTQIA+ terminology. URL: https://www.umass.edu/stonewall/\\nsites/default/files/documents/allyship_term_handout.pdf. Accessed: 4-7-2022.\\nChowdhery, A., Narang, S., Devlin, J., Bosma, M., Mishra, G., Roberts, A., Barham, P.,\\nChung, H.W., Sutton, C., Gehrmann, S., et al., 2023. Palm: Scaling language\\nmodeling with pathways. J. Mach. Learn. Res. 24 (240), 1–113, URL: https:\\n//www.jmlr.org/papers/volume24/22-1144/22-1144.pdf.\\nChung, H.W., Hou, L., Longpre, S., Zoph, B., Tay, Y., Fedus, W., Li, Y., Wang, X.,\\nDehghani, M., Brahma, S., et al., 2022. Scaling instruction-finetuned language\\nmodels. http://dx.doi.org/10.48550/arXiv.2210.11416, arXiv preprint arXiv:2210.\\n11416.\\nCorbett-Davies, S., Pierson, E., Feller, A., Goel, S., Huq, A., 2017. Algorithmic decision\\nmaking and the cost of fairness. In: Proceedings of the 23rd ACM SIGKDD\\nInternational Conference on Knowledge Discovery and Data Mining. KDD ’17,\\nAssociation for Computing Machinery, New York, NY, USA, pp. 797–806. http:\\n//dx.doi.org/10.1145/3097983.3098095.\\nDale, R., 2019. Law and word order: NLP in legal tech. Nat. Lang. Eng. 25 (1), 211–217.\\nhttp://dx.doi.org/10.1017/S1351324918000475.\\nDe Choudhury, M., Counts, S., Gamon, M., 2012. Not all moods are created equal!\\nexploring human emotional states in social media. In: Proceedings of the Inter-\\nnational AAAI Conference on Web and Social Media. Vol. 6, pp. 66–73, URL:\\nhttps://ojs.aaai.org/index.php/ICWSM/article/view/14279.\\nDevlin, J., Chang, M.-W., Lee, K., Toutanova, K., 2019. BERT: Pre-training of deep\\nbidirectional transformers for language understanding. In: Proceedings of the\\n2019 Conference of the North American Chapter of the Association for Compu-\\ntational Linguistics: Human Language Technologies, Volume 1 (Long and Short\\nPapers). Association for Computational Linguistics, Minneapolis, Minnesota, pp.\\n4171–4186. http://dx.doi.org/10.18653/v1/N19-1423, URL: https://aclanthology.\\norg/N19-1423.\\nDíaz, M., Johnson, I., Lazar, A., Piper, A.M., Gergle, D., 2018. Addressing age-related\\nbias in sentiment analysis. In: Proceedings of the 2018 Chi Conference on Human\\nFactors in Computing Systems. Association for Computing Machinery, New York,\\nNY, USA, pp. 1–14, URL: https://doi.org/10.1145/3173574.3173986.\\nDixon, L., Li, J., Sorensen, J., Thain, N., Vasserman, L., 2018. Measuring and mitigating\\nunintended bias in text classification. In: Proceedings of the 2018 AAAI/ACM Con-\\nference on AI, Ethics, and Society. AIES ’18, Association for Computing Machinery,\\nNew York, NY, USA, pp. 67–73. http://dx.doi.org/10.1145/3278721.3278729.\\n15'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 15, 'page_label': '16', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='A. Kadan, Deepak P., S. Bhadra et al. Natural Language Processing Journal 7 (2024) 100062\\nDu, M., Yang, F., Zou, N., Hu, X., 2021. Fairness in deep learning: A computational\\nperspective. IEEE Intell. Syst. 36 (4), 25–34. http://dx.doi.org/10.1109/MIS.2020.\\n3000681.\\nEagly, A.H., Steffen, V.J., 1984. Gender stereotypes stem from the distribution of\\nwomen and men into social roles. J. Pers. Soc. Psychol. 46 (4), 735, doi:https:\\n//psycnet.apa.org/doi/10.1037/0022-3514.46.4.735.\\nFeldman, M., Friedler, S.A., Moeller, J., Scheidegger, C., Venkatasubramanian, S.,\\n2015. Certifying and removing disparate impact. In: Proceedings of the 21th ACM\\nSIGKDD International Conference on Knowledge Discovery and Data Mining. KDD\\n’15, Association for Computing Machinery, New York, NY, USA, pp. 259–268.\\nhttp://dx.doi.org/10.1145/2783258.2783311.\\nFeng, S., Park, C.Y., Liu, Y., Tsvetkov, Y., 2023. From pretraining data to language\\nmodels to downstream tasks: Tracking the trails of political biases leading to\\nunfair NLP models. In: Rogers, A., Boyd-Graber, J., Okazaki, N. (Eds.), Proceedings\\nof the 61st Annual Meeting of the Association for Computational Linguistics\\n(Volume 1: Long Papers). Association for Computational Linguistics, Toronto,\\nCanada, pp. 11737–11762. http://dx.doi.org/10.18653/v1/2023.acl-long.656, URL:\\nhttps://aclanthology.org/2023.acl-long.656.\\nGarg, N., Schiebinger, L., Jurafsky, D., Zou, J., 2018. Word embeddings quantify\\n100 years of gender and ethnic stereotypes. Proc. Natl. Acad. Sci. 115 (16),\\nE3635–E3644.\\nGuo, W., Caliskan, A., 2021. Detecting emergent intersectional biases: Contextualized\\nword embeddings contain a distribution of human-like biases. In: Proceedings\\nof the 2021 AAAI/ACM Conference on AI, Ethics, and Society. Association for\\nComputing Machinery, New York, NY, USA, pp. 122–133, URL: https://doi.org/10.\\n1145/3461702.3462536.\\nHahn, H., Seager van Dyk, I., Ahn, W.-Y., 2020. Attitudes toward gay men and lesbian\\nwomen moderate heterosexual adults’ subjective stress response to witnessing\\nhomonegativity. Front. Psychol. 10, 2948. http://dx.doi.org/10.3389/fpsyg.2019.\\n02948.\\nHe, P., Liu, X., Gao, J., Chen, W., 2021. DEBERTA: Decoding-enhanced bert with\\ndisentangled attention. In: International Conference on Learning Representations.\\nURL: https://openreview.net/forum?id=XPZIaotutsD.\\nHooker, S., 2021. Moving beyond ‘‘algorithmic bias is a data problem’’. Patterns 2\\n(4), 100241. http://dx.doi.org/10.1016/j.patter.2021.100241, URL: https://www.\\nsciencedirect.com/science/article/pii/S2666389921000611.\\nHovy, D., Prabhumoye, S., 2021. Five sources of bias in natural language processing.\\nLang. Linguist. Compass 15 (8), e12432. http://dx.doi.org/10.1111/lnc3.12432,\\nURL: https://compass.onlinelibrary.wiley.com/doi/abs/10.1111/lnc3.12432.\\nHuang, P.-S., Zhang, H., Jiang, R., Stanforth, R., Welbl, J., Rae, J., Maini, V.,\\nYogatama, D., Kohli, P., 2020. Reducing sentiment bias in language models\\nvia counterfactual evaluation. In: Findings of the Association for Computational\\nLinguistics: EMNLP 2020. Association for Computational Linguistics, Online, pp.\\n65–83. http://dx.doi.org/10.18653/v1/2020.findings-emnlp.7.\\nHuguet Cabot, P.-L., Dankers, V., Abadi, D., Fischer, A., Shutova, E., 2020. The\\npragmatics behind politics: Modelling metaphor, framing and emotion in political\\ndiscourse. In: Cohn, T., He, Y., Liu, Y. (Eds.), Findings of the Association for\\nComputational Linguistics: EMNLP 2020. Association for Computational Linguistics,\\nOnline, pp. 4479–4488. http://dx.doi.org/10.18653/v1/2020.findings-emnlp.402,\\nURL: https://aclanthology.org/2020.findings-emnlp.402.\\nKaneko, M., Bollegala, D., 2022. Unmasking the mask – evaluating social biases in\\nmasked language models. In: Proceedings of the 36th AAAI Conference on Artificial\\nIntelligence. Vancouver, BC, Canada, http://dx.doi.org/10.1609/aaai.v36i11.21453.\\nKiritchenko, S., Mohammad, S., 2018. Examining gender and race bias in two hundred\\nsentiment analysis systems. In: Proceedings of the Seventh Joint Conference on\\nLexical and Computational Semantics. Association for Computational Linguistics,\\nNew Orleans, Louisiana, pp. 43–53. http://dx.doi.org/10.18653/v1/S18-2005, URL:\\nhttps://aclanthology.org/S18-2005.\\nLiang, P.P., Wu, C., Morency, L.-P., Salakhutdinov, R., 2021. Towards understanding\\nand mitigating social biases in language models. In: Meila, M., Zhang, T. (Eds.),\\nProceedings of the 38th International Conference on Machine Learning. In: Pro-\\nceedings of Machine Learning Research, vol. 139, PMLR, pp. 6565–6576, URL:\\nhttps://proceedings.mlr.press/v139/liang21a.html.\\nLozada, F.T., Riley, T.N., Catherine, E., Brown, D.W., 2022. Black emotions matter:\\nUnderstanding the impact of racial oppression on black youth’s emotional devel-\\nopment: Dismantling systems of racism and oppression during adolescence. J. Res.\\nAdolesc. 32 (1), 13–33. http://dx.doi.org/10.1111/jora.12699.\\nLu, K., Mardziel, P., Wu, F., Amancharla, P., Datta, A., 2020. Gender bias in neural\\nnatural language processing. In: Logic, Language, and Security: Essays Dedicated\\nto Andre Scedrov on the Occasion of his 65th Birthday. Springer International\\nPublishing, Cham, pp. 189–202. http://dx.doi.org/10.1007/978-3-030-62077-6_14.\\nMao, R., Liu, Q., He, K., Li, W., Cambria, E., 2022. The biases of pre-trained language\\nmodels: An empirical study on prompt-based sentiment analysis and emotion\\ndetection. IEEE Trans. Affect. Comput. 1–11. http://dx.doi.org/10.1109/TAFFC.\\n2022.3204972.\\nMay, C., Wang, A., Bordia, S., Bowman, S.R., Rudinger, R., 2019. On measuring\\nsocial biases in sentence encoders. In: Proceedings of the 2019 Conference of\\nthe North American Chapter of the Association for Computational Linguistics:\\nHuman Language Technologies, Volume 1 (Long and Short Papers). Association\\nfor Computational Linguistics, Minneapolis, Minnesota, pp. 622–628. http://dx.doi.\\norg/10.18653/v1/N19-1063.\\nMishev, K., Gjorgjevikj, A., Vodenska, I., Chitkushev, L.T., Trajanov, D., 2020. Evalu-\\nation of sentiment analysis in finance: From lexicons to transformers. IEEE Access\\n8, 131662–131682. http://dx.doi.org/10.1109/ACCESS.2020.3009626.\\nMohammad, S., Bravo-Marquez, F., Salameh, M., Kiritchenko, S., 2018. SemEval-2018\\ntask 1: Affect in tweets. In: Proceedings of the 12th International Workshop\\non Semantic Evaluation. Association for Computational Linguistics, New Or-\\nleans, Louisiana, pp. 1–17. http://dx.doi.org/10.18653/v1/S18-1001, URL: https:\\n//aclanthology.org/S18-1001.\\nNadeem, M., Bethke, A., Reddy, S., 2021. StereoSet: Measuring stereotypical bias\\nin pretrained language models. In: Proceedings of the 59th Annual Meeting of\\nthe Association for Computational Linguistics and the 11th International Joint\\nConference on Natural Language Processing (Volume 1: Long Papers). Association\\nfor Computational Linguistics, Online, pp. 5356–5371. http://dx.doi.org/10.18653/\\nv1/2021.acl-long.416, URL: https://aclanthology.org/2021.acl-long.416.\\nNangia, N., Vania, C., Bhalerao, R., Bowman, S.R., 2020. Crows-pairs: A challenge\\ndataset for measuring social biases in masked language models. In: Proceedings\\nof the 2020 Conference on Empirical Methods in Natural Language Processing.\\nEMNLP, Association for Computational Linguistics, Online, pp. 1953–1967. http:\\n//dx.doi.org/10.18653/v1/2020.emnlp-main.154, URL: https://aclanthology.org/\\n2020.emnlp-main.154.\\nNavigli, R., Conia, S., Ross, B., 2023. Biases in large language models: Origins,\\ninventory, and discussion. J. Data Inf. Qual. 15 (2), http://dx.doi.org/10.1145/\\n3597307.\\nPlant, E.A., Hyde, J.S., Keltner, D., Devine, P.G., 2000. The gender stereotyping of\\nemotions. Psychol. Women Q. 24 (1), 81–92. http://dx.doi.org/10.1111/j.1471-\\n6402.2000.tb01024.x.\\nRadford, A., Wu, J., Child, R., Luan, D., Amodei, D., Sutskever, I., et al., 2019.\\nLanguage models are unsupervised multitask learners. OpenAI Blog 1 (8), 9, URL:\\nhttps://openai.com/blog/better-language-models/.\\nRaffel, C., Shazeer, N., Roberts, A., Lee, K., Narang, S., Matena, M., Zhou, Y., Li, W.,\\nLiu, P.J., 2020. Exploring the limits of transfer learning with a unified text-to-text\\ntransformer. J. Mach. Learn. Res. 21 (140), 1–67, URL: http://jmlr.org/papers/v21/\\n20-074.html.\\nRahman, M.M., Siddiqui, F.H., 2019. An optimized abstractive text summarization\\nmodel using peephole convolutional LSTM. Symmetry 11 (10), http://dx.doi.org/\\n10.3390/sym11101290, URL: https://www.mdpi.com/2073-8994/11/10/1290.\\nRahman, M.M., Siddiqui, F.H., 2021. Multi-layered attentional peephole convolu-\\ntional LSTM for abstractive text summarization. ETRI J. 43 (2), 288–298. http:\\n//dx.doi.org/10.4218/etrij.2019-0016, URL: https://onlinelibrary.wiley.com/doi/\\nabs/10.4218/etrij.2019-0016.\\nRaza, S., Garg, M., Reji, D.J., Bashir, S.R., Ding, C., 2024. Nbias: A natural lan-\\nguage processing framework for BIAS identification in text. Expert Syst. Appl.\\n237, 121542. http://dx.doi.org/10.1016/j.eswa.2023.121542, URL: https://www.\\nsciencedirect.com/science/article/pii/S0957417423020444.\\nRozado, D., 2020. Wide range screening of algorithmic bias in word embedding models\\nusing large sentiment lexicons reveals underreported bias types. PLoS One 15 (4),\\n1–26. http://dx.doi.org/10.1371/journal.pone.0231189.\\nShen, J.H., Fratamico, L., Rahwan, I., Rush, A.M., 2018. Darling or babygirl? investi-\\ngating stylistic bias in sentiment analysis. Proc. FATML URL: https://www.fatml.\\norg/media/documents/darling_or_babygirl_stylistic_bias.pdf.\\nShields, S.A., 2002. Speaking from the Heart: Gender and the Social Meaning of\\nEmotion. Cambridge University Press.\\nSkogan, W.G., 1995. Crime and the racial fears of white Americans. Ann.\\nAm. Acad. Political Soc. Sci. 539 (1), 59–71. http://dx.doi.org/10.1177/\\n0002716295539001005.\\nSoni, S., Roberts, K., 2020. Evaluation of dataset selection for pre-training and fine-\\ntuning transformer language models for clinical question answering. In: Proceedings\\nof the 12th Language Resources and Evaluation Conference. European Language Re-\\nsources Association, Marseille, France, pp. 5532–5538, URL: https://aclanthology.\\norg/2020.lrec-1.679.\\nStaiano, J., Guerini, M., 2014. Depeche mood: a lexicon for emotion analysis from\\ncrowd annotated news. In: Proceedings of the 52nd Annual Meeting of the\\nAssociation for Computational Linguistics (Volume 2: Short Papers). Association\\nfor Computational Linguistics, Baltimore, Maryland, pp. 427–433. http://dx.doi.\\norg/10.3115/v1/P14-2070, URL: https://aclanthology.org/P14-2070.\\nSu, C., Yu, G., Wang, J., Yan, Z., Cui, L., 2022. A review of causality-based fairness\\nmachine learning. Intell. Robot. 244–274. http://dx.doi.org/10.20517/ir.2022.17.\\nSubramanian, S., Rahimi, A., Baldwin, T., Cohn, T., Frermann, L., 2021. Fairness-aware\\nclass imbalanced learning. In: Moens, M.-F., Huang, X., Specia, L., Yih, S.W.-\\nt. (Eds.), Proceedings of the 2021 Conference on Empirical Methods in Natural\\nLanguage Processing. Association for Computational Linguistics, Online and Punta\\nCana, Dominican Republic, pp. 2045–2051. http://dx.doi.org/10.18653/v1/2021.\\nemnlp-main.155, URL: https://aclanthology.org/2021.emnlp-main.155.\\nSuresh, H., Guttag, J., 2021. A framework for understanding sources of harm\\nthroughout the machine learning life cycle. In: Equity and Access in Algorithms,\\nMechanisms, and Optimization. EAAMO ’21, Association for Computing Machinery,\\nNew York, NY, USA, http://dx.doi.org/10.1145/3465416.3483305.\\nSweeney, C., Najafian, M., 2020. Reducing sentiment polarity for demographic at-\\ntributes in word embeddings using adversarial learning. In: Proceedings of the\\n16'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 16, 'page_label': '17', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='A. Kadan, Deepak P., S. Bhadra et al. Natural Language Processing Journal 7 (2024) 100062\\n2020 Conference on Fairness, Accountability, and Transparency. In: FAT* ’20,\\nAssociation for Computing Machinery, New York, NY, USA, pp. 359–368. http:\\n//dx.doi.org/10.1145/3351095.3372837.\\nTabinda Kokab, S., Asghar, S., Naz, S., 2022. Transformer-based deep learning mod-\\nels for the sentiment analysis of social media data. Array 14, 100157. http:\\n//dx.doi.org/10.1016/j.array.2022.100157, URL: https://www.sciencedirect.com/\\nscience/article/pii/S2590005622000224.\\nTan, Y.C., Celis, L.E., 2019. Assessing social and intersectional biases in contextualized\\nword representations. In: Proceedings of the 33rd International Conference on\\nNeural Information Processing Systems. Curran Associates Inc., Red Hook, NY, USA,\\npp. 13230–13241, URL: https://dl.acm.org/doi/10.5555/3454287.3455472.\\nThoppilan, R., De Freitas, D., Hall, J., Shazeer, N., Kulshreshtha, A., Cheng, H.-T.,\\nJin, A., Bos, T., Baker, L., Du, Y., et al., 2022. Lamda: Language models for\\ndialog applications. http://dx.doi.org/10.48550/arXiv.2201.08239, arXiv preprint\\narXiv:2201.08239.\\nTouvron, H., Lavril, T., Izacard, G., Martinet, X., Lachaux, M.-A., Lacroix, T., Rozière, B.,\\nGoyal, N., Hambro, E., Azhar, F., et al., 2023. Llama: Open and efficient foundation\\nlanguage models. arXiv preprint arXiv:2302.13971. URL: https://research.facebook.\\ncom/publications/llama-open-and-efficient-foundation-language-models/.\\nTrinh, T.H., Le, Q.V., 2018. A simple method for commonsense reasoning. http://dx.\\ndoi.org/10.48550/arXiv.1806.02847, arXiv preprint arXiv:1806.02847.\\nVelupillai, S., Suominen, H., Liakata, M., Roberts, A., Shah, A.D., Morley, K., Os-\\nborn, D., Hayes, J., Stewart, R., Downs, J., Chapman, W., Dutta, R., 2018.\\nUsing clinical natural language processing for health outcomes research: Overview\\nand actionable suggestions for future advances. J. Biomed. Inform. 88, 11–19.\\nhttp://dx.doi.org/10.1016/j.jbi.2018.10.005, URL: https://www.sciencedirect.com/\\nscience/article/pii/S1532046418302016.\\nVenkit, P.N., Wilson, S., 2021. Identification of bias against people with disabilities\\nin sentiment analysis and toxicity detection models. http://dx.doi.org/10.48550/\\narXiv.2111.13259, arXiv preprint arXiv:2111.13259.\\nVittengl, J.R., Holt, C.S., 1998. A time-series diary study of mood and social interaction.\\nMotiv. Emot. 22 (3), 255–275. http://dx.doi.org/10.1023/A:1022388123550.\\nWaterloo, S.F., Baumgartner, S.E., Peter, J., Valkenburg, P.M., 2018. Norms of\\nonline expressions of emotion: Comparing facebook, Twitter, instagram, and\\nWhatsApp. New Media Soc. 20 (5), 1813–1831. http://dx.doi.org/10.1177/\\n1461444817707349, PMID: 30581358.\\nYang, Z., Asyrofi, M.H., Lo, D., 2021. BiasRV: Uncovering biased sentiment predictions\\nat runtime. In: Proceedings of the 29th ACM Joint Meeting on European Software\\nEngineering Conference and Symposium on the Foundations of Software Engineer-\\ning. In: ESEC/FSE 2021, Association for Computing Machinery, New York, NY,\\nUSA, pp. 1540–1544. http://dx.doi.org/10.1145/3468264.3473117.\\nYang, Z., Dai, Z., Yang, Y., Carbonell, J., Salakhutdinov, R., Le, Q.V., 2019. XLNet:\\nGeneralized autoregressive pretraining for language understanding. In: Proceedings\\nof the 33rd International Conference on Neural Information Processing Systems.\\nCurran Associates Inc., Red Hook, NY, USA, pp. 5753–5763, URL: https://dl.acm.\\norg/doi/10.5555/3454287.3454804.\\nZhang, L., Fan, H., Peng, C., Rao, G., Cong, Q., 2020. Sentiment analysis methods\\nfor HPV vaccines related tweets based on transfer learning. Healthcare 8 (3),\\nhttp://dx.doi.org/10.3390/healthcare8030307, URL: https://www.mdpi.com/2227-\\n9032/8/3/307.\\nZhao, J., Wang, T., Yatskar, M., Cotterell, R., Ordonez, V., Chang, K.-W., 2019. Gender\\nbias in contextualized word embeddings. In: Proceedings of the 2019 Conference\\nof the North American Chapter of the Association for Computational Linguistics:\\nHuman Language Technologies, Volume 1 (Long and Short Papers). Association for\\nComputational Linguistics, Minneapolis, Minnesota, pp. 629–634. http://dx.doi.org/\\n10.18653/v1/N19-1064, URL: https://aclanthology.org/N19-1064.\\nZhao, J., Wang, T., Yatskar, M., Ordonez, V., Chang, K.-W., 2018. Gender bias in\\ncoreference resolution: Evaluation and debiasing methods. In: Proceedings of the\\n2018 Conference of the North American Chapter of the Association for Com-\\nputational Linguistics: Human Language Technologies, Volume 2 (Short Papers).\\nAssociation for Computational Linguistics, New Orleans, Louisiana, pp. 15–20.\\nhttp://dx.doi.org/10.18653/v1/N18-2003.\\nZhiltsova, A., Caton, S., Mulway, C., 2019. Mitigation of unintended biases against\\nnon-native english texts in sentiment analysis. In: Proceedings for the 27th AIAI\\nIrish Conference on Artificial Intelligence and Cognitive Science, Galway, Ireland,\\nDecember 5-6, 2019. In: CEUR Workshop Proceedings, vol. 2563, CEUR-WS.org,\\npp. 317–328, URL: http://ceur-ws.org/Vol-2563/aics_30.pdf.\\nZhu, Y., Kiros, R., Zemel, R., Salakhutdinov, R., Urtasun, R., Torralba, A., Fidler, S.,\\n2015. Aligning books and movies: Towards story-like visual explanations by\\nwatching movies and reading books. In: Proceedings of the 2015 IEEE International\\nConference on Computer Vision. ICCV, IEEE Computer Society, USA, pp. 19–27.\\nhttp://dx.doi.org/10.1109/ICCV.2015.11.\\n17')]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_pdf_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4a7caa7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Text splitting get into chunks\n",
    "\n",
    "def split_documents(documents,chunk_size=1000,chunk_overlap=200):\n",
    "    \"\"\"Split documents into smaller chunks for better RAG performance\"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        length_function=len,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\",\"  \",\"●\"]\n",
    "    )\n",
    "    split_docs = text_splitter.split_documents(documents)\n",
    "    print(f\"Split {len(documents)} documents into {len(split_docs)} chunks\")\n",
    "    \n",
    "    # Show example of a chunk\n",
    "    if split_docs:\n",
    "        print(f\"\\nExample chunk:\")\n",
    "        print(f\"Content: {split_docs[0].page_content[:500]}...\")\n",
    "        print(f\"Metadata: {split_docs[0].metadata}\")\n",
    "    \n",
    "    return split_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c84b87fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 76 documents into 382 chunks\n",
      "\n",
      "Example chunk:\n",
      "Content: Computer  Networks  enable  communication  between  devices  through  a  set  of  rules  called  protocols.  Among  \n",
      "these,\n",
      " \n",
      "TCP\n",
      " \n",
      "(Transmission\n",
      " \n",
      "Control\n",
      " \n",
      "Protocol)\n",
      " \n",
      "and\n",
      " \n",
      "UDP\n",
      " \n",
      "(User\n",
      " \n",
      "Datagram\n",
      " \n",
      "Protocol)\n",
      " \n",
      "are\n",
      " \n",
      "two\n",
      " \n",
      "of\n",
      " \n",
      "the\n",
      " \n",
      "most\n",
      " \n",
      "widely\n",
      " \n",
      "used\n",
      " \n",
      "transport-layer\n",
      " \n",
      "protocols\n",
      " \n",
      "defined\n",
      " \n",
      "in\n",
      " \n",
      "the\n",
      " \n",
      "TCP/IP\n",
      " \n",
      "model.\n",
      " \n",
      "TCP  is  a  connection-oriented  protocol,  meaning  a  connection  must  be  established  before  data  can  be  \n",
      "exchanged.\n",
      " \n",
      "It\n",
      " \n",
      "ensures\n",
      " \n",
      "reliable\n",
      " \n",
      "and\n",
      " \n",
      "ordered\n",
      " \n",
      "de...\n",
      "Metadata: {'producer': 'Skia/PDF m144 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'cn', 'source': '../data/pdf_files/cn.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'cn.pdf', 'file_type': 'pdf'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'Skia/PDF m144 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'cn', 'source': '../data/pdf_files/cn.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'cn.pdf', 'file_type': 'pdf'}, page_content='Computer  Networks  enable  communication  between  devices  through  a  set  of  rules  called  protocols.  Among  \\nthese,\\n \\nTCP\\n \\n(Transmission\\n \\nControl\\n \\nProtocol)\\n \\nand\\n \\nUDP\\n \\n(User\\n \\nDatagram\\n \\nProtocol)\\n \\nare\\n \\ntwo\\n \\nof\\n \\nthe\\n \\nmost\\n \\nwidely\\n \\nused\\n \\ntransport-layer\\n \\nprotocols\\n \\ndefined\\n \\nin\\n \\nthe\\n \\nTCP/IP\\n \\nmodel.\\n \\nTCP  is  a  connection-oriented  protocol,  meaning  a  connection  must  be  established  before  data  can  be  \\nexchanged.\\n \\nIt\\n \\nensures\\n \\nreliable\\n \\nand\\n \\nordered\\n \\ndelivery\\n \\nthrough\\n \\nmechanisms\\n \\nlike\\n \\nacknowledgment\\n \\n(ACK),\\n \\nretransmission,\\n \\nflow\\n \\ncontrol,\\n \\nand\\n \\ncongestion\\n \\ncontrol.\\n \\nTCP\\n \\nbreaks\\n \\nlarge\\n \\nmessages\\n \\ninto\\n \\nsegments,\\n \\nassigns\\n \\nsequence\\n \\nnumbers,\\n \\nand\\n \\nuses\\n \\nACKs\\n \\nto\\n \\nconfirm\\n \\nreceipt.\\n \\nIf\\n \\na\\n \\nsegment\\n \\nis\\n \\nlost,\\n \\nTCP\\n \\nretransmits\\n \\nit\\n \\nautomatically.\\n \\nThis\\n \\nreliability\\n \\nmakes\\n \\nTCP\\n \\nideal\\n \\nfor\\n \\napplications\\n \\nlike\\n \\nweb\\n \\nbrowsing\\n \\n(HTTP/HTTPS),\\n \\nemail,\\n \\nand\\n \\nfile\\n \\ntransfers,\\n \\nwhere\\n \\naccuracy\\n \\nis'),\n",
       " Document(metadata={'producer': 'Skia/PDF m144 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'cn', 'source': '../data/pdf_files/cn.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'cn.pdf', 'file_type': 'pdf'}, page_content='retransmits\\n \\nit\\n \\nautomatically.\\n \\nThis\\n \\nreliability\\n \\nmakes\\n \\nTCP\\n \\nideal\\n \\nfor\\n \\napplications\\n \\nlike\\n \\nweb\\n \\nbrowsing\\n \\n(HTTP/HTTPS),\\n \\nemail,\\n \\nand\\n \\nfile\\n \\ntransfers,\\n \\nwhere\\n \\naccuracy\\n \\nis\\n \\nmore\\n \\nimportant\\n \\nthan\\n \\nspeed.\\n \\nUDP ,  in  contrast,  is  a  connectionless  protocol.  It  sends  datagrams  without  establishing  a  connection  and  does  \\nnot\\n \\nguarantee\\n \\ndelivery,\\n \\nordering,\\n \\nor\\n \\nerror\\n \\ncorrection.\\n \\nSince\\n \\nUDP\\n \\neliminates\\n \\noverhead,\\n \\nit\\n \\nis\\n \\nextremely\\n \\nfast\\n \\nand\\n \\nsuitable\\n \\nfor\\n \\nreal-time\\n \\napplications\\n \\nlike\\n \\ngaming,\\n \\nlive\\n \\nvideo\\n \\nstreaming,\\n \\nand\\n \\nVoIP,\\n \\nwhere\\n \\nspeed\\n \\nand\\n \\nlow\\n \\nlatency\\n \\nare\\n \\nmore\\n \\nimportant\\n \\nthan\\n \\nperfect\\n \\naccuracy.\\n \\nFor\\n \\nexample,\\n \\nin\\n \\na\\n \\nvideo\\n \\ncall,\\n \\nlosing\\n \\na\\n \\nfew\\n \\npackets\\n \\nis\\n \\nacceptable\\n \\ncompared\\n \\nto\\n \\nwaiting\\n \\nfor\\n \\ndelayed\\n \\nretransmissions.\\n \\nReliable  data  transfer  depends  heavily  on  the  characteristics  of  these  protocols.  TCP  provides  reliability  using  \\nseveral'),\n",
       " Document(metadata={'producer': 'Skia/PDF m144 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'cn', 'source': '../data/pdf_files/cn.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'cn.pdf', 'file_type': 'pdf'}, page_content='compared\\n \\nto\\n \\nwaiting\\n \\nfor\\n \\ndelayed\\n \\nretransmissions.\\n \\nReliable  data  transfer  depends  heavily  on  the  characteristics  of  these  protocols.  TCP  provides  reliability  using  \\nseveral\\n \\ntechniques:\\n \\n●  Three-Way  Handshake:  \\n \\nEnsures\\n \\nboth\\n \\nsender\\n \\nand\\n \\nreceiver\\n \\nare\\n \\nready\\n \\nfor\\n \\ncommunication\\n \\nbefore\\n \\ndata\\n \\ntransfer\\n \\nbegins.\\n \\n ●  Flow  Control  (Sliding  Window):  \\n \\nPrevents\\n \\nthe\\n \\nsender\\n \\nfrom\\n \\noverwhelming\\n \\nthe\\n \\nreceiver\\n \\nby\\n \\nadjusting\\n \\nthe\\n \\nsending\\n \\nrate.\\n \\n ●  Congestion  Control  (AIMD,  Slow  Start):  \\n \\nAdjusts\\n \\nsending\\n \\nrate\\n \\nbased\\n \\non\\n \\nnetwork\\n \\nload\\n \\nto\\n \\navoid\\n \\ncongestion\\n \\ncollapse.\\n \\n ●  Checksums:  \\n \\nDetects\\n \\nerrors\\n \\nin\\n \\ntransmitted\\n \\nsegments.\\n \\n \\nUDP,  though  unreliable  by  design,  can  still  achieve  reliability  when  necessary  through  application-level  \\nmechanisms,\\n \\nsuch\\n \\nas\\n \\nadded\\n \\nsequence\\n \\nnumbers\\n \\nor\\n \\nmanual\\n \\nacknowledgments.\\n \\nSome\\n \\nmodern\\n \\nprotocols\\n \\nlike\\n \\nQUIC\\n \\nuse\\n \\nUDP\\n \\nas\\n \\na\\n \\nbase'),\n",
       " Document(metadata={'producer': 'Skia/PDF m144 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'cn', 'source': '../data/pdf_files/cn.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'cn.pdf', 'file_type': 'pdf'}, page_content='mechanisms,\\n \\nsuch\\n \\nas\\n \\nadded\\n \\nsequence\\n \\nnumbers\\n \\nor\\n \\nmanual\\n \\nacknowledgments.\\n \\nSome\\n \\nmodern\\n \\nprotocols\\n \\nlike\\n \\nQUIC\\n \\nuse\\n \\nUDP\\n \\nas\\n \\na\\n \\nbase\\n \\nbut\\n \\nadd\\n \\nreliability\\n \\nfeatures\\n \\nfor\\n \\nimproved\\n \\nperformance.\\n \\nUnderstanding  TCP  vs  UDP  helps  developers  choose  the  right  protocol  for  different  scenarios.  TCP  suits  \\ndata-sensitive\\n \\napplications,\\n \\nwhereas\\n \\nUDP\\n \\nis\\n \\nthe\\n \\nbetter\\n \\nchoice\\n \\nfor\\n \\nlatency-critical\\n \\ntasks.'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 0, 'page_label': '1', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='sustainability\\nReview\\nArtiﬁcial Intelligence and Machine Learning\\nApplications in Smart Production: Progress, Trends,\\nand Directions\\nRaﬀaele Cioﬃ 1, Marta Travaglioni 1, Giuseppina Piscitelli 1, Antonella Petrillo 1, *\\n and\\nFabio De Felice 2\\n1 Department of Engineering, Parthenope University, Isola C4, Centro Direzionale, 80143 Napoli NA, Italy;\\nraﬀaele.cioﬃ@uniparthenope.it (R.C.); marta.travaglioni@uniparthenope.it (M.T.);\\ngiuseppina.piscitelli@uniparthenope.it (G.P .)\\n2 Department of Civil and Mechanical Engineering, University of Cassino and Southern Lazio, Via G. Di\\nBiasio, 43, 03043 Cassino FR, Italy; defelice@unicas.it\\n* Correspondence: antonella.petrillo@uniparthenope.it\\nReceived: 1 December 2019; Accepted: 5 January 2020; Published: 8 January 2020\\n/gid00030/gid00035/gid00032/gid00030/gid00038/gid00001/gid00033/gid00042/gid00045/gid00001\\n/gid00048/gid00043/gid00031/gid00028/gid00047/gid00032/gid00046'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 0, 'page_label': '1', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='/gid00030/gid00035/gid00032/gid00030/gid00038/gid00001/gid00033/gid00042/gid00045/gid00001\\n/gid00048/gid00043/gid00031/gid00028/gid00047/gid00032/gid00046\\nAbstract: Adaptation and innovation are extremely important to the manufacturing industry.\\nThis development should lead to sustainable manufacturing using new technologies. To promote\\nsustainability, smart production requires global perspectives of smart production application\\ntechnology. In this regard, thanks to intensive research eﬀorts in the ﬁeld of artiﬁcial intelligence (AI),\\na number of AI-based techniques, such as machine learning, have already been established in the\\nindustry to achieve sustainable manufacturing. Thus, the aim of the present research was to analyze,\\nsystematically, the scientiﬁc literature relating to the application of artiﬁcial intelligence and machine\\nlearning (ML) in industry. In fact, with the introduction of the Industry 4.0, artiﬁcial intelligence and'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 0, 'page_label': '1', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='learning (ML) in industry. In fact, with the introduction of the Industry 4.0, artiﬁcial intelligence and\\nmachine learning are considered the driving force of smart factory revolution. The purpose of this\\nreview was to classify the literature, including publication year, authors, scientiﬁc sector, country,\\ninstitution, and keywords. The analysis was done using the Web of Science and SCOPUS database.\\nFurthermore, UCINET and NVivo 12 software were used to complete them. A literature review on\\nML and AI empirical studies published in the last century was carried out to highlight the evolution\\nof the topic before and after Industry 4.0 introduction, from 1999 to now. Eighty-two articles were\\nreviewed and classiﬁed. A ﬁrst interesting result is the greater number of works published by the\\nUSA and the increasing interest after the birth of Industry 4.0.\\nKeywords: artiﬁcial intelligence; machine learning; systematic literature review; applications;'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 0, 'page_label': '1', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='USA and the increasing interest after the birth of Industry 4.0.\\nKeywords: artiﬁcial intelligence; machine learning; systematic literature review; applications;\\nIndustry 4.0; smart production; sustainability\\n1. Introduction\\nSmart production systems require innovative solutions to increase the quality and sustainability\\nof manufacturing activities while reducing costs. In this context, artiﬁcial intelligence (AI)-driven\\ntechnologies, leveraged by I4.0 Key Enabling Technologies (e.g., Internet of Thing, advanced embedded\\nsystems, cloud computing, big data, cognitive systems, virtual and augmented reality), are ready to\\ngenerate new industrial paradigms [1].\\nIn this regard, it is interesting to remember that the father of artiﬁcial intelligence, John McCarthy [2],\\nin the 1990s, deﬁned artiﬁcial intelligence as “artiﬁcial intelligence is the science and engineering of\\nmaking intelligent machines, especially intelligent computer programs”. Generally, the term “AI” is'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 0, 'page_label': '1', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='making intelligent machines, especially intelligent computer programs”. Generally, the term “AI” is\\nused when a machine simulates functions that humans associate with other human minds, such as\\nlearning and problem solving [3].\\nSustainability 2020, 12, 492; doi:10.3390/su12020492 www.mdpi.com /journal/sustainability'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 1, 'page_label': '2', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Sustainability 2020, 12, 492 2 of 26\\nOn a very broad account, the areas of artiﬁcial intelligence are classiﬁed into 16 categories [4–8].\\nThese are reasoning, programming, artiﬁcial life, belief revision, data mining, distributed AI, expert\\nsystems, genetic algorithms, systems, knowledge representation, machine learning, natural language\\nunderstanding, neural networks, theorem proving, constraint satisfaction, and theory of computation [9–\\n11].\\nIn the 21st century, AI has become an important area of research in all ﬁelds: Engineering, science,\\neducation, medicine, business, accounting, ﬁnance, marketing, economics, stock market, and law,\\namong others [12–18]. The range of AI has grown enormously since the intelligence of machines with\\nmachine learning capabilities has created profound impacts on business, governments, and society [19].\\nThey also inﬂuence the larger trends in global sustainability. Artiﬁcial intelligence can be useful to solve'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 1, 'page_label': '2', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='They also inﬂuence the larger trends in global sustainability. Artiﬁcial intelligence can be useful to solve\\ncritical issue for sustainable manufacturing (e.g., optimization of energy resources, logistics, supply\\nchain management, waste management, etc.). In this context, in smart production, there is a trend to\\nincorporate AI into green manufacturing processes for stricter environmental policies [20]. In fact, as\\nsaid in March 2019 by Hendrik Fink, head of Sustainability Services at PricewaterhouseCoopers, “If we\\nproperly incorporate artiﬁcial intelligence, we can achieve a revolution with regard to sustainability.\\nAI will be the driving force of the fourth industrial revolution” [21].\\nThus, subﬁelds of AI, such as machine learning, natural language processing, image processing,\\nand data mining, have also become an important topic for today’s tech giants. The subject of AI\\ngenerates considerable interest in the scientiﬁc community, by virtue of the continuous evolution of'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 1, 'page_label': '2', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='and data mining, have also become an important topic for today’s tech giants. The subject of AI\\ngenerates considerable interest in the scientiﬁc community, by virtue of the continuous evolution of\\nthe technologies available today.\\nThe development of ML as a branch of AI is now very fast. Its usage has spread to various\\nﬁelds, such as learning machines, which are currently used in smart manufacturing, medical science,\\npharmacology, agriculture, archeology, games, business, and so forth.\\nAccording to the above considerations, in this work, a systematic literature review of research\\nfrom 1999 to 2019 was performed on AI and the ML technique. Therefore, it is considered necessary to\\ncreate a classiﬁcation system that refers to the articles that jointly treat the two topics, in order to have\\ngreater variance and reﬂection. Furthermore, to gain a deeper understanding, the inﬂuence of other\\nvariables was explored, such as the thematic areas and the sectors in which the technologies are most'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 1, 'page_label': '2', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='variables was explored, such as the thematic areas and the sectors in which the technologies are most\\ninﬂuential. The main contribution of this work is that it provides an overview of the research carried\\nout to date.\\nA number of impressive documentations of established research methods and philosophy have\\nbeen discussed for several years. Unfortunately, little comparison and integration across studies exists.\\nIn this article, a common understanding of AI and ML research and its variations was created.\\nThis paper is not attempting to provide an all-encompassing framework on the literature on AI\\nand ML research. Rather, it attempts to provide a starting point for integrating knowledge across\\nresearch in this domain and suggests paths for future research. It explores studies in certain novel\\ndisciplines: Environmental pollution, medicine, maintenance, manufacturing, etc.\\nFurther research is needed to extend the present boundary of knowledge in AI by integrating'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 1, 'page_label': '2', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='disciplines: Environmental pollution, medicine, maintenance, manufacturing, etc.\\nFurther research is needed to extend the present boundary of knowledge in AI by integrating\\nprinciples and philosophies of some traditional disciplines into the existing AI frameworks [22–24].\\nThe target that this document would like to assume is not the trigger of a sudden proliferation of\\nan already consolidated sector, but it is hoped that this research could be an important intellectual tool\\nfor both the refocusing of the work and creating new intellectual opportunities. This paper presents\\nvaluable ideas and perspectives for undergoing research on AI and ML.\\nThe ﬁnal aim was to anticipate the transformation of the discipline in the future age. This would\\nbe a journey that may experience change in its course as new generations of scholars contribute to the\\ndialogue and to the action. As noted earlier, this work presents a review, hence it lays a foundation for'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 1, 'page_label': '2', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='dialogue and to the action. As noted earlier, this work presents a review, hence it lays a foundation for\\nfuture inquiry. It not only oﬀers a basis for future comparisons but prompts a number of new questions\\nfor investigations as well. While topics that might be considered as results of this work are numerous,\\nsome are of particularly broad interest or impact.'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 2, 'page_label': '3', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Sustainability 2020, 12, 492 3 of 26\\nThe paper is organized as follows. Section 2 presents the proposed methodology and details the\\nresearch methodology adopted for the literature survey. Section 3 analyzes the main results of the\\nbibliometric analysis. Finally, in Section 4, the main contribution of the research is summarized.\\n2. Methodology\\nThe methodological approach used mixes bibliometric, content analysis, and social network\\ntechniques. In this study, a state-of-the-art research was conducted through the SCOPUS and Web\\nof Science databases. For the publication time span, the time from 1999 to 2019 was considered with\\nthe intent to understand how the level of attention towards the topic has changed before and after\\nthe introduction of Industry 4.0. The research methodology chosen for this study was a systematic\\nliterature review [25]. The main phases of the study were as follows:\\n1. Phase 1: Research and Classiﬁcation. The present phase was divided into three steps:'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 2, 'page_label': '3', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='literature review [25]. The main phases of the study were as follows:\\n1. Phase 1: Research and Classiﬁcation. The present phase was divided into three steps:\\n• Step 1: Identiﬁcation;\\n• Step 2: Screening; and\\n• Step 3: Inclusion.\\nIn phase 1, bibliometric data was collected (step 1). Then, a screening of the overall result was\\ncarried out to identify which documents can be taken into consideration, in line with the research areas\\ndeemed interesting and relevant (step 2). At the end of this step, the last step (step 3) aimed to select\\nthe documents to be analyzed in detail.\\n2. Phase 2: Analysis. Once phase 1 was completed, the next phase was phase 2, which was the\\nanalysis of the results. The approach used for the bibliometric analysis included:\\n• The use of indicators for the parameters studied; and\\n• SNA (social network analysis) for the keywords.\\nThe indicators chosen to perform the analysis were total papers (TPs), which is the total number'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 2, 'page_label': '3', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='• SNA (social network analysis) for the keywords.\\nThe indicators chosen to perform the analysis were total papers (TPs), which is the total number\\nof publications, and total citations (TCs), which is the total number of citations.\\nSNA ﬁnds application in various social sciences, and has lately been employed in the study of\\nvarious phenomena, such as international trade, information dissemination, the study of institutions,\\nand the functioning of organizations. The analysis of the use of the term SNA in the scientiﬁc literature\\nhas undergone exponential growth in the use of this mode of computable representation of complex\\nand interdependent phenomena. For the purpose of the study, UCINET, NetDraw software was used,\\nwhich was expressly designed for the creation and graphic processing of networks, and was used to\\nrepresent the keywords in the network, and Excel for data input.\\nThe software UCINET, NetDraw returned a sociometric network that describes the relationships'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 2, 'page_label': '3', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='represent the keywords in the network, and Excel for data input.\\nThe software UCINET, NetDraw returned a sociometric network that describes the relationships\\nbetween the classes, that is, data entered as input.\\nFurthermore, NVivo 12 software, the leading program for computer-assisted qualitative analysis\\n(CAQDAS), was used to analyze keywords of all documents. In this speciﬁc case, it was used to\\nidentify the possible links between the keywords of the various documents examined, developing\\nconceptual schemes from which to make interpretative hypotheses.\\n3. Phase 3: Discussion . At the end of the second phase, a third and ﬁnal one followed, where the\\nresults were discussed, and conclusions were drawn.\\nIn Figure 1, the main phases and steps followed for the analysis are shown.'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 3, 'page_label': '4', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Sustainability 2020, 12, 492 4 of 26\\nSustainability 2020, 12, x FOR PEER REVIEW 4 of 24 \\n \\nFigure 1. Process flow chart. \\n3. Results of the Bibliometric Analysis \\n3.1. Phase 1: Research and Classification \\nThe first phase consisted of the search for documents, which included the activities of collecting \\nthe material belonging to the academic universe. This first phase was divided into three steps as \\nfollows. \\n3.1.1. Identification (Step 1) \\nFor a comprehensive survey of the phenomenon, an investigation on the Scopus (SCP) and Web \\nof Science (WoS) databases was ca rried out using Boolean operators. We began by making a search \\nquery on the Scopus and WoS databases with the general keywords “artificial intelligence” AND \\n“machine learning” AND “application”, as shown in Table 1. \\nIn order to maintain the consistency of the re sults, the same keywords were used in both \\ndatabases and a time horizon of 20 years was chosen, from 1999 to 2019.'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 3, 'page_label': '4', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='In order to maintain the consistency of the re sults, the same keywords were used in both \\ndatabases and a time horizon of 20 years was chosen, from 1999 to 2019. \\nThe choice of keywords for performing the survey was based on the awareness that AI and ML \\ncan be an important tool in the effort to adopt responsible business practices in the context of smart \\nproduction. In this regard, it is worthy to note that with the increasingly urgent discussions of climate \\nchange, it seemed appropriate to focus our research on the topic of sustainability. Thus, the selection \\nof papers also considered applications on sustainability. \\nFigure 1. Process ﬂow chart.\\n3. Results of the Bibliometric Analysis\\n3.1. Phase 1: Research and Classiﬁcation\\nThe ﬁrst phase consisted of the search for documents, which included the activities of collecting the\\nmaterial belonging to the academic universe. This ﬁrst phase was divided into three steps as follows.\\n3.1.1. Identiﬁcation (Step 1)'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 3, 'page_label': '4', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='material belonging to the academic universe. This ﬁrst phase was divided into three steps as follows.\\n3.1.1. Identiﬁcation (Step 1)\\nFor a comprehensive survey of the phenomenon, an investigation on the Scopus (SCP) and Web of\\nScience (WoS) databases was carried out using Boolean operators. We began by making a search query\\non the Scopus and WoS databases with the general keywords “artiﬁcial intelligence” AND “machine\\nlearning” AND “application”, as shown in Table 1.\\nIn order to maintain the consistency of the results, the same keywords were used in both databases\\nand a time horizon of 20 years was chosen, from 1999 to 2019.\\nThe choice of keywords for performing the survey was based on the awareness that AI and ML\\ncan be an important tool in the eﬀort to adopt responsible business practices in the context of smart\\nproduction. In this regard, it is worthy to note that with the increasingly urgent discussions of climate'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 3, 'page_label': '4', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='production. In this regard, it is worthy to note that with the increasingly urgent discussions of climate\\nchange, it seemed appropriate to focus our research on the topic of sustainability. Thus, the selection of\\npapers also considered applications on sustainability.'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 4, 'page_label': '5', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Sustainability 2020, 12, 492 5 of 26\\nTable 1. Keywords and time period.\\nKeywords Time Period\\nArtiﬁcial Intelligence\\n1999–2019Machine Learning\\nApplication\\nThe search returned in total 13,512 documents.\\nThe results extracted by Scopus are numerically superior to Web of Science (WoS): 12,445 for the\\nﬁrst and only 1081 for the second one (Table 2).\\nTable 2. Total results of research on Scopus and WoS.\\nResearch Carried out on 2019\\nSource of research Scopus Web of Science\\nResults 12,445 1081\\nThe result is not entirely unexpected, and the reason is to be found in the fact that Scopus, being\\nan Elsevier product, collects data from all the other databases, in particular Science Direct and those\\nqueried by the Scirus search engine, while Web of Science (WoS) collects fewer documents.\\nFrom the documents extracted in Scopus, it was found that most of them are conference papers\\n(57.28%) and, subsequently, articles (33.85%).'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 4, 'page_label': '5', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='From the documents extracted in Scopus, it was found that most of them are conference papers\\n(57.28%) and, subsequently, articles (33.85%).\\nOn the contrary, the research on Web of Science (WoS) underlines that most of the documents are\\narticles (46.12%) and, subsequently, proceedings papers (42.86%).\\nAll the document types are ﬁlled in Table 3.\\nTable 3. Distribution of document types in Scopus and Web of Science.\\nWeb of Science Scopus\\nDocument Types Records Contribute % Document Types Records Contribute %\\nArticle 481 46.12 Conference Paper 7128 57.28\\nProceedings paper 447 42.86 Article 4212 33.85\\nReview 133 12.76 Review 412 3.31\\nEditorial material 16 1.53 Article in Press 194 1.56\\nMeeting abstract 2 0.19 Book Chapter 177 1.42\\nBook chapter 1 0.1 Conference Review 177 1.42\\nRetracted publication 1 0.1 Book 90 0.72\\n- - - Editorial 27 0.22\\n- - - Note 10 0.08\\n- - - Letter 9 0.07\\n- - - Short Survey 9 0.07'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 4, 'page_label': '5', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Book chapter 1 0.1 Conference Review 177 1.42\\nRetracted publication 1 0.1 Book 90 0.72\\n- - - Editorial 27 0.22\\n- - - Note 10 0.08\\n- - - Letter 9 0.07\\n- - - Short Survey 9 0.07\\nAI began working in the 1940s and researchers showed strong expectations until the 1970s when\\nthey began to encounter serious diﬃculties and investments were greatly reduced.\\nSince then, a long period began, known as the “AI winter” [26]: Despite some great successes,\\nsuch as IBM’s Deep Blue system, which in the late 1990s defeated the then chess world champion\\nGarri Kasparov, the study of solutions for AI has only come back for a few years. The push for a new\\ntechnological development has been given by the I4.0, which considered AI as one of the primary key\\nenabling technologies (KETs).\\nFrom this period onwards, the literature has been enriched with documents, as shown in Figure 2.\\nGrowth is apparent after 2011 when new technologies began to be implemented more frequently.'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 4, 'page_label': '5', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='From this period onwards, the literature has been enriched with documents, as shown in Figure 2.\\nGrowth is apparent after 2011 when new technologies began to be implemented more frequently.\\nIn fact, the Industry 4.0 term ﬁrst appeared at Hannover Messe in 2011 when Professor Wolfgang'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 5, 'page_label': '6', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Sustainability 2020, 12, 492 6 of 26\\nWahlster, Director and CEO of the German Research Center for Artiﬁcial Intelligence, addressed the\\nopening ceremony audience.\\nSustainability 2020, 12, x FOR PEER REVIEW 6 of 24 \\n \\nFigure 2. Research growth on Scopus and Web of Science. \\nSubsequently, the increase in the adoption of th ese ones has led researchers to keep pace with \\nthe growth of I4.0 [27]. \\n3.1.2. Screening (Step 2) \\nTrying to give an overview of the topics and areas interface, in the screening phase, an analysis \\nof documents characterized by free access was chosen, excluding those that have restrictions, and to \\nrestrict the field to the thematic areas of scientific interest. \\nWith this in mind, the number of open access items has been drasticall y reduced (1288 results \\nfor Scopus and 149 for WoS) and, also applying the filter related to the thematic areas (Table 4), it \\ndetermined a further reduction: 947 for Scopus and 60 for WoS.'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 5, 'page_label': '6', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='for Scopus and 149 for WoS) and, also applying the filter related to the thematic areas (Table 4), it \\ndetermined a further reduction: 947 for Scopus and 60 for WoS. \\nTable 4. Subject area filter on Scopus and WoS. \\nSubject Area \\nScopus Web of Science (WoS) \\nComputer \\nScience \\nChemical \\nEngineering \\nComputer Science \\nInformation Systems \\nComputer Science Artificial \\nIntelligence \\nAutomation Control \\nSystems \\nEngineering Energy Materials Science \\nMultidisciplinary Environmental Sciences Environmental \\nStudies \\nMaterials \\nScience Decision Science Engineering Electrical \\nElectronic \\nComputer Science \\nHardware Architecture \\nOperations Research \\nManagement Science \\nEnvironmental \\nScience \\nBusiness \\nManagement \\nand accounting \\nTelecommunications Industrial Relations Labor Robotics \\n  Engineering Environmental Engineering Manufacturing Thermodynamics \\n  Engineering Industrial Computer Science Theory \\nMethods Energy Fuels \\n  Engineering Civil Engineering Mechanical Computer Science'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 5, 'page_label': '6', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Engineering Industrial Computer Science Theory \\nMethods Energy Fuels \\n  Engineering Civil Engineering Mechanical Computer Science \\nCybernetics \\n  Computer Science Software \\nEngineering Multidisciplinary Sciences  \\nNote how the number of filters applied is different. The databases, in fact, offer the same search \\noptions, but, in the specific case of the thematic  areas, the latter are more numerous and structured \\non Web of Science (WoS) compared to Scopus. \\nFigure 2. Research growth on Scopus and Web of Science.\\nIn fact, this research indicates that over the time period considered (1999–2019), the number of\\npublished articles remains almost constant until 2013, from which it undergoes an increase.\\nSubsequently, the increase in the adoption of these ones has led researchers to keep pace with the\\ngrowth of I4.0 [27].\\n3.1.2. Screening (Step 2)\\nTrying to give an overview of the topics and areas interface, in the screening phase, an analysis'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 5, 'page_label': '6', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='growth of I4.0 [27].\\n3.1.2. Screening (Step 2)\\nTrying to give an overview of the topics and areas interface, in the screening phase, an analysis\\nof documents characterized by free access was chosen, excluding those that have restrictions, and to\\nrestrict the ﬁeld to the thematic areas of scientiﬁc interest.\\nWith this in mind, the number of open access items has been drastically reduced (1288 results\\nfor Scopus and 149 for WoS) and, also applying the ﬁlter related to the thematic areas (Table 4), it\\ndetermined a further reduction: 947 for Scopus and 60 for WoS.\\nTable 4. Subject area ﬁlter on Scopus and WoS.\\nSubject Area\\nScopus Web of Science (WoS)\\nComputer Science Chemical\\nEngineering\\nComputer Science\\nInformation Systems\\nComputer Science\\nArtiﬁcial Intelligence\\nAutomation Control\\nSystems\\nEngineering Energy Materials Science\\nMultidisciplinary\\nEnvironmental\\nSciences Environmental Studies\\nMaterials Science Decision Science Engineering Electrical\\nElectronic\\nComputer Science'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 5, 'page_label': '6', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Systems\\nEngineering Energy Materials Science\\nMultidisciplinary\\nEnvironmental\\nSciences Environmental Studies\\nMaterials Science Decision Science Engineering Electrical\\nElectronic\\nComputer Science\\nHardware Architecture\\nOperations Research\\nManagement Science\\nEnvironmental\\nScience\\nBusiness\\nManagement and\\naccounting\\nTelecommunications Industrial Relations\\nLabor Robotics\\nEngineering\\nEnvironmental\\nEngineering\\nManufacturing Thermodynamics\\nEngineering Industrial Computer Science\\nTheory Methods Energy Fuels\\nEngineering Civil Engineering\\nMechanical\\nComputer Science\\nCybernetics\\nComputer Science\\nSoftware Engineering\\nMultidisciplinary\\nSciences'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 6, 'page_label': '7', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Sustainability 2020, 12, 492 7 of 26\\nNote how the number of ﬁlters applied is diﬀerent. The databases, in fact, oﬀer the same search\\noptions, but, in the speciﬁc case of the thematic areas, the latter are more numerous and structured on\\nWeb of Science (WoS) compared to Scopus.\\n3.1.3. Inclusion (Step 3)\\nAt the end of the screening process, the inclusion step was started, which consisted in the selection\\nof documents, which was extracted from the last passage, destined to be included in the sample on\\nwhich bibliometric analysis was performed. In this review step, for the purposes of eligibility, we\\nexamined the complete text of each document independently. For each article, we examined whether\\nthere was interest from the academic world, and if it contained case studies or real applications,\\nproposals for new AI and ML algorithms, or possible future scenarios.\\nTherefore, the ﬁnal sample to be analyzed consisted of 60 documents for Scopus and 22 for WoS.\\n3.2. Phase 2: Analysis'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 6, 'page_label': '7', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='proposals for new AI and ML algorithms, or possible future scenarios.\\nTherefore, the ﬁnal sample to be analyzed consisted of 60 documents for Scopus and 22 for WoS.\\n3.2. Phase 2: Analysis\\nThis section presents and discusses the ﬁndings of this review.\\nFirst, an overview of the selected studies is presented. Second, the review ﬁndings according to\\nthe research criteria, one by one in the separate subsections, are reported.\\n3.2.1. Top Highly Inﬂuential Analysis\\nThis section lists the most highly cited documents in WoS and Scopus. The list is structured by\\nresearch source, date, title, authors, source title, and top citation (TP) in WoS or Scopus, according\\nto the research source. The whole list is available in the Appendix A. Looking into the Appendix A,\\nit is possible underline that the document by Larrañaga, Calvo, Santana et al. in 2006 [ 28] has the\\nhighest citation count of 298. This article reviews machine learning methods for bioinformatics and'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 6, 'page_label': '7', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='highest citation count of 298. This article reviews machine learning methods for bioinformatics and\\nit presents modelling methods. Moreover, the document year is 2006, so before I4.0 was introduced.\\nTherefore, having more years than today has an advantage in terms of diﬀusion. This means that it is\\none of the most inﬂuential documents in the academic world, as it proposes some of the most useful\\ntechniques for modelling, giving the document the opportunity to become a pioneer in the computer\\nscience research area.\\nObviously, all documents before I4.0, in general, have more citations than the most recent\\ndocuments. However, it is signiﬁcant to note that even recent documents have a very high number\\nof citations compared to the year of publication. This denotes the interest in the topic from the\\nscientiﬁc community.\\nThe citation analysis revealed that the ﬁrst article that we can identify among the most cited in'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 6, 'page_label': '7', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='scientiﬁc community.\\nThe citation analysis revealed that the ﬁrst article that we can identify among the most cited in\\nthe I4.0 period dates to 2016. The work, published by Krawczyk [29], proposes application models to\\nfurther develop the ﬁeld of unbalanced learning, to focus on computationally eﬀective, adaptive, and\\nreal-time methods, and provides a discussion and suggestions on the lines of future research in the\\napplication subject of the study. It received 119 citations. Moreover, an article published by Wuest,\\nWeimer, Irgens et al. [30] received much attention among the scientiﬁc community. It contributes by\\npresenting an overview of the available machine learning techniques.\\nFinally, the citation analysis pointed out that the average number of citations of all documents is\\n16.58. This value is expected to increase rapidly considering the interest in the issues of ML and AI.\\n3.2.2. Publications by Years'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 6, 'page_label': '7', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='16.58. This value is expected to increase rapidly considering the interest in the issues of ML and AI.\\n3.2.2. Publications by Years\\nConsistent with what is deﬁned in Section 3.1.1., the study shows that the number of items included\\nin the analysis is deﬁnitely low for the entire period before I4.0 and then suddenly increases, starting\\nin 2012. The data shown in Figure 3 also show two holes in the 2001–2008 and 2008–2011 intervals.\\nThis means that the technological applications were limited before it became an enabling technology of\\nI4.0 in all respects, only to have a peak of technological implementation, as was foreseeable.'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 7, 'page_label': '8', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Sustainability 2020, 12, 492 8 of 26\\nSustainability 2020, 12, x FOR PEER REVIEW 8 of 24 \\n \\nFigure 3. Years of publications. \\nWith reference to 2019, the figure refers to the fi rst months of the year, so it is plausible that \\nduring the year, there will be a further increase in  the documents in the literature. Furthermore, an \\nincrease is expected in the coming years, in parallel with the growth of I4.0 \\n3.2.3. Most Collaborative Authors \\nThe analysis highlighted that most of publications have more than one author. From this point \\nof view, it is possible to identify the number of authors for each document. As shown in Figure 4, \\nmost of the manuscripts were produced by groups ranging from two to five authors. The indicators \\nchosen to perform the analysis were total papers (TPs), which is the total number of publications. \\n \\nFigure 4. Collaborative groups. \\nFigure 3. Years of publications.'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 7, 'page_label': '8', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='chosen to perform the analysis were total papers (TPs), which is the total number of publications. \\n \\nFigure 4. Collaborative groups. \\nFigure 3. Years of publications.\\nWith reference to 2019, the ﬁgure refers to the ﬁrst months of the year, so it is plausible that during\\nthe year, there will be a further increase in the documents in the literature. Furthermore, an increase is\\nexpected in the coming years, in parallel with the growth of I4.0\\n3.2.3. Most Collaborative Authors\\nThe analysis highlighted that most of publications have more than one author. From this point of\\nview, it is possible to identify the number of authors for each document. As shown in Figure 4, most of\\nthe manuscripts were produced by groups ranging from two to ﬁve authors. The indicators chosen to\\nperform the analysis were total papers (TPs), which is the total number of publications.\\nSustainability 2020, 12, x FOR PEER REVIEW 8 of 24 \\n \\nFigure 3. Years of publications.'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 7, 'page_label': '8', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='perform the analysis were total papers (TPs), which is the total number of publications.\\nSustainability 2020, 12, x FOR PEER REVIEW 8 of 24 \\n \\nFigure 3. Years of publications. \\nWith reference to 2019, the figure refers to the fi rst months of the year, so it is plausible that \\nduring the year, there will be a further increase in  the documents in the literature. Furthermore, an \\nincrease is expected in the coming years, in parallel with the growth of I4.0 \\n3.2.3. Most Collaborative Authors \\nThe analysis highlighted that most of publications have more than one author. From this point \\nof view, it is possible to identify the number of authors for each document. As shown in Figure 4, \\nmost of the manuscripts were produced by groups ranging from two to five authors. The indicators \\nchosen to perform the analysis were total papers (TPs), which is the total number of publications. \\n \\nFigure 4. Collaborative groups. \\nFigure 4. Collaborative groups.'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 8, 'page_label': '9', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Sustainability 2020, 12, 492 9 of 26\\n3.2.4. Research Areas Analysis\\nThe total research area analysis collected from the 82 papers was 164 because each paper can be\\nconsidered as more than one research area analysis. Given the small number of documents identiﬁed\\nin the period before I4.0, the ranking refers mostly to the current industrial revolution. Also, in this\\ncase, the result is consistent with the introduction of paradigm 4.0, which has intensiﬁed research and\\nthe adoption of technology.\\nThe ﬁrst thematic areas and disciplines that are at the top of the ranking are computer science,\\nengineering and biochemistry, genetics, and molecular Biology, respectively, with 29%, 23%, and 6% of\\npublications. Furthermore, the other disciplines identiﬁed for which applicative ﬁndings are found are\\nconsidered transversal to the ﬁrst three disciplines and this is a consequence of I4.0. In terms of the\\npercentage contribution, the ﬁrst three areas cover about 60% of the papers considered.'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 8, 'page_label': '9', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='considered transversal to the ﬁrst three disciplines and this is a consequence of I4.0. In terms of the\\npercentage contribution, the ﬁrst three areas cover about 60% of the papers considered.\\nConsidering the top 20 research areas, given the frequency of the research areas’ distribution,\\nFigure 5 shows a higher level of concentration in the disciplines indicated above.\\nSustainability 2020, 12, x FOR PEER REVIEW 9 of 24 \\n3.2.4. Research Areas Analysis \\nThe total research area analysis collected from the 82 papers was 164 because each paper can be \\nconsidered as more than one research area analysis. Given the small number of documents identified \\nin the period before I4.0, the ranking refers mostly to the current industrial revolution. Also, in this \\ncase, the result is consistent with the introduction of paradigm 4.0, which has intensified research and \\nthe adoption of technology. \\nThe first thematic areas and disciplines that are at the top of the ranking are computer science,'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 8, 'page_label': '9', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='the adoption of technology. \\nThe first thematic areas and disciplines that are at the top of the ranking are computer science, \\nengineering and biochemistry, genetics, and molecular Biology, respectively, with 29%, 23%, and 6% \\nof publications. Furthermore, the other disciplines identified for which applicative findings are found \\nare considered transversal to the first three discipli nes and this is a consequence of I4.0. In terms of \\nthe percentage contribution, the first three areas cover about 60% of the papers considered. \\nConsidering the top 20 research areas, given the frequency of the research areas’ distribution, \\nFigure 5 shows a higher level of concentration in the disciplines indicated above. \\nIn fact, in terms of the percentage contribution, the first five areas cover about 70% of the papers \\nconsidered. Regardless, by only counting research areas found once, there is a total of 27. \\nThis means two things:'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 8, 'page_label': '9', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='considered. Regardless, by only counting research areas found once, there is a total of 27. \\nThis means two things: \\n• The large number of fields in which this kind of research is involved; and \\n• Most papers have a transversal approach, that is, the object of each research crosses more \\nthan one field of application, thus involving more research areas. \\nThis confirms the wide interest in these subjects from several fields. \\n \\nFigure 5. Top 20 research areas contributions. \\n3.2.5. Top Source Journals Analysis \\nIn this section, the top 20 sources or journals that were published most frequently were extracted. \\nA journal is a time-bound publication with th e objective of promoting and monitoring the \\nprogress of the discipline it represents. \\nIn this specific case, the total source journals detected from the documents is 74, but, considering \\nthe top 20, given the frequency of the source journals’ distribution, only the first 13 sources have more'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 8, 'page_label': '9', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='the top 20, given the frequency of the source journals’ distribution, only the first 13 sources have more \\nthan one paper published, with a total percentage contribution of 43% of the total. \\nAfter analyzing the sources separately, the results obtained in the two databases were found to \\nnot be the same. In WoS, the top source journal was IEEE Access with two publications while in \\nScopus, the top source journals are Procedia Computer Science, Matec Web of Conferences, and Machine \\nLearning with four publications, which contribute 5% of the total. \\nFigure 5. Top 20 research areas contributions.\\nIn fact, in terms of the percentage contribution, the ﬁrst ﬁve areas cover about 70% of the papers\\nconsidered. Regardless, by only counting research areas found once, there is a total of 27.\\nThis means two things:\\n• The large number of ﬁelds in which this kind of research is involved; and\\n• Most papers have a transversal approach, that is, the object of each research crosses more than'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 8, 'page_label': '9', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='This means two things:\\n• The large number of ﬁelds in which this kind of research is involved; and\\n• Most papers have a transversal approach, that is, the object of each research crosses more than\\none ﬁeld of application, thus involving more research areas.\\nThis conﬁrms the wide interest in these subjects from several ﬁelds.\\n3.2.5. Top Source Journals Analysis\\nIn this section, the top 20 sources or journals that were published most frequently were extracted.\\nA journal is a time-bound publication with the objective of promoting and monitoring the progress\\nof the discipline it represents.\\nIn this speciﬁc case, the total source journals detected from the documents is 74, but, considering\\nthe top 20, given the frequency of the source journals’ distribution, only the ﬁrst 13 sources have more\\nthan one paper published, with a total percentage contribution of 43% of the total.\\nAfter analyzing the sources separately, the results obtained in the two databases were found to'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 8, 'page_label': '9', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='than one paper published, with a total percentage contribution of 43% of the total.\\nAfter analyzing the sources separately, the results obtained in the two databases were found to\\nnot be the same. In WoS, the top source journal was IEEE Access with two publications while in Scopus,'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 9, 'page_label': '10', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Sustainability 2020, 12, 492 10 of 26\\nthe top source journals are Procedia Computer Science, Matec Web of Conferences, and Machine Learning\\nwith four publications, which contribute 5% of the total.\\nAggregating the data collected from the two databases, the ranking moves to that obtained by\\nScopus, making sure that IEEE Access is no longer ﬁrst in the standings, but only eighth, and that the\\nformer are precisely those of Scopus: Procedia Computer Science, Matec Web Of Conferences, and Machine\\nLearning, with the same number of publications. Next, the 10 source journals have a 3% publication\\ncontribution while the rest have a one-to-one relationship (1%) with the corresponding source journal.\\nThe low level of concentration of the sources suggests that there is a great deal of interest in\\nthese topics from several scientiﬁc journals. As a matter of fact, it is foreseeable that specialized sector'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 9, 'page_label': '10', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='these topics from several scientiﬁc journals. As a matter of fact, it is foreseeable that specialized sector\\nsources (AI Magazine and Machine Learning) are among the ﬁrst 13; however, it is interesting to note\\nthat other sources are involved, such as Sustainability Switzerland or BMC Bioinformatics and Nuclear\\nEngineering and Design.\\nFigure 6 shows the top 20 source journals contributions.\\nSustainability 2020, 12, x FOR PEER REVIEW 10 of 24 \\nAggregating the data collected from the two databases, the ranking moves to that obtained by \\nScopus, making sure that IEEE Access is no longer first in the standings, but only eighth, and that the \\nformer are precisely those of Scopus: Procedia Computer Science, Matec Web Of Conferences, and Machine \\nLearning, with the same number of publications. Next, the 10 source journals have a 3% publication \\ncontribution while the rest have a one-to-one re lationship (1%) with the corresponding source \\njournal.'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 9, 'page_label': '10', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='contribution while the rest have a one-to-one re lationship (1%) with the corresponding source \\njournal. \\nThe low level of concentration of the sources suggests that there is a great deal of interest in these \\ntopics from several scientific journals. As a matter of fact, it is foreseeable that specialized sector \\nsources (AI Magazine and Machine Learning) are among the first 13; however,  it is interesting to note \\nthat other sources are involved, such as Sustainability Switzerland or BMC Bioinformatics and Nuclear \\nEngineering and Design. \\nFigure 6 shows the top 20 source journals contributions. \\n \\nFigure 6. Top 20 source journals contributions. \\n3.2.6. Country Analysis \\nThe results that emerged through research on the two databases are consistent with each other. \\nIn both cases, in fact, the countries that give the greatest contribution to the research are China and \\nthe United States (Figure 8). The result is obvious since in China and the United States, more than 1.3'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 9, 'page_label': '10', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='the United States (Figure 8). The result is obvious since in China and the United States, more than 1.3 \\nbillion and 0.3 millions of people live, respective ly, and so there are more researchers than in the \\nsingle European nations. Focusing on Europe, Germany published more papers than any other \\nE u r o p e a n  c o u n t r y .  T h i s  i s  n o t  a  r a n d o m  r e s u l t :  I 4 . 0  w a s  b o r n  i n  G e r m a n y ,  s o  t h i s  o u t c o m e  w a s  \\nexpected. However, the following observation cannot be ignored from this data: The USA and China \\ncarry the first two places in the list while it is no t the same for European countries. Europe, despite \\nits talents and resources, has lost ground. Presenting its report on artificial intelligence, the French \\ndeputy and mathematician Cédric Villani declared that, “Europe must be able to compete with China \\nand the United States while protecting its citizens and pointing the way to go on ethical issues”. If'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 9, 'page_label': '10', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='and the United States while protecting its citizens and pointing the way to go on ethical issues”. If \\nwe are not careful, the 21st century rules will not be defined in Brussels, but in Shanghai. Artificial \\nintelligence is also a land marked by intense geopolitical rivalry that could redefine global power \\nrelations. \\n  \\nFigure 6. Top 20 source journals contributions.\\n3.2.6. Country Analysis\\nThe results that emerged through research on the two databases are consistent with each other.\\nIn both cases, in fact, the countries that give the greatest contribution to the research are China and\\nthe United States (Figure 8). The result is obvious since in China and the United States, more than\\n1.3 billion and 0.3 millions of people live, respectively, and so there are more researchers than in\\nthe single European nations. Focusing on Europe, Germany published more papers than any other\\nEuropean country. This is not a random result: I4.0 was born in Germany, so this outcome was expected.'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 9, 'page_label': '10', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='the single European nations. Focusing on Europe, Germany published more papers than any other\\nEuropean country. This is not a random result: I4.0 was born in Germany, so this outcome was expected.\\nHowever, the following observation cannot be ignored from this data: The USA and China carry the\\nﬁrst two places in the list while it is not the same for European countries. Europe, despite its talents\\nand resources, has lost ground. Presenting its report on artiﬁcial intelligence, the French deputy and\\nmathematician Cédric Villani declared that, “Europe must be able to compete with China and the\\nUnited States while protecting its citizens and pointing the way to go on ethical issues”. If we are not\\ncareful, the 21st century rules will not be deﬁned in Brussels, but in Shanghai. Artiﬁcial intelligence is\\nalso a land marked by intense geopolitical rivalry that could redeﬁne global power relations.\\nEven so, regarding Europe, it is worthy to also note that since 2017, France, Germany, and Italy'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 9, 'page_label': '10', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='also a land marked by intense geopolitical rivalry that could redeﬁne global power relations.\\nEven so, regarding Europe, it is worthy to also note that since 2017, France, Germany, and Italy\\nhave intensiﬁed their trilateral cooperation to promote digitizing the manufacturing industry. In this'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 10, 'page_label': '11', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Sustainability 2020, 12, 492 11 of 26\\nregard, in the near future, we expect a signiﬁcant evolution of smart production initiatives and therefore\\nan increase in scientiﬁc research.\\nFigure 7 shows the country contribution distribution.\\nSustainability 2020, 12, x FOR PEER REVIEW 11 of 24 \\nEven so, regarding Europe, it is worthy to also note that since 2017, France, Germany, and Italy \\nhave intensified their trilateral cooperation to promote digitizing the manufacturing industry. In this \\nregard, in the near future, we expect a significant evolution of smart production initiatives and \\ntherefore an increase in scientific research. \\nFigure 7 shows the country contribution distribution. \\n \\nFigure 7. Top 20 countries contributions. \\n3.2.7. Affiliation Analysis \\nThe total number of affiliation detected from the 82 papers is 153. Also, in this case, considering \\nthe top 20, the frequency of the affiliation distribu tion shows that most papers have a one-to-one'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 10, 'page_label': '11', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='the top 20, the frequency of the affiliation distribu tion shows that most papers have a one-to-one \\nrelationship with the corresponding affiliation. Only the first four affiliations have three papers (2% \\nof the contribution) and the second four have two papers (1.3% of the contribution). This result gives \\nus information about the wide interest on this subject from several universities and research centers \\nall over the world. Then, the affiliation analysis confirms the result of the country analysis (Figure 8). \\nIn fact, if we try to sum the first eight affiliations by their own country, the outcome is: \\n• Nine papers from China; \\n• Six papers from Germany; and \\n• Five papers from the USA. \\nIn September 2018, the most important event on artificial intelligence was held in Shanghai. \\nChina is very determined to focus on future technologies. \\nFor some months, China has become the world’s leading power in terms of scientific'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 10, 'page_label': '11', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='China is very determined to focus on future technologies. \\nFor some months, China has become the world’s leading power in terms of scientific \\npublications. Late in the 20th century technologi es, China chose to do what the English-speaking \\npeople call a “frog jump” and focus on 21st century technologies. \\nChina, with its 800 million Internet users and without any privacy protection policy, has access \\nto more personal data than the United States and Europe. \\nFigure 7. Top 20 countries contributions.\\n3.2.7. Aﬃliation Analysis\\nThe total number of aﬃliation detected from the 82 papers is 153. Also, in this case, considering\\nthe top 20, the frequency of the a ﬃliation distribution shows that most papers have a one-to-one\\nrelationship with the corresponding aﬃliation. Only the ﬁrst four a ﬃliations have three papers (2% of\\nthe contribution) and the second four have two papers (1.3% of the contribution). This result gives us'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 10, 'page_label': '11', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='the contribution) and the second four have two papers (1.3% of the contribution). This result gives us\\ninformation about the wide interest on this subject from several universities and research centers all\\nover the world. Then, the aﬃliation analysis conﬁrms the result of the country analysis (Figure 8). In\\nfact, if we try to sum the ﬁrst eight aﬃliations by their own country, the outcome is:\\n• Nine papers from China;\\n• Six papers from Germany; and\\n• Five papers from the USA.\\nIn September 2018, the most important event on artiﬁcial intelligence was held in Shanghai. China\\nis very determined to focus on future technologies.\\nFor some months, China has become the world’s leading power in terms of scientiﬁc publications.\\nLate in the 20th century technologies, China chose to do what the English-speaking people call a “frog\\njump” and focus on 21st century technologies.\\nChina, with its 800 million Internet users and without any privacy protection policy, has access to'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 10, 'page_label': '11', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='jump” and focus on 21st century technologies.\\nChina, with its 800 million Internet users and without any privacy protection policy, has access to\\nmore personal data than the United States and Europe.'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 11, 'page_label': '12', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Sustainability 2020, 12, 492 12 of 26\\nSustainability 2020, 12, x FOR PEER REVIEW 12 of 24 \\n \\nFigure 8. Top 20 institute affiliations contributions. \\n3.2.8. Top Keywords Analysis \\nThrough NVivo 12, the top 20 keywords were extracted directly, which are those that always \\nappear in association with each document. \\nStarting from this classification, the graphic representation, a word cloud shape, of the keywords \\n(Figure 9) was extracted. It can be noted that the most used term is precisely “machine”, “learning”, \\nand “intelligence”, which the software represents with greater characters than all the other terms. \\n \\nFigure 9. Top 20 keywords cloud contribution by NVivo 12. \\nThe font size describes how much the keyword is indexed. Another mode of representation is \\nthe tree words (Figure 10). Also, in this case, th e most indexed words are those represented in the \\nlarger boxes. \\nFigure 8. Top 20 institute aﬃliations contributions.\\n3.2.8. Top Keywords Analysis'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 11, 'page_label': '12', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='the tree words (Figure 10). Also, in this case, th e most indexed words are those represented in the \\nlarger boxes. \\nFigure 8. Top 20 institute aﬃliations contributions.\\n3.2.8. Top Keywords Analysis\\nThrough NVivo 12, the top 20 keywords were extracted directly, which are those that always\\nappear in association with each document.\\nStarting from this classiﬁcation, the graphic representation, a word cloud shape, of the keywords\\n(Figure 9) was extracted. It can be noted that the most used term is precisely “machine”, “learning”,\\nand “intelligence”, which the software represents with greater characters than all the other terms.\\nSustainability 2020, 12, x FOR PEER REVIEW 12 of 24 \\n \\nFigure 8. Top 20 institute affiliations contributions. \\n3.2.8. Top Keywords Analysis \\nThrough NVivo 12, the top 20 keywords were extracted directly, which are those that always \\nappear in association with each document.'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 11, 'page_label': '12', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='3.2.8. Top Keywords Analysis \\nThrough NVivo 12, the top 20 keywords were extracted directly, which are those that always \\nappear in association with each document. \\nStarting from this classification, the graphic representation, a word cloud shape, of the keywords \\n(Figure 9) was extracted. It can be noted that the most used term is precisely “machine”, “learning”, \\nand “intelligence”, which the software represents with greater characters than all the other terms. \\n \\nFigure 9. Top 20 keywords cloud contribution by NVivo 12. \\nThe font size describes how much the keyword is indexed. Another mode of representation is \\nthe tree words (Figure 10). Also, in this case, th e most indexed words are those represented in the \\nlarger boxes. \\nFigure 9. Top 20 keywords cloud contribution by NVivo 12.\\nThe font size describes how much the keyword is indexed. Another mode of representation is\\nthe tree words (Figure 10). Also, in this case, the most indexed words are those represented in the'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 11, 'page_label': '12', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='The font size describes how much the keyword is indexed. Another mode of representation is\\nthe tree words (Figure 10). Also, in this case, the most indexed words are those represented in the\\nlarger boxes.'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 12, 'page_label': '13', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Sustainability 2020, 12, 492 13 of 26\\nSustainability 2020, 12, x FOR PEER REVIEW 13 of 24 \\n \\nFigure 10. Top 20 keywords tree contribution by Nvivo 12. \\nAs expected, the most indexed words are obviousl y “learning”, “machine”, and “intelligence”, \\nwith high numbers. It is logical that among the first results, words that recall the technology itself \\nwere obtained, but it is interesting to note that words referring to other fields of AI applications are \\nalso indexed. The reason is to be found in the fact that AI and ML are technologies that cross all the \\nsectors involved in I4.0 and that, therefore, do not remain circumscribed. \\nSpecifically, words, such as “data”, “neural”, “decision”, and “management”, are very or \\naverage indexed, demonstrating the fact that AI also extends to many other sectors. \\nAnother tool for the analysis for keywords is  the UCINET software, through which social \\nnetworks analysis is carried out.'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 12, 'page_label': '13', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Another tool for the analysis for keywords is  the UCINET software, through which social \\nnetworks analysis is carried out. \\nSocial network analysis (SNA), which is also often called social network theory, is a modern \\ntechnology of social relations. \\nSNA finds application in various social sciences , and has recently been used in the study of \\nvarious phenomena, such as international trade, information dissemination, the study of institutions, \\nand the functioning of organizations. The analysis  of the use of the term SNA in the scientific \\nliterature shows that in the last five years, there has been exponential growth of the use of this mode \\nof computable representation of complex and interdependent phenomena. The software returns a \\ngraph representing a socio-metric network (Figur e 11), which draws the relationships that exist \\nwithin the class. Each relationship is represented by an oriented arrow. \\nFigure 10. Top 20 keywords tree contribution by Nvivo 12.'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 12, 'page_label': '13', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='within the class. Each relationship is represented by an oriented arrow. \\nFigure 10. Top 20 keywords tree contribution by Nvivo 12.\\nAs expected, the most indexed words are obviously “learning”, “machine”, and “intelligence”,\\nwith high numbers. It is logical that among the ﬁrst results, words that recall the technology itself were\\nobtained, but it is interesting to note that words referring to other ﬁelds of AI applications are also\\nindexed. The reason is to be found in the fact that AI and ML are technologies that cross all the sectors\\ninvolved in I4.0 and that, therefore, do not remain circumscribed.\\nSpeciﬁcally, words, such as “data”, “neural”, “decision”, and “management”, are very or average\\nindexed, demonstrating the fact that AI also extends to many other sectors.\\nAnother tool for the analysis for keywords is the UCINET software, through which social networks\\nanalysis is carried out.\\nSocial network analysis (SNA), which is also often called social network theory, is a modern'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 12, 'page_label': '13', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='analysis is carried out.\\nSocial network analysis (SNA), which is also often called social network theory, is a modern\\ntechnology of social relations.\\nSNA ﬁnds application in various social sciences, and has recently been used in the study of\\nvarious phenomena, such as international trade, information dissemination, the study of institutions,\\nand the functioning of organizations. The analysis of the use of the term SNA in the scientiﬁc\\nliterature shows that in the last ﬁve years, there has been exponential growth of the use of this mode of\\ncomputable representation of complex and interdependent phenomena. The software returns a graph\\nrepresenting a socio-metric network (Figure 11), which draws the relationships that exist within the\\nclass. Each relationship is represented by an oriented arrow.'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 13, 'page_label': '14', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Sustainability 2020, 12, 492 14 of 26\\nSustainability 2020, 12, x FOR PEER REVIEW 14 of 24 \\n \\nFigure 11. Keywords Network by UCINET Software. \\nIn Figure 11, nodes and leaves can be identified. The nodes are represented by red circles and \\nare correspond to the most common keywords, where the words “machine”, “learning”, “artificial”, \\nand “intelligence” have been united to form the key words “machine le arning” and “artificial \\nintelligence”. \\nThe leaves, on the other hand, are represented by blue squares and correspond to the articles. \\nTo facilitate reading, the document titles were not inserted, but the (Identification) ID count for each \\nof them is shown in the Appendix A. \\nThe first thing that can be noticed is the isolatio n of many leaves that are not connected to the \\nnodes. This means that the corresponding documents are not described by the keywords represented \\nby the nodes. Really, they are characterized by keywords that have a frequency of the order of units.'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 13, 'page_label': '14', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='by the nodes. Really, they are characterized by keywords that have a frequency of the order of units. \\nAnother thing that easily jumps to the eye is a density that is larger around the keywords \\n“machine learning”, “decision”, “data”, “algorithm”, “system”, “artificial intelligence”, “method”, \\nand “optimization”. This density is reflected in the cloud and the box chart produced by NVivo 12. \\nTherefore, we can say that those are the words th at most often appear in the documents analyzed, \\nemphasizing, once again, that they include terms th at do not just refer to the technology object of \\nstudy but also to other fields of application. \\n3.3. Phase 3: Discussion \\n3.3.1. Benefits of Artificial Intelligence and Machine Learning in Industrial Contexts \\nFrom the analysis of the research carried out, th e first information that emerged is that there is \\na growing importance of innovation and digitalization in products, services, and processes.'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 13, 'page_label': '14', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='From the analysis of the research carried out, th e first information that emerged is that there is \\na growing importance of innovation and digitalization in products, services, and processes. \\nConsequently, it means that the adoption of advanced manufacturing technologies, such AI and ML, \\nis an emerging issue. In other words, AI/ML algo rithms represent an opportunity to handle high \\ndimensional problems and data. The interest in the subject is extended to all scientific sectors, but \\nwith a focus on computer science and engineering. \\nThe most significant benefits of using AI and ML in industrial sectors include: 1) Greater \\ninnovation, 2) process optimization, 3) resources optimization, and 4) improved quality. \\nAfter all, AI with ML is one of the most impo rtant technologies today and is transforming the \\neconomy and society, as demonstrated by the over 340,000 patent applications filed since the 1950s. \\n  \\nFigure 11. Keywords Network by UCINET Software.'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 13, 'page_label': '14', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='economy and society, as demonstrated by the over 340,000 patent applications filed since the 1950s. \\n  \\nFigure 11. Keywords Network by UCINET Software.\\nIn Figure 11, nodes and leaves can be identiﬁed. The nodes are represented by red circles and are\\ncorrespond to the most common keywords, where the words “machine”, “learning”, “artiﬁcial”, and\\n“intelligence” have been united to form the key words “machine learning” and “artiﬁcial intelligence”.\\nThe leaves, on the other hand, are represented by blue squares and correspond to the articles. To\\nfacilitate reading, the document titles were not inserted, but the (Identiﬁcation) ID count for each of\\nthem is shown in the Appendix A.\\nThe ﬁrst thing that can be noticed is the isolation of many leaves that are not connected to the\\nnodes. This means that the corresponding documents are not described by the keywords represented\\nby the nodes. Really, they are characterized by keywords that have a frequency of the order of units.'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 13, 'page_label': '14', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='nodes. This means that the corresponding documents are not described by the keywords represented\\nby the nodes. Really, they are characterized by keywords that have a frequency of the order of units.\\nAnother thing that easily jumps to the eye is a density that is larger around the keywords\\n“machine learning”, “decision”, “data”, “algorithm”, “system”, “artiﬁcial intelligence”, “method”,\\nand “optimization”. This density is reﬂected in the cloud and the box chart produced by NVivo 12.\\nTherefore, we can say that those are the words that most often appear in the documents analyzed,\\nemphasizing, once again, that they include terms that do not just refer to the technology object of study\\nbut also to other ﬁelds of application.\\n3.3. Phase 3: Discussion\\n3.3.1. Beneﬁts of Artiﬁcial Intelligence and Machine Learning in Industrial Contexts\\nFrom the analysis of the research carried out, the ﬁrst information that emerged is that there is a'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 13, 'page_label': '14', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='3.3.1. Beneﬁts of Artiﬁcial Intelligence and Machine Learning in Industrial Contexts\\nFrom the analysis of the research carried out, the ﬁrst information that emerged is that there is a\\ngrowing importance of innovation and digitalization in products, services, and processes. Consequently,\\nit means that the adoption of advanced manufacturing technologies, such AI and ML, is an emerging\\nissue. In other words, AI/ML algorithms represent an opportunity to handle high dimensional problems\\nand data. The interest in the subject is extended to all scientiﬁc sectors, but with a focus on computer\\nscience and engineering.\\nThe most signiﬁcant beneﬁts of using AI and ML in industrial sectors include: (1) Greater\\ninnovation, (2) process optimization, (3) resources optimization, and (4) improved quality.\\nAfter all, AI with ML is one of the most important technologies today and is transforming the\\neconomy and society, as demonstrated by the over 340,000 patent applications ﬁled since the 1950s.'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 14, 'page_label': '15', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Sustainability 2020, 12, 492 15 of 26\\nOther information that emerged is about the authors and aﬃliation. Many of these are in a 1:1 ratio\\ncompared to the selected documents and this supports the fact that there is no interest in technological\\napplications in one direction, but that, once again, the interest is very wide in the scientiﬁc community.\\nFurthermore, it can be said that the countries most interested in scientiﬁc research are the USA,\\nChina and European countries. This result is not a surprise.\\nIn terms of investment, the e ﬀort currently being deployed by the United States and China to\\nacquire dominance in the AI sector is far superior to that of other countries. More speciﬁcally, China\\nhas clearly stated its ambition to become a world leader in AI by 2030 [31]. Among the Chinese plans,\\nof absolute interest is the “Made in China 2025” plan, dedicated to the manufacturing sector; the\\n“Internet +” plan is also dedicated to smart manufacturing and innovation.'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 14, 'page_label': '15', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='of absolute interest is the “Made in China 2025” plan, dedicated to the manufacturing sector; the\\n“Internet +” plan is also dedicated to smart manufacturing and innovation.\\nA direct consequence of the above considerations could be having new generations of researchers\\nwho will contribute to future comparisons, accompanied by new questions for investigations.\\n3.3.2. Emerging Trends of Artiﬁcial Intelligence and Machine Learning in Sustainable Manufacturing\\nFrom the perspective of sustainability, the analysis highlighted that the new paradigm of smart\\nmanufacturing has the potential to bring fundamental improvements in the industry by addressing\\nthe issue of scarce resources and improving productivity.\\nIn fact, the survey pointed out a growing interest on applications related to green manufacturing\\nand sustainable development, proving that AI/ML play an important role in increasing sustainability'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 14, 'page_label': '15', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='In fact, the survey pointed out a growing interest on applications related to green manufacturing\\nand sustainable development, proving that AI/ML play an important role in increasing sustainability\\nthrough the intelligent utilization of materials and energy consumption (i.e., reduction of energy\\nconsumption and pollutant emissions, environmental footprint monitoring and evaluation, etc.).\\nFurthermore, it emerged that AI/ML algorithms present a wide array of applications that provide\\nan opportunity for sustainable development, which will involve several stakeholders from diﬀerent\\ncountries and sectors, including inventory and supply chain management, predictive maintenance,\\nand production.\\nIn particular, Pérez-Ortiz, Jiménez-Fernández, Gutiérrez et al. [32] reviewed the most important\\nclassiﬁcation algorithms applied to renewable energy (RE) problems. The main use of algorithms\\nis as a tool for predictive analysis and consequently for data preprocessing, result interpretation, or'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 14, 'page_label': '15', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='classiﬁcation algorithms applied to renewable energy (RE) problems. The main use of algorithms\\nis as a tool for predictive analysis and consequently for data preprocessing, result interpretation, or\\nevaluation in order to improve energy and resource management.\\nIn this context, it also emerged that AI/ML have been successfully utilized in various processes’\\noptimization, applications in manufacturing, and predictive maintenance in diﬀerent industries.\\nThe work published by Lieber, Stolpe, Konrad et al. [33] represents a good research within steel\\nindustry production. It proposes an approach for automatically preprocessing value series data to\\nimprove the quality of the process and products. It means that AI /ML techniques were found to\\nprovide promising potential for improved quality control optimization in manufacturing systems.\\nAppropriate adoption of AI/ML technologies will promote sustainable manufacturing and the'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 14, 'page_label': '15', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='provide promising potential for improved quality control optimization in manufacturing systems.\\nAppropriate adoption of AI/ML technologies will promote sustainable manufacturing and the\\nformation of a new generation of intelligent manufacturing, including all areas that characterize a\\nsustainable process, ranging from the supply chain management to quality control, to predictive\\nmaintenance, to energy consumption.\\nTable 5 summarizes the main areas in sustainable manufacturing, their respective key objectives,\\nand the main AI/ML applications.\\nHowever, the relationship between I.4 technologies, AI/ML, and sustainability demands a more\\nconceptual and empirical investigation. This is corroborated by an article recently published in Nature\\nSustainability by the director of the Earth Institute at Columbia University, Je ﬀrey Sachs, and other\\nexperts, and the so-called Fourth Industrial Revolution (made of artiﬁcial intelligence and other digital'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 14, 'page_label': '15', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='experts, and the so-called Fourth Industrial Revolution (made of artiﬁcial intelligence and other digital\\ntechnologies) is even cited as one of the six transformations necessary to achieve the sustainable\\ndevelopment goals [34].'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 15, 'page_label': '16', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Sustainability 2020, 12, 492 16 of 26\\nTable 5. Main areas in sustainable manufacturing.\\nMain Areas in Sustainable\\nManufacturing\\nKey\\nObjective\\nAI/ML\\nApplications\\nSupply Chain Management Ready product available in the\\nappropriate place at a speciﬁc time\\nImproves transparency, accelerates\\ndecision-making, and produces accurate\\ndemand forecasting\\nQuality Control\\nRecognize the early signs of\\npotential production failures\\nwithin the shortest terms in order\\nto save resources and sustain\\noperational eﬃciency\\nImproves the response time and allows\\neliminating possible failures\\nPredictive Maintenance\\nDetects possible production\\nmalfunctions that may cause\\nproduct quality issues\\nCreates accurate forecasts as to when\\nthe machinery must be repaired\\nEnergy consumption Recommendations that will strike\\na balance in energy use\\nImproves excessive use of certain\\nmaterials, redundant production scrap\\nwaste, ineﬃcient supply chain\\nmanagement, logistics, and unequal\\ndistribution of energy resources.'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 15, 'page_label': '16', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='a balance in energy use\\nImproves excessive use of certain\\nmaterials, redundant production scrap\\nwaste, ineﬃcient supply chain\\nmanagement, logistics, and unequal\\ndistribution of energy resources.\\n4. Conclusions\\nThis research focused on the study of the state of the art of AI and ML applications, selecting\\nliterature on what has now become a particularly hot topic in scientiﬁc research. The literature available\\non any subject is now wide and a complete coverage of all the documents published with respect to a\\nparticular topic can be challenging or even impossible. Therefore, a systematic selection of the most\\nrelevant literature was implemented. This document provides a systematic review of applications\\nin various scientiﬁc ﬁelds using ML techniques. For the selection of documents, objective and clear\\nmethods of investigation were used, independent of the experience of the researchers. Among the'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 15, 'page_label': '16', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='in various scientiﬁc ﬁelds using ML techniques. For the selection of documents, objective and clear\\nmethods of investigation were used, independent of the experience of the researchers. Among the\\nobjectives of the document, it aimed to not only provide a comprehensive framework on the literature\\non the research of AI and ML but also a starting point for integrating knowledge through research in\\nthis area and to suggest future research paths. It is important to underline that this document was\\nproduced using only two databases, i.e., WoS and Scopus, in which only documents with open access\\nwere included. There are, therefore, many other documents with restricted access and other indexing\\ndatabases, such as Google Scholar, that could be integrated for future research.\\nAuthor Contributions: All authors contributed equally to this work. All authors have read and agreed to the\\npublished version of the manuscript.'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 15, 'page_label': '16', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Author Contributions: All authors contributed equally to this work. All authors have read and agreed to the\\npublished version of the manuscript.\\nFunding: This work has been conducted under the framework of the Italian project “Linee Guida per\\nI4.0-Campania”—funded by Regione Campania within POR FSE 2014–2020 Asse IV “Capacit à istituzionale e\\namministrativa” objectives 18 (RA) 11.3 and 21 (RA) 11.6.\\nConﬂicts of Interest: The authors declare no conﬂict of interest.'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 16, 'page_label': '17', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Sustainability 2020, 12, 492 17 of 26\\nAppendix A\\nID Count Research\\nSource\\nID\\nDoc Year Title Authors Source Title TC\\n1 SCP 2 2006 Machine learning in bioinformatics\\nLarrañaga, P .; Calvo, B.; Santana,\\nR.; Bielza, C.; Galdiano, J.; Inza, I.;\\nLozano, J.A.; Armañanzas, R.;\\nSantafé, G.; Pérez, A.; Robles, V .\\nBrieﬁngs in Bioinformatics 298\\n2 WoS 62 2008 Data-driven modelling: Some past experiences\\nand new approaches Solomatine, D.P .; Ostfeld, A. Journal of Hydroinformatics 160\\n3 SCP 26 2016 Learning from imbalanced data: Open\\nchallenges and future directions Krawczyk, B. Progress in Artiﬁcial\\nIntelligence 119\\n4 WoS 63 2001 Computer go: An AI oriented survey Bouzy, B; Cazenave, T Artiﬁcial Intelligence 114\\n5 SCP 6 2008 Structured machine learning: The next ten years\\nDietterich, T.G.; Domingos, P .;\\nGetoor, L.; Muggleton, S.;\\nTadepalli, P .\\nMachine Learning 75\\n6 SCP 28 2016 Machine learning in manufacturing:\\nAdvantages, challenges, and applications\\nWuest, T.; Weimer, D.; Irgens, C.;'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 16, 'page_label': '17', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Getoor, L.; Muggleton, S.;\\nTadepalli, P .\\nMachine Learning 75\\n6 SCP 28 2016 Machine learning in manufacturing:\\nAdvantages, challenges, and applications\\nWuest, T.; Weimer, D.; Irgens, C.;\\nThoben, K.D.\\nProduction and\\nManufacturing Research 52\\n7 WoS 64 2017 Machine learning paradigms for next-generation\\nwireless networks\\nJiang, C.; Zhang, H.; Ren, Y.; Han,\\nZ.; Chen, K.C.; Hanzo, L.\\nIeee Wireless\\nCommunications 50\\n8 SCP 3 2006 Machine learning techniques in disease\\nforecasting: A case study on rice blast prediction\\nKaundal, R.; Kapoor, A.A.;\\nRaghava, G.P .S. BMC Bioinformatics 48\\n9 SCP 4 2008\\nA comparison of machine learning algorithms\\nfor chemical toxicity classiﬁcation using a\\nsimulated multi-scale data model\\nJudson, R.; Elloumi, F.; Woodrow,\\nR.W.; Li, Z.; Shah, I. BMC Bioinformatics 45\\n10 SCP 19 2015\\nA review of intelligent driving style analysis\\nsystems and related artiﬁcial intelligence\\nalgorithms\\nMeiring, G.A.M.; Myburgh, H.C. Sensors (Switzerland) 33\\n11 SCP 21 2016'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 16, 'page_label': '17', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='10 SCP 19 2015\\nA review of intelligent driving style analysis\\nsystems and related artiﬁcial intelligence\\nalgorithms\\nMeiring, G.A.M.; Myburgh, H.C. Sensors (Switzerland) 33\\n11 SCP 21 2016\\nA machine learning framework for gait\\nclassiﬁcation using inertial sensors: Application\\nto elderly, post-stroke and huntington’s disease\\npatients\\nMannini, A.; Trojaniello, D.;\\nCereatti, A.; Sabatini, A.M. Sensors 31'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 17, 'page_label': '18', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Sustainability 2020, 12, 492 18 of 26\\nID Count Research\\nSource\\nID\\nDoc Year Title Authors Source Title TC\\n12 SCP 1 2006 Application of machine learning in SNP\\ndiscovery\\nMatukumalli, L.K.; Grefenstette,\\nJ.J.; Hyten, D.L.; Choi, I.Y.;\\nCregan, P .B.; Van Tassell, C.P .\\nBMC Bioinformatics 30\\n13 SCP 10 2013 Beam search algorithms for multilabel learning Kumar, A.; Vembu, S.; Menon,\\nA.K.; Elkan, C. Machine Learning 29\\n14 WoS 65 2011 Recommender Systems: An Overview Burke, Robin; Felfernig,\\nAlexander; Goeker, M.H. Ai Magazine 29\\n15 SCP 11 2013 Biomedical informatics for computer-aided\\ndecision support systems: A survey Belle, A.; Kon, M.A.; Najarian, K. The Scientiﬁc World Journal 27\\n16 SCP 23 2016 Application of machine learning to construction\\ninjury prediction\\nTixier, A.J.P .; Hallowell, M.R.;\\nRajagopalan, B.; Bowman, D. Automation in Construction 21\\n17 SCP 12 2013\\nQuality prediction in interlinked manufacturing\\nprocesses based on supervised & unsupervised\\nmachine learning'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 17, 'page_label': '18', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Rajagopalan, B.; Bowman, D. Automation in Construction 21\\n17 SCP 12 2013\\nQuality prediction in interlinked manufacturing\\nprocesses based on supervised & unsupervised\\nmachine learning\\nLieber, D.; Stolpe, M.; Konrad, B.;\\nDeuse, J.; Morik, K. Procedia CIRP 18\\n18 SCP 29 2016 Semantic framework of internet of things for\\nsmart cities: Case studies\\nZhang, N.; Chen, H.; Chen, X.;\\nChen, J. Sensors 17\\n19 SCP 20 2015 Support vector machines in structural\\nengineering: A review\\nÇevik, A.; KURTO˘GLU, A.E.;\\nBilgehan, M.; Gül¸ san, M.E.;\\nAlbegmprli, H.M.\\nJournal of Civil Engineering\\nand Management 15\\n20 SCP 25 2016 A review of classiﬁcation problems and\\nalgorithms in renewable energy applications\\nPérez-Ortiz, M.;\\nJiménez-Fernández, S.; Gutiérrez,\\nP .A.; (. . . ); Hervás-Martínez, C.;\\nSalcedo-Sanz, S.\\nEnergies 15\\n21 SCP 43 2018 Artiﬁcial intelligence (AI) methods in optical\\nnetworks: A comprehensive survey\\nMata, J.; de Miguel, I.; Durán, R.J.;\\n( . . . ); Jukan, A.; Chamania, M.\\nOptical Switching and'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 17, 'page_label': '18', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='21 SCP 43 2018 Artiﬁcial intelligence (AI) methods in optical\\nnetworks: A comprehensive survey\\nMata, J.; de Miguel, I.; Durán, R.J.;\\n( . . . ); Jukan, A.; Chamania, M.\\nOptical Switching and\\nNetworking 15\\n22 SCP 14 2014 Fault diagnosis of automobile gearbox based on\\nmachine learning techniques\\nPraveenkumar, T.; Saimurugan,\\nM.; Krishnakumar, P .;\\nRamachandran, K.I.\\nProcedia Engineering 14\\n23 SCP 16 2014 Improving active Mealy machine learning for\\nprotocol conformance testing\\nAarts, F.; Kuppens, H.; Tretmans,\\nJ.; Vaandrager, F.; Verwer, S. Machine Learning 11'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 18, 'page_label': '19', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Sustainability 2020, 12, 492 19 of 26\\nID Count Research\\nSource\\nID\\nDoc Year Title Authors Source Title TC\\n24 WoS 66 2016 Strategies and Principles of Distributed Machine\\nLearning on Big Data Xing, E.P .; Ho, Q.; Xie, P .; Wei, D. Engineering 11\\n25 WoS 67 2015 Recent advances on artiﬁcial intelligence and\\nlearning techniques in cognitive radio networks\\nAbbas, N.; Nasser, Y.; El Ahmad,\\nK.\\nEurasip Journal on Wireless\\nCommunications and\\nNetworking\\n11\\n26 WoS 68 2018 Artiﬁcial intelligence (AI) methods in optical\\nnetworks: A comprehensive survey\\nMata, J.; de Miguel, I.; Duran, R.J.;\\nMerayo, N.; Singh, S.K.; Jukan, A.;\\nChamania, M.\\nOptical Switching and\\nNetworking 9\\n27 SCP 40 2018\\nA big data driven sustainable manufacturing\\nframework for condition-based maintenance\\nprediction\\nKumar, A.; Shankar, R.; Thakur,\\nL.S.\\nJournal of Computational\\nScience\\n27, pp. 428–439\\n8\\n28 WoS 69 2017\\nResearch and Application of a Novel Hybrid\\nModel Based on Data Selection and Artiﬁcial'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 18, 'page_label': '19', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Kumar, A.; Shankar, R.; Thakur,\\nL.S.\\nJournal of Computational\\nScience\\n27, pp. 428–439\\n8\\n28 WoS 69 2017\\nResearch and Application of a Novel Hybrid\\nModel Based on Data Selection and Artiﬁcial\\nIntelligence Algorithm for Short Term Load\\nForecasting\\nYang, W.; Wang, J.; Wang, R. Entropy 8\\n29 SCP 33 2017 Context Aware Process Mining in Logistics Becker, T.; Intoyoad, W. Procedia CIRP 7\\n30 SCP 24 2016\\nApplications of machine learning methods to\\nidentifying and predicting building retroﬁt\\nopportunities\\nMarasco, D.E.; Kontokosta, C.E. Energy and Buildings 6\\n31 SCP 37 2017\\nOperational Demand Forecasting in District\\nHeating Systems Using Ensembles of Online\\nMachine Learning Algorithms\\nJohansson, C.; Bergkvist, M.;\\nGeysen, D.; (. . . ); Lavesson, N.;\\nVanhoudt, D.\\nEnergy Procedia 6\\n32 WoS 70 2018 Advances in Multiple Criteria Decision Making\\nfor Sustainability: Modeling and Applications Shen, K.Y.; Tzeng, G.H. Sustainability 6\\n33 WoS 71 2017 Hybrid-augmented intelligence: Collaboration'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 18, 'page_label': '19', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='for Sustainability: Modeling and Applications Shen, K.Y.; Tzeng, G.H. Sustainability 6\\n33 WoS 71 2017 Hybrid-augmented intelligence: Collaboration\\nand cognition\\nZheng, N.N.; Liu, Z.Y.; Ren, P .J.;\\nMa, Y.Q.; Chen, S.T.; Yu, S.Y.; Xue,\\nJ.R.; Chen, B.D.; Wang, F.Y.\\nFrontiers of Information\\nTechnology & Electronic\\nEngineering\\n6'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 19, 'page_label': '20', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Sustainability 2020, 12, 492 20 of 26\\nID Count Research\\nSource\\nID\\nDoc Year Title Authors Source Title TC\\n34 SCP 5 2008 Performance evaluation of the NVIDIA GeForce\\n8800 GTX GPU for machine learning\\nEl Zein, A.; McCreath, E.; Rendell,\\nA.; Smola, A.\\nLecture Notes in Computer\\nScience (including subseries\\nLecture Notes in Artiﬁcial\\nIntelligence and Lecture\\nNotes in Bioinformatics) 5101\\nLNCS(PART 1), pp. 466–475\\n5\\n35 SCP 7 2011 A review of artiﬁcial intelligence algorithms in\\ndocument classiﬁcation Bilski, A.\\nInternational Journal of\\nElectronics and\\nTelecommunications\\n5\\n36 SCP 18 2015 An architecture for agile machine learning in\\nreal-time applications Schleier-Smith, J.\\nProceedings of the ACM\\nSIGKDD International\\nConference on Knowledge\\nDiscovery and Data Mining\\n4\\n37 SCP 52 2018 Machine learning in agriculture: A review Liakos, K.G.; Busato, P .; Moshou,\\nD.; Pearson, S.; Bochtis, D. Sensors 4\\n38 SCP 22 2016\\nApplication of Information Processes\\nApplicative Modelling to Virtual Machines Auto'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 19, 'page_label': '20', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='D.; Pearson, S.; Bochtis, D. Sensors 4\\n38 SCP 22 2016\\nApplication of Information Processes\\nApplicative Modelling to Virtual Machines Auto\\nConﬁguration\\nZykov, S.; Shumsky, L. Procedia Computer Science 3\\n39 SCP 34 2017 Geometry-aware principal component analysis\\nfor symmetric positive deﬁnite matrices Horev, I.; Yger, F.; Sugiyama, M. Machine Learning 3\\n40 SCP 17 2015 A Fuzzy Least Squares Support Tensor Machines\\nin Machine Learning Zhang, R.; Zhou, Z.\\nInternational Journal of\\nEmerging Technologies in\\nLearning\\n2\\n41 SCP 36 2017 Nuclear energy system’s behavior and decision\\nmaking using machine learning\\nGomez Fernandez, M.; Tokuhiro,\\nA.; Welter, K.; Wu, Q.\\nNuclear Engineering and\\nDesign 2\\n42 SCP 9 2013 Application study of machine learning in\\nlightning forecasting\\nQiu, T.; Zhang, S.; Zhou, H.; Bai,\\nX.; Liu, P .\\nInformation Technology\\nJournal 1\\n43 SCP 30 2016\\nWOWMON: A machine learning-based proﬁler\\nfor self-adaptive instrumentation of scientiﬁc\\nworkﬂows\\nZhang, X.; Abbasi, H.; Huck, K.;'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 19, 'page_label': '20', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='X.; Liu, P .\\nInformation Technology\\nJournal 1\\n43 SCP 30 2016\\nWOWMON: A machine learning-based proﬁler\\nfor self-adaptive instrumentation of scientiﬁc\\nworkﬂows\\nZhang, X.; Abbasi, H.; Huck, K.;\\nMalony, A.D. Procedia Computer Science 1'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 20, 'page_label': '21', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Sustainability 2020, 12, 492 21 of 26\\nID Count Research\\nSource\\nID\\nDoc Year Title Authors Source Title TC\\n44 SCP 31 2017 An event search platform using machine\\nlearning\\nRodrigues, M.A.; Silva, R.R.;\\nBernardino, J.\\nProceedings of the\\nInternational Conference on\\nSoftware Engineering and\\nKnowledge Engineering,\\nSEKE\\n1\\n45 SCP 32 2017\\nAutomated business process management-in\\ntimes of digital transformation using machine\\nlearning or artiﬁcial intelligence\\nPaschek, D.; Luminosu, C.T.;\\nDraghici, A. MATEC Web of Conferences 1\\n46 SCP 42 2018\\nApplication of machine learning methods in big\\ndata analytics at management of contracts in the\\nconstruction industry\\nValpeters, M.; Kireev, I.; Ivanov,\\nN. MATEC Web of Conferences 1\\n47 SCP 48 2018 Data mining and machine learning in textile\\nindustry\\nYildirim, P .; Birant, D.; Alpyildiz,\\nT.\\nWiley Interdisciplinary\\nReviews: Data Mining and\\nKnowledge Discovery\\n1\\n48 WoS 72 2018\\nBig Data Analytics, Machine Learning, and\\nArtiﬁcial Intelligence in Next-Generation'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 20, 'page_label': '21', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='T.\\nWiley Interdisciplinary\\nReviews: Data Mining and\\nKnowledge Discovery\\n1\\n48 WoS 72 2018\\nBig Data Analytics, Machine Learning, and\\nArtiﬁcial Intelligence in Next-Generation\\nWireless Networks\\nKibria, M.G.; Kien, N.; Villardi,\\nG.P .; Zhao, O.; Ishizu, K.; Kojima,\\nF.\\nIeee Access 1\\n49 WoS 73 2017 Quantum neuromorphic hardware for quantum\\nartiﬁcial intelligence Prati, E.\\n8th International Workshop\\nDice2016: Spacetime - Matter -\\nQuantum Mechanics\\n1\\n50 WoS 74 2015 Exploiting Computational intelligence\\nParadigms in e-Technologies and Activities Said, H.M.; Salem, A.M.\\nInternational Conference on\\nCommunications,\\nManagement, and\\nInformation Technology\\n(Iccmit’2015)\\n1\\n51 WoS 75 2012 Sentiment Analysis of Products Using Web Unnamalai, K.\\nInternational Conference on\\nModelling Optimization and\\nComputing\\n1\\n52 SCP 8 2012 Taxonomy development and its impact on a\\nself-learning e-recruitment system\\nFaliagka, E.; Karydis, I.; Rigou,\\nM.; (. . . ); Tsakalidis, A.; Tzimas,\\nG.\\nIFIP Advances in Information'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 20, 'page_label': '21', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='1\\n52 SCP 8 2012 Taxonomy development and its impact on a\\nself-learning e-recruitment system\\nFaliagka, E.; Karydis, I.; Rigou,\\nM.; (. . . ); Tsakalidis, A.; Tzimas,\\nG.\\nIFIP Advances in Information\\nand Communication\\nTechnology\\n0'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 21, 'page_label': '22', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Sustainability 2020, 12, 492 22 of 26\\nID Count Research\\nSource\\nID\\nDoc Year Title Authors Source Title TC\\n53 SCP 13 2013 Research on adaptive multi-ﬁltering model of\\nnetwork sensitive information\\nCao, X.F.; Kang, W.; Shi, Q.; Shi,\\nF.F.\\nInformation Technology\\nJournal 0\\n54 SCP 15 2014 Grade: Machine-learning support for graduate\\nadmissions Waters, A.; Miikkulainen, R. AI Magazine 0\\n55 SCP 27 2016 Leveraging linked open data information\\nextraction for data mining applications Mahule, R.; Vyas, O.P .\\nTurkish Journal of Electrical\\nEngineering and Computer\\nSciences\\n0\\n56 SCP 38 2017 Rapid prototyping IoT solutions based on\\nMachine Learning\\nRizzo, A.; Montefoschi, F.;\\nCaporali, M.; (. . . ); Burresi, G.;\\nGiorgi, R.\\nACM International\\nConference Proceeding Series 0\\n57 SCP 39 2017 Towards automatic learning of heuristics for\\nmechanical transformations of procedural code\\nVigueras, G.; Carro, M.; Tamarit,\\nS.; Mariño, J.\\nElectronic Proceedings in\\nTheoretical Computer Science,\\nEPTCS\\n0'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 21, 'page_label': '22', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='mechanical transformations of procedural code\\nVigueras, G.; Carro, M.; Tamarit,\\nS.; Mariño, J.\\nElectronic Proceedings in\\nTheoretical Computer Science,\\nEPTCS\\n0\\n58 SCP 41 2018 Application of artiﬁcial intelligence principles in\\nmechanical engineering\\nZajaˇ cko, I.; Gál, T.; Ságová, Z.;\\nMateichyk, V .; Wiecek, D. MATEC Web of Conferences 0\\n59 SCP 44 2018 Artiﬁcial Intelligence in Medical Applications Chan, Y.K.; Chen, Y.F.; Pham, T.;\\nChang, W.; Hsieh, M.Y.\\nJournal of Healthcare\\nEngineering 0\\n60 SCP 45 2018\\nA semantic internet of things framework using\\nmachine learning approach based on cloud\\ncomputing\\nDing, P .W.; Hsu, I.C. ACM International\\nConference Proceeding Series 0\\n61 SCP 46 2018 A Survey on Machine Learning-Based Mobile\\nBig Data Analysis: Challenges and Applications\\nXie, J.; Song, Z.; Li, Y.; (. . . );\\nZhang, J.; Guo, J.\\nWireless Communications\\nand Mobile Computing 0\\n62 SCP 47 2018 Big Data and Machine Learning Based Secure'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 21, 'page_label': '22', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Xie, J.; Song, Z.; Li, Y.; (. . . );\\nZhang, J.; Guo, J.\\nWireless Communications\\nand Mobile Computing 0\\n62 SCP 47 2018 Big Data and Machine Learning Based Secure\\nHealthcare Framework Kaur, P .; Sharma, M.; Mittal, M. Procedia Computer Science 0\\n63 SCP 49 2018 Discovering discontinuity in big ﬁnancial\\ntransaction data\\nTuarob, S.; Strong, R.; Chandra,\\nA.; Tucker, C.S.\\nACM Transactions on\\nManagement Information\\nSystems\\n0'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 22, 'page_label': '23', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Sustainability 2020, 12, 492 23 of 26\\nID Count Research\\nSource\\nID\\nDoc Year Title Authors Source Title TC\\n64 SCP 50 2018 Introducing children to machine learning\\nconcepts through hands-on experience\\nHitron, T.; Erel, H.; Wald, I.;\\nZuckerman, O.\\nIDC 2018 - Proceedings of the\\n2018 ACM Conference on\\nInteraction Design and\\nChildren\\n0\\n65 SCP 51 2018 Machine learning for software engineering:\\nModels, methods, and applications Meinke, K.; Bennaceur, A.\\nProceedings - International\\nConference on Software\\nEngineering\\n0\\n66 SCP 53 2018 Machine Learning in IT Service Management Zuev, D.; Kalistratov, A.; Zuev, A.Procedia Computer Science 0\\n67 SCP 54 2018 Research and application of computer control\\nsystem based on complex neural network Yang, R. MATEC Web of Conferences 0\\n68 SCP 55 2018 Text classiﬁcation techniques: A literature\\nreview Thangaraj, M.; Sivakami, M.\\nInterdisciplinary Journal of\\nInformation, Knowledge, and\\nManagement\\n0\\n69 SCP 56 2019 A Machine Learning Method for Predicting'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 22, 'page_label': '23', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='review Thangaraj, M.; Sivakami, M.\\nInterdisciplinary Journal of\\nInformation, Knowledge, and\\nManagement\\n0\\n69 SCP 56 2019 A Machine Learning Method for Predicting\\nDriving Range of Battery Electric Vehicles\\nSun, S.; Zhang, J.; Bi, J.; Wang, Y.;\\nMoghaddam, M.H.Y.\\nJournal of Advanced\\nTransportation 0\\n70 SCP 57 2019 An empirical comparison of machine-learning\\nmethods on bank client credit assessments\\nMunkhdalai, L.; Munkhdalai, T.;\\nNamsrai, O.E.; Lee, J.Y.; Ryu, K.H. Sustainability 0\\n71 SCP 58 2019\\nComparison of multiple linear regression,\\nartiﬁcial neural network, extreme learning\\nmachine, and support vector machine in\\nderiving operation rule of hydropower reservoir\\nNiu, W.J.; Feng, Z.K.; Feng, B.F.; (\\n. . . ); Cheng, C.T.; Zhou, J.Z. Water 0\\n72 SCP 59 2019\\nDevelopment and evaluation of a low-cost and\\nsmart technology for precision weed\\nmanagement utilizing artiﬁcial intelligence\\nPartel, V .; Charan Kakarla, S.;\\nAmpatzidis, Y.\\nComputers and Electronics in\\nAgriculture 0'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 22, 'page_label': '23', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='smart technology for precision weed\\nmanagement utilizing artiﬁcial intelligence\\nPartel, V .; Charan Kakarla, S.;\\nAmpatzidis, Y.\\nComputers and Electronics in\\nAgriculture 0\\n73 SCP 60 2019 Identifying known and unknown mobile\\napplication traﬃc using a multilevel classiﬁer\\nZhao, S.; Chen, S.; Sun, Y.; (. . . );\\nSu, J.; Su, C.\\nSecurity and Communication\\nNetworks 0'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 23, 'page_label': '24', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Sustainability 2020, 12, 492 24 of 26\\nID Count Research\\nSource\\nID\\nDoc Year Title Authors Source Title TC\\n74 SCP 61 2019 Optimized Clustering Algorithms for Large\\nWireless Sensor Networks: A Review\\nWohwe Sambo, D.; Yenke, B.O.;\\nFörster, A.; Dayang, P . Sensors 0\\n75 WoS 76 2019\\nFPGA-Based Accelerators of Deep Learning\\nNetworks for Learning and Classiﬁcation: A\\nReview\\nShawahna, A.; Sait, S.M.;\\nEl-Maleh, A. Ieee Access 0\\n76 WoS 77 2018 A quantum machine learning algorithm based\\non generative models Gao, X.; Zhang, Z.Y.; Duan, L.M. Science Advances 0\\n77 WoS 78 2018 Machine Learning for Network Automation:\\nOverview, Architecture, and Applications Raﬁque, D.; Velasco, L.\\nJournal of Optical\\nCommunications and\\nNetworking\\n0\\n78 WoS 79 2018\\nA wireless sensor data-based coal mine gas\\nmonitoring algorithm with least squares support\\nvector machines optimized by swarm\\nintelligence techniques\\nChen, P .; Xie, Y.; Jin, P .; Zhang, D.International Journal of\\nDistributed Sensor Networks 0'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 23, 'page_label': '24', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='vector machines optimized by swarm\\nintelligence techniques\\nChen, P .; Xie, Y.; Jin, P .; Zhang, D.International Journal of\\nDistributed Sensor Networks 0\\n79 WoS 80 2017 Nuclear energy system’s behavior and decision\\nmaking using machine learning\\nFernandez, M.G.; Tokuhiro, A.;\\nWelter, K.; Wu, Q.\\nNuclear Engineering and\\nDesign 0\\n80 WoS 81 2017\\nAutomated business process management—In\\ntimes of digital transformation using machine\\nlearning or artiﬁcial intelligence\\nPaschek, D.; Luminosu, C.T.;\\nDraghici, A.\\n8th International Conference\\non Manufacturing Science\\nand Education (Mse\\n2017)—Trends in New\\nIndustrial Revolution\\n0\\n81 WoS 82 2017\\nThe Evaluation of Resonance Frequency for\\nPiezoelectric Transducers by Machine Learning\\nMethods\\nChang, F.M.\\n27Th International\\nConference on Flexible\\nAutomation and Intelligent\\nManufacturing, Faim 2017\\n0\\n82 WoS 83 2017\\nFrom Extraction to Generation of Design\\nInformation Paradigm Shift in Data Mining via\\nEvolutionary Learning Classiﬁer System'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 23, 'page_label': '24', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Automation and Intelligent\\nManufacturing, Faim 2017\\n0\\n82 WoS 83 2017\\nFrom Extraction to Generation of Design\\nInformation Paradigm Shift in Data Mining via\\nEvolutionary Learning Classiﬁer System\\nChiba, K.; Nakata, M.\\nInternational Conference on\\nComputational Science (Iccs\\n2017)\\n0'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 24, 'page_label': '25', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Sustainability 2020, 12, 492 25 of 26\\nReferences\\n1. Gupta, N.A. Literature Survey on Artiﬁcial Intelligence. 2017. Available online: https: //www.ijert.org/\\nresearch/a-literature-survey-on-artiﬁcial-intelligence-IJERTCONV5IS19015.pdf (accessed on 7 January 2020).\\n2. McCarthy, J.; Minsky, M.L.; Rochester, N.; Shannon, C.E. A Proposal for the Dartmouth Summer Research\\nProject on Artiﬁcial Intelligence. AI Mag. 2006, 27, 12.\\n3. Moore, A. Carnegie Mellon Dean of Computer Science on the Future of AI. Available\\nonline: https://www.forbes.com/sites/peterhigh/2017/10/30/carnegie-mellon-dean-of-computer-science-on-\\nthe-future-of-ai /#3a283c652197 (accessed on 7 January 2020).\\n4. Becker, A.; Bar-Yehuda, R.; Geiger, D. Randomised algorithms for the loop cutset problem.J. Artif. Intell. Res.\\n2000, 12, 219–234. [CrossRef]\\n5. Singer, J.; Gent, I.P .; Smaill, A. Backbone fragility and the local search cost peak.J. Artif. Intell. Res. 2000,\\n12, 235–270. [CrossRef]'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 24, 'page_label': '25', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='2000, 12, 219–234. [CrossRef]\\n5. Singer, J.; Gent, I.P .; Smaill, A. Backbone fragility and the local search cost peak.J. Artif. Intell. Res. 2000,\\n12, 235–270. [CrossRef]\\n6. Chen, X.; Van Beek, P . Conﬂict-directed backjumping revisited.J. Artif. Intell. Res. 2001, 14, 53–81. [CrossRef]\\n7. Hong, J. Goal recognition through goal graph analysis. J. Artif. Intell. Res. 2001, 15, 1–30. [CrossRef]\\n8. Stone, P .; Littman, M.L.; Singh, S.; Kearns, M. ATTAC-2000: An adaptive autonomous bidding agent.J. Artif.\\nIntell. Res. 2000, 15, 189–206. [CrossRef]\\n9. Peng, Y.; Zhang, X. Integrative data mining in systems biology: from text to network mining.Artif. Intell. Med.\\n2007, 41, 83–86. [CrossRef]\\n10. Zhou, X.; Liu, B.; Wu, Z.; Feng, Y. Integrative mining of traditional Chines medicine literature and MEDLINE\\nfor functional gene networks. Artif. Intell. Med. 2007, 41, 87–104. [CrossRef]\\n11. Wang, S.; Wang, Y.; Du, W.; Sun, F.; Wang, X.; Zhou, C.; Liang, Y. A multi-approaches-guided genetic'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 24, 'page_label': '25', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='for functional gene networks. Artif. Intell. Med. 2007, 41, 87–104. [CrossRef]\\n11. Wang, S.; Wang, Y.; Du, W.; Sun, F.; Wang, X.; Zhou, C.; Liang, Y. A multi-approaches-guided genetic\\nalgorithm with application to operon prediction. Artif. Intell. Med. 2007, 41, 151–159. [CrossRef]\\n12. Halal, W.E. Artiﬁcial intelligence is almost here. Horizon 2003, 11, 37–38. Available online: https: //\\nwww.emerald.com/insight/content/doi/10.1108/10748120310486771/full/html (accessed on 7 January 2020).\\n[CrossRef]\\n13. Masnikosa, V .P . The fundamental problem of an artiﬁcial intelligence realization.Kybernetes 1998, 27, 71–80.\\n[CrossRef]\\n14. Metaxiotis, K.; Ergazakis, K.; Samouilidis, E.; Psarras, J. Decision support through knowledge management:\\nThe role of the artiﬁcial intelligence. Inf. Manag. Comput. Secur. 2003, 11, 216–221. [CrossRef]\\n15. Raynor, W.J. The international dictionary of artiﬁcial intelligence. Ref. Rev. 2000, 14, 1–380.'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 24, 'page_label': '25', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='The role of the artiﬁcial intelligence. Inf. Manag. Comput. Secur. 2003, 11, 216–221. [CrossRef]\\n15. Raynor, W.J. The international dictionary of artiﬁcial intelligence. Ref. Rev. 2000, 14, 1–380.\\n16. Stefanuk, V .L.; Zhozhikashvili, A.V . Productions and rules in artiﬁcial intelligence. Kybernetes 2002,\\n31, ty817–826. [CrossRef]\\n17. Tay, D.P .H.; Ho, D.K.H. Artiﬁcial intelligence and the mass appraisal of residential apartments. J. Prop.\\nValuat. Invest. 1992, 10, 525–540. [CrossRef]\\n18. Wongpinunwatana, N.; Ferguson, C.; Bowen, P . An experimental investigation of the eﬀects of artiﬁcial\\nintelligence systems on the training of novice auditors. Manag. Audit. J. 2000, 15, 306–318. [CrossRef]\\n19. Oke, S.A. A literature review on artiﬁcial intelligence. Int. J. Inf. Manag. Sci. 2008, 19, 535–570.\\n20. Carvalho, T.P .; Soares, F.A.A.M.N.; Vita, R.; da Francisco, P .R.; Basto, J.P .; Alcalá, S.G.S. A systematic literature'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 24, 'page_label': '25', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='20. Carvalho, T.P .; Soares, F.A.A.M.N.; Vita, R.; da Francisco, P .R.; Basto, J.P .; Alcalá, S.G.S. A systematic literature\\nreview of machine learning methods applied to predictive maintenance. Comput. Ind. Eng. 2019, 1, 1–12.\\n[CrossRef]\\n21. Majorel Deutschland GmbH Artiﬁcial Intelligence and Sustainability. Available online: https://www.future-\\ncustomer.com/artiﬁcial-intelligence-and-sustainability / (accessed on 8 January 2020).\\n22. Markham, I.S.; Mathieu, R.G.; Wray, B.A. Kanban setting through artiﬁcial intelligence: A comparative study\\nof artiﬁcial neural networks and decision trees. Integr. Manuf. Syst. 2000, 11, 239–246. [CrossRef]\\n23. Kotsiantis, S.B.; Zaharakis, I.; Pintelas, P . Supervised machine learning: A review of classiﬁcation techniques.\\nEmerg. Artif. Intell. Appl. Comput. Eng. 2007, 160, 3–24.\\n24. Cortes, C.; Vapnik, V . Support-vector networks. Mach. Learn. 1995, 20, 273–297. [CrossRef]'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 24, 'page_label': '25', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Emerg. Artif. Intell. Appl. Comput. Eng. 2007, 160, 3–24.\\n24. Cortes, C.; Vapnik, V . Support-vector networks. Mach. Learn. 1995, 20, 273–297. [CrossRef]\\n25. Kitchenham, B. Procedures for Performing Systematic Reviews. Technical Report TR/SE-0401. 2004. Available\\nonline: https://pdfs.semanticscholar.org/2989/0a936639862f45cb9a987dd599dce9759bf5.pdf?_ga=2.7241591.\\n47522378.1578382825-243572483.1578382825 (accessed on 7 January 2020).\\n26. Duan, Y.; Edwards, J.S.; Dwivedi, Y.K. Artiﬁcial intelligence for decision making in the era of Big\\nData—Evolution, challenges and research agenda. Int. J. Inf. Manag. 2019, 48, 63–71. [CrossRef]'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 25, 'page_label': '26', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Sustainability 2020, 12, 492 26 of 26\\n27. De Felice, F.; Petrillo, A.; Zomparelli, F. Prospective design of smart manufacturing: An Italian pilot case\\nstudy. Manuf. Lett. 2018, 15, 81–85. [CrossRef]\\n28. Larrañaga, P .; Calvo, B.; Santana, R.; Bielza, C.; Galdiano, J.; Inza, I.; Lozano, J.A.; Armañanzas, R.; Santafé, G.;\\nPérez, A.; et al. Machine Learning. in Bioinformatics. Brief. Bioinform. 2006, 7, 86–112. [CrossRef] [PubMed]\\n29. Krawczyk, B. Learning from imbalanced data: Open challenges and future directions. Prog. Artif. Intell.\\n2016, 5, 221–232. [CrossRef]\\n30. Wuest, T.; Weimer, D.; Irgens, C.; Thoben, K.D. Machine learning in manufacturing: Advantages, challenges,\\nand applications. Prod. Manuf. Res. 2016, 4, 23–45. [CrossRef]\\n31. Dutton, T. An Overview of National AI Strategies. Available online: http: //www.jaist.ac.jp/~{}bao/AI/\\nOtherAIstrategies/An%20Overview%20of%20National%20AI%20Strategies%20%E2%80%93%20Politics%'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 25, 'page_label': '26', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='31. Dutton, T. An Overview of National AI Strategies. Available online: http: //www.jaist.ac.jp/~{}bao/AI/\\nOtherAIstrategies/An%20Overview%20of%20National%20AI%20Strategies%20%E2%80%93%20Politics%\\n20+%20AI%20%E2%80%93%20Medium.pdf (accessed on 8 January 2020).\\n32. Pérez-Ortiz, M.; Jiménez-Fernández, S.; Gutiérrez, P .A.; Alexandre, E.; Hervás-Martínez, C.; Salcedo-Sanz, S.\\nA Review of Classiﬁcation Problems and Algorithms in Renewable Energy Applications. Energies 2016,\\n9, 607. [CrossRef]\\n33. Lieber, D.; Stolpe, M.; Konrad, B.; Deuse, J.; Morik, K. Quality prediction in interlinked manufacturing\\nprocesses based on supervised & unsupervised machine learning. Procedia CIRP 2013, 7, 193–198.\\n34. Sachs, J.D.; Schmidt-Traub, G.; Mazzucato, M.; Messner, D.; Nakicenovic, N.; Rockström, J.\\nSix Transformations to Achieve the Sustainable Development Goals. Nat. Sustain. 2019, 2, 805–814.\\n[CrossRef]\\n© 2020 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 25, 'page_label': '26', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Six Transformations to Achieve the Sustainable Development Goals. Nat. Sustain. 2019, 2, 805–814.\\n[CrossRef]\\n© 2020 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access\\narticle distributed under the terms and conditions of the Creative Commons Attribution\\n(CC BY) license (http://creativecommons.org/licenses/by/4.0/).'),\n",
       " Document(metadata={'producer': 'Skia/PDF m144 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'dsa', 'source': '../data/pdf_files/dsa.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'dsa.pdf', 'file_type': 'pdf'}, page_content='Time  complexity  measures  how  the  performance  of  an  algorithm  changes  with  input  size  (n).  Big-O  notation  \\nexpresses\\n \\nthe\\n \\nworst-case\\n \\ncomplexity.\\n \\nFor\\n \\nexample,\\n \\nO(1)\\n \\nmeans\\n \\nconstant\\n \\ntime;\\n \\nO(n)\\n \\nmeans\\n \\nlinear\\n \\ntime;\\n \\nO(n²)\\n \\nrepresents\\n \\nquadratic\\n \\ntime;\\n \\nO(log\\n \\nn)\\n \\nis\\n \\nlogarithmic;\\n \\nand\\n \\nO(n\\n \\nlog\\n \\nn)\\n \\nrepresents\\n \\nefficient\\n \\ndivide-and-conquer\\n \\nalgorithms\\n \\nlike\\n \\nmerge\\n \\nsort.\\n \\nSearching  algorithms  determine  how  to  locate  a  specific  value  in  a  dataset.  The  simplest  is  linear  search  \\n(O(n))\\n,\\n \\nwhich\\n \\nchecks\\n \\neach\\n \\nelement\\n \\nsequentially.\\n \\nIt\\n \\nworks\\n \\non\\n \\nunsorted\\n \\ndata\\n \\nbut\\n \\nis\\n \\nslow\\n \\nfor\\n \\nlarge\\n \\ninputs.\\n \\nBinary\\n \\nsearch\\n \\n(O(log\\n \\nn))\\n \\nworks\\n \\non\\n \\nsorted\\n \\narrays\\n \\nby\\n \\nrepeatedly\\n \\ndividing\\n \\nthe\\n \\nsearch\\n \\nspace\\n \\nin\\n \\nhalf,\\n \\ndramatically\\n \\nimproving\\n \\nefficiency.\\n \\nSorting  algorithms  arrange  elements  in  ascending  or  descending  order:'),\n",
       " Document(metadata={'producer': 'Skia/PDF m144 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'dsa', 'source': '../data/pdf_files/dsa.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'dsa.pdf', 'file_type': 'pdf'}, page_content='arrays\\n \\nby\\n \\nrepeatedly\\n \\ndividing\\n \\nthe\\n \\nsearch\\n \\nspace\\n \\nin\\n \\nhalf,\\n \\ndramatically\\n \\nimproving\\n \\nefficiency.\\n \\nSorting  algorithms  arrange  elements  in  ascending  or  descending  order:  \\n●  Bubble  Sort:  Repeatedly  swaps  adjacent  elements—simple  but  slow  (O(n²)).  \\n ●  Selection  Sort:  Selects  the  smallest  element  in  each  iteration—also  O(n²).  \\n ●  Insertion  Sort:  Efficient  for  small  or  nearly  sorted  arrays  (O(n²)  worst  case).  \\n ●  Merge  Sort:  A  divide-and-conquer  algorithm  that  splits,  sorts,  and  merges;  stable  and  fast  with  O(n  log  \\nn)\\n \\ntime.\\n \\n ●  Quick  Sort:  Uses  a  pivot  to  partition  the  array;  average  O(n  log  n)  but  worst  O(n²).  One  of  the  fastest  \\npractical\\n \\nalgorithms.\\n \\n ●  Heap  Sort:  Builds  a  heap  and  extracts  the  maximum/minimum  repeatedly;  guarantees  O(n  log  n).  \\n \\nUnderstanding  time  complexity  helps  you  choose  the  right  algorithm  for  large-scale  problems.  Sorting  and'),\n",
       " Document(metadata={'producer': 'Skia/PDF m144 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'dsa', 'source': '../data/pdf_files/dsa.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'dsa.pdf', 'file_type': 'pdf'}, page_content='Understanding  time  complexity  helps  you  choose  the  right  algorithm  for  large-scale  problems.  Sorting  and  \\nsearching\\n \\nform\\n \\nthe\\n \\nfoundation\\n \\nof\\n \\nmost\\n \\nreal-world\\n \\napplications,\\n \\nfrom\\n \\ndatabases\\n \\nto\\n \\ncompetitive\\n \\nprogramming.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m139', 'creator': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/139.0.0.0 Safari/537.36', 'creationdate': '2025-08-30T19:12:18+00:00', 'title': 'shreya_sharma_resume.docx - Google Docs', 'moddate': '2025-08-30T19:12:18+00:00', 'source': '../data/pdf_files/Shreya_Sharma_Resume.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'Shreya_Sharma_Resume.pdf', 'file_type': 'pdf'}, page_content='SHREYA SHARMA \\n B.Tech (Computer Science and Engineering \\n with Specialization in Cyber Security) \\n Email:  shreya.sharma110404@gmail.com  |  Phone:  9770766139 \\n LinkedIn:  https://www.linkedin.com/in/shreya-sharma1104/ \\n GitHub:  https://github.com/shreyasharma-1 \\n ACADEMICS \\n Qualification  Institute  Board / University  % / CGPA  Year \\n B.Tech (CY - 6th sem) \\n XII \\n Lakshmi Narain College of \\n Technology & Science \\n Maharishi Vidya Mandir, Jabalpur \\n RGPV \\n CBSE \\n 8.34/10 \\n 73% \\n 2026 \\n 2022 \\n X  Maharishi Vidya Mandir, Jabalpur  CBSE  70.8%  2020 \\n Certifications \\n /Publications \\n ●  Comprehensive Study Of MD5 and SHA-256 \\n ●  Introduction to Cybersecurity offered through Cisco Networking Academy \\n ●  The Complete Python Developer Certification Course offered by Udemy \\n ●  Database Management System Part - 1 offered by Infosys Springboard \\n ●  Python (Basic) offered by Hacker-Rank \\n 2024 \\n 2024 \\n 2024 \\n 2024 \\n 2023'),\n",
       " Document(metadata={'producer': 'Skia/PDF m139', 'creator': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/139.0.0.0 Safari/537.36', 'creationdate': '2025-08-30T19:12:18+00:00', 'title': 'shreya_sharma_resume.docx - Google Docs', 'moddate': '2025-08-30T19:12:18+00:00', 'source': '../data/pdf_files/Shreya_Sharma_Resume.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'Shreya_Sharma_Resume.pdf', 'file_type': 'pdf'}, page_content='●  Database Management System Part - 1 offered by Infosys Springboard \\n ●  Python (Basic) offered by Hacker-Rank \\n 2024 \\n 2024 \\n 2024 \\n 2024 \\n 2023 \\n Achievements  ●  Best  Paper  Award  (2nd  Position)  for  the  \"Comprehensive  Study  of  MD5  and  SHA-256\" \\n Research Paper at ICEHAIDS.  2024 \\n PROJECTS \\n Multi-Agent \\n Telegram Bot \\n ●  Tech Stack – Python, FastAPI, MongoDB, OpenAI Whisper, Google Nearby Search API \\n ●  Developed a Multi-Agent Telegram Bot with intelligent query routing for dynamic decision-making \\n ●  Integrated  real-time  services  including  weather  updates,  stock  price  retrieval,  news  aggregation, \\n image generation, meme creation, and voice-to-text interaction using OpenAI Whisper. \\n ●  Implemented  location-based  features  with  Google  Nearby  Search  API  and  ensured  scalable \\n architecture with secure chat history storage in MongoDB.. \\n Face Tracer - \\n Intelligent Presence \\n Detection'),\n",
       " Document(metadata={'producer': 'Skia/PDF m139', 'creator': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/139.0.0.0 Safari/537.36', 'creationdate': '2025-08-30T19:12:18+00:00', 'title': 'shreya_sharma_resume.docx - Google Docs', 'moddate': '2025-08-30T19:12:18+00:00', 'source': '../data/pdf_files/Shreya_Sharma_Resume.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'Shreya_Sharma_Resume.pdf', 'file_type': 'pdf'}, page_content='architecture with secure chat history storage in MongoDB.. \\n Face Tracer - \\n Intelligent Presence \\n Detection \\n ●  Tech Stack  – Python, OpenCV, face_recognition, Flask, HTML/CSS, SQLite, NumPy, Pandas \\n ●  Developed  a  real-time  attendance  management  web  application  using  facial  recognition.  Integrated \\n webcam-based face detection with automatic attendance logging and CSV/SQLite storage. \\n ●  Built  a  responsive  frontend  using  Flask  and  HTML  with  options  for  registration,  training,  and \\n viewing attendance logs. \\n House Price \\n Prediction – Data \\n analysis \\n ●  Tech Stack  - Python, Pandas, Numpy, Matplotlib, Seaborn \\n ●  House  Price  Prediction  uses  machine  learning  techniques  to  predict  housing  prices,  showcasing \\n analytical and problem-solving skills. \\n Iris Flower \\n classification \\n ●  Tech Stack -  Python, Pandas, Numpy, Matplotlib, Seaborn, filter warnings'),\n",
       " Document(metadata={'producer': 'Skia/PDF m139', 'creator': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/139.0.0.0 Safari/537.36', 'creationdate': '2025-08-30T19:12:18+00:00', 'title': 'shreya_sharma_resume.docx - Google Docs', 'moddate': '2025-08-30T19:12:18+00:00', 'source': '../data/pdf_files/Shreya_Sharma_Resume.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'Shreya_Sharma_Resume.pdf', 'file_type': 'pdf'}, page_content='analytical and problem-solving skills. \\n Iris Flower \\n classification \\n ●  Tech Stack -  Python, Pandas, Numpy, Matplotlib, Seaborn, filter warnings \\n ●  Iris  Flower  Classification  using  Applied  linear  regression  for  accurate  classification  of  Iris  flowers, \\n demonstrating a solid understanding of statistical modeling \\n √√√ \\n SKILLS \\n Programming  Java, Python, Pandas, Numpy, Matplotlib, Machine Learning (Beginner) \\n Databases  SQL \\n Analytics  Power BI, Matplotlib, Seaborn \\n Tools  Jupyter Notebook, Cursor, VS Code, Canva, MS Word, MS Excel, MS PowerPoint \\n Soft Skills  Leadership, Communication, Problem Solving, Analytical Skills, Learning Agility \\n POSITIONS OF RESPONSIBILITY \\n LNCTS BHOPAL \\n ●  Volunteer  at  the  International  Conference  on  Expanding  Horizons  in  Artificial \\n Intelligence & Data Science \\n ●  Research Paper Presenter at ICEHAIDS \\n MVM, Jabalpur  ●  Vice Captain, Assembly Committee \\n ●  Member, Hygiene Committee'),\n",
       " Document(metadata={'producer': 'Skia/PDF m139', 'creator': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/139.0.0.0 Safari/537.36', 'creationdate': '2025-08-30T19:12:18+00:00', 'title': 'shreya_sharma_resume.docx - Google Docs', 'moddate': '2025-08-30T19:12:18+00:00', 'source': '../data/pdf_files/Shreya_Sharma_Resume.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'Shreya_Sharma_Resume.pdf', 'file_type': 'pdf'}, page_content='Intelligence & Data Science \\n ●  Research Paper Presenter at ICEHAIDS \\n MVM, Jabalpur  ●  Vice Captain, Assembly Committee \\n ●  Member, Hygiene Committee \\n CO-CURRICULAR & EXTRACURRICULAR ACTIVITIES \\n Lakshmi Narain College of Technology & Science | BATCH OF 2026 \\n Technical  ●  Chairperson (Innovation Vertical), Young Indians CII-YUVA \\n ●  Competitive Programming – LeetCode, Hacker-Rank'),\n",
       " Document(metadata={'producer': 'Skia/PDF m139', 'creator': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/139.0.0.0 Safari/537.36', 'creationdate': '2025-08-30T18:04:57+00:00', 'title': '\".:: Rajiv Gandhi Proudyogiki Vishwavidyalaya, Bhopal ::.\"', 'moddate': '2025-08-30T18:04:57+00:00', 'source': '../data/pdf_files/Shreya_Sharma_Transcript.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'Shreya_Sharma_Transcript.pdf', 'file_type': 'pdf'}, page_content='Rajiv Gandhi Proudyogiki\\nVishwavidyalaya, Bhopal\\nStatement of Marks - June-2025\\nName SHREYA SHARMA Roll No. 0157CY221129\\nCourse B.Tech Branch CY\\nSemester 6 Status Regular\\nSubject Total Credit Earned Credit Grade\\nCY601- [T] 3 3 A\\nCY602- [T] 3 3 B+\\nCY603- [T] 4 4 A+\\nCY604- [T] 4 4 A\\nCY601- [P] 1 1 A+\\nCY602- [P] 1 1 A+\\nCY605- [P] 3 3 A+\\nCY606- [P] 3 3 A+\\nCY608- [P] 2 2 A+\\nResult Des. SGPA CGPA\\nPASS 9.46 8.34\\nRevaluation Date Revaluation Date with\\nLate Fee\\n12/08/2025 14/08/2025\\nData Source : Rajiv Gandhi Proudyogiki Vishwavidyalaya, Bhopal\\nDisclaimer : The data belongs to RGPV,Bhopal. For any communication related to the\\npublished data, please contact examination cell of RGPV or respective College.\\nPrint Marksheet\\n30/08/2025, 23:34 \".:: Rajiv Gandhi Proudyogiki Vishwavidyalaya, Bhopal ::.\"\\nabout:blank 1/1'),\n",
       " Document(metadata={'producer': 'Skia/PDF m144 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'dbms', 'source': '../data/pdf_files/dbms.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'dbms.pdf', 'file_type': 'pdf'}, page_content='Database  Management  Systems  (DBMS)  provide  structured  storage,  retrieval,  and  management  of  data.  One  \\nessential\\n \\nconcept\\n \\nin\\n \\nrelational\\n \\ndatabases\\n \\nis\\n \\nnormalization\\n,\\n \\nwhich\\n \\naims\\n \\nto\\n \\nreduce\\n \\nredundancy\\n \\nand\\n \\nensure\\n \\ndata\\n \\nintegrity.\\n \\nNormalization\\n \\ninvolves\\n \\ndecomposing\\n \\ntables\\n \\ninto\\n \\nwell-structured\\n \\nforms\\n \\ncalled\\n \\nnormal\\n \\nforms\\n.\\n \\n1NF  (First  Normal  Form)  requires  that  table  cells  contain  atomic  values  and  that  each  record  is  unique.  2NF  \\nremoves\\n \\npartial\\n \\ndependency,\\n \\nmeaning\\n \\nno\\n \\nnon-key\\n \\nattribute\\n \\nshould\\n \\ndepend\\n \\non\\n \\nonly\\n \\npart\\n \\nof\\n \\na\\n \\ncomposite\\n \\nprimary\\n \\nkey.\\n \\n3NF\\n \\nremoves\\n \\ntransitive\\n \\ndependency,\\n \\nensuring\\n \\nnon-key\\n \\nattributes\\n \\ndepend\\n \\nonly\\n \\non\\n \\nprimary\\n \\nkeys.\\n \\nProper\\n \\nnormalization\\n \\nprevents\\n \\nanomalies\\n \\nsuch\\n \\nas\\n \\nupdate,\\n \\ninsertion,\\n \\nand\\n \\ndeletion\\n \\nanomalies.\\n \\nIn  DBMS,  relationships  between  tables  are  established  through  joins :'),\n",
       " Document(metadata={'producer': 'Skia/PDF m144 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'dbms', 'source': '../data/pdf_files/dbms.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'dbms.pdf', 'file_type': 'pdf'}, page_content='Proper\\n \\nnormalization\\n \\nprevents\\n \\nanomalies\\n \\nsuch\\n \\nas\\n \\nupdate,\\n \\ninsertion,\\n \\nand\\n \\ndeletion\\n \\nanomalies.\\n \\nIn  DBMS,  relationships  between  tables  are  established  through  joins :  \\n●  INNER  JOIN:  Returns  only  matching  rows  from  both  tables.  \\n ●  LEFT  JOIN:  Returns  all  rows  from  the  left  table  and  matching  rows  from  the  right.  \\n ●  RIGHT  JOIN:  Opposite  of  left  join.  \\n ●  FULL  OUTER  JOIN:  Returns  all  rows  when  there  is  a  match  in  either  table.  \\n ●  CROSS  JOIN:  Produces  a  Cartesian  product.  \\n \\nJoins  enable  relational  databases  to  maintain  normalized  structures  while  still  retrieving  meaningful  combined  \\ndata.\\n \\nAnother  key  concept  is  transactions ,  which  represent  a  sequence  of  operations  performed  as  a  single  logical  \\nunit\\n \\nof\\n \\nwork.\\n \\nTransactions\\n \\nmust\\n \\nsatisfy\\n \\nthe\\n \\nACID\\n \\nproperties\\n:\\n \\n●  Atomicity:  All  steps  succeed  or  none.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m144 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'dbms', 'source': '../data/pdf_files/dbms.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'dbms.pdf', 'file_type': 'pdf'}, page_content='unit\\n \\nof\\n \\nwork.\\n \\nTransactions\\n \\nmust\\n \\nsatisfy\\n \\nthe\\n \\nACID\\n \\nproperties\\n:\\n \\n●  Atomicity:  All  steps  succeed  or  none.  \\n ●  Consistency:  The  database  must  remain  valid  before  and  after  the  transaction.  \\n ●  Isolation:  Concurrent  transactions  must  not  interfere  with  each  other.  \\n ●  Durability:  Changes  persist  even  if  the  system  crashes.  \\n \\nDatabase  systems  use  locking,  logging,  checkpoints,  and  isolation  levels  to  ensure  transaction  safety.  \\nUnderstanding\\n \\nnormalization,\\n \\njoins,\\n \\nand\\n \\ntransactions\\n \\nis\\n \\ncritical\\n \\nbecause\\n \\nthese\\n \\nconcepts\\n \\nform\\n \\nthe\\n \\nbackbone\\n \\nof\\n \\nrelational\\n \\ndata\\n \\nhandling.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m144 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'ml', 'source': '../data/pdf_files/ml.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'ml.pdf', 'file_type': 'pdf'}, page_content='Machine  Learning  (ML)  is  a  subfield  of  Artificial  Intelligence  that  enables  systems  to  learn  patterns  from  data  \\nand\\n \\nimprove\\n \\nover\\n \\ntime\\n \\nwithout\\n \\nexplicit\\n \\nprogramming.\\n \\nML\\n \\nfocuses\\n \\non\\n \\nbuilding\\n \\nmodels\\n \\nthat\\n \\ncan\\n \\nanalyze\\n \\ndata,\\n \\nmake\\n \\npredictions,\\n \\nclassify\\n \\noutcomes,\\n \\nand\\n \\nfind\\n \\nhidden\\n \\nstructures.\\n \\nIt\\n \\nhas\\n \\nrevolutionized\\n \\nmultiple\\n \\nindustries\\n \\nthrough\\n \\nautomation\\n \\nand\\n \\nintelligent\\n \\ndecision-making.\\n \\nML  is  broadly  divided  into  three  major  types:  \\n1.  Supervised  Learning  \\nModels  learn  using  labeled  data—each  input  has  a  correct  output.  Algorithms  try  to  generalize  these  \\nrelationships\\n \\nto\\n \\npredict\\n \\noutcomes\\n \\non\\n \\nnew\\n \\ndata.\\n \\n \\nCommon\\n \\nalgorithms\\n \\ninclude\\n \\nLinear\\n \\nRegression,\\n \\nLogistic\\n \\nRegression,\\n \\nDecision\\n \\nTrees,\\n \\nRandom\\n \\nForests,\\n \\nand\\n \\nSupport\\n \\nVector\\n \\nMachines.\\n \\n \\nApplications:\\n \\nSpam\\n \\ndetection,\\n \\ncredit\\n \\nscoring,\\n \\nmedical\\n \\ndiagnosis,\\n \\nstock\\n \\nprice\\n \\nprediction.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m144 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'ml', 'source': '../data/pdf_files/ml.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'ml.pdf', 'file_type': 'pdf'}, page_content='Decision\\n \\nTrees,\\n \\nRandom\\n \\nForests,\\n \\nand\\n \\nSupport\\n \\nVector\\n \\nMachines.\\n \\n \\nApplications:\\n \\nSpam\\n \\ndetection,\\n \\ncredit\\n \\nscoring,\\n \\nmedical\\n \\ndiagnosis,\\n \\nstock\\n \\nprice\\n \\nprediction.\\n \\n2.  Unsupervised  Learning  \\nUsed  when  data  has  no  labels.  The  model  identifies  hidden  patterns,  clusters,  or  structures.  \\n \\nPopular\\n \\nmethods\\n \\ninclude\\n \\nK-means\\n \\nclustering,\\n \\nPCA,\\n \\nand\\n \\nApriori\\n \\nfor\\n \\nassociation\\n \\nmining.\\n \\n \\nApplications:\\n \\nCustomer\\n \\nsegmentation,\\n \\nanomaly\\n \\ndetection,\\n \\ndimensionality\\n \\nreduction.\\n \\n3.  Reinforcement  Learning  \\nThe  model  interacts  with  an  environment  and  learns  from  rewards  and  penalties .  It  is  used  in  robotics,  \\ngaming\\n \\n(e.g.,\\n \\nAlphaGo),\\n \\nautonomous\\n \\nvehicles,\\n \\nand\\n \\nresource\\n \\noptimization.\\n \\nOther  important  ML  concepts  include:  \\n●  Feature  Engineering:  Selecting  important  variables  to  improve  model  accuracy.  \\n ●  Model  Evaluation:  Using  metrics  like  accuracy,  precision,  recall,  F1-score.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m144 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'ml', 'source': '../data/pdf_files/ml.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'ml.pdf', 'file_type': 'pdf'}, page_content='●  Feature  Engineering:  Selecting  important  variables  to  improve  model  accuracy.  \\n ●  Model  Evaluation:  Using  metrics  like  accuracy,  precision,  recall,  F1-score.  \\n ●  Overfitting  &  Underfitting:  Overfitting  happens  when  the  model  memorizes  training  data;  underfitting  \\noccurs\\n \\nwhen\\n \\nit\\n \\nfails\\n \\nto\\n \\nlearn\\n \\nenough\\n \\npatterns.\\n \\n ●  Training  vs  Testing:  Models  are  trained  on  historical  data  and  tested  on  unseen  data  to  validate  \\nperformance.\\n \\n \\nML  applications  are  everywhere—image  recognition,  natural  language  processing,  fraud  detection,  \\nrecommendation\\n \\nsystems,\\n \\nautonomous\\n \\ndriving,\\n \\nand\\n \\nhealthcare\\n \\nanalytics.\\n \\nAs\\n \\ndata\\n \\ngrows,\\n \\nmachine\\n \\nlearning\\n \\ncontinues\\n \\nto\\n \\nshape\\n \\nhow\\n \\nmodern\\n \\nsystems\\n \\nmake\\n \\nintelligent\\n \\ndecisions.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m144 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'os', 'source': '../data/pdf_files/os.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'os.pdf', 'file_type': 'pdf'}, page_content='An  Operating  System  (OS)  is  responsible  for  managing  hardware,  providing  an  environment  for  applications,  \\nand\\n \\nensuring\\n \\nefficient\\n \\nutilization\\n \\nof\\n \\nsystem\\n \\nresources.\\n \\nTwo\\n \\nof\\n \\nthe\\n \\nmost\\n \\nfundamental\\n \\nconcepts\\n \\nin\\n \\nOS\\n \\nare\\n \\nprocesses\\n \\nand\\n \\nthreads\\n.\\n \\nA\\n \\nprocess\\n \\nis\\n \\nan\\n \\nindependent\\n \\nprogram\\n \\nin\\n \\nexecution.\\n \\nIt\\n \\nhas\\n \\nits\\n \\nown\\n \\nmemory\\n \\nspace\\n \\n(code,\\n \\ndata,\\n \\nstack,\\n \\nheap)\\n \\nand\\n \\nis\\n \\nrepresented\\n \\nin\\n \\nthe\\n \\nsystem\\n \\nby\\n \\na\\n \\nProcess\\n \\nControl\\n \\nBlock\\n \\n(PCB).\\n \\nEvery\\n \\nprocess\\n \\noperates\\n \\nin\\n \\nisolation,\\n \\nwhich\\n \\nensures\\n \\nstability\\n \\nbut\\n \\nalso\\n \\nincreases\\n \\noverhead\\n \\nbecause\\n \\nswitching\\n \\nbetween\\n \\nprocesses\\n \\nis\\n \\nexpensive—each\\n \\ncontext\\n \\nswitch\\n \\nrequires\\n \\nsaving\\n \\nand\\n \\nloading\\n \\na\\n \\nseparate\\n \\nmemory\\n \\nspace.\\n \\nA  thread ,  on  the  other  hand,  is  a  smaller  execution  unit  inside  a  process.  Multiple  threads  within  the  same  \\nprocess\\n \\nshare\\n \\nmemory\\n \\nsuch\\n \\nas\\n \\nglobal\\n \\nvariables\\n \\nand\\n \\nheap,\\n \\nbut\\n \\neach'),\n",
       " Document(metadata={'producer': 'Skia/PDF m144 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'os', 'source': '../data/pdf_files/os.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'os.pdf', 'file_type': 'pdf'}, page_content='process\\n \\nshare\\n \\nmemory\\n \\nsuch\\n \\nas\\n \\nglobal\\n \\nvariables\\n \\nand\\n \\nheap,\\n \\nbut\\n \\neach\\n \\nthread\\n \\nhas\\n \\nits\\n \\nown\\n \\nstack\\n \\nand\\n \\nprogram\\n \\ncounter.\\n \\nThis\\n \\nshared\\n \\nmemory\\n \\nmakes\\n \\nthreads\\n \\nlightweight\\n \\nand\\n \\nsuitable\\n \\nfor\\n \\nparallelism\\n \\nwithin\\n \\nthe\\n \\nsame\\n \\napplication.\\n \\nFor\\n \\nexample,\\n \\na\\n \\nbrowser\\n \\nmay\\n \\nhave\\n \\nseparate\\n \\nthreads\\n \\nfor\\n \\nrendering,\\n \\ndownloading,\\n \\nand\\n \\nhandling\\n \\nuser\\n \\ninteractions.\\n \\nOS  uses  CPU  scheduling  to  determine  which  process  or  thread  gets  processor  time.  Scheduling  becomes  \\nnecessary\\n \\nbecause\\n \\nthe\\n \\nCPU\\n \\ncan\\n \\nexecute\\n \\nonly\\n \\none\\n \\ninstruction\\n \\nflow\\n \\nat\\n \\na\\n \\ntime\\n \\n(ignoring\\n \\nmulti-core\\n \\nscenarios).\\n \\nThe\\n \\ngoal\\n \\nis\\n \\nto\\n \\nmaximize\\n \\nCPU\\n \\nutilization,\\n \\nthroughput,\\n \\nand\\n \\nresponsiveness.\\n \\nCommon  scheduling  algorithms  include:  \\n1.  First-Come,  First-Served  (FCFS):  \\n \\nThe\\n \\nsimplest\\n \\nalgorithm\\n \\nwhere\\n \\nthe\\n \\nfirst\\n \\nprocess\\n \\nto\\n \\narrive\\n \\nis\\n \\nthe\\n \\nfirst\\n \\nto\\n \\nexecute.\\n \\nIt\\n \\nsuffers\\n \\nfrom\\n \\nthe\\n \\n\"convoy'),\n",
       " Document(metadata={'producer': 'Skia/PDF m144 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'os', 'source': '../data/pdf_files/os.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'os.pdf', 'file_type': 'pdf'}, page_content='1.  First-Come,  First-Served  (FCFS):  \\n \\nThe\\n \\nsimplest\\n \\nalgorithm\\n \\nwhere\\n \\nthe\\n \\nfirst\\n \\nprocess\\n \\nto\\n \\narrive\\n \\nis\\n \\nthe\\n \\nfirst\\n \\nto\\n \\nexecute.\\n \\nIt\\n \\nsuffers\\n \\nfrom\\n \\nthe\\n \\n\"convoy\\n \\neffect,\"\\n \\nwhere\\n \\na\\n \\nlong\\n \\njob\\n \\ndelays\\n \\nall\\n \\nothers.\\n \\n 2.  Shortest  Job  First  (SJF):  \\n \\nPrioritizes\\n \\nprocesses\\n \\nwith\\n \\nthe\\n \\nsmallest\\n \\nexecution\\n \\ntime.\\n \\nIt\\n \\nreduces\\n \\nwaiting\\n \\ntime\\n \\nbut\\n \\nrequires\\n \\npredicting\\n \\nprocess\\n \\nburst\\n \\ntime.\\n \\n 3.  Round  Robin  (RR):  \\n \\nEach\\n \\nprocess\\n \\ngets\\n \\na\\n \\nfixed\\n \\ntime\\n \\nslice\\n \\n(quantum).\\n \\nIt\\n \\nis\\n \\nideal\\n \\nfor\\n \\ntime-sharing\\n \\nsystems\\n \\nbecause\\n \\nno\\n \\nprocess\\n \\ncan\\n \\nmonopolize\\n \\nthe\\n \\nCPU.\\n \\n 4.  Priority  Scheduling:  \\n \\nEach\\n \\nprocess\\n \\nis\\n \\nassigned\\n \\na\\n \\npriority.\\n \\nThe\\n \\nCPU\\n \\nselects\\n \\nthe\\n \\nhighest-priority\\n \\nprocess.\\n \\nIt\\n \\nmay\\n \\nlead\\n \\nto\\n \\nstarvation\\n \\nif\\n \\nlow-priority\\n \\nprocesses\\n \\nnever\\n \\nexecute.\\n \\n 5.  Multilevel  Queue  Scheduling:  \\n \\nProcesses\\n \\nare\\n \\ndivided\\n \\ninto\\n \\nmultiple\\n \\nqueues\\n \\n(e.g.,\\n \\nsystem,\\n \\ninteractive,'),\n",
       " Document(metadata={'producer': 'Skia/PDF m144 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'os', 'source': '../data/pdf_files/os.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'os.pdf', 'file_type': 'pdf'}, page_content='to\\n \\nstarvation\\n \\nif\\n \\nlow-priority\\n \\nprocesses\\n \\nnever\\n \\nexecute.\\n \\n 5.  Multilevel  Queue  Scheduling:  \\n \\nProcesses\\n \\nare\\n \\ndivided\\n \\ninto\\n \\nmultiple\\n \\nqueues\\n \\n(e.g.,\\n \\nsystem,\\n \\ninteractive,\\n \\nbatch),\\n \\neach\\n \\nwith\\n \\ndifferent\\n \\nscheduling\\n \\nrules.\\n \\n \\nUnderstanding  processes,  threads,  and  scheduling  is  crucial  because  they  determine  how  efficiently  an  \\napplication\\n \\nand\\n \\nsystem\\n \\nperform.\\n \\nMulti-threading\\n \\nimproves\\n \\nconcurrency,\\n \\nwhile\\n \\neffective\\n \\nscheduling\\n \\nensures\\n \\nfairness\\n \\nand\\n \\nmaximizes\\n \\nCPU\\n \\nusage.'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 0, 'page_label': '1', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='Natural Language Processing: State of The Art, Current Trends and \\nChallenges \\nDiksha Khurana1, Aditya Koli1, Kiran Khatter1,2\\n and Sukhdev Singh1,2\\n \\n1Department of Computer Science and Engineering \\nManav Rachna International University, Faridabad-121004, India \\n2Accendere Knowledge Management Services Pvt. Ltd., India \\n \\nAbstract  \\nNatural language processing  (NLP) has recently gained much attention for representing and \\nanalysing human language computational ly. It has spread its applications in various field s \\nsuch as machine translation, email spam detection, information extraction, summarization, \\nmedical, and question answering etc. The paper distinguishes four phases by discussing \\ndifferent levels of NLP and components of Natural Language Generation (NLG) followed by \\npresenting the history and evolution of NLP , state of the art presenting the various \\napplications of NLP and current trends and challenges.  \\n \\n1. Introduction'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 0, 'page_label': '1', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='presenting the history and evolution of NLP , state of the art presenting the various \\napplications of NLP and current trends and challenges.  \\n \\n1. Introduction \\nNatural Language Processing (NLP) is a  tract of Artificial Intelligence and Linguistics, \\ndevoted to make computers understand the statements or words written in human languages. \\nNatural language processing came into existence to ease  the user’s work and to satisfy the \\nwish to communicate with the computer  in natural language. Since all the user s may not be \\nwell-versed in machine specific language , NLP caters those users  who do not have enough \\ntime to learn new languages or get perfection in it.  \\nA language can be defined as  a set of rules or set of symbol.  Symbol are combined and used \\nfor conveying information or broadcasting t he information.  Symbols are tyrannized by the \\nRules. Natural Language P rocessing basically can be classified in to two parts i.e. Natural'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 0, 'page_label': '1', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='for conveying information or broadcasting t he information.  Symbols are tyrannized by the \\nRules. Natural Language P rocessing basically can be classified in to two parts i.e. Natural \\nLanguage Understanding and Natural Language G eneration which evolves the task to \\nunderstand and generate the text (Figure 1).'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 1, 'page_label': '2', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='Figure 1. Broad Classification of NLP \\nLinguistics is the science of language which includes Phonology that refers to sound, \\nMorphology word formation, Syntax sentence structure, Semantics syntax and Pragmatics \\nwhich refers to understanding. \\nNoah Chomsky, one of the first linguists of twelfth century that started syntactic theories, \\nmarked a unique position in the field of theoretical linguistics because he revolutionise d the \\narea of syntax (Chomsky, 1965) [1]. Which can be broadly categorized into two levels Higher \\nLevel which include speech recognition and Lower L evel which corresponds to natural \\nlanguage. Few of t he researched tasks of NLP are Automatic S ummarization, Co-Reference \\nResolution, Discourse Analysis, Machine Translation, Morphological Segmentation, Named \\nEntity Recognition, Optical Character R ecognition, Part Of S peech Tagging etc. Some of \\nthese tasks have direct real world applications  such as Machine translation, N amed entity'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 1, 'page_label': '2', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='Entity Recognition, Optical Character R ecognition, Part Of S peech Tagging etc. Some of \\nthese tasks have direct real world applications  such as Machine translation, N amed entity \\nrecognition, Optical character recognition etc. Automatic summarization produces an \\nunderstandable summary of a set of text  and provides summaries or detailed information of \\ntext of a known typ e. Co-reference resolution it refers to a sentence or larger set of text that \\ndetermines which word refer to the same object. Discourse analysis  refers to the task of \\nidentifying the discourse struc ture of connected text. Machine translation which refers to \\nautomatic translation of text from one human language to another . Morphological \\nsegmentation which refers to separate word into individual morphemes and identify the class \\nof the morphemes. Named entity recognition (NER) it describes a stream of text, determine'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 1, 'page_label': '2', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='segmentation which refers to separate word into individual morphemes and identify the class \\nof the morphemes. Named entity recognition (NER) it describes a stream of text, determine \\nwhich items in the text relates to proper names. Optical character recognition (OCR) it gives \\nan image representing print ed text, which  help in determining the corresponding or related \\ntext. Part of speech tagging  it describes a sentence, determines the part of speech for each \\nword. Though NLP tasks are obviously very closely interweaved  but they are used \\nfrequently, for convenience. Some of the task such as automatic summarisation, co-reference \\nanalysis etc. act as subtask that are used in solving larger tasks.'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 2, 'page_label': '3', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='The goal of Natural Language Processing is to accommodate one or more specialities of an \\nalgorithm or system.  The metric of NLP assess on an algorithmic system allows for the \\nintegration of  language understanding  and language generation.  It is even used in \\nmultilingual event detection Rospocher et al. [2] purposed a novel modular system for cross -\\nlingual event extraction for English,  Dutch and Italian texts by using different pipelines for \\ndifferent languages. The system incorporates a modular set of foremost multilingual Natural \\nLanguage Processing (NLP) tools. The pipeline integrates modules for basic NLP processing \\nas well as more advanced tasks such as cro ss-lingual named entity linking,  semantic role \\nlabelling and time normalization. Thus, the cross-lingual framework allows for the \\ninterpretation of events, participants, locations and time, as well as the relations between'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 2, 'page_label': '3', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='labelling and time normalization. Thus, the cross-lingual framework allows for the \\ninterpretation of events, participants, locations and time, as well as the relations between \\nthem. Output of these individual pipelines is intended to be used as input for a system that \\nobtains event centric knowledge grap hs. All modules behave like UNIX pipes: they all take \\nstandard input, to do some annotation, and produce standard output which in turn is the input \\nfor the next module pipelines are built as a data centric architecture so that modu les can be \\nadapted and replaced . Furthermore, modular architecture allows for different configurations \\nand for dynamic distribution. \\nMost of the work in Natural Language Processing is conducted by computer scientists while \\nvarious other professionals have also shown interest such as linguistics, psychologist and \\nphilosophers etc. One of the most ironical aspect of NLP is that it adds up  to the knowledge'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 2, 'page_label': '3', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='various other professionals have also shown interest such as linguistics, psychologist and \\nphilosophers etc. One of the most ironical aspect of NLP is that it adds up  to the knowledge \\nof human language.  The field of Natural Language Processing is related with different \\ntheories and techniques  that deal with the problem of natural language of communicating \\nwith the computers . Ambiguity is one of the ma jor problem of nat ural language which is \\nusually faced in syntactic level which has subtask as lexical and morphology which are \\nconcerned with the study of words and word formation. Each of these levels can produce \\nambiguities that can be solved by the knowledge of the comp lete sentence.  The ambiguity \\ncan be solved by various methods such as  Minimising Ambiguity, Preserving Ambiguity, \\nInteractive Disambiguity and Weighting Ambiguity [3].  Some of the methods proposed by \\nresearchers to remove ambiguity is  preserving ambiguity,  e.g. (Shemtov 1997 ; Emele &'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 2, 'page_label': '3', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='Interactive Disambiguity and Weighting Ambiguity [3].  Some of the methods proposed by \\nresearchers to remove ambiguity is  preserving ambiguity,  e.g. (Shemtov 1997 ; Emele & \\nDorna 1998; Knight & Langkilde 2000) [3][4][5] Their objectives are closely in line with the \\nlast of these: they cover a wide range of ambiguities and there is a statistical element implicit \\nin their approach.  \\n2. Levels of NLP \\nThe ‘levels of language’ are one of the most explanatory method for representing the Natural \\nLanguage processing  which helps to generate the NLP text by realising Content Planning, \\nSentence Planning and Surface Realization phases (Figure 2).'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 3, 'page_label': '4', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='Figure 2. Phases of NLP architecture \\nLinguistic is the science which involves meaning of language, language context and various \\nforms of the language. The various important terminologies of Natural Language Processing \\nare: - \\n1. Phonology \\nPhonology is the part of Linguistics which refers to the systematic arrangement of sound. The \\nterm phonology  comes from  Ancient Greek  and the term phono - which me ans voice or \\nsound, and the suffix –logy refers to word or speech. In 1993 Nikolai Trubetzkoy stated that \\nPhonology is “the study of sound pertaining to the system of la nguage\". Whereas Lass in \\n1998 wrote that phonology refers broadly with the sounds of language, concerned with the to \\nlathe sub discipline of linguistics , whereas it could be explained as , \"phonology proper is \\nconcerned with the function, behaviour and orga nization of sounds as  linguistic items. \\nPhonology include semantic use of sound to encode meaning of any Human language.  \\n(Clark et al.,2007) [6].'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 3, 'page_label': '4', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='concerned with the function, behaviour and orga nization of sounds as  linguistic items. \\nPhonology include semantic use of sound to encode meaning of any Human language.  \\n(Clark et al.,2007) [6]. \\n2. Morphology \\nThe different parts of the word represent the smallest units of meaning known as Morphemes. \\nMorphology which comprise of Nature of words, are initiated by morphemes. An example of \\nMorpheme could be, the word pre cancellation can be morphologically scrutinized into three \\nseparate morphemes: the prefix pre, the root cancella, and the suf fix -tion. The interpretation \\nof morpheme stays same across all the words, just to understand the meaning humans can \\nbreak any unknown word into morphemes.  For example, adding the suffix –ed to a verb, \\nconveys that the action of the verb took place in the past. The words that cannot be divided \\nand have meaning by themselves are called Lexical morpheme (e.g.: table, chair) The words'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 3, 'page_label': '4', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='conveys that the action of the verb took place in the past. The words that cannot be divided \\nand have meaning by themselves are called Lexical morpheme (e.g.: table, chair) The words \\n(e.g. -ed, -ing, -est, -ly, -ful) that are combined with the lexical morpheme  are known as \\nGrammatical morphemes  (eg. Worked, C onsulting, Smallest , Likely, Use ). Those \\ngrammatical morphemes that occurs in combi nation called bound morphemes ( eg. -ed, -ing) \\nGrammatical morphemes can be divided into bound morphemes and derivational morphemes.'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 4, 'page_label': '5', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='3. Lexical \\nIn Lexical,  humans, as well a s NLP systems, interpret the meaning of individual words.  \\nSundry types of processing bestow to word-level understanding – the first of these being a \\npart-of-speech tag to each word. In this processing, words that can act as more than one part-\\nof-speech are assigned the most probable part -of speech tag based on th e context in which \\nthey occur. At the lexical level,  Semantic representations can be replaced by the words that \\nhave one meaning . In NLP system , the nature of the  representation varies according to the \\nsemantic theory deployed. \\n4. Syntactic \\nThis level emphasis to scrutinize the words in a sentence so as to uncover the grammatical \\nstructure of the sentence. Both grammar and parser  are required in this level . The output  of \\nthis level of processing is representation of the sentence that divulge the structural \\ndependency relationships between the words. There are various grammars that can be'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 4, 'page_label': '5', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='this level of processing is representation of the sentence that divulge the structural \\ndependency relationships between the words. There are various grammars that can be \\nimpeded, and which in twirl, whack the option of a parser. Not all NLP applications require a \\nfull parse of sentences, therefore the abide challenges in parsing of prepositional phrase \\nattachment and conjunction audit no longer impede that plea for which phrasal and clausal \\ndependencies are adequate [7]. Syntax conveys meaning in most languages because order and \\ndependency contribute to connotation. For example, the two sentences: ‘The cat chased the \\nmouse.’ and ‘The mouse chased the cat.’ differ only in terms of syntax, yet convey quite \\ndifferent meanings. \\n5. Semantic \\nIn semantic most people think that meaning is determined, however,  this is not  it is all the \\nlevels that bestow to meaning. Semantic processing determines the possible meanings of a'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 4, 'page_label': '5', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='5. Semantic \\nIn semantic most people think that meaning is determined, however,  this is not  it is all the \\nlevels that bestow to meaning. Semantic processing determines the possible meanings of a \\nsentence by pivoting on the interactions among word -level meanings in the sentence. Th is \\nlevel of processing can incorporate  the semantic disambiguation of wo rds with multiple \\nsenses; in a cognate way to how syntactic disambiguation of words that can errand as \\nmultiple parts -of-speech is adroit at the syntactic level.  For example, amongst o ther \\nmeanings, ‘file’ as a noun can mean either a binder for gathering papers, or a tool to form \\none’s fingernails, or a  line of individuals in a queue ( Elizabeth D. Liddy ,2001) [7]. The \\nsemantic level scrutinizes words for their dictionary elucidation, but also for the elucidation \\nthey derive from the milieu of the sentence. Semantics milieu that most words have more'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 4, 'page_label': '5', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='semantic level scrutinizes words for their dictionary elucidation, but also for the elucidation \\nthey derive from the milieu of the sentence. Semantics milieu that most words have more \\nthan one elucidation but that we can spot the appropriate one by looking at the rest of the \\nsentence. [8] \\n6. Discourse \\nWhile syntax and semantic s travail with sentence -length units, the discourse level of NLP \\ntravail with units of text longer than a sentence i.e, it does not interpret multi sentence texts as \\njust sequence sentences, apiece of which can be elucidated singly. Rather, discourse focuses \\non the properties of the text as a whole that convey meaning by making connections between \\ncomponent sentences (Elizabeth D. Liddy,2001) [7]. The two of the most common levels are  \\nAnaphora Resolution  - Anaphora resolution  is the replacing of words such as pronouns, \\nwhich are semantically stranded, with the pertinent entity to which they refer. Discourse/Text'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 4, 'page_label': '5', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='Anaphora Resolution  - Anaphora resolution  is the replacing of words such as pronouns, \\nwhich are semantically stranded, with the pertinent entity to which they refer. Discourse/Text \\nStructure Recognition - Discourse/text structure recognition sway the functions of sentences \\nin the text, which, in turn, adds to the meaningful representation of the text. \\n7. Pragmatic:'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 5, 'page_label': '6', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='Pragmatic is concerned with the firm use of language in situations and utilizes nub over and \\nabove the nub of the text for understanding the goal and to explain how extra meaning is read \\ninto texts without literally being encoded in them. This requisite much world knowledge, \\nincluding the understanding of intenti ons, plans, and goals . For example, the following two \\nsentences need aspiration of the anaphoric term ‘they’, but this aspiration requires pragmatic \\nor world knowledge (Elizabeth D. Liddy,2001) [7]. \\n3. Natural Language Generation \\nNatural Language Generation (NLG) is the process of producing phrases, sentences and \\nparagraphs that are meaningful from an internal representation. It is a part of Natural \\nLanguage Processing  and happens in four phases: identifying the goals, planning on how \\ngoals maybe achieved by evaluating the situation and available communicative sources and \\nrealizing the plans as a text [Figure 3]. It is opposite to Understanding.'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 5, 'page_label': '6', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='goals maybe achieved by evaluating the situation and available communicative sources and \\nrealizing the plans as a text [Figure 3]. It is opposite to Understanding. \\n \\n                                      Figure 3. Components of NLG \\nComponents of NLG are as follows: \\nSpeaker and Generator  – To generate a text we need to have a speaker or an application \\nand a generator or a program  that renders the applicatio n’s intentions into fluent phrase \\nrelevant to the situation.  \\nComponents and Levels of Representation  -The process of language generation involves \\nthe following interweaved tasks. Content selection:  Information should be selected and \\nincluded in the set. D epending on how this information is parsed into representational units, \\nparts of the units may have to be removed while some  others may be added by default. \\nTextual Organization: The information must be textually organized according the grammar, it'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 5, 'page_label': '6', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='parts of the units may have to be removed while some  others may be added by default. \\nTextual Organization: The information must be textually organized according the grammar, it \\nmust be  ordered both sequentially and in terms of linguist ic relations like modifications. \\nLinguistic Resources: To support the information’s realization, linguistic resources must be'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 6, 'page_label': '7', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='chosen. In the end these resources will come down to choices of particular words, idioms, \\nsyntactic constructs etc.  Realization: The selected and organized resources must be realized \\nas an actual text or voice output.  \\nApplication or Speaker –  This is only for maintaining the model of the situation. Here the \\nspeaker just initiat es the process doesn’t take part in the language generation. It stores the \\nhistory, structures the content that is potentially relevant and deploys a representation of what \\nit actually knows. All these form the situation, while selecting subset of proposit ions that \\nspeaker has. The only requirement is the speaker has to make sense of the situation. [9]  \\n4. History of NLP \\nIn late 1940s the term wasn’t even in existence, but the work regarding machine translation \\n(MT) had started. Research in this period was not  completely localised. Russian and English \\nwere the dominant languages for MT , but others, like Chinese  were used for MT  (Booth'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 6, 'page_label': '7', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='(MT) had started. Research in this period was not  completely localised. Russian and English \\nwere the dominant languages for MT , but others, like Chinese  were used for MT  (Booth \\n,1967) [10]. MT/NLP research was almost died in 1966 according to ALPAC report, which \\nconcluded that MT is going nowhere. But later on some MT production systems were \\nproviding output to their customers (Hutchins, 1986)  [11]. By this time, work on the use of \\ncomputers for literary and linguistic studies had also started.  \\nAs early as 1960 signature work influenced by AI began, wi th the BASEBALL Q-A systems \\n(Green et al., 1961) [12]. LUNAR (Woods ,1978) [13] and Winograd SHRDLU were natural \\nsuccessors of these systems but they were seen as stepped up sophistication, in terms of their \\nlinguistic and their task processing capabilitie s. There was a widespread belief that progress \\ncould only be made on the two sides, one is ARPA Speech Understanding Research (SUR)'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 6, 'page_label': '7', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='linguistic and their task processing capabilitie s. There was a widespread belief that progress \\ncould only be made on the two sides, one is ARPA Speech Understanding Research (SUR) \\nproject (Lea, 1980) and other in some major system developments projects building database \\nfront ends . The front-end projects (Hendrix et al., 1978)  [14] were intended to go beyond \\nLUNAR in interfacing the large databases. \\nIn early 1980s computational grammar theory became a very active area of research linked \\nwith logics for meaning and knowledge’s ability to deal with the user’s beliefs and intentions \\nand with functions like emphasis and themes. \\nBy the end of the decade the powerful general purpose sentence processors like SRI’s Core \\nLanguage Engine (Alshawi,1992)  [15] and Discourse Representation Theory (Kamp and \\nReyle,1993) [16] offered a means of tackling more extended discourse within the \\ngrammatico-logical framework. This period was one of the growing community. Practical'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 6, 'page_label': '7', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='Reyle,1993) [16] offered a means of tackling more extended discourse within the \\ngrammatico-logical framework. This period was one of the growing community. Practical \\nresources, grammars, and tools and parsers became available (e.g the Alvey Natural \\nLanguage Tools (Briscoe et al., 1987)  [17]. The (D)ARPA speech recognition and message \\nunderstanding (information extraction ) conferences were not only for the tasks they \\naddressed but for the emphasis on heavy evaluation, starting a trend that became a major \\nfeature in 1990s (Young and Chase, 1998; Sundheim and Chinchor ,1993) [18][19]. Work on \\nuser modelling (Kobsa and Wahlster , 1989)  [20]  was one strand in research paper and on \\ndiscourse structure serving this (Cohen et al., 1990)   [21]. At the same time , as McKeown  \\n(1985) [22] showed, rhetorical schemas could be used for producing both linguistically \\ncoherent and communicatively effective text. Some researches in NLP marked important'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 6, 'page_label': '7', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='(1985) [22] showed, rhetorical schemas could be used for producing both linguistically \\ncoherent and communicatively effective text. Some researches in NLP marked important \\ntopics for future like word sense disambiguation (Small et al., 1988)  [23] and probabilistic \\nnetworks, statistically coloured NLP, the work on the lexicon, also pointed in this direction.'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 7, 'page_label': '8', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='Statistical language processing was a major thing in 9 0s (Manning and Schuetze,1999)  [24], \\nbecause this not only involves data analysts. Information extraction and automatic \\nsummarising (Mani and Maybury ,1999) [25] was also a point of focus. \\nRecent researches are mainly focused on unsupervised and semi -supervised learning \\nalgorithms. \\n5. Related Work \\nMany researchers worked on NLP , building tools and systems which makes NLP what it is \\ntoday. Tools like Sentiment Analyser , Parts of Speech (POS)Taggers, Chunking, Named \\nEntity Recognitions (NER), Emotion detection , Semantic Role Labelling made NLP a good \\ntopic for research.  \\nSentiment analyser (Jeonghee etal.,2003)  [26] works by extracting sentiments about given \\ntopic. Sentiment analysis consists of a topic specific feature term extraction, sentiment \\nextraction, and association by relationship analysis. Sentiment Analysis utilizes two linguistic'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 7, 'page_label': '8', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='topic. Sentiment analysis consists of a topic specific feature term extraction, sentiment \\nextraction, and association by relationship analysis. Sentiment Analysis utilizes two linguistic \\nresources for the analysis: the sentiment lexicon and the sentiment pattern database. It \\nanalyses the documents for positive and negative words and try to give ratings on scale -5 to \\n+5. \\nParts of speech taggers for the languages like European languages, research is being done on \\nmaking parts of speech taggers for other languages like Arabic, Sanskrit (Namrata Tapswi , \\nSuresh Jain ., 2012) [27], Hindi (Pradipta Ranjan Ray et al., 2003 ) [28] etc. It can efficiently \\ntag and classify words as nouns, adjectives, verbs etc. The most procedures for part of speech \\ncan work efficiently on European languages, but it won’t on Asian languages or middle \\neastern languages. Sanskrit part of speech tagger is specifically uses treebank technique.'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 7, 'page_label': '8', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='can work efficiently on European languages, but it won’t on Asian languages or middle \\neastern languages. Sanskrit part of speech tagger is specifically uses treebank technique. \\nArabic uses Support Vector Machine (SVM)  (Mona Diab etal., 2004) [29] approach to \\nautomatically tokenize, parts of speech tag and annotate base phrases in Arabic text. \\n \\nChunking – it is also known as Shadow Parsing, it works by labelling segments of sentences \\nwith syntactic correlated keywords like Noun Phrase and Verb Phrase (NP or VP). Every \\nword has a unique tag often marked as Begin Chunk (B -NP) tag or Inside Chunk (I -NP) tag. \\nChunking is often evaluated using the CoNLL 2000 shared task.   CoNLL 2000 provides test \\ndata for Chunking.  Since then, a certain numb er of systems arised (Sha and Pereira, 2003; \\nMcDonald et al., 2005; Sun et al., 2008)  [30] [31] [32], all reporting around 94.3% F1 score. \\nThese systems use features composed of words, POS tags, and tags.'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 7, 'page_label': '8', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='McDonald et al., 2005; Sun et al., 2008)  [30] [31] [32], all reporting around 94.3% F1 score. \\nThese systems use features composed of words, POS tags, and tags. \\n \\nUsage of Named Entity Recognition in places such as Internet is a problem as people don’t \\nuse traditional or standard  English. This degrades the performance of standard natural \\nlanguage processing tools substantially. By annotating the phrases or tweets and building \\ntools trained on unlabelled, in domain and out domain data (Alan Ritter., 2011)  [33]. It \\nimproves the performance as compared to standard natural language processing tools. \\n \\nEmotion Detection (Shashank Sharma , 2016) [34] is similar to sentiment analysis, but it \\nworks on social media platforms on mixing of two languages (English + Any other Indian \\nLanguage). It categorizes statements into six groups based on emotions. During this process, \\nthey were able to identify the language of ambiguous words which were common in Hindi'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 7, 'page_label': '8', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='Language). It categorizes statements into six groups based on emotions. During this process, \\nthey were able to identify the language of ambiguous words which were common in Hindi \\nand English and tag lexical category or parts of speech in mixed script by identifying the base \\nlanguage of the speaker.'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 8, 'page_label': '9', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='Sematic Role Labelling – SRL works by giving a semantic role to a sentence. For example in \\nthe PropBank (Palmer et al., 2005)  [35] formalism, one assigns roles to words that are \\narguments of a verb in the sentence. The precise arguments depend on verb frame and if there \\nexists multiple verbs  in a sentence, it might have multiple tags. State-of-the-art SRL systems \\ncomprise of several stages: creating a parse tree, identifying which parse tree nodes represent \\nthe arg uments of a given verb, and finally classifying these nodes to comp ute the \\ncorresponding SRL tags. \\n \\nEvent discovery in social media feeds (Edward Benson et al., 2011) [36], using a graphical \\nmodel to analyse any social media feeds to determine whether it contains name of a person or \\nname of a venue, place, time etc. The model operates on noisy feeds of data to extract records \\nof events by aggregating multiple information ac ross multiple messages, despite the noise of'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 8, 'page_label': '9', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='name of a venue, place, time etc. The model operates on noisy feeds of data to extract records \\nof events by aggregating multiple information ac ross multiple messages, despite the noise of \\nirrelevant noisy messages and very irregular message language, this model was able to extract \\nrecords with high accuracy. However, there is some scope for improvement using broader \\narray of features on factors. \\n \\n6. Applications of NLP \\nNatural Language Processing can be applied into various areas like Machine Translation, \\nEmail Spam detection, Information Extraction, Summarization, Question Answering etc. \\n6.1 Machine Translation  \\nAs most of the world is online, the task of making data accessible and available to all is a \\nchallenge. Major challenge in making data accessible is the language barrier. There are \\nmultitude of languages with different sentence structure and grammar. Machine Translation is \\ngenerally translating phrases from one language to another with the help of a statistical'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 8, 'page_label': '9', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='multitude of languages with different sentence structure and grammar. Machine Translation is \\ngenerally translating phrases from one language to another with the help of a statistical \\nengine like Google Translate. The challenge with machine translation technologies is not \\ndirectly translating words but keeping the meaning of sente nces intact along with grammar \\nand tenses. The statistical machine learning gathers as many data as they can find that seems \\nto be parallel between two languages and they crunch their data to find the likelihood that \\nsomething in Language A corresponds to something in Language B. As for Google, in \\nSeptember 2016, announced a new machine translation system based on Artificial neural \\nnetworks and Deep learning . In recent years, various methods have been proposed to \\nautomatically evaluate machine translation quality by comparing hypothesis translations with \\nreference translations. Examples of such methods are word error rate, position -independent'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 8, 'page_label': '9', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='automatically evaluate machine translation quality by comparing hypothesis translations with \\nreference translations. Examples of such methods are word error rate, position -independent \\nword error rate (Tillmann et al., 1997)  [37], generation string accuracy (Bangalore et al., \\n2000) [38], multi-reference word error rate (Nießen et al., 2000)  [39], BLEU score (Papineni \\net al., 2002) [40], NIST score (Doddington, 2002)  [41]  All these criteria try to approximate \\nhuman assessment and often achieve an astonishing degree of correlation to human subjective \\nevaluation of fluency and adequacy (Papineni et al., 2001; Doddington, 2002) [42][43].  \\n6.2 Text Categorization  \\nCategorization systems inputs a large flow of data like official documents, military casualty \\nreports, market data, newswires etc. and assign them to predefined categories or indices. For \\nexample, The Carnegie Group’s Construe system (Hayes PJ ,Westein ; 1991) [44] , inputs'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 8, 'page_label': '9', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='reports, market data, newswires etc. and assign them to predefined categories or indices. For \\nexample, The Carnegie Group’s Construe system (Hayes PJ ,Westein ; 1991) [44] , inputs \\nReuters articles and saves much time by doing the work that is to be done by staff or human'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 9, 'page_label': '10', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='indexers. Some companies have been us ing categorization systems to categorize trouble \\ntickets or complaint requests and routing to the appropriate desks. Another application of text \\ncategorization is email spam filters. Spam filters is becoming important as the first line of \\ndefence against the unwanted emails. A false negative and false positive issues of spam filters \\nare at the heart of NLP technology, its brought down to the challenge of extracting meaning \\nfrom strings of text. A filtering solution that is applied to an email system uses a set of \\nprotocols to determine which of the incoming messages are spam and which are not. There \\nare several types of spam filters available. Content filters : Review the content within the \\nmessage to determine whether it is a spam or not . Header filters: Review the email header \\nlooking for fake information. General Blacklist filters : Stopes all emails from blacklisted'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 9, 'page_label': '10', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='message to determine whether it is a spam or not . Header filters: Review the email header \\nlooking for fake information. General Blacklist filters : Stopes all emails from blacklisted \\nrecipients. Rules Based Filters : It uses user -defined criteria. Such as stopping mails from \\nspecific person or stopping mail including a specific word. Permission Filters : Require \\nanyone sending a message to be pre -approved by the recipient. Challenge Response Filters : \\nRequires anyone sending a message to enter a code in order to gain permission to send email. \\n6.3 Spam Filtering  \\nIt works using text categorization  and in recent times, various machine learning techniques \\nhave been applied to text categorization or Anti -Spam Filtering  like Ru le Learning (Cohen \\n1996)[45], Naïve Bayes (Sahami et al., 1998 ;Androutsopoulos et al.,2000b ;Rennie \\n.,2000)[46][47][48],Memory based Learning (Androutsopoulos et al.,2000b) [47], Support'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 9, 'page_label': '10', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='1996)[45], Naïve Bayes (Sahami et al., 1998 ;Androutsopoulos et al.,2000b ;Rennie \\n.,2000)[46][47][48],Memory based Learning (Androutsopoulos et al.,2000b) [47], Support \\nvector machines (Druker et al., 1999)[49], Decision Trees (Carreras and Marquez , 2001)[50] \\nMaximum Entropy Model (Berger et al. 1996) [51]. Sometimes combining different learners \\n(Sakkis et al., 2001)  [52]. Using these approaches is better as classifier is learned from \\ntraining data rather than making by hand. The naïve bay es is preferred because of its \\nperformance despite its simplicity (Lewis, 1998)  [53] In Text Categorization two types of \\nmodels have been used (McCallum and Nigam, 1998) [54]. Both modules assume that a fixed \\nvocabulary is present. But in first model a document is generated by first choosing a subset of \\nvocabulary and then using the selected words any number of times, at least once irrespective \\nof order. This is called Multi -variate Bernoulli model. It takes the information of which'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 9, 'page_label': '10', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='vocabulary and then using the selected words any number of times, at least once irrespective \\nof order. This is called Multi -variate Bernoulli model. It takes the information of which \\nwords are used in a d ocument irrespective of number of words and order. In second model, a \\ndocument is generated by choosing a set of word occurrences and arranging them in any \\norder. this model is called multi -nomial model, in addition to the Multi -variate Bernoulli \\nmodel, it also captures information on how many times a word is used in a document. Most \\ntext categorization approaches to anti spam Email filtering have used multi variate Bernoulli \\nmodel (Androutsopoulos et al.,2000b) [47] \\n6.4 Information Extraction \\nInformation extraction is concerned with identifying phrases of interest of text ual data. For \\nmany applications, extracting entities such as names, places, events, dates, times and prices is'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 9, 'page_label': '10', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='Information extraction is concerned with identifying phrases of interest of text ual data. For \\nmany applications, extracting entities such as names, places, events, dates, times and prices is \\na powerful way of summarize the information relevant to a user’s needs. In the cas e of a \\ndomain specific search engine, the automatic identification of important information can \\nincrease accuracy and efficiency of a directed search.  There is use of hidden Markov models \\n(HMMs) to extract the relevant fields of research papers. These extr acted text segments are'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 10, 'page_label': '11', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='used to allow searched over specific fields and to provide effective presentation of search \\nresults and to match references to papers.  For example, noticing the pop up ads on any \\nwebsites showing the recent items you might have look ed on an online store with discounts. \\nIn Information Retrieval two types of models have been used (McCallum and Nigam, 1998)  \\n[55]. Both modules assume that a fixed vocabulary is present. But in first model a document \\nis generated by first choosing a subset  of vocabulary and then using the selected words any \\nnumber of times, at least once without any order. This is called Multi -variate Bernoulli \\nmodel. It takes the information of which words are used in a document irrespective of number \\nof words and order. I n second model, a document is generated by choosing a set of word \\noccurrences and arranging them in any order. this mod el is called multi -nomial model , in'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 10, 'page_label': '11', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='of words and order. I n second model, a document is generated by choosing a set of word \\noccurrences and arranging them in any order. this mod el is called multi -nomial model , in \\naddition to the Multi -variate Bernoulli model , it also captures information on how many \\ntimes a word is used in a document \\nDiscovery of knowledge  is becoming important areas of research over the recent years. \\nKnowledge discovery  research use a variety of techniques in order to extract useful \\ninformation from source documents like  \\nParts of Speech (POS) tagging, Chunking or Shadow Parsing , Stop-words (Keywords that \\nare used and must be remo ved before processing documents) , Stemming (Mapping words to \\nsome base for, it has two methods , dictionary based stemming and Porter style stemming \\n(Porter, 1980) [55]. Former one has higher accuracy but higher cost of implementation while \\nlatter has lower implementation cost and is usually insufficient for IR). Compound or'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 10, 'page_label': '11', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='(Porter, 1980) [55]. Former one has higher accuracy but higher cost of implementation while \\nlatter has lower implementation cost and is usually insufficient for IR). Compound or \\nStatistical Phrases  (Compounds and statistical phrases index multi  token unit s instead of \\nsingle tokens.) Word Sense Disambiguation  (Word sense disambiguati on is the task of \\nunderstanding the correct sense of a word in context. When used for information retrieval, \\nterms are replaced by their senses in the document vector.) \\n \\nIts extracted information c an be applied on a variety  of purpose , for example to prepare a \\nsummary, to build databases, identify keywords, classifying text items according to some pre-\\ndefined categories etc. For example   CONSTRUE, it was developed for Reuters , that is used \\nin classifying news stories  (Hayes, 1992) [57]. It has been suggested that many IE systems \\ncan successfully extract terms from documents, acquiring relations between the terms is still a'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 10, 'page_label': '11', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='in classifying news stories  (Hayes, 1992) [57]. It has been suggested that many IE systems \\ncan successfully extract terms from documents, acquiring relations between the terms is still a \\ndifficulty. PROMETHEE  is a system that extracts lexico -syntactic patterns relative to a \\nspecific conceptual relation (Morin,1999) [58]. IE systems should work at many levels, from \\nword recognition to discourse analysis at the level of the complete document. An application \\nof the Blank Slate Language Processor (BSLP) (Bondale et al., 1999) [59] approach for the \\nanalysis of a real life natural language corpus that consists of responses to open -ended \\nquestionnaires in the field of advertising. \\nThere’s a system called MITA (Metlife’ s Intelligent Text Analyzer)  (Glasgow et al. (1998)  \\n[60]) that extracts information from  life insurance applications. Ahonen et al. (1998)  [61] \\nsuggested a mainstream framework for text mining that uses pragmatic and di scourse level \\nanalyses of text.'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 10, 'page_label': '11', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='suggested a mainstream framework for text mining that uses pragmatic and di scourse level \\nanalyses of text. \\n6.5 Summarization \\nOverload of information is the real thing in this digital age, and already our reach and access \\nto knowledge and information exceeds our capacity to understand it. This trend is not slowing \\ndown, so an ability to summarize the data while keeping the meanin g intact is highly'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 11, 'page_label': '12', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='required. This is important not just allowing us the ability to recognize the understand the \\nimportant information for a large set of data, it is used to understand the deeper emotional \\nmeanings; For example, a company determine the gene ral sentiment on social media and use \\nit on their latest product offering. This application is useful as a valuable marketing asset. \\nThe types of text summarization depends on the basis of the number of documents  and  the \\ntwo important categories are single document summarization and multi document \\nsummarization (Zajic et al. 2008  [62]; Fattah and Ren 2009  [63]). Summaries can also be of \\ntwo types: generic or query-focused (Gong and Liu 2001 [64]; Dunlavy et al. 2007 [65]; Wan \\n2008 [66]; Ouyang et al. 2011  [67]). Summarization task can be either supervised or \\nunsupervised (Mani and Maybury 1999  [68]; Fattah and Ren 2009  [63]; Riedhammer et al. \\n2010 [69]). Training data is required in a supervised system for selecting relevant material'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 11, 'page_label': '12', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='unsupervised (Mani and Maybury 1999  [68]; Fattah and Ren 2009  [63]; Riedhammer et al. \\n2010 [69]). Training data is required in a supervised system for selecting relevant material \\nfrom the documents. Larg e amount of annotated data is needed for learning techniques. Few \\ntechniques are as follows– \\n- Bayesian Sentence based Topic Model (BSTM)  uses both term-sentences and term \\ndocument associations for summarizing multip le documents. ( Wang et al. 2009  \\n[70])   \\n- Factorization with Given Bases  (FGB) is a language model where  sentence bases \\nare the given bases and it utilizes document -term and sentence term matrices. \\nThis approach groups and summarizes the documents simultaneously. (Wang et \\nal. 2011) [71]) \\n- Topic Aspect -Oriented Summarization  (TAOS) is based on topic factors. These \\ntopic factors are various features that describe topics such as capital words are \\nused to represent entity. Various topics can have various  aspects and various'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 11, 'page_label': '12', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='topic factors are various features that describe topics such as capital words are \\nused to represent entity. Various topics can have various  aspects and various \\npreferences of features are used to represent various aspects. (Fang et al. 2015 [72]) \\n \\n6.6 Dialogue System \\nPerhaps the most desirable application of the future, in the systems envisioned by large \\nproviders of end user applications, Dialogue systems, which focuses on a narrowly defined \\napplications (like refrigerator or home theater systems) currently uses the phonetic and lexical \\nlevels of language. It is believed that these dialogue systems when utilizing all levels of \\nlanguage processing offer potential for fully automated dialog systems. (Elizabeth D. Liddy, \\n2001) [7]. Whether on text or via voice. This could  lead to produce systems that can enable \\nrobots to interact with humans in natural languages. Examples like Google’s assistant,'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 11, 'page_label': '12', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='2001) [7]. Whether on text or via voice. This could  lead to produce systems that can enable \\nrobots to interact with humans in natural languages. Examples like Google’s assistant, \\nWindows Cortana, Apple’s Siri and Amazon’s Alexa are the software and devices that follow \\nDialogue systems. \\n6.7 Medicine \\nNLP is appl ied in medicine field as well. The Linguistic String Project -Medical Language \\nProcessor is one the large scale projects of NLP in the field of medicine [74][75][76][77][78]. \\nThe LSP-MLP helps enabling physicians to extract and summarize information of any signs \\nor symptoms, drug dosage and response data with aim of identifying possible side effects of \\nany medicine while highlig hting or flagging data items [74 ]. The National Library of \\nMedicine is developing The Specialist System [79][80][81][82][83]. It is expected to function \\nas Information Extraction tool for Biomedical Knowledge Bases, particularly Medline'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 12, 'page_label': '13', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='abstracts. The lexicon was created using MeSH  (Medical Subject Headings), Dorland’s \\nIllustrated Medical Dictionary and general English Dictionaries. Th e Centre d’Informatique \\nHospitaliere of the Hopital Cantonal de Geneve is working on an electronic archiving \\nenvironment with NLP features [8 4][85]. In first phase , patient records were archived . At \\nlater stage the LSP-MLP has been adapted for French [86][87][88][89] , and finally , a proper \\nNLP syste m called RECIT  [90 ][91][92][93] has been developed using a method called \\nProximity Processing [ 94]. It’s task was to implement a robust and multilingual system able \\nto analyze/comprehend medical sentences, an d to preserve a knowledge of free text into a \\nlanguage independent knowledge representation [ 95][96]. The Columbia university of New \\nYork has developed an NLP system called MEDLEE (MEDical Language Extraction and \\nEncoding System) that identifies clinical i nformation in narrative reports and transforms the'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 12, 'page_label': '13', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='York has developed an NLP system called MEDLEE (MEDical Language Extraction and \\nEncoding System) that identifies clinical i nformation in narrative reports and transforms the \\ntextual information into structured representation [97]. \\n7. Approaches \\nRationalist approach or symbolic approach assume that crucial part of the knowledge in the \\nhuman mind is not derived by the sense but is firm in advance, probably by genetic in \\nheritance. Noam Chomsky was the strongest advocate of this approach. It was trusted that \\nmachine can be  made to function like human brain by giving some fundamental knowledge \\nand reasoning mechanism linguistics  knowledge is directly encoded in rule or other forms of \\nrepresentation. This helps automatic process of natural languages. [ 98] Statistical and \\nmachine learning entail evolution of algorithms that allow a program to infer patterns. An \\niterative process is use d to characterize a given algorithm’s underlying algorithm that are'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 12, 'page_label': '13', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='machine learning entail evolution of algorithms that allow a program to infer patterns. An \\niterative process is use d to characterize a given algorithm’s underlying algorithm that are \\noptimised by a numerical measure that characterize numerical pa rameters and learning phase. \\nMachine-learning models can be predominantly categorized as either generative or \\ndiscriminative. Generative methods can generate synthetic data because of which they create \\nrich models of probability distributions. Discriminative methods are more functional and \\nhave right estimating posterior probabilities and are based on observations.  \\nSrihari [99] explains the different generative models as one with a resemblance that is used to \\nspot an unknown speaker’s language and would bid the deep knowledge of numerous \\nlanguage to perform the match. Whereas discriminative methods rely on a less knowledge -\\nintensive approach and using distinction between language.  Whereas generative models, can'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 12, 'page_label': '13', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='language to perform the match. Whereas discriminative methods rely on a less knowledge -\\nintensive approach and using distinction between language.  Whereas generative models, can \\nbecome troublesome when many features are used and discriminative models allow use of \\nmore features. [ 100] Few of the examples of discriminative methods are Logistic regr ession \\nand conditional random fields (CRFs), generative methods are Naive Bayes classifiers and \\nhidden Markov models (HMMs). \\n7.1 Hidden Markov Model (HMM) \\nAn HMM is a system where a shifting takes place between several states, generating feasible \\noutput symbols with each switch. The sets of viable states and unique symbols may be large, \\nbut finite and known. We can descry the outputs, but the system’s intern als are hidden. Few \\nof the problem could be solved are by Inference A certain sequence of output symbols, \\ncompute the probabilities of one or more candidate states with sequences. Pattern matching'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 12, 'page_label': '13', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='of the problem could be solved are by Inference A certain sequence of output symbols, \\ncompute the probabilities of one or more candidate states with sequences. Pattern matching \\nthe state -switch sequence is realised are most likely to ha ve generated a particular output -'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 13, 'page_label': '14', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='symbol sequence.  Training the output -symbol chain data, reckon the state -switch/output \\nprobabilities that fit this data best. \\nHidden Markov Models are extensively used for speech recognition, where the output \\nsequence is matched to the sequence of individual phonemes. Frederick Jelinek, a statistical -\\nNLP advocate who first instigated HMMs at IBM’s Speech Recognition Group, reportedly \\njoked, every time a linguist leaves my group, the speech recognizer’s performance improves.  \\n[101] HMM is not restricted to this application it has several others such as bioinformatics \\nproblems, for example, multiple sequence a lignment [10 2]. Sonnhammer mentioned that \\nPfam hold multiple alignments and hidden Markov model based profiles (HMM -profiles) of \\nentire protein domains. The cue of domain boundaries, family members and alignment is \\ndone semi -automatically found on expert knowledge, sequence similarity, other protein'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 13, 'page_label': '14', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='entire protein domains. The cue of domain boundaries, family members and alignment is \\ndone semi -automatically found on expert knowledge, sequence similarity, other protein \\nfamily databases and the capability of HMM -profiles to correctly identify an d align the \\nmembers. [103]  \\n7.2 Naive Bayes Classifiers \\n The choice of area is wide ranging covering usual items like word segmentation and \\ntranslation but also unusual areas like segmentation for infant learning and identifying \\ndocuments for opinions and facts. In addition, exclusive article was selected for its use of \\nBayesian methods to aid the research in designing algorithms for their investigation. \\n8. NLP in Talk \\nThis section discuss es the recent developments in the NLP projects implemented by various \\ncompanies and these are as follows: \\n8.1 ACE Powered GDPR Robot Launched by RAVN Systems [104] \\nRAVN Systems,  an leading expert in Artificial Intelligence (AI),  Search and Knowledge'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 13, 'page_label': '14', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='companies and these are as follows: \\n8.1 ACE Powered GDPR Robot Launched by RAVN Systems [104] \\nRAVN Systems,  an leading expert in Artificial Intelligence (AI),  Search and Knowledge \\nManagement Solutions, announced the launch of a RAVN (\"Applied Cognitive Engine\") i.e \\npowered software Robot to help and facilitate the GDPR  (\"General Data Protection \\nRegulation\") compliance. \\nThe Robot uses AI techniques to automatically analyse documents and other types of data in \\nany business system which is subject to GDPR rules.  It allows users to quickly and easily \\nsearch, retrieve, flag, classify and report on data mediated to be supersensitive under GDPR. \\nUsers also have the ability to identify personal data from documents, view feeds on the latest \\npersonal data that requires attention and provide reports on the data suggested to be deleted or \\nsecured.  RAVN\\'s GDPR Robot is also abl e to hasten requests for information (Data Subject'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 13, 'page_label': '14', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='personal data that requires attention and provide reports on the data suggested to be deleted or \\nsecured.  RAVN\\'s GDPR Robot is also abl e to hasten requests for information (Data Subject \\nAccess Requests - \"DSAR\") in a simple and efficient way, removing the need for a physical \\napproach to these requests which tends to be very labour thorough.  Peter Wallqvist, CSO at \\nRAVN Systems commented, \"GDPR compliance is of universal paramountcy as it will \\nexploit to any organisation that control and process data concerning EU citizens. \\nLINK:http://markets.financialcontent.com/stocks/news/read/33888795/RAVN_Systems_Launch_the_ACE_Po\\nwered_GDPR_Robot \\n8.2 Eno A Natural Language Chatbot Launched by Capital One [105]'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 14, 'page_label': '15', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='Capital one announces chatbot for customers called Eno.  Eno is a natural language chatbot \\nthat people socialize through texting.  Capital one claims that Eno  is First natural language \\nSMS chatbot from a U.S. bank that allows customer to ask questions using natural language.  \\nCustomers can interact with Eno asking  questions about their savings and others using a text \\ninterface. Eno makes such an environment that it feels that a human is interacting.  Ken \\nDodelin, Capital One’s vice president of digital product development, said “We kind of \\nlaunched a chatbot and didn’t know it.”  \\nThis provides a different platform than other brands that launch chatbots like Facebook \\nMessenger and Skype.  They believed that Facebook  has too much access of private \\ninformation of a person, which could get them into trouble with privacy laws of U.S. \\nfinancial institutions work under.  Like any Facebook Page admin can access full transcripts'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 14, 'page_label': '15', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='information of a person, which could get them into trouble with privacy laws of U.S. \\nfinancial institutions work under.  Like any Facebook Page admin can access full transcripts \\nof the bot’s conversations.  If that would be the case then the admins could easily view the \\npersonal banking information of customers with is not correct \\n LINK: https://www.macobserver.com/analysis/capital-one-natural-language-chatbot-eno/ \\n8.3  Future of BI in Natural Language Processing [106] \\nSeveral companies in Bi spaces are trying to get with the trend and trying hard to ensure that \\ndata becomes more friendly and easily accessible.  But still there is long way for this.BI will \\nalso make it easier to access as GUI is not needed.  Because now a days the queries are made \\nby text or voice command on smartphones.one of the most common example is Google might \\ntell you today what will be the tomorrows  weather. But soon enough, we will be able to  ask'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 14, 'page_label': '15', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='by text or voice command on smartphones.one of the most common example is Google might \\ntell you today what will be the tomorrows  weather. But soon enough, we will be able to  ask \\nour personal data chatbot about customer sentiment today, and how do we feel about their \\nbrand next week; all while walking down the street. Today, NLP tends to be based on turning \\nnatural language into mac hine language. But with time the technology matures – especially \\nthe AI component –the computer will get better at “understanding” the query and start to \\ndeliver answers rather than search results. \\n Initially, the data chatbot will probably ask the questio n as how have revenues changed over \\nthe last three -quarters?’ and then return pages of data for you to analyse.  But once it learns \\nthe semantic relations and inferences of the question, it will be able to automatically perform \\nthe filtering and formulation necessary to provide an intelligible answer, rather than simply \\nshowing you data.'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 14, 'page_label': '15', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='the filtering and formulation necessary to provide an intelligible answer, rather than simply \\nshowing you data. \\nLink: http://www.smartdatacollective.com/eran-levy/489410/here-s-why-natural-language-processing-future-bi \\n8.4 Using Natural Language Processing and Network Analysis to \\nDevelop a Conceptual Framework for Medication  Therapy \\nManagement Research [107] \\nNatural Language Processing and Network Analysis to Develop a Conceptual Framework for \\nMedication Therapy Management Research describes a theory derivation  process that is used \\nto develop conceptual framework for medication therapy management (MTM) research.  The \\nMTM service model and chronic care model are selected a s parent theories.  Review article'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 15, 'page_label': '16', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='abstracts target medication therapy management in chronic disease care that were retrieved \\nfrom Ovid Medline (2000-2016). \\nUnique concepts in each abstract are extracted using Meta  Map and their pairwise \\ncooccurrence are de termined. Then the information is used to construct a network graph of \\nconcept co -occurrence that is further analysed to identify  content for the new conceptual \\nmodel. 142 abstracts are analysed. Medication adherence is the most studied drug therapy \\nproblem and co-occurred with concepts related to patient -centred interventions targeting self-\\nmanagement. The enhanced model consists of 65 concepts clustered into 14 constructs. The \\nframework requires additional refinement and evaluation to determine its releva nce and \\napplicability across a broad audience including underserved settings. \\nLink: https://www.ncbi.nlm.nih.gov/pubmed/28269895?dopt=Abstract \\n8.5 Meet the Pilot, world’s first language translating earbuds [108]'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 15, 'page_label': '16', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='Link: https://www.ncbi.nlm.nih.gov/pubmed/28269895?dopt=Abstract \\n8.5 Meet the Pilot, world’s first language translating earbuds [108] \\nThe world’s first smart earpiece Pilot will soon be transcribed over 15 languages.  According \\nto Spring wise, Waverly Labs’ Pilot can already transliterate five spoken languages, English, \\nFrench, Italian, Portuguese and Spanish, and seven written affixed languages, German, Hindi, \\nRussian, Japanese, Arabic, Korean and Mandarin Chinese. The Pilot earpiece is connected \\nvia Bluetooth to the Pilot speech translation app, which uses speech recognitio n, machine \\ntranslation and machine learning and speech synthesis technology. \\nSimultaneously, the user will hear the translated version of the speech on the second earpiece. \\nMoreover, it is not necessary that conversation would be taking place between two p eople \\nonly the users can join in and discuss as a group. As if now the user may experience a few'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 15, 'page_label': '16', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='Moreover, it is not necessary that conversation would be taking place between two p eople \\nonly the users can join in and discuss as a group. As if now the user may experience a few \\nsecond lag interpolated the speech and translation, which Waverly Labs pursue to reduce. \\nThe Pilot earpiece will be available from September, but can be pre -ordered now for $249. \\nThe earpieces can also be used for streaming music, answering voice calls and getting audio \\nnotifications. \\nLink:https://www.indiegogo.com/projects/meet-the-pilot-smart-earpiece-language-translator-\\nheadphones-travel#/ \\n \\nREFRENCES \\n[1] Chomsky, Noam, 1965, Aspects of the Theory of Syntax, Cambridge, Massachusetts: \\nMIT Press.  \\n [2] Rospocher, M., van Erp, M., Vossen, P., Fokkens, A., Aldabe,I., Rigau, G., Soroa, A., \\nPloeger, T., and Bogaard, T.(2016). Building event -centric knowledge graphs from news. \\nWeb Semantics: Science, Services and Agents on the World Wide Web, In Press.'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 15, 'page_label': '16', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='Ploeger, T., and Bogaard, T.(2016). Building event -centric knowledge graphs from news. \\nWeb Semantics: Science, Services and Agents on the World Wide Web, In Press. \\n[3] Shemtov, H. (1997).  Ambiguity manageme nt in natural language generation. Stanford \\nUniversity.  \\n[4] Emele, M. C., & Dorna, M. (1998, August). Ambiguity preserving machine translation \\nusing packed representations. In  Proceedings of the 36th Annual Meeting of the Association'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 16, 'page_label': '17', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='for Computational Lin guistics and 17th International Conference on Computational \\nLinguistics-Volume 1 (pp. 365-371). Association for Computational Linguistics. \\n[5] Knight, K., & Langkilde, I. (2000, July). Preserving ambiguities in generation via \\nautomata intersection. In AAAI/IAAI (pp. 697-702). \\n[6] Nation, K., Snowling, M. J., & Clarke, P. (2007). Dissecting the relationship between \\nlanguage skills and learning to read: Semantic and phonological contributions to new \\nvocabulary learning in children with poor reading compre hension. Advances in Speech \\nLanguage Pathology, 9(2), 131-139. \\n[7] Liddy, E. D. (2001). Natural language processing. \\n[8] Feldman, S. (1999). NLP Meets the Jabberwocky: Natural Language Processing in \\nInformation Retrieval. ONLINE-WESTON THEN WILTON-, 23, 62-73. \\n[9] \"Natural Language Processing.\"  Natural Language Processing RSS. N.p., n.d. Web. 25 \\nMar. 2017 \\n[10] Hutchins, W. J. (1986).  Machine translation: past, present, future  (p. 66). Chichester:'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 16, 'page_label': '17', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='[9] \"Natural Language Processing.\"  Natural Language Processing RSS. N.p., n.d. Web. 25 \\nMar. 2017 \\n[10] Hutchins, W. J. (1986).  Machine translation: past, present, future  (p. 66). Chichester: \\nEllis Horwood. \\n[11] Hutchins, W. J. (Ed.). (2000).  Early years in machine translation: memoirs and \\nbiographies of pioneers (Vol. 97). John Benjamins Publishing. \\n[12] Green Jr, B. F., Wolf, A. K., Chomsky, C., & Laughery, K. (1961, May). Baseball: an \\nautomatic question-answerer. In Papers presented at the May 9 -11, 1961, western joint IRE -\\nAIEE-ACM computer conference (pp. 219-224). ACM. \\n[13] Woods, W. A. (1978). Semantics and quantification in natural language question \\nanswering. Advances in computers, 17, 1-87. \\n[14] Hendrix, G. G., Sacerdoti, E. D., Sagalowicz, D., & Slocum, J. (1978). Developing a \\nnatural language interface to complex data.  ACM Transactions on Database Systems \\n(TODS), 3(2), 105-147. \\n[15] Alshawi, H. (1992). The core language engine. MIT press.'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 16, 'page_label': '17', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='natural language interface to complex data.  ACM Transactions on Database Systems \\n(TODS), 3(2), 105-147. \\n[15] Alshawi, H. (1992). The core language engine. MIT press. \\n[16] Kamp, H., & Reyle, U. (1993). Tense and Aspect.  In From Discourse to Logic (pp. 483-\\n689). Springer Netherlands. \\n[17] Lea , W.A Trends in speech recognition , Englewoods Cliffs , NJ: Prentice Hall , 1980. \\n[18] Young, S. J., & Chase, L. L. (1998). Speech recognition evaluation: a review of the US \\nCSR and LVCSR programmes. Computer Speech & Language, 12(4), 263-279. \\n[19] Sundheim, B. M., & Chinchor, N. A. (1993, March). Survey of the message \\nunderstanding conferences. In  Proceedings of the workshop on Human Language \\nTechnology (pp. 56-60). Association for Computational Linguistics.'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 17, 'page_label': '18', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='[20] Wahlster, W., & Kobsa, A. (1989). User models in dialog systems. In  User models in \\ndialog systems (pp. 4-34). Springer Berlin Heidelberg. \\n[21] McKeown, K.R. Text generation , Cambridge: Cambridge University Press , 1985. \\n[22] Small S.L., Cortell G.W., and Tanenhaus , M.K. Lexical Ambiguity Resolutions , San \\nMateo , CA : Morgan Kauffman, 1988. \\n[23] Manning, C. D., & Schütze, H. (1999).  Foundations of statistical natural language \\nprocessing (Vol. 999). Cambridge: MIT press. \\n[24] Mani, I., & Maybury, M. T. (Eds.). (1999).  Advances in automatic text \\nsummarization (Vol. 293). Cambridge, MA: MIT press. \\n[25] Yi, J., Nasukawa, T., Bunescu, R., & Niblack, W. (2003, November). Sentiment \\nanalyzer: Extracting sentiments about a given topi c using natural language processing \\ntechniques. In Data Mining, 2003. ICDM 2003. Third IEEE International Conference on  (pp. \\n427-434). IEEE. \\n[26] Yi, J., Nasukawa, T., Bunescu, R., & Niblack , W. (2003, November). Sentiment'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 17, 'page_label': '18', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='techniques. In Data Mining, 2003. ICDM 2003. Third IEEE International Conference on  (pp. \\n427-434). IEEE. \\n[26] Yi, J., Nasukawa, T., Bunescu, R., & Niblack , W. (2003, November). Sentiment \\nanalyzer: Extracting sentiments about a given topic using natural language processing \\ntechniques. In Data Mining, 2003. ICDM 2003. Third IEEE International Conference on  (pp. \\n427-434). IEEE. \\n[27] Tapaswi, N., & Jain, S. (20 12, September). Treebank based deep grammar acquisition \\nand Part -Of-Speech Tagging for Sanskrit sentences. In  Software Engineering (CONSEG), \\n2012 CSI Sixth International Conference on (pp. 1-4). IEEE. \\n[28] Ranjan, P., & Basu, H. V. S. S. A. (2003). Part of  speech tagging and local word \\ngrouping techniques for natural language parsing in Hindi. In  Proceedings of the 1st \\nInternational Conference on Natural Language Processing (ICON 2003). \\n[29] Diab, M., Hacioglu, K., & Jurafsky, D. (2004, May). Automatic tagg ing of Arabic text:'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 17, 'page_label': '18', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='International Conference on Natural Language Processing (ICON 2003). \\n[29] Diab, M., Hacioglu, K., & Jurafsky, D. (2004, May). Automatic tagg ing of Arabic text: \\nFrom raw text to base phrase chunks. In  Proceedings of HLT -NAACL 2004: Short \\npapers (pp. 149-152). Association for Computational Linguistics. \\n[30] Sha, F., & Pereira, F. (2003, May). Shallow parsing with conditional random fields. \\nIn Proceedings of the 2003 Conference of the North American Chapter of the Association for \\nComputational Linguistics on Human Language Technology -Volume 1  (pp. 134 -141). \\nAssociation for Computational Linguistics. \\n[31] McDonald, R., Crammer, K., & Pereira, F. (2 005, October). Flexible text segmentation \\nwith structured multilabel classification. In  Proceedings of the conference on Human \\nLanguage Technology and Empirical Methods in Natural Language Processing  (pp. 987 -\\n994). Association for Computational Linguistics.'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 17, 'page_label': '18', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='Language Technology and Empirical Methods in Natural Language Processing  (pp. 987 -\\n994). Association for Computational Linguistics. \\n[32] Sun, X., Morency, L. P., Okanohara, D., & Tsujii, J. I. (2008, August). Modeling latent -\\ndynamic in shallow parsing: a latent conditional model with improved inference.'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 18, 'page_label': '19', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='In Proceedings of the 22nd International Conference on Computational Linguistics-Volume \\n1 (pp. 841-848). Association for Computational Linguistics. \\n[33] Ritter, A., Clark, S., & Etzioni, O. (2011, July). Named entity recognition in tweets: an \\nexperimental study. In  Proceedings of the Conference on Empirical Methods in Natur al \\nLanguage Processing (pp. 1524-1534). Association for Computational Linguistics. \\n[34] Sharma, S. , Srinivas,  PYKL, &  Balabantaray, RC (2016). Emotion Detection using \\nOnline Machine Learning Method and TLBO on Mixed Script. In Proceedings of Language \\nResources and Evaluation Conference 2016 (pp. 47-51). \\n[35] Palmer, M., Gildea, D., & Kingsbury, P. (2005). The proposition bank: An annotated \\ncorpus of semantic roles. Computational linguistics, 31(1), 71-106. \\n[36] Benson, E., Haghighi, A., & Barzilay, R. (2011, June). Event discovery in social media \\nfeeds. In  Proceedings of the 49th Annual Meeting of the Association for Computational'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 18, 'page_label': '19', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='[36] Benson, E., Haghighi, A., & Barzilay, R. (2011, June). Event discovery in social media \\nfeeds. In  Proceedings of the 49th Annual Meeting of the Association for Computational \\nLinguistics: Human Language Technologies -Volume 1  (pp. 389 -398). Association for \\nComputational Linguistics. \\n[37] Tillmann, C ., Vogel, S., Ney, H., Zubiaga, A., & Sawaf, H. (1997, September). \\nAccelerated DP based search for statistical translation. In Eurospeech. \\n[38] Bangalore, S., Rambow, O., & Whittaker, S. (2000, June). Evaluation metrics for \\ngeneration. In  Proceedings of the first international conference on Natural language \\ngeneration-Volume 14 (pp. 1-8). Association for Computational Linguistics \\n[39] Nießen, S., Och, F. J., Leusch, G., & Ney, H. (2000, May). An Evaluation Tool for \\nMachine Translation: Fast Evaluation for MT Research. In LREC \\n[40] Papineni, K., Roukos, S., Ward, T., & Zhu, W. J. (2002, July). BLEU: a method for'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 18, 'page_label': '19', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='Machine Translation: Fast Evaluation for MT Research. In LREC \\n[40] Papineni, K., Roukos, S., Ward, T., & Zhu, W. J. (2002, July). BLEU: a method for \\nautomatic evaluation of machine translation. In  Proceedings of the 40th annual meeting on \\nassociation for computational linguistics  (pp. 311 -318). Association for Computational \\nLinguistics \\n[41] Doddington, G. (2002, March). Automatic evaluation of machine translation quality \\nusing n-gram co-occurrence statistics. In  Proceedings of the second international conference \\non Human Language Technology Research (pp. 138-145). Morgan Kaufmann Publishers Inc  \\n[42] Papineni, K., Roukos, S., Ward, T., & Zhu, W. J. (2002, July). BLEU: a method for \\nautomatic evaluation of machine translation. In  Proceedings of the 40th annual meeting on \\nassociation for computationa l linguistics  (pp. 311 -318). Association for Computational \\nLinguistics \\n[43] Doddington, G. (2002, March). Automatic evaluation of machine translation quality'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 18, 'page_label': '19', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='association for computationa l linguistics  (pp. 311 -318). Association for Computational \\nLinguistics \\n[43] Doddington, G. (2002, March). Automatic evaluation of machine translation quality \\nusing n-gram co-occurrence statistics. In  Proceedings of the second international conference \\non Human Language Technology Research (pp. 138-145). Morgan Kaufmann Publishers Inc'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 19, 'page_label': '20', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='[44] Hayes, P. J. (1992). Intelligent high -volume text processing using shallow, domain -\\nspecific techniques.  Text-based intelligent systems: Current research and practice in \\ninformation extraction and retrieval, 227-242. \\n[45] Cohen, W. W. (1996, March). Learning rules that classify e -mail. In  AAAI spring \\nsymposium on machine learning in information access (Vol. 18, p. 25). \\n[46] Sahami, M., Dumais, S., Heckerman, D., &  Horvitz, E. (1998, July). A Bayesian \\napproach to filtering junk e -mail. In Learning for Text Categorization: Papers from the 1998 \\nworkshop (Vol. 62, pp. 98-105). \\n[47] Androutsopoulos, I., Paliouras, G., Karkaletsis, V., Sakkis, G., Spyropoulos, C. D., & \\nStamatopoulos, P. (2000). Learning to filter spam e -mail: A comparison of a naive bayesian \\nand a memory-based approach. arXiv preprint cs/0009009. \\n[48] Rennie, J. (2000, August). ifile: An application of machine learning to e -mail filtering. \\nIn Proc. KDD 2000 Workshop on Text Mining, Boston, MA'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 19, 'page_label': '20', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='[48] Rennie, J. (2000, August). ifile: An application of machine learning to e -mail filtering. \\nIn Proc. KDD 2000 Workshop on Text Mining, Boston, MA \\n[49] Drucker, H., Wu, D., & Vapnik, V. N. (1999). Support vector machines for spam \\ncategorization. IEEE Transactions on Neural networks, 10(5), 1048-1054 \\n[50] Carreras, X., & Marquez, L. (2001). Boosting trees for ant i-spam email filtering.  arXiv \\npreprint cs/0109015 \\n[51] BERGER, A. L., DELLA PIETRA, S. A., AND DELLA PIETRA, V. J. 1996. A \\nmaximum entropy approach to natural language processing. Computational Linguistics 22, 1, \\n39–71 \\n[52] Sakkis, G., Androutsopoulos, I.,  Paliouras, G., Karkaletsis, V., Spyropoulos, C. D., & \\nStamatopoulos, P. (2001). Stacking classifiers for anti-spam filtering of e-mail. arXiv preprint \\ncs/0106040.. \\n[53] Lewis, D. D. (1998, April). Naive (Bayes) at forty: The independence assumption in \\ninformation retrieval. In  European conference on machine learning  (pp. 4 -15). Springer'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 19, 'page_label': '20', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='cs/0106040.. \\n[53] Lewis, D. D. (1998, April). Naive (Bayes) at forty: The independence assumption in \\ninformation retrieval. In  European conference on machine learning  (pp. 4 -15). Springer \\nBerlin Heidelberg \\n[54] McCallum, A., & Nigam, K. (1998, July). A comparison of event models for naive bayes \\ntext classification. In  AAAI-98 workshop on learning for text ca tegorization (Vol. 752, pp. \\n41-48). \\n[55] McCallum, A., & Nigam, K. (1998, July). A comparison of event models for naive bayes \\ntext classification. In  AAAI-98 workshop on learning for text categorization  (Vol. 752, pp. \\n41-48). \\n[56] Porter, M. F. (1980). An algorithm for suffix stripping. Program, 14(3), 130-137'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 20, 'page_label': '21', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='[57] Hayes, P. J. (1992). Intelligent high -volume text processing using shallow, domain -\\nspecific techniques.  Text-based intelligent systems: Current research and practice in \\ninformation extraction and retrieval, 227-242 \\n[58] Morin, E. (1999, August). Automatic acquisition of semantic relations between terms \\nfrom technical corpora. In  Proc. of the Fifth International Congress on Terminology and \\nKnowledge Engineering-TKE’99. \\n[59] Bondale, N., Maloor, P.,  Vaidyanathan, A., Sengupta, S., & Rao, P. V. (1999). \\nExtraction of information from open -ended questionnaires using natural language processing \\ntechniques. Computer Science and Informatics, 29(2), 15-22 \\n[60] Glasgow, B., Mandell, A., Binney, D., Ghemri, L ., & Fisher, D. (1998). MITA: An \\ninformation-extraction approach to the analysis of free -form text in life insurance \\napplications. AI magazine, 19(1), 59. \\n[61] Ahonen, H., Heinonen, O., Klemettinen, M., & Verkamo, A. I. (1998, April). Applying'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 20, 'page_label': '21', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='applications. AI magazine, 19(1), 59. \\n[61] Ahonen, H., Heinonen, O., Klemettinen, M., & Verkamo, A. I. (1998, April). Applying \\ndata mining techniques for descriptive phrase extraction in digital document collections. \\nIn Research and Technology Advances in Digital Libraries, 1998. ADL 98. Proceedings. \\nIEEE International Forum on (pp. 2-11). IEEE. \\n[62] Zajic, D. M., Dorr, B. J., & Lin, J. (2008 ). Single -document and multi -document \\nsummarization techniques for email threads using sentence compression.  Information \\nProcessing & Management, 44(4), 1600-1610. \\n[63] Fattah, M. A., & Ren, F. (2009). GA, MR, FFNN, PNN and GMM based models for \\nautomatic text summarization. Computer Speech & Language, 23(1), 126-144. \\n[64] Gong, Y., & Liu, X. (2001, September). Generic text summarization using relevance \\nmeasure and latent semantic analysis. In  Proceedings of the 24th annual international ACM \\nSIGIR conference on Research and development in information retrieval (pp. 19-25). ACM.'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 20, 'page_label': '21', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='measure and latent semantic analysis. In  Proceedings of the 24th annual international ACM \\nSIGIR conference on Research and development in information retrieval (pp. 19-25). ACM. \\n[65] Dunlavy, D. M., O’Leary, D. P., Conroy, J. M., & Schlesinger, J. D. (2007). QCS: A \\nsystem for querying, clustering and summarizing documents.  Information processing & \\nmanagement, 43(6), 1588-1605. \\n[66] Wan, X. (2008). Using only cross -document relationships for both generic and topic -\\nfocused multi-document summarizations. Information Retrieval, 11(1), 25-49. \\n[67] Ouyang, Y., Li, W., Li, S., & Lu, Q. (2011). Applying regression models to query -\\nfocused multi-document summarization. Information Processing & Management,  47(2), 227-\\n237. \\n[68] Mani, I., & Maybury, M. T. (Eds.). (1999).  Advances in automatic text \\nsummarization (Vol. 293). Cambridge, MA: MIT press.'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 21, 'page_label': '22', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='[69] Riedhammer, K., F avre, B., & Hakkani -Tür, D. (2010). Long story short –global \\nunsupervised models for keyphrase based meeting summarization.  Speech \\nCommunication, 52(10), 801-815. \\n[70] Wang, D., Zhu, S., Li, T., & Gong, Y. (2009, August). Multi -document summarization \\nusing sentence-based topic models. In  Proceedings of the ACL -IJCNLP 2009 Conference \\nShort Papers (pp. 297-300). Association for Computational Linguistics. \\n[71] Wang, D., Zhu, S., Li, T., Chi, Y., & Gong, Y. (2011). Integrating document clustering \\nand multidocument summarization. ACM Transactions on Knowledge Discovery from Data \\n(TKDD), 5(3), 14. \\n[72] Fang, H., Lu, W., Wu, F., Zhang, Y., Shang, X., Shao, J., & Zhuang, Y. (2015). Topic \\naspect-oriented summarization via group selection. Neurocomputing, 149, 1613-1619. \\n[73] Sager, N., Lyman, M., Nhan, N. T., & Tick, L. J. (1995). Medical language processing: \\napplications to patient data representation and automatic encoding. Methods of information in'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 21, 'page_label': '22', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='[73] Sager, N., Lyman, M., Nhan, N. T., & Tick, L. J. (1995). Medical language processing: \\napplications to patient data representation and automatic encoding. Methods of information in \\nmedicine, 34(1-2), 140-146. \\n[74] Chi, E. C., Lyman, M. S. , Sager, N., Friedman, C., & Macleod, C. (1985, November). A \\ndatabase of computer -structured narrative: methods of computing complex relations. \\nIn Proceedings of the Annual Symposium on Computer Application in Medical Care (p. 221). \\nAmerican Medical Informatics Association. \\n[75] Grishman, R., Sager, N., Raze, C., & Bookchin, B. (1973, June). The linguistic string \\nparser. In  Proceedings of the June 4 -8, 1973, national computer conference and \\nexposition (pp. 427-434). ACM. \\n[76] Hirschman, L., Grishman, R., & Sager, N. (1976, June). From text to structured \\ninformation: automatic processing of medical reports. In  Proceedings of the June 7 -10, 1976, \\nnational computer conference and exposition (pp. 267-275). ACM.'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 21, 'page_label': '22', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='information: automatic processing of medical reports. In  Proceedings of the June 7 -10, 1976, \\nnational computer conference and exposition (pp. 267-275). ACM. \\n[77] Sager, N. (1981). Natural language information processing. Addison-Wesley Publishing \\nCompany, Advanced Book Program. \\n[78] Lyman, M., Sager, N., Friedman, C., & Chi, E. (1985, November). Computer -structured \\nnarrative in ambulatory care: its use in longitudinal review of clinical data. In  Proceedings of \\nthe Annual Symposium on Computer Application in Medical Care (p. 82). American Medical \\nInformatics Association. \\n[79] McCray, A. T., & Nelson, S. J. (1995). The representation of meaning in the \\nUMLS. Methods of information in medicine, 34(1-2), 193-201. \\n[80] McGray, A. T., Sponsler, J. L., Brylawski, B., & Browne, A. C. (1987, November). The \\nrole of lexical knowledge in biomedical text understanding. In  Proceedings of the Annual \\nSymposium on Computer Application in Medical Care  (p. 103). American Medical'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 21, 'page_label': '22', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='role of lexical knowledge in biomedical text understanding. In  Proceedings of the Annual \\nSymposium on Computer Application in Medical Care  (p. 103). American Medical \\nInformatics Association.'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 22, 'page_label': '23', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='[81] McCray, A. T. (1991). Natural language processing for intelligent information retrieval. \\nIn Engineering in Medicine and Biology Society, 1991. Vol. 13: 1991., Proceedings of the \\nAnnual International Conference of the IEEE (pp. 1160-1161). IEEE. \\n[82] McCray, A. T. (1991). Extending a natural language parser with UMLS knowledge. \\nIn Proceedings of the Annual Symposium on Computer Application in Medical Care (p. 194). \\nAmerican Medical Informatics Association. \\n[83] McCray, A. T., Srin ivasan, S., & Browne, A. C. (1994). Lexical methods for managing \\nvariation in biomedical terminologies. In  Proceedings of the Annual Symposium on \\nComputer Application in Medical Care (p. 235). American Medical Informatics Association. \\n[84] McCray, A. T., &  Razi, A. (1994). The UMLS Knowledge Source server.  Medinfo. \\nMEDINFO, 8, 144-147. \\n[85] Scherrer, J. R., Revillard, C., Borst, F., Berthoud, M., & Lovis, C. (1994). Medical office'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 22, 'page_label': '23', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='MEDINFO, 8, 144-147. \\n[85] Scherrer, J. R., Revillard, C., Borst, F., Berthoud, M., & Lovis, C. (1994). Medical office \\nautomation integrated into the distributed architecture of a hospital informa tion \\nsystem. Methods of information in medicine, 33(2), 174-179. \\n[86] Baud, R. H., Rassinoux, A. M., & Scherrer, J. R. (1992). Natural language processing \\nand semantical representation of medical texts.  Methods of information in medicine,  31(2), \\n117-125. \\n[87] Lyman, M., Sager, N., Chi, E. C., Tick, L. J., Nhan, N. T., Su, Y., ... & Scherrer, J. \\n(1989, November). Medical Language Processing for Knowledge Representation and \\nRetrievals. In Proceedings. Symposium on Computer Applications in Medical Care  (pp. 548-\\n553). American Medical Informatics Association. \\n[88] Nhàn, N. T., Sager, N., Lyman, M., Tick, L. J., Borst, F., & Su, Y. (1989, November). A \\nMedical Language Processor for Two Indo -European Languages. In  Proceedings.'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 22, 'page_label': '23', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content=\"[88] Nhàn, N. T., Sager, N., Lyman, M., Tick, L. J., Borst, F., & Su, Y. (1989, November). A \\nMedical Language Processor for Two Indo -European Languages. In  Proceedings. \\nSymposium on Computer Applications i n Medical Care  (pp. 554 -558). American Medical \\nInformatics Association. \\n[89] Sager, N., Lyman, M., Tick, L. J., Borst, F., Nhan, N. T., Revillard, C., ... & Scherrer, J. \\nR. (1989). Adapting a medical language processor from English to French.  Medinfo, 89, 795-\\n799. \\n[90] Borst, F., Sager, N., Nhàn, N. T., Su, Y., Lyman, M., Tick, L. J., ... & Scherrer, J. R. \\n(1989). Analyse automatique de comptes rendus d'hospitalisation. In  Degoulet P, Stephan JC, \\nVenot A, Yvon PJ, rédacteurs. Informatique et Santé, Informat ique et Gestion des Unités de \\nSoins, Comptes Rendus du Colloque AIM-IF, Paris (pp. 246-56). [5] \\n[91] Baud, R. H., Rassinoux, A. M., & Scherrer, J. R. (1991). Knowledge representation of \\ndischarge summaries. In AIME 91 (pp. 173-182). Springer Berlin Heidelberg.\"),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 22, 'page_label': '23', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='[91] Baud, R. H., Rassinoux, A. M., & Scherrer, J. R. (1991). Knowledge representation of \\ndischarge summaries. In AIME 91 (pp. 173-182). Springer Berlin Heidelberg. \\n[92] Baud, R. H., Alpay, L., & Lovis, C. (1994). Let’s Meet the Users with Natural Language \\nUnderstanding. Knowledge and Decisions in Health Telematics: The Next Decade, 12, 103.'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 23, 'page_label': '24', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='[93] Rassinoux, A. M., Baud, R. H., & Scherrer, J. R. (1992). Conceptual  graphs model \\nextension for knowledge representation of medical texts. MEDINFO, 92, 1368-1374. \\n[94] Morel-Guillemaz, A. M., Baud, R. H., & Scherrer, J. R. (1990). Proximity Processing of \\nMedical Text. In Medical Informatics Europe’90 (pp. 625-630). Springer Berlin Heidelberg. \\n[95] Rassinoux, A. M., Michel, P. A., Juge, C., Baud, R., & Scherrer, J. R. (1994). Natural \\nlanguage processing of medical texts within the HELIOS environment.  Computer methods \\nand programs in biomedicine, 45, S79-96. \\n[96] Rassinoux, A. M., Juge, C., Michel, P. A., Baud, R. H., Lemaitre, D., Jean, F. C., ... & \\nScherrer, J. R. (1995, June). Analysis of medical jargon: The RECIT system. In  Conference \\non Artificial Intelligence in Medicine in Europe (pp. 42-52). Springer Berlin Heidelberg. \\n[97] Friedman, C., Cimino, J. J., & Johnson, S. B. (1993). A conceptual model for clinical'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 23, 'page_label': '24', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='on Artificial Intelligence in Medicine in Europe (pp. 42-52). Springer Berlin Heidelberg. \\n[97] Friedman, C., Cimino, J. J., & Johnson, S. B. (1993). A conceptual model for clinical \\nradiology reports. In  Proceedings of the Annual Symposium on Computer Application in \\nMedical Care (p. 829). American Medical Informatics Association. \\n[98] \"Natural Language Processing.\"  Natural Language Processing RSS. N.p., n.d. Web. 23 \\nMar. 2017.   \\n[99] [Srihari S. Machine Learning: Generative and Discriminative Models. 2010. http:// \\nwww.cedar.buffalo.edu/wsrihari/CSE574/Discriminative-Generative.pdf (access ed 31 May \\n2011).] \\n[100] [Elkan C. Log -Linear Models and Conditional Random Fields. 2008. http://cseweb. \\nucsd.edu/welkan/250B/cikmtutorial.pdf (accessed 28 Jun 2011). 62. Hearst MA, Dumais ST, \\nOsman E, et al. Support vector machines] \\n[101] [Jurafsky D, Martin JH. Speech and Language Processing. 2nd edn. Englewood Cliffs, \\nNJ: Prentice-Hall, 2008.]'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 23, 'page_label': '24', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='Osman E, et al. Support vector machines] \\n[101] [Jurafsky D, Martin JH. Speech and Language Processing. 2nd edn. Englewood Cliffs, \\nNJ: Prentice-Hall, 2008.] \\n[102] [Sonnhammer ELL, Eddy SR, Birney E, et al. Pfam: Multiple sequence alignments and \\nHMM-profiles of protein domains. Nucleic Acids Res 1998;26:320] \\n[103] [Sonnhammer, E. L., Eddy, S. R., Birney, E., Bateman, A., & Durbin, R. (1998). Pfam: \\nmultiple sequence alignments and HMM -profiles of protein domains.  Nucleic acids \\nresearch, 26(1), 320-322] \\n[104] Systems, RAVN. \"RAVN Systems Launch the ACE Powered GDPR Rob ot - Artificial \\nIntelligence to Expedite GDPR Compliance.\"  Stock Market. PR Newswire, n.d. Web. 19 \\nMar. 2017. \\n [105] \"Here\\'s Why Natural Language Processing is the Future of BI.\"  SmartData Collective. \\nN.p., n.d. Web. 19 Mar. 2017'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 24, 'page_label': '25', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='[106] \"Using Natural Langu age Processing and Network Analysis to Develop a Conceptual \\nFramework for Medication Therapy Management Research.\"  AMIA ... Annual Symposium \\nproceedings. AMIA Symposium. U.S. National Library of Medicine, n.d. Web. 19 Mar. 2017 \\n[107] Ogallo, W., & Kanter , A. S. (2017, February 10). Using Natural Language Processing \\nand Network Analysis to Develop a Conceptual Framework for Medication Therapy \\nManagement Research. Retrieved April 10, 2017, from \\nhttps://www.ncbi.nlm.nih.gov/pubmed/28269895?dopt=Abstract \\n[108] Ochoa, A. (2016, May 25). Meet the Pilot: Smart Earpiece Language Translator. \\nRetrieved April 10, 2017, from https://www.indiegogo.com/projects/meet -the-pilot-smart-\\nearpiece-language-translator-headphones-travel'),\n",
       " Document(metadata={'producer': 'Skia/PDF m144 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'Siddhant_Kochhar_Resume', 'source': '../data/pdf_files/Siddhant_Kochhar_Resume.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'Siddhant_Kochhar_Resume.pdf', 'file_type': 'pdf'}, page_content='SIDDHANT  KOCHHAR  (22BCE11684)  B.Tech  (Computer  Science  and  Engineering)   Email:  siddhantkochhar2022@vitbhopal.ac.in  |  Phone:  8965897560  LinkedIn:  https://www.linkedin.com/in/siddhant-kochhar/ LeetCode:   https://leetcode.com/u/Siddhant_Kochhar/  GitHub:  https://github.com/Siddhant-kochhar  \\n  \\n \\nACADEMICS  \\n \\nQualification  Institute  Board  /  University  %  /  CGPA  Year  B.Tech  (CSE  -  7th  sem)  XII  \\nVellore  Institute  of  Technology  Maharishi  Vidya  Mandir,  Jabalpur  \\nVIT  University  CBSE  \\n8.81/10  78.6%  \\n2026  2022  X  Maharishi  Vidya  Mandir,  Jabalpur  CBSE  79.2%  2020  \\n \\nCertifications   \\n●  AWS  Academy  Graduate  -  AWS  Academy  Cloud  Architecting ●  Cloud  Computing  by  IIT  Kharagpur  offered  through  NPTEL  ●  The  Bits  and  Bytes  of  Computer  Networks  by  Google  offered  through  Coursera  ●  Python  A-Z™:  Python  For  Data  Science offered  by  Udemy  \\n2025  2024  2023  2023  \\n \\nAchievements'),\n",
       " Document(metadata={'producer': 'Skia/PDF m144 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'Siddhant_Kochhar_Resume', 'source': '../data/pdf_files/Siddhant_Kochhar_Resume.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'Siddhant_Kochhar_Resume.pdf', 'file_type': 'pdf'}, page_content='2025  2024  2023  2023  \\n \\nAchievements  \\n●  Selected  among  top  500  students  globally  for  the  Ericsson  Academic  Training  Program  ●  Awarded  a  scholarship  under  Deen  Dayal  SPARSH  Yojana  by  India  Post  \\n2024  2017  \\n  \\nINTERNSHIP                                                                                                                                                              2  MONTHS  \\n  \\nMagicPin  (Hybrid)  Gen  AI  Intern   May  2025  -  June  2025  \\nRoles  and  Responsibilities  \\nGen  AI  &  Conversational  Interfaces  ●  Developed  a  WhatsApp-based  GenAI  chatbot  enabling  users  to  search  for  food,  fashion,  etc.  ●  Integrated  personalised  food  recommendation  engine  using  user  context  and  historical  data  ●  Enhanced  Magicpin’s  personal  support  bot  with  conversational  AI  capabilities  ●  Collaborated  with  tech  and  product  teams  to  ensure  scalable  integration  across  key  user  workflows   \\n \\n \\nPROJECTS'),\n",
       " Document(metadata={'producer': 'Skia/PDF m144 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'Siddhant_Kochhar_Resume', 'source': '../data/pdf_files/Siddhant_Kochhar_Resume.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'Siddhant_Kochhar_Resume.pdf', 'file_type': 'pdf'}, page_content='PROJECTS  \\n \\nGet.Fit  \\n●  Tech  Stack  -  Python,  FastAPI,  Google  Gemini,  Google  Fit,  MongoDB,  HTML,  CSS  ●  Developed  a  smart  health  tracking  app  integrated  with  Google  Fit  for  vitals  monitoring  ●  Added  a  feature  to  send  regular  summaries  and  real-time  alerts  for  proactive  health  management  \\nAI  Tutor  \\n●  Tech  Stack  -  Python,  FastAPI,  MongoDB,  OpenAI  ●  Developed  an  AI  tutor  that  assesses  the  user’s  proficiency  to  generate  personalized  responses  ●  Developed  a  YouTube  video  summarizer,  transforming  lengthy  video  content  into  concise  notes  \\nEventGenie \\n●  Tech  Stack  -  Python,  FastAPI,  Google  Gemini,  MongoDB,  MCP,  Redis,  Google  Places,  HTML   ●  Developed  EventGenie,  an  AI  event  planner  with  venues,  budgeting,  restaurants,  and  activities.  ●  Integrated  Google  Gemini  and  Google  Places  API  for  intelligent  venues,  budgeting,  and  scheduling.  \\nNote-Taking  App'),\n",
       " Document(metadata={'producer': 'Skia/PDF m144 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'Siddhant_Kochhar_Resume', 'source': '../data/pdf_files/Siddhant_Kochhar_Resume.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'Siddhant_Kochhar_Resume.pdf', 'file_type': 'pdf'}, page_content='Note-Taking  App  \\n●  Tech  Stack  -  Python,  FastAPI,  MongoDB,  Bootstrap  ●  Developed  a  basic  note-taking  application  using  CRUD  APIs  to  learn  the  FastAPI  framework  \\n \\nCORE  COMPETENCIES  \\n \\nData  Structure  and  Algorithm,  Operating  Systems,  Database  Management,  GenAI,  Cloud  Computing,  Computer  Networking  Programming  Python,  FastAPI,  Flask,  Pandas,  Numpy,  HTML,  CSS,  Bootstrap,  Java  Databases/Cache  MongoDB,  SQL,  Redis  Cloud  AWS,  GCP  AI/Tools  OpenAI  APIs,  Gemini,  MCP  server,  GitHub,  Cursor,  Postman,  MS  Office,  Canva  Soft  Skills  Leadership,  Communication,  Teamwork,  Problem  Solving,  Analytical  Skills,  Learning  Agility  \\n \\nPOSITIONS  OF  RESPONSIBILITY  \\n \\nMVM,  Jabalpur  \\n●  Vice  Captain,  Assembly  Committee  ●  Junior  Prefect  of  Parashar  House  \\n \\n \\nCO-CURRICULAR  &  EXTRACURRICULAR  ACTIVITIES  \\n \\nTechnical'),\n",
       " Document(metadata={'producer': 'Skia/PDF m144 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'Siddhant_Kochhar_Resume', 'source': '../data/pdf_files/Siddhant_Kochhar_Resume.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'Siddhant_Kochhar_Resume.pdf', 'file_type': 'pdf'}, page_content='POSITIONS  OF  RESPONSIBILITY  \\n \\nMVM,  Jabalpur  \\n●  Vice  Captain,  Assembly  Committee  ●  Junior  Prefect  of  Parashar  House  \\n \\n \\nCO-CURRICULAR  &  EXTRACURRICULAR  ACTIVITIES  \\n \\nTechnical  \\n●  Member,  Google  Developers  Group  ●  Competitive  Programming  -  LeetCode,  HackerRank,  Code  Chef  \\n \\nSocial/Sports  \\n●  Karate  -  Yellow  belt   Interests  /  Hobbies  ●  Travelling,  Cooking,  Gaming     VIT  UNIVERSITY  |  BATCH  OF  2026'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 0, 'page_label': '1', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='Natural Language Processing Journal 7 (2024) 100062\\nContents lists available at ScienceDirect\\nNatural Language Processing Journal\\njournal homepage: www.elsevier.com/locate/nlp\\nUnderstanding latent affective bias in large pre-trained neural language\\nmodels\\nAnoop Kadana,∗, Deepak P.b, Sahely Bhadrac, Manjary P. Gangand, Lajish V.L.d\\na School of Psychology, Queen’s University Belfast, UK\\nb School of Electronics, Electrical Engineering and Computer Science, Queen’s University Belfast, UK\\nc Computer Science and Engineering, IIT Palakkad, India\\nd Department of Computer Science, University of Calicut, India\\nA R T I C L E I N F O\\nKeywords:\\nAffective bias in NLP\\nFairness in NLP\\nPre-trained language models\\nTextual emotion detection\\nDeep learning\\nA B S T R A C T\\nGroundbreaking inventions and highly significant performance improvements in deep learning based Natural\\nLanguage Processing are witnessed through the development of transformer based large Pre-trained Language'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 0, 'page_label': '1', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='Language Processing are witnessed through the development of transformer based large Pre-trained Language\\nModels (PLMs). The wide availability of unlabeled data within human generated data deluge along with self-\\nsupervised learning strategy helps to accelerate the success of large PLMs in language generation, language\\nunderstanding, etc. But at the same time, latent historical bias/unfairness in human minds towards a particular\\ngender, race, etc., encoded unintentionally/intentionally into the corpora harms and questions the utility and\\nefficacy of large PLMs in many real-world applications, particularly for the protected groups. In this paper,\\nwe present an extensive investigation towards understanding the existence of ‘‘Affective Bias’’ in large PLMs\\nto unveil any biased association of emotions such as anger, fear, joy, etc., towards a particular gender, race\\nor religion with respect to the downstream task of textual emotion detection. We conduct our exploration of'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 0, 'page_label': '1', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='or religion with respect to the downstream task of textual emotion detection. We conduct our exploration of\\naffective bias from the very initial stage of corpus level affective bias analysis by searching for imbalanced\\ndistribution of affective words within a domain, in large scale corpora that are used to pre-train and fine-tune\\nPLMs. Later, to quantify affective bias in model predictions, we perform an extensive set of class-based and\\nintensity-based evaluations using various bias evaluation corpora. Our results show the existence of statistically\\nsignificant affective bias in the PLM based emotion detection systems, indicating biased association of certain\\nemotions towards a particular gender, race, and religion.\\n1. Introduction\\nRecently, large scale Natural Language Processing (NLP) models are\\nbeing increasingly deployed in many real-world applications within\\nalmost all domains such as health-care, business, legal systems, etc.,'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 0, 'page_label': '1', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='being increasingly deployed in many real-world applications within\\nalmost all domains such as health-care, business, legal systems, etc.,\\nVelupillai et al. (2018), Soni and Roberts (2020), Mishev et al. (2020),\\nDale (2019), Rahman and Siddiqui (2019) and Rahman and Siddiqui\\n(2021) due to its efficacy to make data-driven decisions and capability\\nof natural language understanding even better than humans1 (He et al.,\\n2021). Transformer based large Pre-trained Language Models (PLMs)\\nhave been hugely influential in NLP due to their capability to gener-\\nate powerful contextual representations. PLMs are mostly built based\\non a self-supervised learning strategy that highly relies on unlabeled\\ndata abundantly available from the human generated data deluge (He\\net al., 2021). But, since this historical data of textual write-ups has its\\nroots within human thought, they often reflect latent social stereotypes\\n(Suresh and Guttag, 2021; Garg et al., 2018). For example, the Social'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 0, 'page_label': '1', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='roots within human thought, they often reflect latent social stereotypes\\n(Suresh and Guttag, 2021; Garg et al., 2018). For example, the Social\\n∗ Correspondence to: School of Psychology, Queen’s University Belfast, Northern Ireland, UK.\\nE-mail addresses: a.kadan@qub.ac.uk (A. Kadan), deepaksp@acm.org (Deepak P.), sahely@iitpkd.ac.in (S. Bhadra), manjaryp_dcs@uoc.ac.in\\n(M. P. Gangan), lajish@uoc.ac.in (Lajish V.L.).\\n1 https://www.infoq.com/news/2021/01/google-microsoft-superhuman/.\\nRole Theory by Eagly and Steffen (1984) demonstrates that the idea of\\ngender stereotype develops from perceivers’ observations, associating\\nthe capabilities and personality attributes of different genders with the\\nactivities in which they engage in their day-to-day lives over time,\\nbuilding rigid stereotypes in human minds and their writings, on how\\nthese genders behave (e.g. women are highly emotional), where they\\nwork (e.g. women preferred in children’s daycare), etc. Hence the data'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 0, 'page_label': '1', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='these genders behave (e.g. women are highly emotional), where they\\nwork (e.g. women preferred in children’s daycare), etc. Hence the data\\nfrom such human generated data repositories eventually convey these\\nstereotypes as linguistic biases through the NLP algorithms (Raza et al.,\\n2024), especially those built on large PLMs that utilize huge amounts\\nof data (Suresh and Guttag, 2021).\\nIn this direction, investigation of ‘‘Affective Bias’’ in NLP is a re-\\ncent stream of research to study the existence of any unfair/biased\\nassociation of emotions (anger, fear, joy, etc.) or sentiments (positive,\\nnegative, etc.) towards underrepresented or protected groups in a\\ndomain, that may lead affective computing systems such as sentiment\\nor emotion detection systems to deliver unfavorable outcomes for these\\nhttps://doi.org/10.1016/j.nlp.2024.100062\\nReceived 5 November 2023; Received in revised form 6 January 2024; Accepted 1 March 2024'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 0, 'page_label': '1', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='https://doi.org/10.1016/j.nlp.2024.100062\\nReceived 5 November 2023; Received in revised form 6 January 2024; Accepted 1 March 2024\\n2949-7191/© 2024 The Author(s). Published by Elsevier B.V. This is an open access article under the CC BY-NC license\\n(http://creativecommons.org/licenses/by-nc/4.0/).'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 1, 'page_label': '2', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='A. Kadan, Deepak P., S. Bhadra et al. Natural Language Processing Journal 7 (2024) 100062\\nTable 1\\nDifferences in predicted emotion classes/intensities between sentences that differ only on a target term\\nrepresenting various social groups, indicating existence of ‘Affective Bias’.\\nSentence Emotion prediction\\nMen know how to drive Joy\\nWomen know how to drive Fear\\nWhite people are very ambitious as a whole Joy\\nBlack people are very ambitious as a whole Anger\\nTasha fell in love with the Christian man’s looks Joy\\nTasha fell in love with the Muslim man’s looks Fear\\nHe eventually wants to become a doctor Joy: 0.700\\nShe eventually wants to become a doctor Joy: 0.506\\nMy man friend made me feel alarmed Fear: 0.694\\nMy woman friend made me feel alarmed Fear: 0.750\\nMy queer friend made me feel alarmed Fear: 0.940\\nBlack people can dance very well Joy: 0.491\\nWhite people can dance very well Joy: 0.746\\nIt is always the Christian people who think their films are the best Joy: 0.996'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 1, 'page_label': '2', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='Black people can dance very well Joy: 0.491\\nWhite people can dance very well Joy: 0.746\\nIt is always the Christian people who think their films are the best Joy: 0.996\\nIt is always the Muslim people who think their films are the best Joy: 0.488\\nprotected groups (Anoop et al., 2022). For instance, a model consis-\\ntently associating women with a different class of emotion or same\\nemotion differing in emotion intensities vis-a-vis predictions for male\\n(Shields, 2002) could be seen as a manifestation of affective bias.\\nSimilarly, association of a particular religion always with a specific\\nemotion (Abid et al., 2021a) represents affective bias too. A real world\\nscenario of affective bias is the case of Google sentiment analyzer\\njudging that being gay is bad by assigning high negative sentiments\\nto sentences such as ‘ I’m a gay black woman’, ‘I’m a homosexual’, etc.,.2\\nFor better understandability of affective bias, we illustrate in Table 1,'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 1, 'page_label': '2', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='to sentences such as ‘ I’m a gay black woman’, ‘I’m a homosexual’, etc.,.2\\nFor better understandability of affective bias, we illustrate in Table 1,\\na sample set of affectively biased emotion predictions from PLM based\\ntextual emotion detection models constructed in this study for affective\\nbias analysis (detailed explanation of the models are provided in Sec-\\ntion 4.1). The first set in the table demonstrates affective bias due to\\ndifferences in predicted emotion classes, whereas the second set shows\\naffective bias due to differences in predicted emotion intensities.\\nSimilar to other general algorithmic biases like gender bias, racial\\nbias, etc., a possible stimuli to affective biases are the latent emotion\\nbased stereotypes about different social groups in the data. Studies\\nreport that such emotion based stereotyping influence socialization\\nof emotions leading to propagation of stereotypes such as associating\\nwomen’s (or men’s) experiences and expressions being aligned with'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 1, 'page_label': '2', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='of emotions leading to propagation of stereotypes such as associating\\nwomen’s (or men’s) experiences and expressions being aligned with\\nfear and sadness (or anger and pride) (Plant et al., 2000). Similarly,\\naffective bias within systems could facilitate a higher association of\\nblack women to the emotion anger when considering emotions with\\nthe domains race and gender (Ashley, 2014). In addition to biased\\ndata, another reason for bias is based on how the model/algorithmic\\ndesign considers or treats the underrepresented or protected attributes\\nconcerning a domain (Hooker, 2021). Similar to any other general\\nsocial biases, the existence of these affective biases make textual af-\\nfective computing systems generate unfair or biased decisions that can\\nharm its utility towards socially marginalized populations by denying\\nopportunities/resources or by false portrayal of these groups when\\ndeployed in the real-world. Hence, understanding affective bias in NLP'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 1, 'page_label': '2', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='opportunities/resources or by false portrayal of these groups when\\ndeployed in the real-world. Hence, understanding affective bias in NLP\\n2 https://www.vice.com/en/article/j5jmj8/google-artificial-intelligence-\\nbias.\\nplays a vital role in achieving algorithmic fairness, by protecting the\\nsocio-political and moral equality of marginalized groups.\\nIn this context, we present an extensive experimental analysis to\\nunderstand and illustrate the existence of latent ‘‘Affective Bias’’ in\\ntransformer based large PLMs 3 with respect to the downstream task\\nof textual emotion detection. Hence, we set our research question: Do\\npredictions made by large PLM based textual emotion detection sys-\\ntems systematically or consistently exemplify ‘Affective Bias’ towards\\ndemographic groups?Our investigation of affective bias in large PLMs\\nprimarily aims to identify the existence of gender, racial, and religious\\naffective biases and set aside the task of affective bias mitigation in'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 1, 'page_label': '2', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='primarily aims to identify the existence of gender, racial, and religious\\naffective biases and set aside the task of affective bias mitigation in\\nthe scope for future work. We start with an exploration of corpus level\\naffective bias or affect imbalance in corpus to find out any biased emo-\\ntion associations in the large scale corpora that are used to pre-train and\\nfine-tune the PLMs, by analyzing the distribution of emotions or their\\nassociations with demographic target terms (e.g., Islam, Quran) related\\nto a social group (e.g., Muslim) concerning a domain (e.g., Religion).\\nLater, we explore the prediction level affective bias in four popular\\ntransformer based PLMs, BERT (Bidirectional Encoder Representation\\nfrom Transformers) (Devlin et al., 2019), OpenAI GPT-2 (Generative\\nPre-trained Transformer) (Radford et al., 2019), XLNet (Yang et al.,\\n2019), and T5 (Text-to-Text Transfer Transformer) (Raffel et al., 2020),\\nthat are fine-tuned using a popular corpora SemEval-2018 EI-oc (Mo-'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 1, 'page_label': '2', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='2019), and T5 (Text-to-Text Transfer Transformer) (Raffel et al., 2020),\\nthat are fine-tuned using a popular corpora SemEval-2018 EI-oc (Mo-\\nhammad et al., 2018) for the task of textual emotion detection. To\\nquantify prediction level affective bias, we subject the PLMs to an\\nextensive set of class-based and intensity-based evaluations using three\\ndifferent evaluation corpora EEC (Kiritchenko and Mohammad, 2018),\\nBITS (Venkit and Wilson, 2021) and CSP (Nangia et al., 2020). A\\ndetailed sketch of the overall analysis is shown in Fig. 1.\\nThe rest of the paper is organized as follows. Section 2 presents\\nthe relevant related works. Section 3 presents corpus level affective\\n3 Even though, the current interpretation of large language models seems to\\nbe changing to billions of parameters (for e.g., LLaMA (Touvron et al., 2023),\\nFLAN-T5 XXL (Chung et al., 2022), etc.), there are works that utilize the term\\n‘large PLMs’ to indicate PLMs trained on millions of parameters (e.g., Navigli'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 1, 'page_label': '2', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='FLAN-T5 XXL (Chung et al., 2022), etc.), there are works that utilize the term\\n‘large PLMs’ to indicate PLMs trained on millions of parameters (e.g., Navigli\\net al. (2023)). In this study also, we use the term ‘large PLMs’ in the context\\nof having a PLM trained on millions of parameters.\\n2'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 2, 'page_label': '3', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='A. Kadan, Deepak P., S. Bhadra et al. Natural Language Processing Journal 7 (2024) 100062\\nFig. 1. Workflow of Affective bias analysis.\\nbias analysis with corresponding methodology and results. Section 4\\npresents the exploration towards prediction level affective bias with\\ndetails of constructing PLM based textual emotion detection model,\\nmethodology of analysis, and the corresponding results. Section 5\\npresents a discussion based on the entire results and finally, Section 6\\ndraws the conclusions.\\n2. Related works\\nHere we review two categories of algorithmic bias analysis pertinent\\nto our work, i.e., the general affect-agnostic bias analysis and affect-\\noriented bias analysis, and demarcate our work from these related\\nworks.\\n2.1. General affect agnostic bias analysis\\nRecent works in the literature have focused on several approaches\\nto identify the existence of latent biases in PLMs by inspecting at\\nvarious levels, commencing from bias analysis at the corpus level to the'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 2, 'page_label': '3', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='to identify the existence of latent biases in PLMs by inspecting at\\nvarious levels, commencing from bias analysis at the corpus level to the\\ndownstream-task level (Anoop et al., 2022; Suresh and Guttag, 2021).\\nWorks addressing bias at the corpus level analyze the terms relating\\na domain and their associations with key terms against which bias\\nis examined, e.g., the association between gender and stereotypically\\ngendered occupation terms (Bordia and Bowman, 2019; Tan and Celis,\\n2019). In model level analysis, bias are quantified using various metrics\\ndepending on the tasks, where evaluating geometry of the word vector\\nspace (Bolukbasi et al., 2016), performing association tests such as\\nWord Embedding Association Test (Caliskan et al., 2017) and Sentence\\nEncoder Association Test (May et al., 2019), measuring bias of classifi-\\ncation tasks using demographic parity and equal opportunity (Du et al.,\\n2021), etc., are popular approaches in the literature. At the downstream'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 2, 'page_label': '3', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='cation tasks using demographic parity and equal opportunity (Du et al.,\\n2021), etc., are popular approaches in the literature. At the downstream\\ntask level, bias is quantified by comparing the performance scores of a\\nmodel for a set of sentence pairs in an evaluation corpus that differs\\nonly on target terms in which the domain of bias is being studied.\\nFor example, comparing performances of a model for gender-swapped\\nsentences like ‘She is here’ versus ‘He is here’, where the model exhibits\\ngender bias if it produces different performance scores for both sets\\nof sentence pairs. Bias identification at the downstream task level is\\nexplored for a variety of tasks like identification of toxic comments\\n(Dixon et al., 2018), text generation (Nadeem et al., 2021), coreference\\nresolution (Zhao et al., 2018; Lu et al., 2020), etc.\\n2.2. Affect-oriented bias analysis\\nMost affect-oriented bias analysis studies in the literature predom-'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 2, 'page_label': '3', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='resolution (Zhao et al., 2018; Lu et al., 2020), etc.\\n2.2. Affect-oriented bias analysis\\nMost affect-oriented bias analysis studies in the literature predom-\\ninantly focus on the coarse-grained sentiment perspective of these\\nbiases (i.e. positive, negative, and neutral sentiments), and that too\\nmostly specific to gender domain (Yang et al., 2021; Bhaskaran and\\nBhallamudi, 2019; Rozado, 2020; Shen et al., 2018; Sweeney and\\nNajafian, 2020). But, affective bias in context of fine-grained emotion\\nclasses like anger, fear, joy, etc., and the variability of these biases\\nin diverse domains such as religion, politics, race, or intersectional\\nbiases, are not well explored (Anoop et al., 2022), except in Kiritchenko\\nand Mohammad (2018) and Venkit and Wilson (2021). In Kiritchenko\\nand Mohammad (2018) Kiritchenko and Mohammad identify affective\\nbias in the emotion prediction systems developed for the shared task\\nSemEval-2018 Task 1 Affect in Tweets, and in Venkit and Wilson (2021)'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 2, 'page_label': '3', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='bias in the emotion prediction systems developed for the shared task\\nSemEval-2018 Task 1 Affect in Tweets, and in Venkit and Wilson (2021)\\nVenkit et al. identifies affective bias in the domain of persons with\\ndisabilities in sentiment analysis and toxicity classification models; both\\nthese works use a synthetics evaluation corpus to identify affective bias.\\nAffect-oriented bias analysis are seen to be conducted in lexicon\\nand deep learning based sentiment analysis systems (Shen et al., 2018;\\nZhiltsova et al., 2019), and in non-contextual word embeddings such as\\nFastText, GloVe, and Word2Vec to address bias in sentiment analysis\\nand toxicity classification (Sweeney and Najafian, 2020), age-related\\nbias (Díaz et al., 2018) and other underreported bias types (Rozado,\\n2020). Recently several works also address bias in contextual repre-\\nsentations of large PLMs. But most of these works in PLMs address\\ngeneral affect-agnostic biases (Liang et al., 2021; Nadeem et al., 2021;'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 2, 'page_label': '3', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='sentations of large PLMs. But most of these works in PLMs address\\ngeneral affect-agnostic biases (Liang et al., 2021; Nadeem et al., 2021;\\nTan and Celis, 2019; Zhao et al., 2019), very few works address affect-\\noriented biases in PLMs through sentiment perspective (Bhaskaran and\\nBhallamudi, 2019; Yang et al., 2021; Huang et al., 2020), and to our\\nbest knowledge only the work in Mao et al. (2022) investigates affective\\nbias in large PLMs through the perspective of fine-grained emotions, so\\nfar, and that too specifically in prompt-based sentiment and emotion\\ndetection tasks.\\n2.3. Our work in context\\nTo put our work in context, we conduct experiments to identify\\naffective bias in large PLMs through the perspective of fine-grained\\nemotions. Hence, as a natural first step, we consider textual emotion\\ndetection systems, unlike the considerable amount of bias analysis\\nworks in large PLMs relying on text generation, coreference resolution,\\n3'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 3, 'page_label': '4', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='A. Kadan, Deepak P., S. Bhadra et al. Natural Language Processing Journal 7 (2024) 100062\\nprompt-based classification, etc., Mao et al. (2022), Liang et al. (2021),\\nNadeem et al. (2021) and Huang et al. (2020). Our work, in particular,\\nconsiders investigating affective bias in transformer based large PLMs\\ndue to their wide applicability in developing textual emotion detection\\nsystems (Acheampong et al., 2021). Distinct from the recent work (Mao\\net al., 2022) that addresses affective bias in PLMs with respect to label-\\nword, prompt template, etc., specifically focusing on prompt-based\\nsentiment and emotion detection, our work investigates affective bias\\nin four different PLMs with respect to the domains gender, race, and\\nreligion, focusing on fine-tuning based emotion classification. Unlike\\nthe works (Venkit and Wilson, 2021; Kiritchenko and Mohammad,\\n2018) addressing affective bias, we start our investigation from the very'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 3, 'page_label': '4', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='the works (Venkit and Wilson, 2021; Kiritchenko and Mohammad,\\n2018) addressing affective bias, we start our investigation from the very\\ninitial stage of corpus level affective bias analysis, inspired by the works\\n(Bordia and Bowman, 2019; Tan and Celis, 2019) that address corpus\\nlevel general affect-agnostic biases, and later we progress towards\\nanalyzing affective bias in predictions of the PLM based textual emotion\\ndetection models. We conduct a much broader intensity based and class\\nbased affective bias analysis using a set of synthetic (template based)\\nevaluation corpora as well as non-synthetic (crowdsourced) evaluation\\ncorpus that much more suits the real-world scenario.\\n3. Corpus level affective bias\\nThe existence of bias in PLM based language processing systems are\\nobserved due to many sources such as data, annotation, representa-\\ntions, model, etc. (Anoop et al., 2022; Hovy and Prabhumoye, 2021).\\nA substantial amount of works that address general social biases on'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 3, 'page_label': '4', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='tions, model, etc. (Anoop et al., 2022; Hovy and Prabhumoye, 2021).\\nA substantial amount of works that address general social biases on\\ngender and race lines report the existence of data bias from innate\\nhistorical biases as the most primeval source of bias (Corbett-Davies\\net al., 2017; Bordia and Bowman, 2019; Tan and Celis, 2019; Zhao\\net al., 2019). To the best of our knowledge, this is the first attempt\\nthat explore affective bias in large scale textual corpora utilized by\\nPLMs. Hence, as an initial step to explore the affective bias, we conduct\\nexperiments to understand the existence of affective bias if any, in the\\npre-training corpora that are integral ingredients of large PLMs and\\nfine-tuning corpora used to build the textual emotion detection systems.\\nData quality issues, uneven distributions of data, and class imbal-\\nances that target marginalized groups, etc., are the root factors that\\ncontribute towards data bias (Navigli et al., 2023; Hovy and Prab-'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 3, 'page_label': '4', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='ances that target marginalized groups, etc., are the root factors that\\ncontribute towards data bias (Navigli et al., 2023; Hovy and Prab-\\nhumoye, 2021; Subramanian et al., 2021; Anoop et al., 2022). Many\\nworks that address affect agnostic biases focus on exploring data bias by\\nunderstanding any uneven distributions of the target terms associated\\nwithin the domain of interest (Tan and Celis, 2019; Zhao et al., 2019).\\nMotivated by these lines of works, as an initial attempt to unveil the\\ncorpus level affective bias, we follow this simple approach of analyzing\\nthe distributions of affective target terms. A detailed description of pre-\\ntraining and fine-tuning corpora, the method to measure corpus level\\naffective bias, and the analysis of corpus level affective bias are given\\nbelow.\\n3.1. Training corpora\\nOur choice of large scale datasets for corpus level affective bias\\nanalysis hinges on the large PLMs, BERT (Devlin et al., 2019), GPT-2'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 3, 'page_label': '4', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='below.\\n3.1. Training corpora\\nOur choice of large scale datasets for corpus level affective bias\\nanalysis hinges on the large PLMs, BERT (Devlin et al., 2019), GPT-2\\n(Radford et al., 2019), XLNet (Yang et al., 2019), and T5 (Raffel et al.,\\n2020). BERT is trained on Wikipedia dump (WikiEn)4 and BookCorpus\\n(Zhu et al., 2015), GPT-2 is trained on WebText (Radford et al., 2019),\\nXLNet is trained on WikiEn, BookCorpus, Giga5, 5 ClueWeb6 and Com-\\nmon Crawl,7 and T5 is trained on Colossal Clean Crawled Corpus (C4).8\\n4 https://dumps.wikimedia.org/enwiki/.\\n5 https://catalog.ldc.upenn.edu/LDC2011T07.\\n6 https://lemurproject.org/clueweb12/index.php.\\n7 http://commoncrawl.org/.\\n8 https://www.tensorflow.org/datasets/catalog/c4.\\nTable 2\\nDetails of training corpora used for corpus level affective bias analysis.\\nCorpus Size Number of PLM\\nsentences BERT GPT-2 XLNet a T5\\nPre-training corpora\\nWikiEn 19.8 GB 95 917 189 ✓ ✓\\nBookCorpus 6.19 GB 91 025 872 ✓ ✓\\nWebText-250 620 MB 5 314 965 ✓'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 3, 'page_label': '4', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='Corpus Size Number of PLM\\nsentences BERT GPT-2 XLNet a T5\\nPre-training corpora\\nWikiEn 19.8 GB 95 917 189 ✓ ✓\\nBookCorpus 6.19 GB 91 025 872 ✓ ✓\\nWebText-250 620 MB 5 314 965 ✓\\nC4-Val 731 MB 4 959 563 ✓\\nFine-tuning corpora\\nSemEval-2018 925 KB 10 030\\na Giga5, ClueWeb, & Common Crawl used to pre-train XLNet are omitted.\\nFrom these set of large-scale pre-training datasets, we chose WikiEn, 9\\nBookCorpus, WebText, and C4, for our study. The details regarding size\\nof these corpora and number of sentences are shown in Table 2. We\\nomit Giga5 and ClueWeb due to their unavailability as open-source\\ncorpora and Common Crawl as it is reported to have significant data\\nquality issues due to a large number of unintelligible document content\\n(Trinh and Le, 2018; Radford et al., 2019). Since BookCorpus 10 is no\\nlonger hosted by the authors, we choose its open version available in\\nHugging Face.11 We make use of the partially released 250K documents'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 3, 'page_label': '4', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='longer hosted by the authors, we choose its open version available in\\nHugging Face.11 We make use of the partially released 250K documents\\nfrom WebText test set, similar to Tan and Celis (2019), since WebText\\ncorpora has not been fully released and call it WebText-250. 12 As\\nthe train split of C4 corpus is very large (305 GB with 364868892\\ndocuments) and cumbersome to process, we use only a part of the\\ncorpus, i.e., the validation split, and call it C4-Val. Apart from the above\\nmentioned pre-training datasets, we also consider SemEval-2018 EI-oc\\n(Mohammad et al., 2018) that is used to fine-tune the textual emotion\\ndetection model, for our analysis.\\n3.2. Measuring corpus level affective bias\\nInspired by the recent methods to identify gender bias in datasets\\nwith respect to occupations (Tan and Celis, 2019; Zhao et al., 2019), we\\nidentify the existence of affective bias in the large scale corpora used to\\ntrain large PLMs with respect to various domains such as gender, race,'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 3, 'page_label': '4', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='identify the existence of affective bias in the large scale corpora used to\\ntrain large PLMs with respect to various domains such as gender, race,\\nand religion. That is, for a corpus, we identify any imbalances in the\\ndistribution of emotions, or any imbalanced association of the emotions\\ntowards social groups within a domain. Accordingly, for each corpus,\\nwe measure the occurrence of emotion terms representing or related\\nto an emotion and their co-occurrence or association with target terms\\nrepresenting a social group in a domain.\\nAlgorithm 1 illustrates the method of computing occurrence and\\nco-occurrence for a training corpora 𝐷 that is considered as a set of\\nsentences [𝑆1,𝑆2,𝑆3,…] derived from documents in the corpus, where\\neach sentence consists of a sequence of words[𝑤1,𝑤2,𝑤3,…]. The algo-\\nrithm sifts through each word in the sentences of the corpus 𝐷. Once\\na word belonging to the set of emotion terms related to an emotion'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 3, 'page_label': '4', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='rithm sifts through each word in the sentences of the corpus 𝐷. Once\\na word belonging to the set of emotion terms related to an emotion\\n𝐸 (i.e., 𝐸𝑡𝑒𝑟𝑚𝑠) is encountered in a sentence, the algorithm increments\\nthe occurrence of that emotion 𝑜𝑐𝑐𝐸, for that corpus. Similarly in a\\nsentence, once a word related to the emotion 𝐸 co-occurs with a\\nterm belonging to the set of target terms related to a social group 𝑇\\nin a domain (i.e., 𝑇𝑡𝑒𝑟𝑚𝑠), the algorithm increments the co-occurrence\\nof that emotion with the corresponding social group 𝑐𝑜𝑜𝑐𝑐𝑇\\n𝐸, for that\\ncorpus. For example, we increment the occurrence of the emotion Joy\\n(i.e., 𝑜𝑐𝑐𝑗𝑜𝑦), for a corpus, once an emotion term related to Joy like\\n‘happy’, ‘bliss’, ‘cheer’, etc., is encountered in a sentence of the corpus.\\nWe increment the co-occurrence of Joy-Male (i.e., 𝑐𝑜𝑜𝑐𝑐𝑚𝑎𝑙𝑒\\n𝑗𝑜𝑦 ), for the\\n9 Latest Wikipedia dump (date: 02/June/2022), extracted using https://\\ngithub.com/attardi/wikiextractor.\\n10 https://yknzhu.wixsite.com/mbweb.'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 3, 'page_label': '4', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='𝑗𝑜𝑦 ), for the\\n9 Latest Wikipedia dump (date: 02/June/2022), extracted using https://\\ngithub.com/attardi/wikiextractor.\\n10 https://yknzhu.wixsite.com/mbweb.\\n11 https://huggingface.co/datasets/bookcorpus.\\n12 https://github.com/openai/gpt-2-output-dataset.\\n4'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 4, 'page_label': '5', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='A. Kadan, Deepak P., S. Bhadra et al. Natural Language Processing Journal 7 (2024) 100062\\ncorpus, if an emotion term related to Joy co-occurs with target terms\\nrelated to the social group Male like ‘husband’, ‘boy’, ‘brother’, etc.,\\nand increment the co-occurrence of Joy-Female (i.e., 𝑐𝑜𝑜𝑐𝑐𝑓𝑒𝑚𝑎𝑙𝑒\\n𝑗𝑜𝑦 ) if an\\nemotion term related to Joy co-occurs with target terms related to the\\nsocial group Female like ‘wife’, ‘girl’, ‘sister’, etc., in a sentence of the\\ncorpus. Finally, for each social group in a domain, the co-occurrence\\nvalues with respect to each emotion are expressed in percentages.\\nAlgorithm 1:Occurrence and Co-occurrence\\ninput : Corpus 𝐷\\nEmotion terms for emotion 𝐸 (𝐸𝑡𝑒𝑟𝑚𝑠)\\nTarget terms for social group 𝑇 (𝑇𝑡𝑒𝑟𝑚𝑠)\\noutput : Emotion occurrence 𝑜𝑐𝑐𝐸\\nEmotion and Social group co-occurrence 𝑐𝑜𝑜𝑐𝑐𝑇\\n𝐸\\n1 Let 𝐷= [𝑆1,𝑆2,… ,𝑆𝑚] and 𝑆 = [𝑤1,𝑤2,… ,𝑤𝑛] ;\\n2 initialize 𝑜𝑐𝑐𝐸 = 0; 𝑐𝑜𝑜𝑐𝑐𝑇\\n𝐸 = 0; 𝑓𝑙𝑎𝑔 = 𝐹𝑎𝑙𝑠𝑒 ;\\n3 for (𝑗 = 1; 𝑗 ≤ 𝑚; 𝑗+ +)do\\n4 for (𝑖= 1; 𝑖≤ 𝑛; 𝑖+ +)do\\n5 if (𝑤𝑖 ∈ 𝐸𝑡𝑒𝑟𝑚𝑠) then'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 4, 'page_label': '5', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='𝐸\\n1 Let 𝐷= [𝑆1,𝑆2,… ,𝑆𝑚] and 𝑆 = [𝑤1,𝑤2,… ,𝑤𝑛] ;\\n2 initialize 𝑜𝑐𝑐𝐸 = 0; 𝑐𝑜𝑜𝑐𝑐𝑇\\n𝐸 = 0; 𝑓𝑙𝑎𝑔 = 𝐹𝑎𝑙𝑠𝑒 ;\\n3 for (𝑗 = 1; 𝑗 ≤ 𝑚; 𝑗+ +)do\\n4 for (𝑖= 1; 𝑖≤ 𝑛; 𝑖+ +)do\\n5 if (𝑤𝑖 ∈ 𝐸𝑡𝑒𝑟𝑚𝑠) then\\n6 𝑓𝑙𝑎𝑔 = 𝑇𝑟𝑢𝑒;\\n7 𝑜𝑐𝑐𝐸 = 𝑜𝑐𝑐𝐸 + 1;\\n8 break;\\n9 end\\n10 end\\n11 for (𝑖= 1; 𝑖≤ 𝑛; 𝑖+ +)do\\n12 if (𝑤𝑖 ∈ 𝑇𝑡𝑒𝑟𝑚𝑠 and 𝑓𝑙𝑎𝑔 = 𝑇𝑟𝑢𝑒) then\\n13 𝑐𝑜𝑜𝑐𝑐𝑇\\n𝐸 = 𝑐𝑜𝑜𝑐𝑐𝑇\\n𝐸 + 1;\\n14 break;\\n15 end\\n16 end\\n17 end\\n18 output 𝑜𝑐𝑐𝐸, 𝑐𝑜𝑜𝑐𝑐𝑇\\n𝐸\\nTo conduct this study on corpus level affective bias, we maintain\\na list of emotion terms (or affective terms) for the basic emotions\\n𝐸 = {𝑎𝑛𝑔𝑒𝑟,𝑓𝑒𝑎𝑟,𝑗𝑜𝑦,𝑠𝑎𝑑𝑛𝑒𝑠𝑠 }, because our emotion prediction models\\n(discussed in Section 4.1, to identify affective bias in model predic-\\ntions) relies on these categories of basic emotions. Hence, initially, we\\nprocure a list of affective terms collectively from Parrott’s primary,\\nsecondary, and tertiary emotions,13 and refer the works Kiritchenko and\\nMohammad (2018) and Venkit and Wilson (2021), to represent these'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 4, 'page_label': '5', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='secondary, and tertiary emotions,13 and refer the works Kiritchenko and\\nMohammad (2018) and Venkit and Wilson (2021), to represent these\\nbasic emotions. Later, we extend this list of affective terms by including\\nlinguistic inflections of each word in the list using Merriam-Webster 14\\ndictionary and an automated python package pyinflect. 15 As a result\\nthe entire list contains 735 affective terms (given in supplementary\\nmaterial), where 162 represent anger, 143 fear, 222 joy, and 208\\nsadness.\\nA similar procedure is carried out to procure target terms related to\\na social group within gender, race, and religion, the domains that are\\nconsidered in this study. In domain gender, the target terms considered\\nrepresent three social groups 𝑇 = {𝑀,𝐹,𝑁𝑏 } for Male, Female, and\\nNon-binary groups. Similarly in domain race, we consider European\\nAmerican and African American social groups i.e., 𝑇 = {𝐸𝐴,𝐴𝐴}, and\\nfor religion, we consider Christian, Muslim, and Jewish social groups'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 4, 'page_label': '5', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='American and African American social groups i.e., 𝑇 = {𝐸𝐴,𝐴𝐴}, and\\nfor religion, we consider Christian, Muslim, and Jewish social groups\\ni.e., 𝑇 = { 𝐶ℎ,𝑀𝑢,𝐽𝑤 }. An initial list of target terms representing\\nthese social groups is prepared collectively by referring to the works\\n(Bolukbasi et al., 2016; Lu et al., 2020; Guo and Caliskan, 2021;\\nNadeem et al., 2021; Liang et al., 2021; Kaneko and Bollegala, 2022),\\nwhich is later expanded by adding linguistic inflections. As these works\\ndo not consider target terms related to the non-binary social group\\nin the gender domain, we manually curated the corresponding target\\n13 https://en.wikipedia.org/wiki/Emotion_classification#Parrott’s_emotions_\\nby_groups.\\n14 https://www.merriam-webster.com/.\\n15 https://pypi.org/project/pyinflect/.\\nterms from various articles and web resources (e.g. Center (2022)) and\\nverified these terms with the help of an expert in gender studies. The\\nentire list contains 507, 167, and 332 target terms in the domains'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 4, 'page_label': '5', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='verified these terms with the help of an expert in gender studies. The\\nentire list contains 507, 167, and 332 target terms in the domains\\nof gender, race, and religion, respectively (given in supplementary\\nmaterial), with 199 male, 211 female, and 97 non-binary target terms\\nfor the gender domain, 82 African American and 85 European American\\ntarget terms for the racial domain, and 122 Muslim, 111 Jewish, and\\n99 Christian target terms for the religious domain.\\n3.3. Results and analysis of corpus level affective bias\\nIn this section, we present the results of occurrence of emotions\\nin the corpora and their co-occurrence with social groups in various\\ndomains of gender, race, and religion to analyze corpus level affective\\nbias.\\n3.3.1. Occurrence of emotions in the corpora\\nResults of the occurrence statistics of emotions for our corpus level\\naffective bias analysis are shown in Table 3. The trends of emotion\\noccurrence illustrate that, for all the corpora, the occurrence of affective'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 4, 'page_label': '5', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='affective bias analysis are shown in Table 3. The trends of emotion\\noccurrence illustrate that, for all the corpora, the occurrence of affective\\nterms related to joy is consistently higher than all other emotions;\\nescalating joy from the next highest occurring emotionsfear and sadness\\nminimally by a factor of 1.1 in SemEval-2018 EI-oc and maximum by\\na factor of 5.6 in C4-Val, respectively. The predominance of joy in\\ntextual corpora can be possibly due to the reason that, psychologically\\npeople are inclined towards expressing more positive emotions on the\\nweb (Vittengl and Holt, 1998; De Choudhury et al., 2012; Staiano and\\nGuerini, 2014; Waterloo et al., 2018). On the other side, for all the\\ncorpora, the instances of anger are consistently very low in count. The\\nstandard deviation computed to measure the dispersion between the\\noccurrence of various emotions within a corpus shows that there exists\\na large disparity between the occurrence of emotions within a corpus,'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 4, 'page_label': '5', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='occurrence of various emotions within a corpus shows that there exists\\na large disparity between the occurrence of emotions within a corpus,\\nparticularly in the large scale corpora used to pre-train PLMs. In total,\\nthe occurrence statistics over the four basic emotions anger, fear, joy\\nand sadness, clearly affirms the existence of emotion imbalances in both\\nPLM pre-training and fine-tuning corpora.\\nBookCorpus contains the highest number of total affective words\\namong all other corpora considered. This brings to another observation\\nthat despite BookCorpus being almost one-third of the size of WikiEn,\\nthe number of affective words in BookCorpus exceeds WikiEn by a\\nfactor of 1.3. We presume this is because BookCorpus being a large\\ncorpus curated from books in the web, contains more affective words\\nthan WikiEn curated from Wikipedia articles in the web.\\n3.3.2. Co-occurrence of emotions with social groups\\nThe co-occurrence statistics of basic emotions with various social'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 4, 'page_label': '5', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='than WikiEn curated from Wikipedia articles in the web.\\n3.3.2. Co-occurrence of emotions with social groups\\nThe co-occurrence statistics of basic emotions with various social\\ngroups in gender, racial and religious domains for each corpus is\\nillustrated in Table 4, where the domains are separated column wise\\nand emotions are grouped across the rows. We look into each domain\\nseparately, (in the order of gender, race, and religion) and analyze the\\nassociation of emotion categories (in the order of anger, fear, joy, and\\nsadness) with social groups in these domains.\\n(A) Emotion Co-occurrence with Gender Domain: In the gender do-\\nmain, anger mostly co-occurs with the non-binary and female\\nsocial groups than male. Fear is always highly associated with\\nthe non-binary group, followed secondly by female. The positive\\nemotion joy is found to mostly co-occur with male, but, it has\\nthe least co-occurrence with non-binary gender. Sadness mostly'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 4, 'page_label': '5', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='the non-binary group, followed secondly by female. The positive\\nemotion joy is found to mostly co-occur with male, but, it has\\nthe least co-occurrence with non-binary gender. Sadness mostly\\nco-occurs with non-binary and female groups, similar to anger.\\nFor the fine-tuning corpus SemEval-2018, in particular, there\\nis no instance of co-occurrence between any of the emotions\\nand non-binary gender, this is due to the lack of non-binary\\ngender terms in the corpus; also, for this corpus, negative emo-\\ntions such as, anger, fear, and sadness are always found to have\\nhigh co-occurrence with female gender and the positive emotion\\n5'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 5, 'page_label': '6', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='A. Kadan, Deepak P., S. Bhadra et al. Natural Language Processing Journal 7 (2024) 100062\\nTable 3\\nOccurrence statistics of emotions in the corpora.\\nCorpus Anger Fear Joy Sadness Total affective words Standard deviation\\nWikiEn 533 111 745 221 2 479 326 1 802 466 5 560 124 914 103.94\\nBookCorpus 1 049 407 1 647 267 3 143 907 1 400 423 7 241 004 922 324.00\\nWebText-250k 50 207 85 325 220 354 88 749 444 635 74 851.63\\nC4-Val 33 182 66 239 394 413 69 686 563 520 169 821.19\\nSemEval-2018 984 1 472 1 579 1 131 5 166 280.21\\nTable 4\\nCo-occurrence statistics of basic emotions with various domains in corpora (in\\npercentage).\\nCorpus Co-occurrence with\\nGender Race Religion\\nM F Nb EA AA Ch Mu Jw\\nAnger\\nWikiEn 12.12 13.41 14.25 10.44 10.68 8.55 11.69 13.93\\nBookCorpus 17.61 16.15 19.02 15.09 17.06 12.20 13.74 18.64\\nWebText-250k 14.13 14.24 11.46 15.05 16.53 12.86 15.05 19.55\\nC4-Val 9.32 9.08 6.02 7.06 7.71 6.22 11.19 13.49\\nSemEval-2018 22.36 24.56 0 22.55 52.17 15.79 15.06 0\\nFear'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 5, 'page_label': '6', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='WebText-250k 14.13 14.24 11.46 15.05 16.53 12.86 15.05 19.55\\nC4-Val 9.32 9.08 6.02 7.06 7.71 6.22 11.19 13.49\\nSemEval-2018 22.36 24.56 0 22.55 52.17 15.79 15.06 0\\nFear\\nWikiEn 12.61 15.09 21.01 14.73 14.62 9.81 17.03 16.05\\nBookCorpus 22.03 24.00 25.05 23.09 23.52 14.65 21.42 16.44\\nWebText-250k 19.56 21.80 23.02 21.11 21.02 16.66 36.00 28.39\\nC4-Val 13.95 13.79 16.87 13.56 13.46 9.33 23.09 19.70\\nSemEval-2018 25.36 26.06 0 31.37 10.87 36.84 62.16 75.00\\nJoy\\nWikiEn 40.81 40.81 39.18 45.46 45.31 51.94 36.47 41.93\\nBookCorpus 41.09 40.01 38.40 44.01 41.07 51.12 44.53 40.77\\nWebText-250k 44.25 40.01 42.79 43.69 42.44 47.54 25.06 27.53\\nC4-Val 57.76 61.28 55.42 63.49 63.95 68.05 44.28 45.75\\nSemEval-2018 33.53 30.83 0 34.31 13.04 27.02 12.16 25.00\\nSadness\\nWikiEn 34.46 30.70 25.56 29.37 29.38 29.70 34.81 28.09\\nBookCorpus 19.76 19.84 21.02 18.11 18.55 22.03 20.30 24.14\\nWebText-250k 24.05 25.25 20.83 20.75 20.51 22.94 24.09 24.52\\nC4-Val 18.96 16.95 21.69 15.89 14.88 16.40 21.44 21.05'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 5, 'page_label': '6', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='BookCorpus 19.76 19.84 21.02 18.11 18.55 22.03 20.30 24.14\\nWebText-250k 24.05 25.25 20.83 20.75 20.51 22.94 24.09 24.52\\nC4-Val 18.96 16.95 21.69 15.89 14.88 16.40 21.44 21.05\\nSemEval-2018 17.75 19.05 0 11.76 23.91 21.05 10.81 0\\njoy is found to have high co-occurrence with male. The over-\\nall co-occurrence statistics of the gender domain illustrate that\\nnegative emotions mostly co-occur with the non-binary gender\\ngroup, followed by female, and conversely, positive emotions\\nco-occur mostly with the male group. The observations thus\\nclearly dictate imbalanced associations between affective terms\\nand social groups of gender domain, in both pre-training and\\nfine-tuning corpora.\\n(B) Emotion Co-occurrence with Racial Domain: Evaluation results\\nover the racial domain illustrate that the negative emotions\\nanger and sadness mostly co-occur with African American race\\ngroup, whereas negative emotion fear and the positive emotion\\njoy mostly co-occur with European American. But, for all the'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 5, 'page_label': '6', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='anger and sadness mostly co-occur with African American race\\ngroup, whereas negative emotion fear and the positive emotion\\njoy mostly co-occur with European American. But, for all the\\npre-training corpora, the imbalance of co-occurrence values in\\nthe racial domain is comparatively less than the previously\\ndiscussed gender domain; for example, imbalance in the co-\\noccurrence of all emotions with the racial groups is negligible\\nin the case of WikiEn corpus. Contrary to the observations of\\npre-training corpora, in fine-tuning corpus SemEval-2018, there\\nexists a large difference in co-occurrence values between African\\nand European American groups. That is, in SemEval-2018, the\\nnegative emotions anger and sadness co-occur with the African\\nAmerican race double the times than European American, indi-\\ncating highly imbalanced association of anger and sadness with\\nAfrican American race. Whereas, the co-occurrence of negative\\nemotion fear and positive emotion joy with European American'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 5, 'page_label': '6', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='cating highly imbalanced association of anger and sadness with\\nAfrican American race. Whereas, the co-occurrence of negative\\nemotion fear and positive emotion joy with European American\\ngroup is almost thrice African American, again indicating a\\nhighly imbalanced association, that of fear and joy emotions in\\nSemEval-2018 with European American group.\\n(C) Emotion Co-occurrence with Religious Domain:Analysis in the do-\\nmain of religion shows that anger mostly co-occurs with Jewish\\nand fear mostly co-occurs with Muslim. Whereas, joy is always\\nfound to have maximum co-occurrence with Christian.Sadness is\\nfound to mostly co-occur with Muslim and Jew religious groups\\nthan Christian. The results thus shows existence of high co-\\noccurrence between negative emotions anger, fear, and sadness\\nwith Muslim and Jew, whereas the positive emotion joy with\\nChristian. Moreover, when considering previous observations\\nof gender and racial domains, the imbalance in the religious'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 5, 'page_label': '6', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='with Muslim and Jew, whereas the positive emotion joy with\\nChristian. Moreover, when considering previous observations\\nof gender and racial domains, the imbalance in the religious\\ndomain is comparatively higher.\\nThe entire occurrence and co-occurrence analysis over gender, race\\nand religious domains thus consolidate the existence of corpus level\\naffective bias in pre-training and fine-tuning corpora. The extensions of\\nsuch corpora holding latent affect imbalances, to build computational\\nmodels may eventually trigger chances of bias in learning models,\\nespecially when building large scale contextual pre-trained language\\nmodels that extract all possible properties of a language.\\n4. Prediction level affective bias\\nTo identify the existence of prediction level affective bias, if any,\\nin the perspective of large PLMs, we utilize textual emotion detection\\nsystems built using popular large PLMs that are fine-tuned using an\\nemotion detection corpus. We evaluate the existence of affective bias'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 5, 'page_label': '6', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='systems built using popular large PLMs that are fine-tuned using an\\nemotion detection corpus. We evaluate the existence of affective bias\\nin the context of domains gender, race, and religion via different\\nsynthetic and non-synthetic paired evaluation sentence corpora and\\nan extensive set of evaluation measures. Details of our investigation,\\nincluding description and settings of textual emotion detection models\\nbased on large PLMs, the method to measure prediction level affective\\nbias with the details of evaluation corpora and measures, and the\\nresults and analysis of prediction level affective bias, are given below.\\n4.1. Textual emotion detection using large PLMs\\nWe formulate the task of textual emotion detection as a four-class\\nclassification system with classes being the basic emotions anger, fear,\\njoy, and sadness. For this classification task, we utilize pre-trained lan-\\nguage models and fine-tune them with an aim to find the best-fit map-'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 5, 'page_label': '6', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='joy, and sadness. For this classification task, we utilize pre-trained lan-\\nguage models and fine-tune them with an aim to find the best-fit map-\\nping function 𝑓 ∶ 𝑦 = 𝑓(𝑥) for the fine-tuning data (𝑥1,𝑦1),(𝑥2,𝑦2),… ,\\n(𝑥𝑁,𝑦𝑁) with 𝑁 documents, where 𝑥𝑖 indicates ith document in the\\nfine-tuning corpus and 𝑦𝑖 indicates the corresponding ground-truth\\nemotion.\\nThe choice of PLMs, GPT-2 (Radford et al., 2019), BERT (De-\\nvlin et al., 2019), XLNet (Yang et al., 2019), and T5 (Raffel et al.,\\n2020), that are utilized in this study to identify affective bias, is\\nmotivated by considering their acceptance as relevant and neoteric\\ncontextualized models with high performance efficacy towards textual\\nemotion detection (Adoma et al., 2020; Acheampong et al., 2021)\\nand the much related task of sentiment analysis (Zhang et al., 2020;\\nTabinda Kokab et al., 2022) within the area of affective computing.\\nGPT and BERT are the very popular PLMs that follow the most ef-'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 5, 'page_label': '6', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='Tabinda Kokab et al., 2022) within the area of affective computing.\\nGPT and BERT are the very popular PLMs that follow the most ef-\\nfective auto-regressive and auto-encoding self-supervised pre-training\\nobjectives, respectively, where GPT uses transformer decoder blocks,\\nwhereas BERT uses transformer encoder blocks. The autoregressive\\n6'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 6, 'page_label': '7', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='A. Kadan, Deepak P., S. Bhadra et al. Natural Language Processing Journal 7 (2024) 100062\\nTable 5\\nFine-tuning corpus statistics.\\nEmotions Number of documents\\nTraining Validation\\nAnger 2089 388\\nFear 2641 389\\nJoy 1906 290\\nSadness 1930 397\\nnature of GPT helps to effectively encode sequential knowledge and\\nachieve good results (Radford et al., 2019). On the other hand, by\\neliminating the autoregressive objective and alleviating unidirectional\\nconstraints through the masked language model pre-training objective,\\nBERT attains powerful bi-directional representations. This ability of\\nBERT to learn context from both sides of a word makes it an empirically\\npowerful state-of-the-art model (Devlin et al., 2019). XLNet brings back\\nthe auto-regressive pre-training objective with alternate ways to extract\\ncontext from both sides of a word and overcome the pretrain-finetune\\ndiscrepancy of BERT outperforming it in several downstream NLP tasks'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 6, 'page_label': '7', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='context from both sides of a word and overcome the pretrain-finetune\\ndiscrepancy of BERT outperforming it in several downstream NLP tasks\\n(Yang et al., 2019). The development of T5 explores the landscape of\\nNLP transfer learning and proposes a unified framework that converts\\nall textual language related problems into the text-to-text format and\\nachieves improved performance (Raffel et al., 2020).\\nEach pre-trained language model (PLM) after fine-tuning and appli-\\ncation of softmax function at the final layer forms the textual emotion\\ndetection model (i.e., softmax(PLM)). For each textual document 𝑑, the\\nfine-tuned textual emotion detection models predict an emotion class\\n̂ 𝑒𝑐𝑙𝑎𝑠𝑠 by finding the highest prediction intensity score ̂ 𝑒𝑠𝑐𝑜𝑟𝑒 among 𝐸\\nclasses of emotions (namely anger, fear, joy, and sadness, for our task)\\nrepresented as,\\n̂ 𝑒𝑐𝑙𝑎𝑠𝑠(𝑑) = argmax\\n𝑘∈1,2,…,𝐸\\n𝑠𝑜𝑓𝑡𝑚𝑎𝑥(𝑃𝐿𝑀(𝑑)) (1)\\n̂ 𝑒𝑠𝑐𝑜𝑟𝑒(𝑑) = max\\n𝑘∈1,2,…,𝐸\\n𝑠𝑜𝑓𝑡𝑚𝑎𝑥(𝑃𝐿𝑀(𝑑)) (2)'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 6, 'page_label': '7', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='classes of emotions (namely anger, fear, joy, and sadness, for our task)\\nrepresented as,\\n̂ 𝑒𝑐𝑙𝑎𝑠𝑠(𝑑) = argmax\\n𝑘∈1,2,…,𝐸\\n𝑠𝑜𝑓𝑡𝑚𝑎𝑥(𝑃𝐿𝑀(𝑑)) (1)\\n̂ 𝑒𝑠𝑐𝑜𝑟𝑒(𝑑) = max\\n𝑘∈1,2,…,𝐸\\n𝑠𝑜𝑓𝑡𝑚𝑎𝑥(𝑃𝐿𝑀(𝑑)) (2)\\nTo fine-tune PLMs and build emotion detection models, we use\\n24-layered version of the pre-trained BERT, GPT-2, XLNet, and T5\\navailable at HuggingFace, 16 i.e., bert-large-uncased,17 gpt2-medium,18\\nxlnet-large-cased,19 and t5-large, 20 respectively, and update these ar-\\nchitectures by adding a final dense layer of four neurons with softmax\\nactivation function on top of the base models to suit our four class\\nclassification task. For our study, the choice of GPT-2 instead of the\\nlatest version GPT-3 (Brown et al., 2020) is due to its unavailability as\\nan open-source pre-trained model. All four models are fine-tuned using\\na popular affect detection corpus SemEval-2018 EI-oc (Mohammad\\net al., 2018) that consists a total of 10 030 data instances for the'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 6, 'page_label': '7', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='a popular affect detection corpus SemEval-2018 EI-oc (Mohammad\\net al., 2018) that consists a total of 10 030 data instances for the\\nemotions anger, fear, joy, and sadness. The fine-tuning corpus is split as\\n8566 data instances for training and 1464 data instances for validation;\\ndetails of the number of data instances belonging to each emotion\\ncategory in the train and validation splits are shown in Table 5.\\nThe hyperparameters that can aid the reproducibility of our emotion\\ndetection models are, for GPT-2, XLNet, and T5 we useAdam optimizer\\nwith learning rate 0.000001, categorical crossentropy loss function,\\nand 100 epochs, whereas for BERT the learning rate is 0.00001 and\\nrest of the above mentioned parameters are the same. The batch size\\nis set to 80 for BERT, XLNet, and T5, whereas 64 for GPT-2. The\\ntotal number of trainable parameters for our BERT, GPT-2, XLNet,\\nand T5 textual emotion detection models come out as 335145988,'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 6, 'page_label': '7', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='is set to 80 for BERT, XLNet, and T5, whereas 64 for GPT-2. The\\ntotal number of trainable parameters for our BERT, GPT-2, XLNet,\\nand T5 textual emotion detection models come out as 335145988,\\n354827268, 360272900, and 334943748, respectively. All experiments\\nwere conducted on a deep learning workstation equipped with Intel\\n16 https://huggingface.co/.\\n17 https://huggingface.co/docs/transformers/model_doc/bert.\\n18 https://huggingface.co/docs/transformers/model_doc/gpt2.\\n19 https://huggingface.co/docs/transformers/model_doc/xlnet.\\n20 https://huggingface.co/docs/transformers/model_doc/t5.\\nXeon Silver 4208 CPU at 2.10 GHz, 256 GB RAM, and two GPUs\\nof NVIDIA Quadro RTX 5000 (16 GB for each), using the libraries\\nTensorflow (version 2.8.0), Keras (version 2.8.0), Transformer (version\\n4.17.0), and NLTK (version 3.6.5).\\n4.2. Measuring prediction level affective bias\\nThe textual emotion detection models, when supplied with a docu-'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 6, 'page_label': '7', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='4.17.0), and NLTK (version 3.6.5).\\n4.2. Measuring prediction level affective bias\\nThe textual emotion detection models, when supplied with a docu-\\nment/sentence, predict as output the emotion class and corresponding\\nemotion intensity of the document/sentence. To identify prediction\\nlevel affective bias in textual emotion detection models, we input into\\nthese models a sentence pair that differs only in key terms representing\\ndifferent social groups, with an aim to compare and contrast between\\nemotion predictions of sentences in that pair. For instance, sentence\\npairs such as ‘ She made me feel angry’ versus ‘ He made me feel angry’\\nthat only differ in key terms representing female and male social groups\\nconcerning gender domain, or ‘ African American people can dance very\\nwell’ versus ‘ European American people can dance very well’ that only\\ndiffer in key terms representing African American and European Amer-\\nican social groups concerning racial domain, are input to the models'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 6, 'page_label': '7', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='differ in key terms representing African American and European Amer-\\nican social groups concerning racial domain, are input to the models\\nto compare and contrast between emotion predictions of sentences in\\nthese pairs. Comparing emotion predictions using such sentence pairs\\nhelps to pair-wise analyze and understand whether algorithmic deci-\\nsions of emotion classification are similar (or different) across different\\nsocial groups within a domain. Accordingly, to identify prediction level\\naffective bias, we use evaluation corpora that consist of sentence pairs\\ndiffering only in key terms representing various social groups.\\nThe prediction of emotion class for a sentence is decided by the\\nintensity of emotions predicted by the textual emotion detection model\\nfor that sentence. For example, for a prediction ̂𝐸𝑠𝑐𝑜𝑟𝑒(𝑑) = {0.5,0.2,\\n0.1,0.2}, the choice of emotion class from the set 𝐸 = {𝑎𝑛𝑔𝑒𝑟,𝑓𝑒𝑎𝑟,\\n𝑗𝑜𝑦,𝑠𝑎𝑑𝑛𝑒𝑠𝑠}, would be anger. Differences in the intensities of emotion'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 6, 'page_label': '7', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='0.1,0.2}, the choice of emotion class from the set 𝐸 = {𝑎𝑛𝑔𝑒𝑟,𝑓𝑒𝑎𝑟,\\n𝑗𝑜𝑦,𝑠𝑎𝑑𝑛𝑒𝑠𝑠}, would be anger. Differences in the intensities of emotion\\npredictions between sentences in a pair show existence of affective bias\\nat the intensity level, which when higher enough can alter the predic-\\ntion of emotion class and thereby cause affective bias at the class level.\\nThat is, an unbiased model is expected to predict the same emotion\\nclass and intensities for the sentence pairs that only differ in key terms\\nrepresenting different social groups. Hence, to analyze affective bias in\\nthe predictions, we utilize class based and intensity based evaluation\\nmeasures capable of comparing predictions of these sentence pairs. The\\nevaluation corpora and measures are detailed below.\\n4.2.1. Evaluation corpora\\nOur choice of bias evaluation corpora is based on the objective\\nto identify affective bias in textual emotion detection models using'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 6, 'page_label': '7', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='4.2.1. Evaluation corpora\\nOur choice of bias evaluation corpora is based on the objective\\nto identify affective bias in textual emotion detection models using\\nsentence pairs that only differ in key terms representing social groups,\\nconcerning either gender, racial, or religious domain. Suitably, we\\nutilize three different evaluation corpora, Equity Evaluation Corpus\\n(EEC) (Kiritchenko and Mohammad, 2018), Bias Identification Test\\nin Sentiments (BITS) corpus (Venkit and Wilson, 2021), and Crowd-\\nsourced Stereotype Pairs (CSP) corpus (Nangia et al., 2020). Similar\\nto most bias evaluation corpora, EEC and BITS contain template based\\nsynthetically created sentences along with ground truth emotions. On\\nthe contrary, CSP is a crowd sourced non-synthetic bias evaluation\\ncorpus that possesses greater diversity within data in the perspective\\nof context expressed and structure of sentence pairs, but it does not\\ncontain ground truth emotions.'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 6, 'page_label': '7', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='corpus that possesses greater diversity within data in the perspective\\nof context expressed and structure of sentence pairs, but it does not\\ncontain ground truth emotions.\\nEEC consists of a total of 8640 sentences capable of evaluating\\ngender and racial domains, from which we select 8400 sentences for\\nour study after excluding 240 sentences with no emotion words. For\\nthe gender domain, the sentence pairs in EEC represent only two social\\ngroups, female and male. To tease out affective bias towards the gender\\ndomain, we select 1400 sentence pairs. For the racial domain, the\\nsentence pairs represent African American and European American\\nsocial groups, and we select 2800 sentence pairs to analyze affective\\nbias in racial domain.\\n7'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 7, 'page_label': '8', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='A. Kadan, Deepak P., S. Bhadra et al. Natural Language Processing Journal 7 (2024) 100062\\nBITS consists of a total of 720 sentences capable of evaluating\\ngender and racial domains. In BITS, the sentence pairs for gender\\ndomain also include the non-binary social group besides female and\\nmale groups. For this study, we select the available 120 sentences\\nfor each non-binary, female, and male social group in the gender\\ndomain. The racial domain includes social groups such as American\\nIndian, Asian, and Latino, apart from African American and European\\nAmerican groups. For this study, we only select the available small\\nset of 72 sentence pairs representing African American and European\\nAmerican social groups, as we limit our investigation only to these two\\nracial groups.\\nCSP contains 1508 sentence pairs that cover nine domains, includ-\\ning gender, race, religion, age, nationality, etc., that, unlike EEC and\\nBITS, do not differ ‘only’ on a single key term. A sample sentence pair in'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 7, 'page_label': '8', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='ing gender, race, religion, age, nationality, etc., that, unlike EEC and\\nBITS, do not differ ‘only’ on a single key term. A sample sentence pair in\\nCSP for the racial domain is ‘African Americanpeople are notvery ambi-\\ntious as a whole’ versus ‘European Americanpeople arevery ambitious as a\\nwhole’. Such sentence pairs violate our evaluation setting of considering\\nsentence pairs that ‘only’ differ in key terms representing certain social\\ngroups, an evaluation strategy to identify bias. But considering the\\nusefulness of such a non-synthetic corpus that suits the real-world con-\\ntext, we manually evaluate all sentence pairs in CSP and modify them\\n(if required) to suit our evaluation settings. An example of modified\\nversions for the above mentioned sentence pair is, ‘ African American\\npeople are not very ambitious as a whole’ versus ‘European Americanpeople\\nare not very ambitious as a whole’, and ‘ African American people are'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 7, 'page_label': '8', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='people are not very ambitious as a whole’ versus ‘European Americanpeople\\nare not very ambitious as a whole’, and ‘ African American people are\\nvery ambitious as a whole’ versus ‘ European American people are very\\nambitious as a whole’. Finally, after such modifications and exclusion\\nof pairs belonging to domains other than gender, race, and religion,\\nwe gather 1970 sentences, where the gender domain consists of 263\\nsentence pairs representing female and male, the racial domain consists\\nof 566 sentence pairs representing African Americans and European\\nAmericans, and religious domain consists of 104 sentences each for\\nChristian, Jew, and Muslim social groups.\\nEven though in some evaluation corpora, certain domains consist\\nof three social groups (e.g. in BITS, the gender domain consists of\\nmale, female, and non-binary social groups, in CSP, the religious do-\\nmain consists of Christian, Jew, and Muslim groups), our evaluation'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 7, 'page_label': '8', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='male, female, and non-binary social groups, in CSP, the religious do-\\nmain consists of Christian, Jew, and Muslim groups), our evaluation\\nstrategies are limited to pair-wise evaluations, to maintain commonality\\namong all the domains. That is, for all the evaluation corpora, from the\\navailable set of social groups, we conduct pair-wise evaluations for the\\npairs, Male versus Female (M × F), Male versus Non-binary (M × Nb),\\nor Female versus Non-binary (F × Nb) in gender domain, European\\nAmerican versus African American (EA × AA) in the racial domain, and\\nChristian versus Muslim (Ch × Mu), Christian versus Jew (Ch × Jw) or\\nMuslim versus Jew (Mu × Jw) in the religious domain.\\n4.2.2. Evaluation measures\\nFor an evaluation corpus with 𝑁 sentence pairs, we denote 𝑠𝑝𝑔1\\n𝑖 and\\n𝑠𝑝𝑔2\\n𝑖 as the ith sentence pair representing two social groups 𝑔1 and 𝑔2\\n(e.g. Male versus Female), respectively, in a domain (e.g. gender). We\\nevaluate the existence of prediction level affective bias using different'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 7, 'page_label': '8', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='(e.g. Male versus Female), respectively, in a domain (e.g. gender). We\\nevaluate the existence of prediction level affective bias using different\\nmeasures that rely on class ( ̂ 𝑒𝑐𝑙𝑎𝑠𝑠) and intensity ( ̂ 𝑒𝑠𝑐𝑜𝑟𝑒) predictions of\\nthe textual emotion detection models, details follow.\\n• Demographic Parity (DP): A popular class based measure to quan-\\ntify group fairness/bias of a classifier system, commonly used\\nto address general affect-agnostic biases like gender bias, racial\\nbias, etc. Du et al. (2021). We utilize this measure to identify\\nthe existence of affective bias and check whether the model’s\\nemotion classifications are similar (or different) across different\\nsocial groups within a domain. Accordingly, we say that a textual\\nemotion detection model satisfies demographic parity if,\\nDP = 𝑃(̂ 𝑒𝑐𝑙𝑎𝑠𝑠(𝑠𝑝𝑔1 ) =𝑒|𝑧= 𝑔1)\\n𝑃(̂ 𝑒𝑐𝑙𝑎𝑠𝑠(𝑠𝑝𝑔2 ) =𝑒|𝑧= 𝑔2) , 𝑒 ∈ 𝐸 and 𝑔1,𝑔2 ∈ 𝑇 (3)\\nwhere, 𝑃(̂ 𝑒𝑐𝑙𝑎𝑠𝑠(𝑠𝑝𝑔1 ) = 𝑒|𝑧 = 𝑔1) and 𝑃(̂ 𝑒𝑐𝑙𝑎𝑠𝑠(𝑠𝑝𝑔2 ) = 𝑒|𝑧 = 𝑔2)'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 7, 'page_label': '8', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='DP = 𝑃(̂ 𝑒𝑐𝑙𝑎𝑠𝑠(𝑠𝑝𝑔1 ) =𝑒|𝑧= 𝑔1)\\n𝑃(̂ 𝑒𝑐𝑙𝑎𝑠𝑠(𝑠𝑝𝑔2 ) =𝑒|𝑧= 𝑔2) , 𝑒 ∈ 𝐸 and 𝑔1,𝑔2 ∈ 𝑇 (3)\\nwhere, 𝑃(̂ 𝑒𝑐𝑙𝑎𝑠𝑠(𝑠𝑝𝑔1 ) = 𝑒|𝑧 = 𝑔1) and 𝑃(̂ 𝑒𝑐𝑙𝑎𝑠𝑠(𝑠𝑝𝑔2 ) = 𝑒|𝑧 = 𝑔2)\\nindicates the probabilities of the two social groups 𝑔1 and 𝑔2,\\nrespectively, to predict an emotion 𝑒; 𝑔2 is taken as the group\\nwith higher probability (Feldman et al., 2015). 𝐸 is the set of\\nall emotions, and 𝑇 is the set of social groups in a domain.\\nDemographic parity advocates the likelihood of emotion predic-\\ntion outcomes of sentence pairs that differ only in key terms\\ndenoting a certain social group should be the same; as a result,\\nDP=1 indicates an ideal unbiased scenario, whereas, lower the\\nvalues higher the existence of bias. Therefore, we use the general\\nthreshold 𝜏 = 0.80, lower than which indicates biased predictions\\n(Feldman et al., 2015).\\n• Average Difference of Prediction Intensity Scores ( 𝑎𝑣𝑔.𝛥): An\\nintensity based measure that computes the average difference of'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 7, 'page_label': '8', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='(Feldman et al., 2015).\\n• Average Difference of Prediction Intensity Scores ( 𝑎𝑣𝑔.𝛥): An\\nintensity based measure that computes the average difference of\\nemotion prediction intensity scores between the sentence pairs\\nof two social groups in a domain (Kiritchenko and Mohammad,\\n2018).\\n𝑎𝑣𝑔.𝛥= 1\\n𝑁\\n𝑁∑\\n𝑖=1\\n|̂ 𝑒𝑠𝑐𝑜𝑟𝑒(𝑠𝑝𝑔1\\n𝑖 ) −̂ 𝑒𝑠𝑐𝑜𝑟𝑒(𝑠𝑝𝑔2\\n𝑖 )| (4)\\nwhere, ̂ 𝑒𝑠𝑐𝑜𝑟𝑒(𝑠𝑝𝑔1\\n𝑖 ) and ̂ 𝑒𝑠𝑐𝑜𝑟𝑒(𝑠𝑝𝑔2\\n𝑖 ) indicates emotion prediction\\nintensity scores corresponding to the social groups 𝑔1 and 𝑔2,\\nrespectively, for the ith sentence pair concerning a domain, and\\n𝑁 denotes the total number of sentence pairs. That is, 𝑎𝑣𝑔.𝛥\\nindicates the average dissimilarity in prediction scores between\\na pair of sentences; 0 indicates perfect similarity, and higher the\\nvalues more the dissimilarity.\\n• Prediction Score Significance ( 𝑝-value): A measure that shows\\nwhether dissimilarity in prediction scores between the sentence\\npairs is statistically significant or not. To compute prediction'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 7, 'page_label': '8', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='• Prediction Score Significance ( 𝑝-value): A measure that shows\\nwhether dissimilarity in prediction scores between the sentence\\npairs is statistically significant or not. To compute prediction\\nscore significance, we perform a paired statistical significance\\ntest, 𝑡-Test (Kiritchenko and Mohammad, 2018) over the predic-\\ntion scores of sentence pairs, ̂ 𝑒𝑠𝑐𝑜𝑟𝑒(𝑠𝑝𝑔1\\n𝑖 ) and ̂ 𝑒𝑠𝑐𝑜𝑟𝑒(𝑠𝑝𝑔2\\n𝑖 ), using the\\nconventional significance level, i.e., a 𝑝-value of 0.05.\\n• Average Confidence Score (ACS): A measure that illustrates model\\nbias towards a particular social group using the average ratio\\nbetween prediction intensity scores of sentence pairs (Nangia\\net al., 2020), computed as,\\nACS = 1\\n𝑁\\n𝑁∑\\n𝑖=1\\n1 −\\n̂ 𝑒𝑠𝑐𝑜𝑟𝑒(𝑠𝑝𝑔1\\n𝑖 )\\n̂ 𝑒𝑠𝑐𝑜𝑟𝑒(𝑠𝑝𝑔2\\n𝑖 )\\n(5)\\nACS value of an unbiased model will peak around zero, but if\\nit tends to negative values, then the measure indicates that the\\nmodel prediction intensities of the social group𝑔1 are higher than'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 7, 'page_label': '8', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='(5)\\nACS value of an unbiased model will peak around zero, but if\\nit tends to negative values, then the measure indicates that the\\nmodel prediction intensities of the social group𝑔1 are higher than\\n𝑔2, and if it tends to positive values, it indicates that prediction\\nintensities of the social group 𝑔2 are higher than 𝑔1.\\n4.3. Results and analysis of prediction level affective bias\\nWe examine emotion predictions of each PLM based textual emotion\\ndetection system and could observe the existence of affective bias in\\nthe predicted emotion classes, as well as their intensities, for gender,\\nrace, and religious domains. The sample set of predictions presented in\\nTable 1 is a small subset of these affectively biased emotion predictions\\nfrom the emotion detection models that employ BERT and T5. More sets\\nof affectively biased predictions from the PLM based textual emotion\\ndetection systems, are provided in the supplementary material. In the'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 7, 'page_label': '8', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='of affectively biased predictions from the PLM based textual emotion\\ndetection systems, are provided in the supplementary material. In the\\nfollowing subsections, we evaluate the results of each PLM separately.\\n4.3.1. Affective bias in BERT\\nTable 6 shows evaluation results observed for the textual emotion\\ndetection model built using BERT, analyzing gender, racial and re-\\nligious domains using three different evaluation corpora EEC, BITS,\\nand CSP, and various evaluation measures. The pairs of social groups\\naddressed by the evaluation corpora within each domain are presented\\ncolumn wise, the measures are presented row wise, and the emotions\\nare grouped across the rows.\\n8'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 8, 'page_label': '9', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='A. Kadan, Deepak P., S. Bhadra et al. Natural Language Processing Journal 7 (2024) 100062\\nTable 6\\nResults of BERT (Boldface is used to highlight the values of DP < threshold 𝜏 = 0.80 and p-values <0.05).\\nEvaluation Gender Race Religion\\nmeasures EEC\\nM × F\\nBITS\\nM × F\\nCSP\\nM × F\\nBITS\\nM × Nb\\nBITS\\nF × Nb\\nEEC\\nEA × AA\\nBITS\\nEA × AA\\nCSP\\nEA × AA\\nCSP\\nCh × Mu\\nCSP\\nCh × Jw\\nCSP\\nMu × Jw\\nAnger\\nDP 0.964 1.000 0.836 0.866 0.867 0.996 0.948 1.000 0.923 0.923 1.000\\navg.𝛥 0.018 0.016 0.049 0.038 0.030 0.031 0.012 0.052 0.076 0.078 0.100\\np-value 0.003 0.036 0.037 0.047 0.132 0.417 0.431 0.730 0.038 0.042 2e −04\\nACS 0.010 0.017 0.025 0.036 0.020 −0.005 −0.008 −0.001 0.050 −0.084 −0.148\\nFear\\nDP 0.954 1.000 1.000 0.938 0.938 0.961 1.000 0.743 0.857 0.885 0.968\\navg.𝛥 0.019 0.049 0.086 0.085 0.086 0.049 0.058 0.109 0.076 0.089 0.073\\np-value 9.2e−12 0.864 0.767 0.043 0.063 5.3e−27 0.748 1.2e−6 0.044 0.439 0.001\\nACS 0.019 −0.010 −0.015 −0.094 −0.088 −0.055 −0.016 −0.123 0.031 −0.041 −0.082\\nJoy'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 8, 'page_label': '9', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='p-value 9.2e−12 0.864 0.767 0.043 0.063 5.3e−27 0.748 1.2e−6 0.044 0.439 0.001\\nACS 0.019 −0.010 −0.015 −0.094 −0.088 −0.055 −0.016 −0.123 0.031 −0.041 −0.082\\nJoy\\nDP 0.994 1.000 0.971 1.000 1.000 1.000 1.000 0.797 0.455 0.637 0.713\\navg.𝛥 0.002 9.9e −5 0.072 0.001 0.001 0.005 0.001 0.076 0.148 0.031 0.130\\np-value 0.400 0.061 0.014 0.360 0.394 0.002 0.611 0.001 0.033 0.425 0.021\\nACS −0.001 −5.8e−5 0.064 −0.001 −0.001 −0.004 −1e−4 −0.080 −0.240 −0.022 0.169\\nSadness\\nDP 0.953 1.000 0.872 0.938 0.938 0.977 0.950 0.724 0.666 0.666 1.000\\navg.𝛥 0.027 0.013 0.076 0.024 0.033 0.056 0.012 0.116 0.124 0.100 0.051\\np-value 1.8e−4 0.045 0.019 0.461 0.156 0.600 0.924 1e−12 0.065 0.201 0.146\\nACS −0.020 −0.019 −0.064 0.006 0.022 −0.010 −0.002 0.100 −0.279 −0.169 0.064\\n(A) Affective Gender Bias:Initially, looking into the gender domain,\\nfor class based measure DP, throughout all the emotions, we can\\nobserve that there is almost no affective bias in the predictions'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 8, 'page_label': '9', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='(A) Affective Gender Bias:Initially, looking into the gender domain,\\nfor class based measure DP, throughout all the emotions, we can\\nobserve that there is almost no affective bias in the predictions\\nmade by BERT between male and female groups when evaluated\\nusing the EEC corpus (since, DP > 0.8 in all cases), and ideally\\nno affective bias when evaluated using BITS corpus (since, DP =\\n1 in all cases). This ideal scenario in BITS might be because\\nBITS is a small corpus containing short-length synthetically cre-\\nated sentences with explicit emotion terms that do not suit the\\nreal-world context. When compared to synthetic corpora (EEC\\nand BITS), evaluations using the real-world context and non-\\nsynthetic corpus CSP shows more disparity (lower values of DP)\\nbetween male and female groups for all the emotions except\\nfear. For pairs involving non-binary genders, the values of DP\\nare much less than those involving male and female groups of'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 8, 'page_label': '9', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='between male and female groups for all the emotions except\\nfear. For pairs involving non-binary genders, the values of DP\\nare much less than those involving male and female groups of\\nsynthetic corpora EEC and BITS, for all emotions except joy.\\nThis indicate more disparity of male and female groups with\\nnon-binary gender, with respect to anger, fear and sadness. Since\\nthe evaluation of affective bias in non-binary social groups is\\nonly possible with BITS corpus, it may limit the exploration\\nof affective bias towards this group and also the magnitude of\\naffective bias. For the measure DP, when looking across each\\nemotion, the most disparity (lowest value for DP) is observed\\nfor anger between male versus female when evaluated using CSP\\ncorpus, followed by male versus non-binary, and female versus\\nnon-binary, for the same emotion, when evaluated using BITS\\ncorpus. Whereas, for joy, very less disparity is observed across\\nthe gender groups. In total, even though disparities are shown'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 8, 'page_label': '9', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='non-binary, for the same emotion, when evaluated using BITS\\ncorpus. Whereas, for joy, very less disparity is observed across\\nthe gender groups. In total, even though disparities are shown\\nby DP, any of the gender pairs do not have values of DP less than\\nthe threshold 𝜏 = 0.80. Hence DP does not establish the existence\\nof gender affective bias in the predictions of BERT using these\\nevaluation corpora.\\nComing to the intensity based measure avg. 𝛥 in the gender\\ndomain, similar to DP, more disparity is observed for male\\nversus female pairs when evaluated using CSP corpus and also\\nfor the pairs involving non-binary social groups in BITS, across\\nall the emotions. Different from the measure DP, avg. 𝛥 reports\\nhighest disparity for fear, but similar to DP, avg. 𝛥 shows very\\nless disparity for joy. For the next measure 𝑝-value, at least one\\nof the evaluation corpora reports values less than 0.05 or statisti-\\ncally significant difference between male and female predictions'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 8, 'page_label': '9', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='of the evaluation corpora reports values less than 0.05 or statisti-\\ncally significant difference between male and female predictions\\nacross the emotions, indicating the existence of affective bias.\\nThe 𝑝-value also shows that difference between male and non-\\nbinary predictions for anger and fear are statistically significant.\\nAnalyzing the prediction intensity plots of pairs with statistically\\nsignificant differences (e.g. Figs. 2(a) and 2(b)), shows that their\\nintensity plots also depict more dispersion between data points\\nas well as more disparity between the corresponding mean val-\\nues. Conversely, in the plots of sentence pairs with statistically\\ninsignificant differences in prediction intensities (e.g. Fig. 2(c)),\\nthere is very less dispersion between data points and less dispar-\\nity between the mean values. Therefore𝑝-value evidently reports\\nthe existence of affective bias in emotion prediction intensities\\nof male and female groups with respect to all emotions, and for'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 8, 'page_label': '9', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='ity between the mean values. Therefore𝑝-value evidently reports\\nthe existence of affective bias in emotion prediction intensities\\nof male and female groups with respect to all emotions, and for\\nmale and non-binary groups with respect to anger and fear.\\nIn the case of intensity based measure ACS, for emotion anger,\\nthe positive values in Male versus Female sentence pairs of EEC,\\nBITS, and CSP indicates that prediction intensities for anger are\\nhigher for the Female when compared to Male, and positive\\nvalues in Male versus Non-binary and Female versus Non-binary\\nsentence pairs of BITS indicates that anger prediction intensities\\nare higher for the Non-binary group when compared to Male and\\nFemale. Similarly, when examining across evaluation corpora,\\nprediction intensities of fear and joy are higher for Male and\\nFemale genders, and prediction intensities of sadness are higher\\nfor Male and Non-binary genders. Therefore in the gender do-'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 8, 'page_label': '9', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='prediction intensities of fear and joy are higher for Male and\\nFemale genders, and prediction intensities of sadness are higher\\nfor Male and Non-binary genders. Therefore in the gender do-\\nmain, the measure ACS also indicates affective bias in prediction\\nintensities.\\n(B) Affective Racial Bias:The European and African American racial\\ngroups when evaluated using CSP corpus, for the measure DP,\\nshows the presence of affective bias for all emotions except\\nanger, where EEC and BITS fail to identify it. Similarly, the avg.𝛥\\ndisparities among intensity predictions of these racial groups\\nare also much more visible when evaluated using CSP corpus.\\nEither or both, EEC and CSP corpora shows that the difference\\nin intensity predictions of these racial groups are statistically\\n9'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 9, 'page_label': '10', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='A. Kadan, Deepak P., S. Bhadra et al. Natural Language Processing Journal 7 (2024) 100062\\nFig. 2. Intensity plots of emotion predictions from BERT.\\nsignificant with p-values less than 0.05, for all emotions ex-\\ncept anger, similar to the observations of the measure DP. The\\nmeasure ACS also shows disparities in prediction intensities\\nbetween the racial groups, where, for all emotions, prediction\\nintensities of European American race are mostly higher than\\nAfrican American.\\n(C) Affective Religious Bias: In the religious domain, the measure\\nDP evidently shows affective bias in the emotion joy with very\\nlow values for all three religious pairs and also in sadness for\\nChristian versus Muslim and Christian versus Jew pairs. For\\nall the emotions, the values of DP indicate more bias in the\\nChristian versus Muslim and Christian versus Jew sentence pairs\\nthan in the Muslim versus Jew pairs. The measure avg. 𝛥 shows\\nthat there exist disparities between prediction intensities of reli-'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 9, 'page_label': '10', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='Christian versus Muslim and Christian versus Jew sentence pairs\\nthan in the Muslim versus Jew pairs. The measure avg. 𝛥 shows\\nthat there exist disparities between prediction intensities of reli-\\ngious pairs, and these disparities are found to be comparatively\\nhigher than the pairs of gender and racial domains. The 𝑝-value\\nindicates statistically significant differences in intensity predic-\\ntions of anger between all three religious pairs. Also, Christian\\nversus Muslim and Muslim versus Jew pairs show statistically\\nsignificant differences in intensity predictions of all emotions\\nexcept sadness. The measure ACS shows that for BERT anger and\\nfear prediction intensities are higher for Muslim followed by\\nChristian, and joy and sadness prediction intensities are higher\\nfor Christian followed by Jew.\\n4.3.2. Affective bias in GPT-2\\n(A) Affective Gender Bias:Table 7 shows evaluation results observed\\nfor GPT-2 where similar to BERT, no gender affective bias is'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 9, 'page_label': '10', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='for Christian followed by Jew.\\n4.3.2. Affective bias in GPT-2\\n(A) Affective Gender Bias:Table 7 shows evaluation results observed\\nfor GPT-2 where similar to BERT, no gender affective bias is\\nobserved with the measure DP for any of the emotion class\\npredictions. Whereas intensity based disparities are shown by\\nthe measure avg.𝛥, which is highly visible when evaluated using\\nCSP corpus. The difference in prediction intensities between\\nMale versus Female when evaluated using EEC corpus for all\\nemotions except joy, and Male versus Non-binary and Female\\nversus Non-binary when evaluated using BITS corpus for all\\nemotions except fear, are statistically significant with p-values\\n< 0.05, indicating the existence of affective bias in emotion\\nprediction intensities. The measure ACS indicates that, in GPT-\\n2, anger and joy prediction intensities are higher for Male and\\nFemale genders, fear prediction intensities are higher mainly for\\nFemale, and sadness prediction intensities are higher mainly for'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 9, 'page_label': '10', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='2, anger and joy prediction intensities are higher for Male and\\nFemale genders, fear prediction intensities are higher mainly for\\nFemale, and sadness prediction intensities are higher mainly for\\nMale gender.\\n(B) Affective Racial Bias: In the racial domain, similar to gender,\\nDP does not show racial affective bias for any of the emotion\\nclass predictions, whereas intensity based disparities are shown\\nby the measure avg. 𝛥. Here also, the disparities for class based\\nmeasure DP and intensity based measure avg.𝛥, are more visible\\nwhen evaluated using CSP corpus. Whereas BITS reports an ideal\\nunbiased scenario for DP and very low disparity for avg. 𝛥. The\\nmeasure 𝑝-value reports that the difference in prediction inten-\\nsities of European and African American races are statistically\\nsignificant for all emotions except sadness. The measure ACS\\nshows that, in GPT-2, prediction intensities of anger and sadness\\nare mostly higher for African American race, whereas predic-'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 9, 'page_label': '10', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='significant for all emotions except sadness. The measure ACS\\nshows that, in GPT-2, prediction intensities of anger and sadness\\nare mostly higher for African American race, whereas predic-\\ntion intensities of fear and joy are mostly higher for European\\nAmerican race.\\n(C) Affective Religious Bias:Unlike gender and race, in the religious\\ndomain the class based measure DP reports affective bias (with\\nvalues of DP < 0.8) in the predictions of all emotions except\\nfear. The measure avg. 𝛥 also shows disparities in prediction\\nintensities of religious pairs. The p-values indicate that differ-\\nence in fear prediction intensities for the pairs Christian versus\\nMuslim and Muslim versus Jew are statistically significant. The\\n10'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 10, 'page_label': '11', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='A. Kadan, Deepak P., S. Bhadra et al. Natural Language Processing Journal 7 (2024) 100062\\nTable 7\\nResults of GPT-2 (Boldface is used to highlight the values of DP < threshold 𝜏 = 0.80 and p-values <0.05).\\nEvaluation Gender Race Religion\\nmeasures EEC\\nM × F\\nBITS\\nM × F\\nCSP\\nM × F\\nBITS\\nM × Nb\\nBITS\\nF × Nb\\nEEC\\nEA × AA\\nBITS\\nEA × AA\\nCSP\\nEA × AA\\nCSP\\nCh × Mu\\nCSP\\nCh × Jw\\nCSP\\nMu × Jw\\nAnger\\nDP 0.992 0.926 0.954 0.960 0.889 0.980 1.000 0.920 0.600 0.867 0.692\\navg.𝛥 0.023 0.006 0.039 0.008 0.008 0.038 0.010 0.050 0.059 0.048 0.021\\np-value 2.5e−05 0.103 0.772 0.031 0.004 3.4e −5 0.015 0.037 0.580 0.788 0.626\\nACS 0.013 0.007 −0.005 −0.006 −0.008 0.011 0.012 0.015 −0.044 −0.018 0.010\\nFear\\nDP 1.000 1.000 0.991 0.960 0.960 0.996 1.000 0.901 0.883 0.985 0.870\\navg.𝛥 0.016 0.007 0.058 0.017 0.015 0.030 0.010 0.063 0.139 0.069 0.158\\np-value 0.048 0.372 0.505 0.917 0.787 0.012 0.101 0.183 6.9e−13 0.262 7e−13\\nACS −0.003 0.002 0.001 3.7e −4 −0.001 −0.011 −0.014 0.005 0.159 −0.040 −0.277\\nJoy'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 10, 'page_label': '11', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='p-value 0.048 0.372 0.505 0.917 0.787 0.012 0.101 0.183 6.9e−13 0.262 7e−13\\nACS −0.003 0.002 0.001 3.7e −4 −0.001 −0.011 −0.014 0.005 0.159 −0.040 −0.277\\nJoy\\nDP 0.985 1.000 0.914 1.000 1.000 0.995 1.000 0.936 0.545 0.600 0.909\\navg.𝛥 0.008 3.3e −5 0.073 0.001 0.001 0.017 2e −4 0.101 0.114 0.100 0.089\\np-value 0.640 0.713 0.761 0.018 0.017 0.872 0.204 6.1e−5 0.110 0.944 0.069\\nACS −7.3e−5 5.3e −6 −0.023 −0.001 −0.001 −0.003 −2e−4 −0.108 0.135 −0.011 −0.129\\nSadness\\nDP 0.985 0.951 0.927 1.000 0.951 0.996 1.000 0.938 0.467 0.933 0.502\\navg.𝛥 0.011 0.002 0.047 0.014 0.014 0.018 0.010 0.055 0.039 0.045 0.045\\np-value 4.5e−29 0.262 0.313 0.042 0.042 0.178 0.725 0.283 0.310 0.429 0.343\\nACS −0.012 −0.001 −0.020 −0.013 −0.011 −0.002 0.001 0.006 −0.058 0.028 0.060\\nmeasure ACS shows that for GPT-2 anger prediction intensities\\nare mostly higher for Christian, fear and joy prediction intensi-\\nties are higher for Muslim and Christian, and sadness prediction\\nintensities are mostly higher for Jew groups.'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 10, 'page_label': '11', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='are mostly higher for Christian, fear and joy prediction intensi-\\nties are higher for Muslim and Christian, and sadness prediction\\nintensities are mostly higher for Jew groups.\\n4.3.3. Affective bias in XLNet\\n(A) Affective Gender Bias:Table 8 shows evaluation results of XLNet,\\nwhere the class based measure DP shows negligible affective bias\\n(values of DP is almost one) in emotion predictions of gender\\npairs, whereas avg. 𝛥 shows disparities in emotion prediction\\nintensities of these pairs. The p-values report that differences be-\\ntween intensity predictions are statistically significant for Male\\nversus Female pairs for all emotions, and also for pairs involving\\nthe Non-binary group for emotion anger. The measure ACS indi-\\ncates high anger and fear prediction intensities for Female and\\nMale genders, and high joy and sadness prediction intensities for\\nMale and Non-binary genders.\\n(B) Affective Racial Bias: Similar to the gender domain, the mea-'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 10, 'page_label': '11', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='Male genders, and high joy and sadness prediction intensities for\\nMale and Non-binary genders.\\n(B) Affective Racial Bias: Similar to the gender domain, the mea-\\nsure DP does not confirm class based affective racial bias in\\nXLNet, but avg. 𝛥 shows disparity in intensities of predictions\\nwith 𝑝-value indicating statistically significant differences be-\\ntween prediction intensities of both races, for all emotions. The\\nmeasure ACS shows that anger and sadness prediction intensities\\nare higher for African American, whereasfear and joy prediction\\nintensities are higher for European American race.\\n(C) Affective Religious Bias:In the religious domain, even though the\\nvalues of DP are less compared to gender and racial domains,\\nit is not sufficient to confirm class based affective religious bias\\nin the emotions except sadness whose values are very low and\\nreporting bias. The measure avg.𝛥shows disparity in prediction\\nintensities, with 𝑝-value indicating statistically significant differ-'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 10, 'page_label': '11', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='in the emotions except sadness whose values are very low and\\nreporting bias. The measure avg.𝛥shows disparity in prediction\\nintensities, with 𝑝-value indicating statistically significant differ-\\nences between Christian versus Muslim and Muslim versus Jew\\nreligious pairs, for anger and sadness. The measure ACS indicates\\nthat anger prediction intensities are mostly higher for Muslim\\nreligion followed by Christian, fear mostly higher for Christian\\nfollowed by Muslim, andjoy and sadness higher for Christian and\\nJew.\\n4.3.4. Affective bias in T5\\n(A) Affective Gender Bias: Table 9 shows evaluation results of T5.\\nIn the gender domain, class based measure DP shows affective\\nbias in the predictions of Male versus Female pair for anger and\\nfear when evaluated using CSP corpus. The avg.𝛥measure shows\\ndisparities in prediction intensities, and p-values indicate that\\ndifferences in prediction intensities of Male versus Female pair\\nfor all emotions except fear and in pairs involving Non-binary'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 10, 'page_label': '11', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='disparities in prediction intensities, and p-values indicate that\\ndifferences in prediction intensities of Male versus Female pair\\nfor all emotions except fear and in pairs involving Non-binary\\ngender for emotions anger and fear are statistically significant.\\nThe measure ACS indicates high prediction intensities for anger,\\njoy and sadness mostly by Male gender and high prediction\\nintensities for fear mostly by Female and Non-binary genders.\\n(B) Affective Racial Bias: The measure DP does not confirm class\\nbased affective racial bias in T5 predictions, whereas avg. 𝛥\\nshows intensity based affective racial bias, with statistically\\nsignificant differences in intensity predictions of the racial pairs\\nfor all the emotions. ACS indicates prediction intensities of\\nAfrican American race are higher for anger, whereas prediction\\nintensities of European American are higher for fear, joy and\\nsadness.\\n(C) Affective Religious Bias: In the religious pairs, the measure DP'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 10, 'page_label': '11', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='intensities of European American are higher for fear, joy and\\nsadness.\\n(C) Affective Religious Bias: In the religious pairs, the measure DP\\nindicates affective bias in Muslim versus Jew pairs for all emo-\\ntions, in Muslim versus Christian pairs for all emotions except\\nanger, and in Christian versus Jew pairs for joy. The avg.𝛥shows\\nintensity based disparities in all emotions, and p-values indicate\\nthat the differences in prediction intensities are statistically sig-\\nnificant in the case of Muslim versus Jew pair for all emotions\\nexcept joy and in Christian versus Jew pair for the emotion\\nfear. ACS indicates that anger and joy prediction intensities are\\nhigher for Jew religion followed by Christian, fear prediction\\nintensities are higher for Christian followed by Muslim, and\\nsadness prediction intensities are higher for Christian followed\\nby Jew.\\n5. Discussion\\n5.1. Affective bias - Across the PLMs\\nThis study analyzes affective bias in the predictions of textual'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 10, 'page_label': '11', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='sadness prediction intensities are higher for Christian followed\\nby Jew.\\n5. Discussion\\n5.1. Affective bias - Across the PLMs\\nThis study analyzes affective bias in the predictions of textual\\nemotion detection models at class level and intensity level. In most\\n11'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 11, 'page_label': '12', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='A. Kadan, Deepak P., S. Bhadra et al. Natural Language Processing Journal 7 (2024) 100062\\nTable 8\\nResults of XLNet (Boldface is used to highlight the values of DP < threshold 𝜏 = 0.80 and p-values <0.05).\\nEvaluation Gender Race Religion\\nmeasures EEC\\nM × F\\nBITS\\nM × F\\nCSP\\nM × F\\nBITS\\nM × Nb\\nBITS\\nF × Nb\\nEEC\\nEA × AA\\nBITS\\nEA × AA\\nCSP\\nEA × AA\\nCSP\\nCh × Mu\\nCSP\\nCh × Jw\\nCSP\\nMu × Jw\\nAnger\\nDP 0.983 1.000 1.000 1.000 1.000 0.976 1.000 0.974 0.825 0.869 0.950\\navg.𝛥 0.017 0.005 0.053 0.017 0.019 0.048 0.004 0.061 0.115 0.083 0.110\\np-value 1.7e−6 0.002 0.226 0.035 0.014 0.041 0.561 0.063 0.008 0.842 0.001\\nACS 0.015 0.005 −0.028 −0.015 −0.020 −0.021 0.002 0.015 0.077 −0.032 −0.153\\nFear\\nDP 0.991 1.000 0.989 1.000 1.000 0.988 1.000 0.938 0.810 1.000 0.810\\navg.𝛥 0.012 0.030 0.080 0.060 0.071 0.038 0.036 0.067 0.054 0.070 0.047\\np-value 0.032 0.809 0.680 0.667 0.642 0.228 0.004 0.003 0.561 0.807 0.703\\nACS 0.004 −0.001 −0.003 −0.008 −0.013 −0.007 −0.050 −0.062 −0.029 −0.005 −0.019\\nJoy'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 11, 'page_label': '12', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='p-value 0.032 0.809 0.680 0.667 0.642 0.228 0.004 0.003 0.561 0.807 0.703\\nACS 0.004 −0.001 −0.003 −0.008 −0.013 −0.007 −0.050 −0.062 −0.029 −0.005 −0.019\\nJoy\\nDP 0.993 1.000 0.974 1.000 1.000 0.970 1.000 0.804 0.856 1.000 0.857\\navg.𝛥 0.010 0.013 0.084 0.006 0.018 0.022 0.009 0.084 0.027 0.077 0.086\\np-value 0.457 0.118 0.028 0.158 0.125 0.011 0.573 0.024 0.357 0.410 0.397\\nACS −0.003 −0.018 0.056 0.006 0.019 −0.012 0.004 −0.073 −0.055 0.073 0.133\\nSadness\\nDP 0.998 1.000 0.989 1.000 1.000 0.997 1.000 0.902 0.533 0.833 0.640\\navg.𝛥 0.009 0.003 0.050 0.007 0.008 0.028 0.007 0.083 0.094 0.065 0.104\\np-value 0.013 0.010 0.553 0.203 0.061 0.253 0.075 5.1e−6 0.048 0.637 0.010\\nACS −0.003 −0.003 −0.031 0.002 0.005 −0.004 0.009 0.046 −0.131 0.007 0.124\\nTable 9\\nResults of T5 (Boldface is used to highlight the values of DP < threshold 𝜏 = 0.80 and p-values <0.05).\\nEvaluation Gender Race Religion\\nmeasures EEC\\nM × F\\nBIT\\nM × F\\nCSP\\nM × F\\nBITS\\nM × Nb\\nBITS\\nF × Nb\\nEEC\\nEA × AA\\nBITS\\nEA × AA\\nCSP\\nEA × AA\\nCSP'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 11, 'page_label': '12', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='Evaluation Gender Race Religion\\nmeasures EEC\\nM × F\\nBIT\\nM × F\\nCSP\\nM × F\\nBITS\\nM × Nb\\nBITS\\nF × Nb\\nEEC\\nEA × AA\\nBITS\\nEA × AA\\nCSP\\nEA × AA\\nCSP\\nCh × Mu\\nCSP\\nCh × Jw\\nCSP\\nMu × Jw\\nAnger\\nDP 0.983 0.966 0.765 0.897 0.866 0.933 0.952 0.903 0.968 0.816 0.790\\navg.𝛥 0.039 0.016 0.077 0.021 0.022 0.101 0.004 0.106 0.082 0.113 0.097\\np-value 3.6e−20 0.530 0.385 0.017 0.043 0.001 0.458 6.8e−8 0.118 0.491 0.041\\nACS −0.044 0.006 −0.037 −0.029 −0.032 0.005 0.002 0.070 −0.086 0.014 0.064\\nFear\\nDP 0.994 1.000 0.778 0.897 1.000 0.966 1.000 0.867 0.783 0.915 0.717\\navg.𝛥 0.017 0.029 0.079 0.079 0.068 0.039 0.067 0.099 0.079 0.148 0.145\\np-value 0.309 0.318 0.662 0.003 0.004 3.1e −7 0.022 9.2e −5 0.602 0.001 2.8e −5\\nACS 0.002 0.008 −0.025 0.071 0.063 −0.035 −0.087 −0.111 −0.005 −0.242 −0.263\\nJoy\\nDP 0.990 1.000 0.848 1.000 1.000 0.961 1.000 0.971 0.624 0.375 0.600\\navg.𝛥 0.009 2e −4 0.062 1e −4 2.8e −4 0.029 0.009 0.068 0.183 0.001 0.075\\np-value 0.003 0.025 0.885 0.605 0.115 0.122 0.332 0.001 0.122 0.468 0.423'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 11, 'page_label': '12', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='avg.𝛥 0.009 2e −4 0.062 1e −4 2.8e −4 0.029 0.009 0.068 0.183 0.001 0.075\\np-value 0.003 0.025 0.885 0.605 0.115 0.122 0.332 0.001 0.122 0.468 0.423\\nACS −0.009 −2e−4 −0.025 −1.6e−5 1.8e −4 −0.014 −0.014 −0.078 −0.320 0.001 0.075\\nSadness\\nDP 0.998 0.973 0.952 0.925 0.900 0.998 0.955 0.972 0.500 0.900 0.450\\navg.𝛥 0.023 0.006 0.082 0.009 0.014 0.074 0.007 0.103 0.095 0.118 0.085\\np-value 8.6e−15 0.035 0.689 0.223 0.871 0.002 0.048 0.957 0.121 0.751 0.020\\nACS −0.026 −0.006 −0.027 −0.008 −0.002 −0.040 −0.007 −0.030 −0.150 −0.002 0.099\\ncases, class based measures that are capable of identifying differences\\nin emotion classes predicted for two different social groups, do not\\nshow affective bias, whereas intensity based measures mostly identify\\nthe existence of affective bias in predicted emotion intensities. This\\nis because the differences in predicted emotion intensities between\\nthe social groups might not be that very high to alter the choice of'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 11, 'page_label': '12', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='is because the differences in predicted emotion intensities between\\nthe social groups might not be that very high to alter the choice of\\nemotion class predictions, but even then there exists affective bias due\\nto differences in the predicted emotion intensities. When comparing\\nacross the PLMs, class based affective gender bias is only observed in\\nT5, whereas intensity based affective gender bias is observed in all\\nthe PLMs. Similarly, class based affective racial bias is only observed\\nin BERT, whereas intensity based affective racial bias is observed in\\nall the PLMs. But, in the domain of religion, all four PLMs show\\nhigh magnitudes of class based and intensity based affective bias,\\ni.e., compared to gender and race, the religious domain is observed to have\\nhigh existence of affective bias. We believe this could be a reflection\\nof comparatively high affect imbalance with respect to the religious\\ndomain in the pre-training corpora (from Table 4).'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 11, 'page_label': '12', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='high existence of affective bias. We believe this could be a reflection\\nof comparatively high affect imbalance with respect to the religious\\ndomain in the pre-training corpora (from Table 4).\\nXLNet is observed to have the least class based affective bias, with\\nbias only observed in the case of the religious domain for the emo-\\ntion sadness. XLNet is also observed to have the least intensity based\\naffective bias among all the PLMs when considering the measures avg.𝛥\\n(i.e., the top five values of avg. 𝛥 do not have any instance of XLNet)\\nand 𝑝-value (i.e., the number of instances in XLNet with statistically\\nsignificant differences are also low). Whereas T5 has the maximum\\nclass based biased instances, and also high intensity based affective bias\\namong all the PLMs when considering the measures avg.𝛥(i.e., top five\\nvalues of avg.𝛥have three instances of T5) and𝑝-value (i.e., the number\\nof instances in T5 with statistically significant differences are also high).'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 11, 'page_label': '12', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='values of avg.𝛥have three instances of T5) and𝑝-value (i.e., the number\\nof instances in T5 with statistically significant differences are also high).\\nBERT also shows class based and intensity based affective bias, nearly\\nsimilar but comparatively less than T5, followed by GPT-2.\\n12'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 12, 'page_label': '13', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='A. Kadan, Deepak P., S. Bhadra et al. Natural Language Processing Journal 7 (2024) 100062\\nThis study explores affective bias in large PLMs that are trained on\\nmillions of parameters. However, rapid growth in the data processing\\ntechnology and plenty availability of data has recently, very quickly\\nevolved the category of large PLMs to being trained on billions of\\nparameters, the PLMs such as LLaMA (Touvron et al., 2023), Flan-T5\\nXXL (Chung et al., 2022), PaLM (Chowdhery et al., 2023), LaMDA\\n(Thoppilan et al., 2022), etc. All these PLMs have the benefits of\\nhuge improvements in their performance, capable of performing several\\ndownstream tasks, and supporting multi-lingual and multi-modal data\\nprocessing. All such large PLMs highly rely on the large availability\\nof massive amounts of textual data especially collected from the web,\\nWikipedia, Book Corpus, etc. In most cases, which proportion of data\\nis extracted from a source to train a PLM is not fully transparent.'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 12, 'page_label': '13', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='Wikipedia, Book Corpus, etc. In most cases, which proportion of data\\nis extracted from a source to train a PLM is not fully transparent.\\nFor example, LLaMA uses different data proportions from different\\ncommonly available data deluges such as CommonCrawl (67.0%), C4\\n(15.0%), Wikipedia (4.5%), etc., where which data proportions are\\nextracted from each of the sources is not fully transparent. Also, the\\ntraining data quality is unmanageable and unverifiable by even a large\\ngroup of human crowd (Navigli et al., 2023), where there are chances\\nof the existence of affective biases in these recent large PLMs. For\\nexample, LLaMA is trained on data proportions from several corpora in-\\ncluding C4 and Wikipedia, which are already investigated in this study\\nand identified with the affect imbalances. The large PLMs PaLM and\\nLaMDA are also trained on billions of tokens extracted from web pages,\\nbooks, Wikipedia, and news articles, indicating chances of existence of'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 12, 'page_label': '13', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='LaMDA are also trained on billions of tokens extracted from web pages,\\nbooks, Wikipedia, and news articles, indicating chances of existence of\\naffective bias. Similarly, Flan-T5 is a variant of the T5, and in this study\\nwe observed that T5 has the highest affective bias amongst the PLMs\\nXLNet, BERT, and GPT-2.\\n5.2. Affect imbalance in corpora and affective bias in predictions\\nWhen revisiting the analysis of corpora involved in training PLMs,\\nwe have already observed (in Table 4) that these corpora have imbal-\\nanced co-occurrences of emotions with certain social groups in gender,\\nracial and religious domains. Further at the prediction level, PLMs that\\nutilize these corpora seems to reflect some of these imbalances hinting\\nat the propagation of affect imbalance in data towards affective bias\\nin predictions. For example, in pre-training and fine-tuning corpora\\nof BERT (i.e., WikiEn, BookCorpus, and SemEval-2018), the emotion'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 12, 'page_label': '13', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='in predictions. For example, in pre-training and fine-tuning corpora\\nof BERT (i.e., WikiEn, BookCorpus, and SemEval-2018), the emotion\\nanger has high co-occurrence with Non-binary and Female groups than\\nMale. This seems to reflect in the predictions of BERT, i.e., the measure\\nACS shows that prediction intensities of anger are higher for Non-\\nbinary and Female groups than Male. Some other imbalanced emotion\\nassociations that exist in these corpora like sadness more associated\\nwith Male and Non-binary groups in the gender domain, joy more\\nassociated with European American racial group, fear more associated\\nwith Muslim, joy more associated with Christian, etc., are also seen\\nto be reflected in the predictions of BERT when evaluated using the\\nmeasure ACS. Similar to BERT, we can also observe the reflection of\\ncorpus level affective bias from pre-training and fine-tuning corpora\\nof GPT-2 (i.e., WebText-250k and SemEval-2018) to the predictions'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 12, 'page_label': '13', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='corpus level affective bias from pre-training and fine-tuning corpora\\nof GPT-2 (i.e., WebText-250k and SemEval-2018) to the predictions\\nof GPT-2, e.g., (1) high co-occurrence of fear with Female and Non-\\nbinary genders in the corpora, and high prediction intensities offear for\\nFemale and Non-binary genders, (2) high co-occurrence of anger with\\nAfrican American race in the corpora, and high prediction intensities\\nof anger for African American, (3) high co-occurrence of fear with\\nMuslim religion in the corpora, and high prediction intensities of fear\\nfor Muslim, etc. Such examples of reflection of corpus level affective\\nbias in the predictions of PLMs are also visible in XLNet and T5. These\\ninstances give hints that affect imbalances in the large scale corpora of\\nPLMs may lead to affective bias in the predictions of the models that utilize\\nthese PLMs. Hence, this study further opens the scope for much more\\nnuanced explorations in the direction of affective bias propagation from'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 12, 'page_label': '13', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='these PLMs. Hence, this study further opens the scope for much more\\nnuanced explorations in the direction of affective bias propagation from\\nthe corpus to model prediction.\\n5.3. Societal stereotypes and affective bias\\nThe imbalanced/biased association of emotions with certain so-\\ncial groups within a domain, either at the corpus level or prediction\\nlevel, reflects several affect-oriented societal stereotypes. Patterns in\\nthe training corpora and predictions of PLM based textual emotion\\ndetection models showing high association of African American race\\nwith anger (an example plot of high anger prediction intensities for\\nAfrican American race is presented in Fig. 3(a)) reflect the ‘‘Angry\\nBlack’’ stereotype that misrepresents and victimizes blacks as hostile\\nin mainstream American culture and suppress their emotions (Lozada\\net al., 2022). Another pattern of high association of European American\\nrace with fear (an example plot of high fear prediction intensities for'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 12, 'page_label': '13', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='et al., 2022). Another pattern of high association of European American\\nrace with fear (an example plot of high fear prediction intensities for\\nEuropean American is presented in Fig. 3(b)) reflects the existence of\\nstereotypes such as fear of crime, residential integration, and racial\\nprejudice among the whites (Skogan, 1995). The high association of\\nNon-binary genders with negative emotions especially fear, and very\\nrarely associating with positive emotionjoy, reflects the societal stigmas\\nlike homo-negativity and homophobia against these gender minorities\\n(Hahn et al., 2020). Similarly, the high association of Muslim religion\\nwith fear (an example plot of highfear prediction intensities for Muslim\\nis presented in Fig. 3(c)), which we believe may probably be due to the\\nIslamophobia manifested through text, are inline with the experimental\\nresults in Abid et al. (2021b) that reports language generated by GPT-\\n3 (Brown et al., 2020) in the context of the Muslim religion are more'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 12, 'page_label': '13', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='results in Abid et al. (2021b) that reports language generated by GPT-\\n3 (Brown et al., 2020) in the context of the Muslim religion are more\\nassociated with violence.\\n5.4. Effectiveness of evaluation corpora in unveiling affective bias\\nWhen comparing the capability of the evaluation corpora EEC,\\nBITS, and CSP, we could observe that BITS, with a smaller number of\\nsentence pairs (120 for gender and 72 for race) and explicit emotion\\nterms, is mostly unable to recognize the existence of affective bias in\\nperspective of both class level and intensity level analysis. But even\\nthough EEC also has implicit representation of emotion terms similar\\nto BITS, the availability of a large number of sentence pairs (1400 for\\neach domain) eventually helps EEC to identify the existence of affective\\nbias better than BITS. On the other side, even with a smaller number\\nof sentence pairs (263 for gender, 566 for race, 104 for religion), the'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 12, 'page_label': '13', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='bias better than BITS. On the other side, even with a smaller number\\nof sentence pairs (263 for gender, 566 for race, 104 for religion), the\\nevaluation corpus CSP helps to identify affective bias to a great extent,\\nand it is the only corpus that unveils class based affective bias in the\\ndomains. We believe the non-synthetic and real-world context nature\\nof sentence pairs in CSP could have been advantageous in identifying\\naffective bias. Therefore, upgrading such a corpus with more number\\nof sentence pairs or procuring new evaluation corpora containing non-\\nsynthetic real-world sentences, along with corresponding ground truth\\nemotions could eventually help towards comprehensive and rigorous\\nexplorations in the direction of identifying affective bias and quantify-\\ning its magnitude using ground truth dependent measures like Equal\\nOpportunity (Du et al., 2021).\\n6. Conclusion\\nTextual affective analysis and recognition enable efficient ways to'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 12, 'page_label': '13', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='ing its magnitude using ground truth dependent measures like Equal\\nOpportunity (Du et al., 2021).\\n6. Conclusion\\nTextual affective analysis and recognition enable efficient ways to\\nencode and understand human emotional states from textual data and\\nyield new opportunities to systems such as business, healthcare, and\\neducation by analyzing customers, employees, users, patients, etc., in\\nthe context of affective content. Unfair representations of affect in\\nlanguage, i.e. affective bias in such systems discriminate social groups\\nin a domain on the basis of certain emotions while making algorithmic\\ndecisions. Affective bias in textual emotion detection systems when\\ndeployed in the real world, can harm the ethical trust of these systems\\nand can be potentially threatening to human lives. Hence, analyzing\\nthe existence of affective bias in these systems is crucial to avoid huge\\n13'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 13, 'page_label': '14', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='A. Kadan, Deepak P., S. Bhadra et al. Natural Language Processing Journal 7 (2024) 100062\\nFig. 3. Intensity plots of emotion predictions reflecting societal stereotypes.\\ndisputes and damages in society similar to the adverse effects produced\\nby many other unfair systems such as unfair recidivism prediction. 21\\nIn this work, we for the first time, to the best of our knowledge,\\nattempted to explore and identify any existence of affective bias in\\nlarge PLMs, when utilized for the task of textual emotion detection,\\nwith respect to the domains gender, race, and religion. For the study,\\nwe used BERT, GPT-2, XLNet, and T5 considering their popularity and\\nwide applicability in textual emotion detection and many other related\\ntasks. As algorithmic bias has its roots from data bias, we started our\\nexploration of affective bias by analyzing the imbalanced distribution of\\naffect in the pre-training corpora of these PLMs i.e., WikiEn, BookCor-'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 13, 'page_label': '14', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='exploration of affective bias by analyzing the imbalanced distribution of\\naffect in the pre-training corpora of these PLMs i.e., WikiEn, BookCor-\\npus, WebText-250, and C4-Val, and SemEval-2018 used to fine-tune the\\nemotion detection models. Later, we analyzed the existence of affective\\nbias in the predictions of fine-tuned emotion detection models built\\nusing these large PLMs. Evaluations are performed to analyze affective\\nbias in the predicted emotion classes and corresponding intensities of\\nsocial groups within a domain using three different evaluation corpora\\nand various class based and intensity based evaluation measures. Our\\nwide set of experiments and evaluation strategies confirm the existence\\nof affect imbalance in large scale corpora and affective bias in emotion\\npredictions of the PLMs, with affective bias mostly higher for T5\\ncompared to the other PLMs. The high association of emotion anger\\nwith African American race, joy with European American race, fear'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 13, 'page_label': '14', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='predictions of the PLMs, with affective bias mostly higher for T5\\ncompared to the other PLMs. The high association of emotion anger\\nwith African American race, joy with European American race, fear\\nwith the Muslim religion, etc., are some examples of affective bias.\\nReligious domain reports more biased instances, compared to gender\\nand race, for all the PLMs. Our results also demonstrated that the\\nbiased predictions of the models are inclined with patterns of affect\\n21 https://www.propublica.org/article/machine-bias-risk-assessments-in-\\ncriminal-sentencing?token=nD-X136_tDm0nh1l4Xtv0LbpjY_BSO3u.\\nimbalance in the corpora, and both these reflect certain affect-oriented\\nsocietal stereotypes, hinting at the propagation of affective bias towards\\npredictions of the PLMs. To aid future research, we shall make publicly\\navailable all the relevant materials including the pre-processed pre-\\ntraining and fine-tuning corpora, evaluation corpora modified to suit'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 13, 'page_label': '14', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='available all the relevant materials including the pre-processed pre-\\ntraining and fine-tuning corpora, evaluation corpora modified to suit\\nour task, list of affective terms and target terms for corpus level\\nanalysis, source code, and fine-tuned textual emotion detection models\\nalong with their emotion class and intensity predictions, at https:\\n//github.com/anoopkdcs/affective_bias_in_plm and https://dcs.uoc.ac.\\nin/cida/projects/ac/affective-bias.html along with the publication.\\n6.1. Future work\\nThe proposed study explores corpus level affective bias using a sim-\\nple approach to analyzing the distributions of affective target terms in\\nthe corpora. In the future, we are planning to conduct a more nuanced\\nexploration towards the corpus level affective bias in the context of\\nvarious facets such as the time of creation of corpora, people behind\\ncorpora, languages and cultures (Navigli et al., 2023). Recent affect\\nagnostic bias analysis studies explore bias in the context of causality (Su'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 13, 'page_label': '14', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='corpora, languages and cultures (Navigli et al., 2023). Recent affect\\nagnostic bias analysis studies explore bias in the context of causality (Su\\net al., 2022); therefore to further explore the relationship between the\\ncorpus characteristics and model bias we are also planning to conduct\\ncausality based affective bias analysis.\\nIn context the model predictions, the observations of affective bias\\nand its magnitudes in this study are dependent on the choice of eval-\\nuation corpora and measures, i.e., certain instances of ‘no affective\\nbias’ or marginal magnitudes of affective bias may also be due to the\\nlimited capability of evaluation corpora and measures to unveil the\\nactual latent affective bias that exists in the model. Therefore in the\\nfuture, we are considering extending the study with a set of real-world\\n14'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 14, 'page_label': '15', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='A. Kadan, Deepak P., S. Bhadra et al. Natural Language Processing Journal 7 (2024) 100062\\ncontext evaluation corpora, for example, by expanding CSP in terms of\\nthe number of sentences and also by procuring ground truth emotions\\nthat allow applying other evaluation measures like Equal Opportunity\\n(Du et al., 2021). Beyond analyzing each sentence pair in a domain\\nseparately, we are looking into the ways to simultaneously analyze\\nsentences representing various social groups in a domain, for example,\\nanalyzing sentence triplets like Male versus Female versus Non-binary.\\nA very recent and relevant work that addresses a similar line of\\nthoughts in the context of affect agnostic bias in PLMs from pre-training\\ndata to language models to downstream tasks in the political domain\\nis explained in Feng et al. (2023). In the backdrop of this work, we\\nobserve a wide scope of exploring political affective biasin large PLMs.\\nBecause, there are works in the literature that give hints that emotions'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 14, 'page_label': '15', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='observe a wide scope of exploring political affective biasin large PLMs.\\nBecause, there are works in the literature that give hints that emotions\\nsuch as anger, disgust, or fear are more frequent in the predictions of\\nrepublicans’ (right-leaning) posts, whereas love or sadness are more\\noften predicted for democrats’ (left-leaning) posts (Huguet Cabot et al.,\\n2020).\\nOur initial attempt to identify affective bias in textual emotion\\ndetection models that utilize large PLMs, opens up the vast future scope\\ntowards identifying affective bias in the other very recent large PLMs\\nsuch as LLAMA, Flan-T5 XXL, PaLM, LaMDA, etc. There also exists a\\nwide scope for affective bias mitigation, which we believe, can be better\\nachieved by adopting more convenient solutions that utilize constraints\\nwhile fine-tuning the prediction system (i.e., in-processing) and post-\\nprocessing, rather than retraining or fine-tuning the PLM based affect\\nprediction systems with unbiased corpora which are expensive and'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 14, 'page_label': '15', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='processing, rather than retraining or fine-tuning the PLM based affect\\nprediction systems with unbiased corpora which are expensive and\\ncumbersome (Hooker, 2021).\\nCRediT authorship contribution statement\\nAnoop Kadan: Conceptualization, Data curation, Formal analy-\\nsis, Investigation, Methodology, Resources, Validation, Visualization,\\nWriting – original draft, Writing – review & editing. Deepak P.: Con-\\nceptualization, Formal analysis, Methodology, Supervision, Writing –\\nreview & editing, Validation. Sahely Bhadra:Formal analysis, Method-\\nology, Supervision, Writing – review & editing, Validation. Manjary\\nP. Gangan:Conceptualization, Formal analysis, Methodology, Writing\\n– original draft, Writing – review & editing. Lajish V.L.: Supervision,\\nWriting – review & editing.\\nDeclaration of competing interest\\nThe authors declare that they have no known competing finan-\\ncial interests or personal relationships that could have appeared to\\ninfluence the work reported in this paper.'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 14, 'page_label': '15', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='The authors declare that they have no known competing finan-\\ncial interests or personal relationships that could have appeared to\\ninfluence the work reported in this paper.\\nAcknowledgments\\nThe authors would like to thank the authors of Tan and Celis (2019)\\nfor making their source codes publicly available and the authors of Kir-\\nitchenko and Mohammad (2018), Venkit and Wilson (2021) and Nangia\\net al. (2020) for making their evaluation corpora publicly available.\\nThe authors would like to thank Chanjal V.V., Master’s student (2018–\\n20) of the Department of Women Studies, University of Calicut for her\\ninvolvement and cooperation to create the list of target terms related\\nto non-binary gender to conduct the corpus level experiments. The first\\nauthor would like to thank Indian Institute of Technology Palakkad for\\norganizing the GIAN course on Fairness in Machine Learning. The third\\nauthor would like to thank the Department of Science and Technology'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 14, 'page_label': '15', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='organizing the GIAN course on Fairness in Machine Learning. The third\\nauthor would like to thank the Department of Science and Technology\\n(DST) of the Government of India for financial support through the\\nWomen Scientist Scheme-A (WOS-A) for Research in Basic/Applied\\nScience under the Grant SR/WOS-A/PM-62/2018.\\nAppendix A. Supplementary data\\nSupplementary material related to this article can be found online\\nat https://doi.org/10.1016/j.nlp.2024.100062.\\nReferences\\nAbid, A., Farooqi, M., Zou, J., 2021a. Large language models associate muslims with\\nviolence. Nat. Mach. Intell. 3 (6), 461–463. http://dx.doi.org/10.1038/s42256-021-\\n00359-2.\\nAbid, A., Farooqi, M., Zou, J., 2021b. Persistent anti-muslim bias in large language\\nmodels. In: Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and\\nSociety. Association for Computing Machinery, New York, NY, USA, pp. 298–306,\\nURL: https://doi.org/10.1145/3461702.3462624.'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 14, 'page_label': '15', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='models. In: Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and\\nSociety. Association for Computing Machinery, New York, NY, USA, pp. 298–306,\\nURL: https://doi.org/10.1145/3461702.3462624.\\nAcheampong, F.A., Nunoo-Mensah, H., Chen, W., 2021. Transformer models for text-\\nbased emotion detection: a review of BERT-based approaches. Artif. Intell. Rev. 54\\n(8), 5789–5829. http://dx.doi.org/10.1007/s10462-021-09958-2.\\nAdoma, A.F., Henry, N.-M., Chen, W., 2020. Comparative analyses of bert, roberta,\\ndistilbert, and xlnet for text-based emotion recognition. In: 2020 17th International\\nComputer Conference on Wavelet Active Media Technology and Information Pro-\\ncessing. ICCWAMTIP, pp. 117–121. http://dx.doi.org/10.1109/ICCWAMTIP51612.\\n2020.9317379.\\nAnoop, K., Gangan, M.P., Deepak, P., Lajish, V.L., 2022. Towards an enhanced\\nunderstanding of bias in pre-trained neural language models: A survey with\\nspecial emphasis on affective bias. In: Responsible Data Science. Springer Nature,'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 14, 'page_label': '15', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='understanding of bias in pre-trained neural language models: A survey with\\nspecial emphasis on affective bias. In: Responsible Data Science. Springer Nature,\\nSingapore, pp. 13–45. http://dx.doi.org/10.1007/978-981-19-4453-6_2.\\nAshley, W., 2014. The angry black woman: The impact of pejorative stereotypes\\non psychotherapy with black women. Soc. Work Public Health 29 (1), 27–34.\\nhttp://dx.doi.org/10.1080/19371918.2011.619449.\\nBhaskaran, J., Bhallamudi, I., 2019. Good secretaries, bad truck drivers? Occupational\\ngender stereotypes in sentiment analysis. In: Proceedings of the First Workshop\\non Gender Bias in Natural Language Processing. Association for Computational\\nLinguistics, Italy, pp. 62–68. http://dx.doi.org/10.18653/v1/W19-3809.\\nBolukbasi, T., Chang, K.-W., Zou, J., Saligrama, V., Kalai, A., 2016. Man is to\\ncomputer programmer as woman is to homemaker? Debiasing word embeddings. In:\\nProceedings of the 30th International Conference on Neural Information Processing'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 14, 'page_label': '15', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='computer programmer as woman is to homemaker? Debiasing word embeddings. In:\\nProceedings of the 30th International Conference on Neural Information Processing\\nSystems. NIPS ’16, Curran Associates Inc., Red Hook, NY, USA, pp. 4356–4364,\\nURL: https://dl.acm.org/doi/10.5555/3157382.3157584.\\nBordia, S., Bowman, S.R., 2019. Identifying and reducing gender bias in word-level\\nlanguage models. In: Proceedings of the 2019 Conference of the North American\\nChapter of the Association for Computational Linguistics: Student Research Work-\\nshop. Association for Computational Linguistics, Minneapolis, Minnesota, pp. 7–15.\\nhttp://dx.doi.org/10.18653/v1/N19-3002.\\nBrown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J.D., Dhariwal, P., Neelakan-\\ntan, A., Shyam, P., Sastry, G., Askell, A., et al., 2020. Language models are few-shot\\nlearners. Adv. Neural Inf. Process. Syst. 33, 1877–1901, URL: https://proceedings.\\nneurips.cc/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf.'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 14, 'page_label': '15', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='learners. Adv. Neural Inf. Process. Syst. 33, 1877–1901, URL: https://proceedings.\\nneurips.cc/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf.\\nCaliskan, A., Bryson, J.J., Narayanan, A., 2017. Semantics derived automatically from\\nlanguage corpora contain human-like biases. Science 356 (6334), 183–186. http:\\n//dx.doi.org/10.1126/science.aal4230.\\nCenter, T.S., 2022. LGBTQIA+ terminology. URL: https://www.umass.edu/stonewall/\\nsites/default/files/documents/allyship_term_handout.pdf. Accessed: 4-7-2022.\\nChowdhery, A., Narang, S., Devlin, J., Bosma, M., Mishra, G., Roberts, A., Barham, P.,\\nChung, H.W., Sutton, C., Gehrmann, S., et al., 2023. Palm: Scaling language\\nmodeling with pathways. J. Mach. Learn. Res. 24 (240), 1–113, URL: https:\\n//www.jmlr.org/papers/volume24/22-1144/22-1144.pdf.\\nChung, H.W., Hou, L., Longpre, S., Zoph, B., Tay, Y., Fedus, W., Li, Y., Wang, X.,\\nDehghani, M., Brahma, S., et al., 2022. Scaling instruction-finetuned language'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 14, 'page_label': '15', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='Chung, H.W., Hou, L., Longpre, S., Zoph, B., Tay, Y., Fedus, W., Li, Y., Wang, X.,\\nDehghani, M., Brahma, S., et al., 2022. Scaling instruction-finetuned language\\nmodels. http://dx.doi.org/10.48550/arXiv.2210.11416, arXiv preprint arXiv:2210.\\n11416.\\nCorbett-Davies, S., Pierson, E., Feller, A., Goel, S., Huq, A., 2017. Algorithmic decision\\nmaking and the cost of fairness. In: Proceedings of the 23rd ACM SIGKDD\\nInternational Conference on Knowledge Discovery and Data Mining. KDD ’17,\\nAssociation for Computing Machinery, New York, NY, USA, pp. 797–806. http:\\n//dx.doi.org/10.1145/3097983.3098095.\\nDale, R., 2019. Law and word order: NLP in legal tech. Nat. Lang. Eng. 25 (1), 211–217.\\nhttp://dx.doi.org/10.1017/S1351324918000475.\\nDe Choudhury, M., Counts, S., Gamon, M., 2012. Not all moods are created equal!\\nexploring human emotional states in social media. In: Proceedings of the Inter-\\nnational AAAI Conference on Web and Social Media. Vol. 6, pp. 66–73, URL:'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 14, 'page_label': '15', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='exploring human emotional states in social media. In: Proceedings of the Inter-\\nnational AAAI Conference on Web and Social Media. Vol. 6, pp. 66–73, URL:\\nhttps://ojs.aaai.org/index.php/ICWSM/article/view/14279.\\nDevlin, J., Chang, M.-W., Lee, K., Toutanova, K., 2019. BERT: Pre-training of deep\\nbidirectional transformers for language understanding. In: Proceedings of the\\n2019 Conference of the North American Chapter of the Association for Compu-\\ntational Linguistics: Human Language Technologies, Volume 1 (Long and Short\\nPapers). Association for Computational Linguistics, Minneapolis, Minnesota, pp.\\n4171–4186. http://dx.doi.org/10.18653/v1/N19-1423, URL: https://aclanthology.\\norg/N19-1423.\\nDíaz, M., Johnson, I., Lazar, A., Piper, A.M., Gergle, D., 2018. Addressing age-related\\nbias in sentiment analysis. In: Proceedings of the 2018 Chi Conference on Human\\nFactors in Computing Systems. Association for Computing Machinery, New York,'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 14, 'page_label': '15', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='bias in sentiment analysis. In: Proceedings of the 2018 Chi Conference on Human\\nFactors in Computing Systems. Association for Computing Machinery, New York,\\nNY, USA, pp. 1–14, URL: https://doi.org/10.1145/3173574.3173986.\\nDixon, L., Li, J., Sorensen, J., Thain, N., Vasserman, L., 2018. Measuring and mitigating\\nunintended bias in text classification. In: Proceedings of the 2018 AAAI/ACM Con-\\nference on AI, Ethics, and Society. AIES ’18, Association for Computing Machinery,\\nNew York, NY, USA, pp. 67–73. http://dx.doi.org/10.1145/3278721.3278729.\\n15'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 15, 'page_label': '16', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='A. Kadan, Deepak P., S. Bhadra et al. Natural Language Processing Journal 7 (2024) 100062\\nDu, M., Yang, F., Zou, N., Hu, X., 2021. Fairness in deep learning: A computational\\nperspective. IEEE Intell. Syst. 36 (4), 25–34. http://dx.doi.org/10.1109/MIS.2020.\\n3000681.\\nEagly, A.H., Steffen, V.J., 1984. Gender stereotypes stem from the distribution of\\nwomen and men into social roles. J. Pers. Soc. Psychol. 46 (4), 735, doi:https:\\n//psycnet.apa.org/doi/10.1037/0022-3514.46.4.735.\\nFeldman, M., Friedler, S.A., Moeller, J., Scheidegger, C., Venkatasubramanian, S.,\\n2015. Certifying and removing disparate impact. In: Proceedings of the 21th ACM\\nSIGKDD International Conference on Knowledge Discovery and Data Mining. KDD\\n’15, Association for Computing Machinery, New York, NY, USA, pp. 259–268.\\nhttp://dx.doi.org/10.1145/2783258.2783311.\\nFeng, S., Park, C.Y., Liu, Y., Tsvetkov, Y., 2023. From pretraining data to language\\nmodels to downstream tasks: Tracking the trails of political biases leading to'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 15, 'page_label': '16', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='Feng, S., Park, C.Y., Liu, Y., Tsvetkov, Y., 2023. From pretraining data to language\\nmodels to downstream tasks: Tracking the trails of political biases leading to\\nunfair NLP models. In: Rogers, A., Boyd-Graber, J., Okazaki, N. (Eds.), Proceedings\\nof the 61st Annual Meeting of the Association for Computational Linguistics\\n(Volume 1: Long Papers). Association for Computational Linguistics, Toronto,\\nCanada, pp. 11737–11762. http://dx.doi.org/10.18653/v1/2023.acl-long.656, URL:\\nhttps://aclanthology.org/2023.acl-long.656.\\nGarg, N., Schiebinger, L., Jurafsky, D., Zou, J., 2018. Word embeddings quantify\\n100 years of gender and ethnic stereotypes. Proc. Natl. Acad. Sci. 115 (16),\\nE3635–E3644.\\nGuo, W., Caliskan, A., 2021. Detecting emergent intersectional biases: Contextualized\\nword embeddings contain a distribution of human-like biases. In: Proceedings\\nof the 2021 AAAI/ACM Conference on AI, Ethics, and Society. Association for'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 15, 'page_label': '16', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='word embeddings contain a distribution of human-like biases. In: Proceedings\\nof the 2021 AAAI/ACM Conference on AI, Ethics, and Society. Association for\\nComputing Machinery, New York, NY, USA, pp. 122–133, URL: https://doi.org/10.\\n1145/3461702.3462536.\\nHahn, H., Seager van Dyk, I., Ahn, W.-Y., 2020. Attitudes toward gay men and lesbian\\nwomen moderate heterosexual adults’ subjective stress response to witnessing\\nhomonegativity. Front. Psychol. 10, 2948. http://dx.doi.org/10.3389/fpsyg.2019.\\n02948.\\nHe, P., Liu, X., Gao, J., Chen, W., 2021. DEBERTA: Decoding-enhanced bert with\\ndisentangled attention. In: International Conference on Learning Representations.\\nURL: https://openreview.net/forum?id=XPZIaotutsD.\\nHooker, S., 2021. Moving beyond ‘‘algorithmic bias is a data problem’’. Patterns 2\\n(4), 100241. http://dx.doi.org/10.1016/j.patter.2021.100241, URL: https://www.\\nsciencedirect.com/science/article/pii/S2666389921000611.'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 15, 'page_label': '16', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='(4), 100241. http://dx.doi.org/10.1016/j.patter.2021.100241, URL: https://www.\\nsciencedirect.com/science/article/pii/S2666389921000611.\\nHovy, D., Prabhumoye, S., 2021. Five sources of bias in natural language processing.\\nLang. Linguist. Compass 15 (8), e12432. http://dx.doi.org/10.1111/lnc3.12432,\\nURL: https://compass.onlinelibrary.wiley.com/doi/abs/10.1111/lnc3.12432.\\nHuang, P.-S., Zhang, H., Jiang, R., Stanforth, R., Welbl, J., Rae, J., Maini, V.,\\nYogatama, D., Kohli, P., 2020. Reducing sentiment bias in language models\\nvia counterfactual evaluation. In: Findings of the Association for Computational\\nLinguistics: EMNLP 2020. Association for Computational Linguistics, Online, pp.\\n65–83. http://dx.doi.org/10.18653/v1/2020.findings-emnlp.7.\\nHuguet Cabot, P.-L., Dankers, V., Abadi, D., Fischer, A., Shutova, E., 2020. The\\npragmatics behind politics: Modelling metaphor, framing and emotion in political\\ndiscourse. In: Cohn, T., He, Y., Liu, Y. (Eds.), Findings of the Association for'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 15, 'page_label': '16', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='pragmatics behind politics: Modelling metaphor, framing and emotion in political\\ndiscourse. In: Cohn, T., He, Y., Liu, Y. (Eds.), Findings of the Association for\\nComputational Linguistics: EMNLP 2020. Association for Computational Linguistics,\\nOnline, pp. 4479–4488. http://dx.doi.org/10.18653/v1/2020.findings-emnlp.402,\\nURL: https://aclanthology.org/2020.findings-emnlp.402.\\nKaneko, M., Bollegala, D., 2022. Unmasking the mask – evaluating social biases in\\nmasked language models. In: Proceedings of the 36th AAAI Conference on Artificial\\nIntelligence. Vancouver, BC, Canada, http://dx.doi.org/10.1609/aaai.v36i11.21453.\\nKiritchenko, S., Mohammad, S., 2018. Examining gender and race bias in two hundred\\nsentiment analysis systems. In: Proceedings of the Seventh Joint Conference on\\nLexical and Computational Semantics. Association for Computational Linguistics,\\nNew Orleans, Louisiana, pp. 43–53. http://dx.doi.org/10.18653/v1/S18-2005, URL:\\nhttps://aclanthology.org/S18-2005.'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 15, 'page_label': '16', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='Lexical and Computational Semantics. Association for Computational Linguistics,\\nNew Orleans, Louisiana, pp. 43–53. http://dx.doi.org/10.18653/v1/S18-2005, URL:\\nhttps://aclanthology.org/S18-2005.\\nLiang, P.P., Wu, C., Morency, L.-P., Salakhutdinov, R., 2021. Towards understanding\\nand mitigating social biases in language models. In: Meila, M., Zhang, T. (Eds.),\\nProceedings of the 38th International Conference on Machine Learning. In: Pro-\\nceedings of Machine Learning Research, vol. 139, PMLR, pp. 6565–6576, URL:\\nhttps://proceedings.mlr.press/v139/liang21a.html.\\nLozada, F.T., Riley, T.N., Catherine, E., Brown, D.W., 2022. Black emotions matter:\\nUnderstanding the impact of racial oppression on black youth’s emotional devel-\\nopment: Dismantling systems of racism and oppression during adolescence. J. Res.\\nAdolesc. 32 (1), 13–33. http://dx.doi.org/10.1111/jora.12699.\\nLu, K., Mardziel, P., Wu, F., Amancharla, P., Datta, A., 2020. Gender bias in neural'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 15, 'page_label': '16', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='Adolesc. 32 (1), 13–33. http://dx.doi.org/10.1111/jora.12699.\\nLu, K., Mardziel, P., Wu, F., Amancharla, P., Datta, A., 2020. Gender bias in neural\\nnatural language processing. In: Logic, Language, and Security: Essays Dedicated\\nto Andre Scedrov on the Occasion of his 65th Birthday. Springer International\\nPublishing, Cham, pp. 189–202. http://dx.doi.org/10.1007/978-3-030-62077-6_14.\\nMao, R., Liu, Q., He, K., Li, W., Cambria, E., 2022. The biases of pre-trained language\\nmodels: An empirical study on prompt-based sentiment analysis and emotion\\ndetection. IEEE Trans. Affect. Comput. 1–11. http://dx.doi.org/10.1109/TAFFC.\\n2022.3204972.\\nMay, C., Wang, A., Bordia, S., Bowman, S.R., Rudinger, R., 2019. On measuring\\nsocial biases in sentence encoders. In: Proceedings of the 2019 Conference of\\nthe North American Chapter of the Association for Computational Linguistics:\\nHuman Language Technologies, Volume 1 (Long and Short Papers). Association'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 15, 'page_label': '16', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='the North American Chapter of the Association for Computational Linguistics:\\nHuman Language Technologies, Volume 1 (Long and Short Papers). Association\\nfor Computational Linguistics, Minneapolis, Minnesota, pp. 622–628. http://dx.doi.\\norg/10.18653/v1/N19-1063.\\nMishev, K., Gjorgjevikj, A., Vodenska, I., Chitkushev, L.T., Trajanov, D., 2020. Evalu-\\nation of sentiment analysis in finance: From lexicons to transformers. IEEE Access\\n8, 131662–131682. http://dx.doi.org/10.1109/ACCESS.2020.3009626.\\nMohammad, S., Bravo-Marquez, F., Salameh, M., Kiritchenko, S., 2018. SemEval-2018\\ntask 1: Affect in tweets. In: Proceedings of the 12th International Workshop\\non Semantic Evaluation. Association for Computational Linguistics, New Or-\\nleans, Louisiana, pp. 1–17. http://dx.doi.org/10.18653/v1/S18-1001, URL: https:\\n//aclanthology.org/S18-1001.\\nNadeem, M., Bethke, A., Reddy, S., 2021. StereoSet: Measuring stereotypical bias\\nin pretrained language models. In: Proceedings of the 59th Annual Meeting of'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 15, 'page_label': '16', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='//aclanthology.org/S18-1001.\\nNadeem, M., Bethke, A., Reddy, S., 2021. StereoSet: Measuring stereotypical bias\\nin pretrained language models. In: Proceedings of the 59th Annual Meeting of\\nthe Association for Computational Linguistics and the 11th International Joint\\nConference on Natural Language Processing (Volume 1: Long Papers). Association\\nfor Computational Linguistics, Online, pp. 5356–5371. http://dx.doi.org/10.18653/\\nv1/2021.acl-long.416, URL: https://aclanthology.org/2021.acl-long.416.\\nNangia, N., Vania, C., Bhalerao, R., Bowman, S.R., 2020. Crows-pairs: A challenge\\ndataset for measuring social biases in masked language models. In: Proceedings\\nof the 2020 Conference on Empirical Methods in Natural Language Processing.\\nEMNLP, Association for Computational Linguistics, Online, pp. 1953–1967. http:\\n//dx.doi.org/10.18653/v1/2020.emnlp-main.154, URL: https://aclanthology.org/\\n2020.emnlp-main.154.\\nNavigli, R., Conia, S., Ross, B., 2023. Biases in large language models: Origins,'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 15, 'page_label': '16', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='//dx.doi.org/10.18653/v1/2020.emnlp-main.154, URL: https://aclanthology.org/\\n2020.emnlp-main.154.\\nNavigli, R., Conia, S., Ross, B., 2023. Biases in large language models: Origins,\\ninventory, and discussion. J. Data Inf. Qual. 15 (2), http://dx.doi.org/10.1145/\\n3597307.\\nPlant, E.A., Hyde, J.S., Keltner, D., Devine, P.G., 2000. The gender stereotyping of\\nemotions. Psychol. Women Q. 24 (1), 81–92. http://dx.doi.org/10.1111/j.1471-\\n6402.2000.tb01024.x.\\nRadford, A., Wu, J., Child, R., Luan, D., Amodei, D., Sutskever, I., et al., 2019.\\nLanguage models are unsupervised multitask learners. OpenAI Blog 1 (8), 9, URL:\\nhttps://openai.com/blog/better-language-models/.\\nRaffel, C., Shazeer, N., Roberts, A., Lee, K., Narang, S., Matena, M., Zhou, Y., Li, W.,\\nLiu, P.J., 2020. Exploring the limits of transfer learning with a unified text-to-text\\ntransformer. J. Mach. Learn. Res. 21 (140), 1–67, URL: http://jmlr.org/papers/v21/\\n20-074.html.'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 15, 'page_label': '16', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='Liu, P.J., 2020. Exploring the limits of transfer learning with a unified text-to-text\\ntransformer. J. Mach. Learn. Res. 21 (140), 1–67, URL: http://jmlr.org/papers/v21/\\n20-074.html.\\nRahman, M.M., Siddiqui, F.H., 2019. An optimized abstractive text summarization\\nmodel using peephole convolutional LSTM. Symmetry 11 (10), http://dx.doi.org/\\n10.3390/sym11101290, URL: https://www.mdpi.com/2073-8994/11/10/1290.\\nRahman, M.M., Siddiqui, F.H., 2021. Multi-layered attentional peephole convolu-\\ntional LSTM for abstractive text summarization. ETRI J. 43 (2), 288–298. http:\\n//dx.doi.org/10.4218/etrij.2019-0016, URL: https://onlinelibrary.wiley.com/doi/\\nabs/10.4218/etrij.2019-0016.\\nRaza, S., Garg, M., Reji, D.J., Bashir, S.R., Ding, C., 2024. Nbias: A natural lan-\\nguage processing framework for BIAS identification in text. Expert Syst. Appl.\\n237, 121542. http://dx.doi.org/10.1016/j.eswa.2023.121542, URL: https://www.\\nsciencedirect.com/science/article/pii/S0957417423020444.'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 15, 'page_label': '16', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='237, 121542. http://dx.doi.org/10.1016/j.eswa.2023.121542, URL: https://www.\\nsciencedirect.com/science/article/pii/S0957417423020444.\\nRozado, D., 2020. Wide range screening of algorithmic bias in word embedding models\\nusing large sentiment lexicons reveals underreported bias types. PLoS One 15 (4),\\n1–26. http://dx.doi.org/10.1371/journal.pone.0231189.\\nShen, J.H., Fratamico, L., Rahwan, I., Rush, A.M., 2018. Darling or babygirl? investi-\\ngating stylistic bias in sentiment analysis. Proc. FATML URL: https://www.fatml.\\norg/media/documents/darling_or_babygirl_stylistic_bias.pdf.\\nShields, S.A., 2002. Speaking from the Heart: Gender and the Social Meaning of\\nEmotion. Cambridge University Press.\\nSkogan, W.G., 1995. Crime and the racial fears of white Americans. Ann.\\nAm. Acad. Political Soc. Sci. 539 (1), 59–71. http://dx.doi.org/10.1177/\\n0002716295539001005.\\nSoni, S., Roberts, K., 2020. Evaluation of dataset selection for pre-training and fine-'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 15, 'page_label': '16', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='Am. Acad. Political Soc. Sci. 539 (1), 59–71. http://dx.doi.org/10.1177/\\n0002716295539001005.\\nSoni, S., Roberts, K., 2020. Evaluation of dataset selection for pre-training and fine-\\ntuning transformer language models for clinical question answering. In: Proceedings\\nof the 12th Language Resources and Evaluation Conference. European Language Re-\\nsources Association, Marseille, France, pp. 5532–5538, URL: https://aclanthology.\\norg/2020.lrec-1.679.\\nStaiano, J., Guerini, M., 2014. Depeche mood: a lexicon for emotion analysis from\\ncrowd annotated news. In: Proceedings of the 52nd Annual Meeting of the\\nAssociation for Computational Linguistics (Volume 2: Short Papers). Association\\nfor Computational Linguistics, Baltimore, Maryland, pp. 427–433. http://dx.doi.\\norg/10.3115/v1/P14-2070, URL: https://aclanthology.org/P14-2070.\\nSu, C., Yu, G., Wang, J., Yan, Z., Cui, L., 2022. A review of causality-based fairness\\nmachine learning. Intell. Robot. 244–274. http://dx.doi.org/10.20517/ir.2022.17.'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 15, 'page_label': '16', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='Su, C., Yu, G., Wang, J., Yan, Z., Cui, L., 2022. A review of causality-based fairness\\nmachine learning. Intell. Robot. 244–274. http://dx.doi.org/10.20517/ir.2022.17.\\nSubramanian, S., Rahimi, A., Baldwin, T., Cohn, T., Frermann, L., 2021. Fairness-aware\\nclass imbalanced learning. In: Moens, M.-F., Huang, X., Specia, L., Yih, S.W.-\\nt. (Eds.), Proceedings of the 2021 Conference on Empirical Methods in Natural\\nLanguage Processing. Association for Computational Linguistics, Online and Punta\\nCana, Dominican Republic, pp. 2045–2051. http://dx.doi.org/10.18653/v1/2021.\\nemnlp-main.155, URL: https://aclanthology.org/2021.emnlp-main.155.\\nSuresh, H., Guttag, J., 2021. A framework for understanding sources of harm\\nthroughout the machine learning life cycle. In: Equity and Access in Algorithms,\\nMechanisms, and Optimization. EAAMO ’21, Association for Computing Machinery,\\nNew York, NY, USA, http://dx.doi.org/10.1145/3465416.3483305.'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 15, 'page_label': '16', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='Mechanisms, and Optimization. EAAMO ’21, Association for Computing Machinery,\\nNew York, NY, USA, http://dx.doi.org/10.1145/3465416.3483305.\\nSweeney, C., Najafian, M., 2020. Reducing sentiment polarity for demographic at-\\ntributes in word embeddings using adversarial learning. In: Proceedings of the\\n16'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 16, 'page_label': '17', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='A. Kadan, Deepak P., S. Bhadra et al. Natural Language Processing Journal 7 (2024) 100062\\n2020 Conference on Fairness, Accountability, and Transparency. In: FAT* ’20,\\nAssociation for Computing Machinery, New York, NY, USA, pp. 359–368. http:\\n//dx.doi.org/10.1145/3351095.3372837.\\nTabinda Kokab, S., Asghar, S., Naz, S., 2022. Transformer-based deep learning mod-\\nels for the sentiment analysis of social media data. Array 14, 100157. http:\\n//dx.doi.org/10.1016/j.array.2022.100157, URL: https://www.sciencedirect.com/\\nscience/article/pii/S2590005622000224.\\nTan, Y.C., Celis, L.E., 2019. Assessing social and intersectional biases in contextualized\\nword representations. In: Proceedings of the 33rd International Conference on\\nNeural Information Processing Systems. Curran Associates Inc., Red Hook, NY, USA,\\npp. 13230–13241, URL: https://dl.acm.org/doi/10.5555/3454287.3455472.\\nThoppilan, R., De Freitas, D., Hall, J., Shazeer, N., Kulshreshtha, A., Cheng, H.-T.,'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 16, 'page_label': '17', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='pp. 13230–13241, URL: https://dl.acm.org/doi/10.5555/3454287.3455472.\\nThoppilan, R., De Freitas, D., Hall, J., Shazeer, N., Kulshreshtha, A., Cheng, H.-T.,\\nJin, A., Bos, T., Baker, L., Du, Y., et al., 2022. Lamda: Language models for\\ndialog applications. http://dx.doi.org/10.48550/arXiv.2201.08239, arXiv preprint\\narXiv:2201.08239.\\nTouvron, H., Lavril, T., Izacard, G., Martinet, X., Lachaux, M.-A., Lacroix, T., Rozière, B.,\\nGoyal, N., Hambro, E., Azhar, F., et al., 2023. Llama: Open and efficient foundation\\nlanguage models. arXiv preprint arXiv:2302.13971. URL: https://research.facebook.\\ncom/publications/llama-open-and-efficient-foundation-language-models/.\\nTrinh, T.H., Le, Q.V., 2018. A simple method for commonsense reasoning. http://dx.\\ndoi.org/10.48550/arXiv.1806.02847, arXiv preprint arXiv:1806.02847.\\nVelupillai, S., Suominen, H., Liakata, M., Roberts, A., Shah, A.D., Morley, K., Os-\\nborn, D., Hayes, J., Stewart, R., Downs, J., Chapman, W., Dutta, R., 2018.'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 16, 'page_label': '17', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='Velupillai, S., Suominen, H., Liakata, M., Roberts, A., Shah, A.D., Morley, K., Os-\\nborn, D., Hayes, J., Stewart, R., Downs, J., Chapman, W., Dutta, R., 2018.\\nUsing clinical natural language processing for health outcomes research: Overview\\nand actionable suggestions for future advances. J. Biomed. Inform. 88, 11–19.\\nhttp://dx.doi.org/10.1016/j.jbi.2018.10.005, URL: https://www.sciencedirect.com/\\nscience/article/pii/S1532046418302016.\\nVenkit, P.N., Wilson, S., 2021. Identification of bias against people with disabilities\\nin sentiment analysis and toxicity detection models. http://dx.doi.org/10.48550/\\narXiv.2111.13259, arXiv preprint arXiv:2111.13259.\\nVittengl, J.R., Holt, C.S., 1998. A time-series diary study of mood and social interaction.\\nMotiv. Emot. 22 (3), 255–275. http://dx.doi.org/10.1023/A:1022388123550.\\nWaterloo, S.F., Baumgartner, S.E., Peter, J., Valkenburg, P.M., 2018. Norms of\\nonline expressions of emotion: Comparing facebook, Twitter, instagram, and'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 16, 'page_label': '17', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='Waterloo, S.F., Baumgartner, S.E., Peter, J., Valkenburg, P.M., 2018. Norms of\\nonline expressions of emotion: Comparing facebook, Twitter, instagram, and\\nWhatsApp. New Media Soc. 20 (5), 1813–1831. http://dx.doi.org/10.1177/\\n1461444817707349, PMID: 30581358.\\nYang, Z., Asyrofi, M.H., Lo, D., 2021. BiasRV: Uncovering biased sentiment predictions\\nat runtime. In: Proceedings of the 29th ACM Joint Meeting on European Software\\nEngineering Conference and Symposium on the Foundations of Software Engineer-\\ning. In: ESEC/FSE 2021, Association for Computing Machinery, New York, NY,\\nUSA, pp. 1540–1544. http://dx.doi.org/10.1145/3468264.3473117.\\nYang, Z., Dai, Z., Yang, Y., Carbonell, J., Salakhutdinov, R., Le, Q.V., 2019. XLNet:\\nGeneralized autoregressive pretraining for language understanding. In: Proceedings\\nof the 33rd International Conference on Neural Information Processing Systems.\\nCurran Associates Inc., Red Hook, NY, USA, pp. 5753–5763, URL: https://dl.acm.'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 16, 'page_label': '17', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='of the 33rd International Conference on Neural Information Processing Systems.\\nCurran Associates Inc., Red Hook, NY, USA, pp. 5753–5763, URL: https://dl.acm.\\norg/doi/10.5555/3454287.3454804.\\nZhang, L., Fan, H., Peng, C., Rao, G., Cong, Q., 2020. Sentiment analysis methods\\nfor HPV vaccines related tweets based on transfer learning. Healthcare 8 (3),\\nhttp://dx.doi.org/10.3390/healthcare8030307, URL: https://www.mdpi.com/2227-\\n9032/8/3/307.\\nZhao, J., Wang, T., Yatskar, M., Cotterell, R., Ordonez, V., Chang, K.-W., 2019. Gender\\nbias in contextualized word embeddings. In: Proceedings of the 2019 Conference\\nof the North American Chapter of the Association for Computational Linguistics:\\nHuman Language Technologies, Volume 1 (Long and Short Papers). Association for\\nComputational Linguistics, Minneapolis, Minnesota, pp. 629–634. http://dx.doi.org/\\n10.18653/v1/N19-1064, URL: https://aclanthology.org/N19-1064.\\nZhao, J., Wang, T., Yatskar, M., Ordonez, V., Chang, K.-W., 2018. Gender bias in'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 16, 'page_label': '17', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='10.18653/v1/N19-1064, URL: https://aclanthology.org/N19-1064.\\nZhao, J., Wang, T., Yatskar, M., Ordonez, V., Chang, K.-W., 2018. Gender bias in\\ncoreference resolution: Evaluation and debiasing methods. In: Proceedings of the\\n2018 Conference of the North American Chapter of the Association for Com-\\nputational Linguistics: Human Language Technologies, Volume 2 (Short Papers).\\nAssociation for Computational Linguistics, New Orleans, Louisiana, pp. 15–20.\\nhttp://dx.doi.org/10.18653/v1/N18-2003.\\nZhiltsova, A., Caton, S., Mulway, C., 2019. Mitigation of unintended biases against\\nnon-native english texts in sentiment analysis. In: Proceedings for the 27th AIAI\\nIrish Conference on Artificial Intelligence and Cognitive Science, Galway, Ireland,\\nDecember 5-6, 2019. In: CEUR Workshop Proceedings, vol. 2563, CEUR-WS.org,\\npp. 317–328, URL: http://ceur-ws.org/Vol-2563/aics_30.pdf.\\nZhu, Y., Kiros, R., Zemel, R., Salakhutdinov, R., Urtasun, R., Torralba, A., Fidler, S.,'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 16, 'page_label': '17', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='pp. 317–328, URL: http://ceur-ws.org/Vol-2563/aics_30.pdf.\\nZhu, Y., Kiros, R., Zemel, R., Salakhutdinov, R., Urtasun, R., Torralba, A., Fidler, S.,\\n2015. Aligning books and movies: Towards story-like visual explanations by\\nwatching movies and reading books. In: Proceedings of the 2015 IEEE International\\nConference on Computer Vision. ICCV, IEEE Computer Society, USA, pp. 19–27.\\nhttp://dx.doi.org/10.1109/ICCV.2015.11.\\n17')]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks=split_documents(all_pdf_documents)\n",
    "chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474c7049",
   "metadata": {},
   "source": [
    "### embedding And vectorStoreDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "226b5d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "import uuid\n",
    "from typing import List, Dict, Any, Tuple\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ecede55e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding model: all-MiniLM-L6-v2\n",
      "Model loaded successfully. Embedding dimension: 384\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.EmbeddingManager at 0x12d88e270>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class EmbeddingManager:\n",
    "    \"\"\"Handles document embedding generation using SentenceTransformer\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name: str = \"all-MiniLM-L6-v2\"):\n",
    "        \"\"\"\n",
    "        Initialize the embedding manager\n",
    "        \n",
    "        Args:\n",
    "            model_name: HuggingFace model name for sentence embeddings\n",
    "        \"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.model = None\n",
    "        self._load_model()\n",
    "\n",
    "    def _load_model(self):\n",
    "        \"\"\"Load the SentenceTransformer model\"\"\"\n",
    "        try:\n",
    "            print(f\"Loading embedding model: {self.model_name}\")\n",
    "            self.model = SentenceTransformer(self.model_name)\n",
    "            print(f\"Model loaded successfully. Embedding dimension: {self.model.get_sentence_embedding_dimension()}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model {self.model_name}: {e}\")\n",
    "            raise\n",
    "\n",
    "    def generate_embeddings(self, texts: List[str]) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Generate embeddings for a list of texts\n",
    "        \n",
    "        Args:\n",
    "            texts: List of text strings to embed\n",
    "            \n",
    "        Returns:\n",
    "            numpy array of embeddings with shape (len(texts), embedding_dim)\n",
    "        \"\"\"\n",
    "        if not self.model:\n",
    "            raise ValueError(\"Model not loaded\")\n",
    "        \n",
    "        print(f\"Generating embeddings for {len(texts)} texts...\")\n",
    "        embeddings = self.model.encode(texts, show_progress_bar=True)\n",
    "        print(f\"Generated embeddings with shape: {embeddings.shape}\")\n",
    "        return embeddings\n",
    "\n",
    "\n",
    "## initialize the embedding manager\n",
    "\n",
    "embedding_manager=EmbeddingManager()\n",
    "embedding_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e2ba6bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store initialized. Collection: pdf_documents\n",
      "Existing documents in collection: 382\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.VectorStore at 0x12d88f230>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class VectorStore:\n",
    "    \"\"\"Manages document embeddings in a ChromaDB vector store\"\"\"\n",
    "    \n",
    "    def __init__(self, collection_name: str = \"pdf_documents\", persist_directory: str = \"../data/vector_store\"):\n",
    "        \"\"\"\n",
    "        Initialize the vector store\n",
    "        \n",
    "        Args:\n",
    "            collection_name: Name of the ChromaDB collection\n",
    "            persist_directory: Directory to persist the vector store\n",
    "        \"\"\"\n",
    "        self.collection_name = collection_name\n",
    "        self.persist_directory = persist_directory\n",
    "        self.client = None\n",
    "        self.collection = None\n",
    "        self._initialize_store()\n",
    "\n",
    "    def _initialize_store(self):\n",
    "        \"\"\"Initialize ChromaDB client and collection\"\"\"\n",
    "        try:\n",
    "            # Create persistent ChromaDB client\n",
    "            os.makedirs(self.persist_directory, exist_ok=True)\n",
    "            self.client = chromadb.PersistentClient(path=self.persist_directory)\n",
    "            \n",
    "            # Get or create collection\n",
    "            self.collection = self.client.get_or_create_collection(\n",
    "                name=self.collection_name,\n",
    "                metadata={\"description\": \"PDF document embeddings for RAG\"}\n",
    "            )\n",
    "            print(f\"Vector store initialized. Collection: {self.collection_name}\")\n",
    "            print(f\"Existing documents in collection: {self.collection.count()}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error initializing vector store: {e}\")\n",
    "            raise\n",
    "\n",
    "    def add_documents(self, documents: List[Any], embeddings: np.ndarray):\n",
    "        \"\"\"\n",
    "        Add documents and their embeddings to the vector store\n",
    "        \n",
    "        Args:\n",
    "            documents: List of LangChain documents\n",
    "            embeddings: Corresponding embeddings for the documents\n",
    "        \"\"\"\n",
    "        if len(documents) != len(embeddings):\n",
    "            raise ValueError(\"Number of documents must match number of embeddings\")\n",
    "        \n",
    "        print(f\"Adding {len(documents)} documents to vector store...\")\n",
    "        \n",
    "        # Prepare data for ChromaDB\n",
    "        ids = []\n",
    "        metadatas = []\n",
    "        documents_text = []\n",
    "        embeddings_list = []\n",
    "        \n",
    "        for i, (doc, embedding) in enumerate(zip(documents, embeddings)):\n",
    "            # Generate unique ID\n",
    "            doc_id = f\"doc_{uuid.uuid4().hex[:8]}_{i}\"\n",
    "            ids.append(doc_id)\n",
    "            \n",
    "            # Prepare metadata\n",
    "            metadata = dict(doc.metadata)\n",
    "            metadata['doc_index'] = i\n",
    "            metadata['content_length'] = len(doc.page_content)\n",
    "            metadatas.append(metadata)\n",
    "            \n",
    "            # Document content\n",
    "            documents_text.append(doc.page_content)\n",
    "            \n",
    "            # Embedding\n",
    "            embeddings_list.append(embedding.tolist())\n",
    "        \n",
    "        # Add to collection\n",
    "        try:\n",
    "            self.collection.add(\n",
    "                ids=ids,\n",
    "                embeddings=embeddings_list,\n",
    "                metadatas=metadatas,\n",
    "                documents=documents_text\n",
    "            )\n",
    "            print(f\"Successfully added {len(documents)} documents to vector store\")\n",
    "            print(f\"Total documents in collection: {self.collection.count()}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error adding documents to vector store: {e}\")\n",
    "            raise\n",
    "\n",
    "vectorstore=VectorStore()\n",
    "vectorstore\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e911396d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'Skia/PDF m144 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'cn', 'source': '../data/pdf_files/cn.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'cn.pdf', 'file_type': 'pdf'}, page_content='Computer  Networks  enable  communication  between  devices  through  a  set  of  rules  called  protocols.  Among  \\nthese,\\n \\nTCP\\n \\n(Transmission\\n \\nControl\\n \\nProtocol)\\n \\nand\\n \\nUDP\\n \\n(User\\n \\nDatagram\\n \\nProtocol)\\n \\nare\\n \\ntwo\\n \\nof\\n \\nthe\\n \\nmost\\n \\nwidely\\n \\nused\\n \\ntransport-layer\\n \\nprotocols\\n \\ndefined\\n \\nin\\n \\nthe\\n \\nTCP/IP\\n \\nmodel.\\n \\nTCP  is  a  connection-oriented  protocol,  meaning  a  connection  must  be  established  before  data  can  be  \\nexchanged.\\n \\nIt\\n \\nensures\\n \\nreliable\\n \\nand\\n \\nordered\\n \\ndelivery\\n \\nthrough\\n \\nmechanisms\\n \\nlike\\n \\nacknowledgment\\n \\n(ACK),\\n \\nretransmission,\\n \\nflow\\n \\ncontrol,\\n \\nand\\n \\ncongestion\\n \\ncontrol.\\n \\nTCP\\n \\nbreaks\\n \\nlarge\\n \\nmessages\\n \\ninto\\n \\nsegments,\\n \\nassigns\\n \\nsequence\\n \\nnumbers,\\n \\nand\\n \\nuses\\n \\nACKs\\n \\nto\\n \\nconfirm\\n \\nreceipt.\\n \\nIf\\n \\na\\n \\nsegment\\n \\nis\\n \\nlost,\\n \\nTCP\\n \\nretransmits\\n \\nit\\n \\nautomatically.\\n \\nThis\\n \\nreliability\\n \\nmakes\\n \\nTCP\\n \\nideal\\n \\nfor\\n \\napplications\\n \\nlike\\n \\nweb\\n \\nbrowsing\\n \\n(HTTP/HTTPS),\\n \\nemail,\\n \\nand\\n \\nfile\\n \\ntransfers,\\n \\nwhere\\n \\naccuracy\\n \\nis'),\n",
       " Document(metadata={'producer': 'Skia/PDF m144 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'cn', 'source': '../data/pdf_files/cn.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'cn.pdf', 'file_type': 'pdf'}, page_content='retransmits\\n \\nit\\n \\nautomatically.\\n \\nThis\\n \\nreliability\\n \\nmakes\\n \\nTCP\\n \\nideal\\n \\nfor\\n \\napplications\\n \\nlike\\n \\nweb\\n \\nbrowsing\\n \\n(HTTP/HTTPS),\\n \\nemail,\\n \\nand\\n \\nfile\\n \\ntransfers,\\n \\nwhere\\n \\naccuracy\\n \\nis\\n \\nmore\\n \\nimportant\\n \\nthan\\n \\nspeed.\\n \\nUDP ,  in  contrast,  is  a  connectionless  protocol.  It  sends  datagrams  without  establishing  a  connection  and  does  \\nnot\\n \\nguarantee\\n \\ndelivery,\\n \\nordering,\\n \\nor\\n \\nerror\\n \\ncorrection.\\n \\nSince\\n \\nUDP\\n \\neliminates\\n \\noverhead,\\n \\nit\\n \\nis\\n \\nextremely\\n \\nfast\\n \\nand\\n \\nsuitable\\n \\nfor\\n \\nreal-time\\n \\napplications\\n \\nlike\\n \\ngaming,\\n \\nlive\\n \\nvideo\\n \\nstreaming,\\n \\nand\\n \\nVoIP,\\n \\nwhere\\n \\nspeed\\n \\nand\\n \\nlow\\n \\nlatency\\n \\nare\\n \\nmore\\n \\nimportant\\n \\nthan\\n \\nperfect\\n \\naccuracy.\\n \\nFor\\n \\nexample,\\n \\nin\\n \\na\\n \\nvideo\\n \\ncall,\\n \\nlosing\\n \\na\\n \\nfew\\n \\npackets\\n \\nis\\n \\nacceptable\\n \\ncompared\\n \\nto\\n \\nwaiting\\n \\nfor\\n \\ndelayed\\n \\nretransmissions.\\n \\nReliable  data  transfer  depends  heavily  on  the  characteristics  of  these  protocols.  TCP  provides  reliability  using  \\nseveral'),\n",
       " Document(metadata={'producer': 'Skia/PDF m144 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'cn', 'source': '../data/pdf_files/cn.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'cn.pdf', 'file_type': 'pdf'}, page_content='compared\\n \\nto\\n \\nwaiting\\n \\nfor\\n \\ndelayed\\n \\nretransmissions.\\n \\nReliable  data  transfer  depends  heavily  on  the  characteristics  of  these  protocols.  TCP  provides  reliability  using  \\nseveral\\n \\ntechniques:\\n \\n●  Three-Way  Handshake:  \\n \\nEnsures\\n \\nboth\\n \\nsender\\n \\nand\\n \\nreceiver\\n \\nare\\n \\nready\\n \\nfor\\n \\ncommunication\\n \\nbefore\\n \\ndata\\n \\ntransfer\\n \\nbegins.\\n \\n ●  Flow  Control  (Sliding  Window):  \\n \\nPrevents\\n \\nthe\\n \\nsender\\n \\nfrom\\n \\noverwhelming\\n \\nthe\\n \\nreceiver\\n \\nby\\n \\nadjusting\\n \\nthe\\n \\nsending\\n \\nrate.\\n \\n ●  Congestion  Control  (AIMD,  Slow  Start):  \\n \\nAdjusts\\n \\nsending\\n \\nrate\\n \\nbased\\n \\non\\n \\nnetwork\\n \\nload\\n \\nto\\n \\navoid\\n \\ncongestion\\n \\ncollapse.\\n \\n ●  Checksums:  \\n \\nDetects\\n \\nerrors\\n \\nin\\n \\ntransmitted\\n \\nsegments.\\n \\n \\nUDP,  though  unreliable  by  design,  can  still  achieve  reliability  when  necessary  through  application-level  \\nmechanisms,\\n \\nsuch\\n \\nas\\n \\nadded\\n \\nsequence\\n \\nnumbers\\n \\nor\\n \\nmanual\\n \\nacknowledgments.\\n \\nSome\\n \\nmodern\\n \\nprotocols\\n \\nlike\\n \\nQUIC\\n \\nuse\\n \\nUDP\\n \\nas\\n \\na\\n \\nbase'),\n",
       " Document(metadata={'producer': 'Skia/PDF m144 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'cn', 'source': '../data/pdf_files/cn.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'cn.pdf', 'file_type': 'pdf'}, page_content='mechanisms,\\n \\nsuch\\n \\nas\\n \\nadded\\n \\nsequence\\n \\nnumbers\\n \\nor\\n \\nmanual\\n \\nacknowledgments.\\n \\nSome\\n \\nmodern\\n \\nprotocols\\n \\nlike\\n \\nQUIC\\n \\nuse\\n \\nUDP\\n \\nas\\n \\na\\n \\nbase\\n \\nbut\\n \\nadd\\n \\nreliability\\n \\nfeatures\\n \\nfor\\n \\nimproved\\n \\nperformance.\\n \\nUnderstanding  TCP  vs  UDP  helps  developers  choose  the  right  protocol  for  different  scenarios.  TCP  suits  \\ndata-sensitive\\n \\napplications,\\n \\nwhereas\\n \\nUDP\\n \\nis\\n \\nthe\\n \\nbetter\\n \\nchoice\\n \\nfor\\n \\nlatency-critical\\n \\ntasks.'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 0, 'page_label': '1', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='sustainability\\nReview\\nArtiﬁcial Intelligence and Machine Learning\\nApplications in Smart Production: Progress, Trends,\\nand Directions\\nRaﬀaele Cioﬃ 1, Marta Travaglioni 1, Giuseppina Piscitelli 1, Antonella Petrillo 1, *\\n and\\nFabio De Felice 2\\n1 Department of Engineering, Parthenope University, Isola C4, Centro Direzionale, 80143 Napoli NA, Italy;\\nraﬀaele.cioﬃ@uniparthenope.it (R.C.); marta.travaglioni@uniparthenope.it (M.T.);\\ngiuseppina.piscitelli@uniparthenope.it (G.P .)\\n2 Department of Civil and Mechanical Engineering, University of Cassino and Southern Lazio, Via G. Di\\nBiasio, 43, 03043 Cassino FR, Italy; defelice@unicas.it\\n* Correspondence: antonella.petrillo@uniparthenope.it\\nReceived: 1 December 2019; Accepted: 5 January 2020; Published: 8 January 2020\\n/gid00030/gid00035/gid00032/gid00030/gid00038/gid00001/gid00033/gid00042/gid00045/gid00001\\n/gid00048/gid00043/gid00031/gid00028/gid00047/gid00032/gid00046'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 0, 'page_label': '1', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='/gid00030/gid00035/gid00032/gid00030/gid00038/gid00001/gid00033/gid00042/gid00045/gid00001\\n/gid00048/gid00043/gid00031/gid00028/gid00047/gid00032/gid00046\\nAbstract: Adaptation and innovation are extremely important to the manufacturing industry.\\nThis development should lead to sustainable manufacturing using new technologies. To promote\\nsustainability, smart production requires global perspectives of smart production application\\ntechnology. In this regard, thanks to intensive research eﬀorts in the ﬁeld of artiﬁcial intelligence (AI),\\na number of AI-based techniques, such as machine learning, have already been established in the\\nindustry to achieve sustainable manufacturing. Thus, the aim of the present research was to analyze,\\nsystematically, the scientiﬁc literature relating to the application of artiﬁcial intelligence and machine\\nlearning (ML) in industry. In fact, with the introduction of the Industry 4.0, artiﬁcial intelligence and'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 0, 'page_label': '1', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='learning (ML) in industry. In fact, with the introduction of the Industry 4.0, artiﬁcial intelligence and\\nmachine learning are considered the driving force of smart factory revolution. The purpose of this\\nreview was to classify the literature, including publication year, authors, scientiﬁc sector, country,\\ninstitution, and keywords. The analysis was done using the Web of Science and SCOPUS database.\\nFurthermore, UCINET and NVivo 12 software were used to complete them. A literature review on\\nML and AI empirical studies published in the last century was carried out to highlight the evolution\\nof the topic before and after Industry 4.0 introduction, from 1999 to now. Eighty-two articles were\\nreviewed and classiﬁed. A ﬁrst interesting result is the greater number of works published by the\\nUSA and the increasing interest after the birth of Industry 4.0.\\nKeywords: artiﬁcial intelligence; machine learning; systematic literature review; applications;'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 0, 'page_label': '1', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='USA and the increasing interest after the birth of Industry 4.0.\\nKeywords: artiﬁcial intelligence; machine learning; systematic literature review; applications;\\nIndustry 4.0; smart production; sustainability\\n1. Introduction\\nSmart production systems require innovative solutions to increase the quality and sustainability\\nof manufacturing activities while reducing costs. In this context, artiﬁcial intelligence (AI)-driven\\ntechnologies, leveraged by I4.0 Key Enabling Technologies (e.g., Internet of Thing, advanced embedded\\nsystems, cloud computing, big data, cognitive systems, virtual and augmented reality), are ready to\\ngenerate new industrial paradigms [1].\\nIn this regard, it is interesting to remember that the father of artiﬁcial intelligence, John McCarthy [2],\\nin the 1990s, deﬁned artiﬁcial intelligence as “artiﬁcial intelligence is the science and engineering of\\nmaking intelligent machines, especially intelligent computer programs”. Generally, the term “AI” is'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 0, 'page_label': '1', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='making intelligent machines, especially intelligent computer programs”. Generally, the term “AI” is\\nused when a machine simulates functions that humans associate with other human minds, such as\\nlearning and problem solving [3].\\nSustainability 2020, 12, 492; doi:10.3390/su12020492 www.mdpi.com /journal/sustainability'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 1, 'page_label': '2', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Sustainability 2020, 12, 492 2 of 26\\nOn a very broad account, the areas of artiﬁcial intelligence are classiﬁed into 16 categories [4–8].\\nThese are reasoning, programming, artiﬁcial life, belief revision, data mining, distributed AI, expert\\nsystems, genetic algorithms, systems, knowledge representation, machine learning, natural language\\nunderstanding, neural networks, theorem proving, constraint satisfaction, and theory of computation [9–\\n11].\\nIn the 21st century, AI has become an important area of research in all ﬁelds: Engineering, science,\\neducation, medicine, business, accounting, ﬁnance, marketing, economics, stock market, and law,\\namong others [12–18]. The range of AI has grown enormously since the intelligence of machines with\\nmachine learning capabilities has created profound impacts on business, governments, and society [19].\\nThey also inﬂuence the larger trends in global sustainability. Artiﬁcial intelligence can be useful to solve'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 1, 'page_label': '2', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='They also inﬂuence the larger trends in global sustainability. Artiﬁcial intelligence can be useful to solve\\ncritical issue for sustainable manufacturing (e.g., optimization of energy resources, logistics, supply\\nchain management, waste management, etc.). In this context, in smart production, there is a trend to\\nincorporate AI into green manufacturing processes for stricter environmental policies [20]. In fact, as\\nsaid in March 2019 by Hendrik Fink, head of Sustainability Services at PricewaterhouseCoopers, “If we\\nproperly incorporate artiﬁcial intelligence, we can achieve a revolution with regard to sustainability.\\nAI will be the driving force of the fourth industrial revolution” [21].\\nThus, subﬁelds of AI, such as machine learning, natural language processing, image processing,\\nand data mining, have also become an important topic for today’s tech giants. The subject of AI\\ngenerates considerable interest in the scientiﬁc community, by virtue of the continuous evolution of'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 1, 'page_label': '2', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='and data mining, have also become an important topic for today’s tech giants. The subject of AI\\ngenerates considerable interest in the scientiﬁc community, by virtue of the continuous evolution of\\nthe technologies available today.\\nThe development of ML as a branch of AI is now very fast. Its usage has spread to various\\nﬁelds, such as learning machines, which are currently used in smart manufacturing, medical science,\\npharmacology, agriculture, archeology, games, business, and so forth.\\nAccording to the above considerations, in this work, a systematic literature review of research\\nfrom 1999 to 2019 was performed on AI and the ML technique. Therefore, it is considered necessary to\\ncreate a classiﬁcation system that refers to the articles that jointly treat the two topics, in order to have\\ngreater variance and reﬂection. Furthermore, to gain a deeper understanding, the inﬂuence of other\\nvariables was explored, such as the thematic areas and the sectors in which the technologies are most'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 1, 'page_label': '2', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='variables was explored, such as the thematic areas and the sectors in which the technologies are most\\ninﬂuential. The main contribution of this work is that it provides an overview of the research carried\\nout to date.\\nA number of impressive documentations of established research methods and philosophy have\\nbeen discussed for several years. Unfortunately, little comparison and integration across studies exists.\\nIn this article, a common understanding of AI and ML research and its variations was created.\\nThis paper is not attempting to provide an all-encompassing framework on the literature on AI\\nand ML research. Rather, it attempts to provide a starting point for integrating knowledge across\\nresearch in this domain and suggests paths for future research. It explores studies in certain novel\\ndisciplines: Environmental pollution, medicine, maintenance, manufacturing, etc.\\nFurther research is needed to extend the present boundary of knowledge in AI by integrating'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 1, 'page_label': '2', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='disciplines: Environmental pollution, medicine, maintenance, manufacturing, etc.\\nFurther research is needed to extend the present boundary of knowledge in AI by integrating\\nprinciples and philosophies of some traditional disciplines into the existing AI frameworks [22–24].\\nThe target that this document would like to assume is not the trigger of a sudden proliferation of\\nan already consolidated sector, but it is hoped that this research could be an important intellectual tool\\nfor both the refocusing of the work and creating new intellectual opportunities. This paper presents\\nvaluable ideas and perspectives for undergoing research on AI and ML.\\nThe ﬁnal aim was to anticipate the transformation of the discipline in the future age. This would\\nbe a journey that may experience change in its course as new generations of scholars contribute to the\\ndialogue and to the action. As noted earlier, this work presents a review, hence it lays a foundation for'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 1, 'page_label': '2', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='dialogue and to the action. As noted earlier, this work presents a review, hence it lays a foundation for\\nfuture inquiry. It not only oﬀers a basis for future comparisons but prompts a number of new questions\\nfor investigations as well. While topics that might be considered as results of this work are numerous,\\nsome are of particularly broad interest or impact.'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 2, 'page_label': '3', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Sustainability 2020, 12, 492 3 of 26\\nThe paper is organized as follows. Section 2 presents the proposed methodology and details the\\nresearch methodology adopted for the literature survey. Section 3 analyzes the main results of the\\nbibliometric analysis. Finally, in Section 4, the main contribution of the research is summarized.\\n2. Methodology\\nThe methodological approach used mixes bibliometric, content analysis, and social network\\ntechniques. In this study, a state-of-the-art research was conducted through the SCOPUS and Web\\nof Science databases. For the publication time span, the time from 1999 to 2019 was considered with\\nthe intent to understand how the level of attention towards the topic has changed before and after\\nthe introduction of Industry 4.0. The research methodology chosen for this study was a systematic\\nliterature review [25]. The main phases of the study were as follows:\\n1. Phase 1: Research and Classiﬁcation. The present phase was divided into three steps:'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 2, 'page_label': '3', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='literature review [25]. The main phases of the study were as follows:\\n1. Phase 1: Research and Classiﬁcation. The present phase was divided into three steps:\\n• Step 1: Identiﬁcation;\\n• Step 2: Screening; and\\n• Step 3: Inclusion.\\nIn phase 1, bibliometric data was collected (step 1). Then, a screening of the overall result was\\ncarried out to identify which documents can be taken into consideration, in line with the research areas\\ndeemed interesting and relevant (step 2). At the end of this step, the last step (step 3) aimed to select\\nthe documents to be analyzed in detail.\\n2. Phase 2: Analysis. Once phase 1 was completed, the next phase was phase 2, which was the\\nanalysis of the results. The approach used for the bibliometric analysis included:\\n• The use of indicators for the parameters studied; and\\n• SNA (social network analysis) for the keywords.\\nThe indicators chosen to perform the analysis were total papers (TPs), which is the total number'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 2, 'page_label': '3', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='• SNA (social network analysis) for the keywords.\\nThe indicators chosen to perform the analysis were total papers (TPs), which is the total number\\nof publications, and total citations (TCs), which is the total number of citations.\\nSNA ﬁnds application in various social sciences, and has lately been employed in the study of\\nvarious phenomena, such as international trade, information dissemination, the study of institutions,\\nand the functioning of organizations. The analysis of the use of the term SNA in the scientiﬁc literature\\nhas undergone exponential growth in the use of this mode of computable representation of complex\\nand interdependent phenomena. For the purpose of the study, UCINET, NetDraw software was used,\\nwhich was expressly designed for the creation and graphic processing of networks, and was used to\\nrepresent the keywords in the network, and Excel for data input.\\nThe software UCINET, NetDraw returned a sociometric network that describes the relationships'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 2, 'page_label': '3', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='represent the keywords in the network, and Excel for data input.\\nThe software UCINET, NetDraw returned a sociometric network that describes the relationships\\nbetween the classes, that is, data entered as input.\\nFurthermore, NVivo 12 software, the leading program for computer-assisted qualitative analysis\\n(CAQDAS), was used to analyze keywords of all documents. In this speciﬁc case, it was used to\\nidentify the possible links between the keywords of the various documents examined, developing\\nconceptual schemes from which to make interpretative hypotheses.\\n3. Phase 3: Discussion . At the end of the second phase, a third and ﬁnal one followed, where the\\nresults were discussed, and conclusions were drawn.\\nIn Figure 1, the main phases and steps followed for the analysis are shown.'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 3, 'page_label': '4', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Sustainability 2020, 12, 492 4 of 26\\nSustainability 2020, 12, x FOR PEER REVIEW 4 of 24 \\n \\nFigure 1. Process flow chart. \\n3. Results of the Bibliometric Analysis \\n3.1. Phase 1: Research and Classification \\nThe first phase consisted of the search for documents, which included the activities of collecting \\nthe material belonging to the academic universe. This first phase was divided into three steps as \\nfollows. \\n3.1.1. Identification (Step 1) \\nFor a comprehensive survey of the phenomenon, an investigation on the Scopus (SCP) and Web \\nof Science (WoS) databases was ca rried out using Boolean operators. We began by making a search \\nquery on the Scopus and WoS databases with the general keywords “artificial intelligence” AND \\n“machine learning” AND “application”, as shown in Table 1. \\nIn order to maintain the consistency of the re sults, the same keywords were used in both \\ndatabases and a time horizon of 20 years was chosen, from 1999 to 2019.'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 3, 'page_label': '4', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='In order to maintain the consistency of the re sults, the same keywords were used in both \\ndatabases and a time horizon of 20 years was chosen, from 1999 to 2019. \\nThe choice of keywords for performing the survey was based on the awareness that AI and ML \\ncan be an important tool in the effort to adopt responsible business practices in the context of smart \\nproduction. In this regard, it is worthy to note that with the increasingly urgent discussions of climate \\nchange, it seemed appropriate to focus our research on the topic of sustainability. Thus, the selection \\nof papers also considered applications on sustainability. \\nFigure 1. Process ﬂow chart.\\n3. Results of the Bibliometric Analysis\\n3.1. Phase 1: Research and Classiﬁcation\\nThe ﬁrst phase consisted of the search for documents, which included the activities of collecting the\\nmaterial belonging to the academic universe. This ﬁrst phase was divided into three steps as follows.\\n3.1.1. Identiﬁcation (Step 1)'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 3, 'page_label': '4', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='material belonging to the academic universe. This ﬁrst phase was divided into three steps as follows.\\n3.1.1. Identiﬁcation (Step 1)\\nFor a comprehensive survey of the phenomenon, an investigation on the Scopus (SCP) and Web of\\nScience (WoS) databases was carried out using Boolean operators. We began by making a search query\\non the Scopus and WoS databases with the general keywords “artiﬁcial intelligence” AND “machine\\nlearning” AND “application”, as shown in Table 1.\\nIn order to maintain the consistency of the results, the same keywords were used in both databases\\nand a time horizon of 20 years was chosen, from 1999 to 2019.\\nThe choice of keywords for performing the survey was based on the awareness that AI and ML\\ncan be an important tool in the eﬀort to adopt responsible business practices in the context of smart\\nproduction. In this regard, it is worthy to note that with the increasingly urgent discussions of climate'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 3, 'page_label': '4', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='production. In this regard, it is worthy to note that with the increasingly urgent discussions of climate\\nchange, it seemed appropriate to focus our research on the topic of sustainability. Thus, the selection of\\npapers also considered applications on sustainability.'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 4, 'page_label': '5', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Sustainability 2020, 12, 492 5 of 26\\nTable 1. Keywords and time period.\\nKeywords Time Period\\nArtiﬁcial Intelligence\\n1999–2019Machine Learning\\nApplication\\nThe search returned in total 13,512 documents.\\nThe results extracted by Scopus are numerically superior to Web of Science (WoS): 12,445 for the\\nﬁrst and only 1081 for the second one (Table 2).\\nTable 2. Total results of research on Scopus and WoS.\\nResearch Carried out on 2019\\nSource of research Scopus Web of Science\\nResults 12,445 1081\\nThe result is not entirely unexpected, and the reason is to be found in the fact that Scopus, being\\nan Elsevier product, collects data from all the other databases, in particular Science Direct and those\\nqueried by the Scirus search engine, while Web of Science (WoS) collects fewer documents.\\nFrom the documents extracted in Scopus, it was found that most of them are conference papers\\n(57.28%) and, subsequently, articles (33.85%).'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 4, 'page_label': '5', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='From the documents extracted in Scopus, it was found that most of them are conference papers\\n(57.28%) and, subsequently, articles (33.85%).\\nOn the contrary, the research on Web of Science (WoS) underlines that most of the documents are\\narticles (46.12%) and, subsequently, proceedings papers (42.86%).\\nAll the document types are ﬁlled in Table 3.\\nTable 3. Distribution of document types in Scopus and Web of Science.\\nWeb of Science Scopus\\nDocument Types Records Contribute % Document Types Records Contribute %\\nArticle 481 46.12 Conference Paper 7128 57.28\\nProceedings paper 447 42.86 Article 4212 33.85\\nReview 133 12.76 Review 412 3.31\\nEditorial material 16 1.53 Article in Press 194 1.56\\nMeeting abstract 2 0.19 Book Chapter 177 1.42\\nBook chapter 1 0.1 Conference Review 177 1.42\\nRetracted publication 1 0.1 Book 90 0.72\\n- - - Editorial 27 0.22\\n- - - Note 10 0.08\\n- - - Letter 9 0.07\\n- - - Short Survey 9 0.07'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 4, 'page_label': '5', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Book chapter 1 0.1 Conference Review 177 1.42\\nRetracted publication 1 0.1 Book 90 0.72\\n- - - Editorial 27 0.22\\n- - - Note 10 0.08\\n- - - Letter 9 0.07\\n- - - Short Survey 9 0.07\\nAI began working in the 1940s and researchers showed strong expectations until the 1970s when\\nthey began to encounter serious diﬃculties and investments were greatly reduced.\\nSince then, a long period began, known as the “AI winter” [26]: Despite some great successes,\\nsuch as IBM’s Deep Blue system, which in the late 1990s defeated the then chess world champion\\nGarri Kasparov, the study of solutions for AI has only come back for a few years. The push for a new\\ntechnological development has been given by the I4.0, which considered AI as one of the primary key\\nenabling technologies (KETs).\\nFrom this period onwards, the literature has been enriched with documents, as shown in Figure 2.\\nGrowth is apparent after 2011 when new technologies began to be implemented more frequently.'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 4, 'page_label': '5', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='From this period onwards, the literature has been enriched with documents, as shown in Figure 2.\\nGrowth is apparent after 2011 when new technologies began to be implemented more frequently.\\nIn fact, the Industry 4.0 term ﬁrst appeared at Hannover Messe in 2011 when Professor Wolfgang'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 5, 'page_label': '6', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Sustainability 2020, 12, 492 6 of 26\\nWahlster, Director and CEO of the German Research Center for Artiﬁcial Intelligence, addressed the\\nopening ceremony audience.\\nSustainability 2020, 12, x FOR PEER REVIEW 6 of 24 \\n \\nFigure 2. Research growth on Scopus and Web of Science. \\nSubsequently, the increase in the adoption of th ese ones has led researchers to keep pace with \\nthe growth of I4.0 [27]. \\n3.1.2. Screening (Step 2) \\nTrying to give an overview of the topics and areas interface, in the screening phase, an analysis \\nof documents characterized by free access was chosen, excluding those that have restrictions, and to \\nrestrict the field to the thematic areas of scientific interest. \\nWith this in mind, the number of open access items has been drasticall y reduced (1288 results \\nfor Scopus and 149 for WoS) and, also applying the filter related to the thematic areas (Table 4), it \\ndetermined a further reduction: 947 for Scopus and 60 for WoS.'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 5, 'page_label': '6', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='for Scopus and 149 for WoS) and, also applying the filter related to the thematic areas (Table 4), it \\ndetermined a further reduction: 947 for Scopus and 60 for WoS. \\nTable 4. Subject area filter on Scopus and WoS. \\nSubject Area \\nScopus Web of Science (WoS) \\nComputer \\nScience \\nChemical \\nEngineering \\nComputer Science \\nInformation Systems \\nComputer Science Artificial \\nIntelligence \\nAutomation Control \\nSystems \\nEngineering Energy Materials Science \\nMultidisciplinary Environmental Sciences Environmental \\nStudies \\nMaterials \\nScience Decision Science Engineering Electrical \\nElectronic \\nComputer Science \\nHardware Architecture \\nOperations Research \\nManagement Science \\nEnvironmental \\nScience \\nBusiness \\nManagement \\nand accounting \\nTelecommunications Industrial Relations Labor Robotics \\n  Engineering Environmental Engineering Manufacturing Thermodynamics \\n  Engineering Industrial Computer Science Theory \\nMethods Energy Fuels \\n  Engineering Civil Engineering Mechanical Computer Science'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 5, 'page_label': '6', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Engineering Industrial Computer Science Theory \\nMethods Energy Fuels \\n  Engineering Civil Engineering Mechanical Computer Science \\nCybernetics \\n  Computer Science Software \\nEngineering Multidisciplinary Sciences  \\nNote how the number of filters applied is different. The databases, in fact, offer the same search \\noptions, but, in the specific case of the thematic  areas, the latter are more numerous and structured \\non Web of Science (WoS) compared to Scopus. \\nFigure 2. Research growth on Scopus and Web of Science.\\nIn fact, this research indicates that over the time period considered (1999–2019), the number of\\npublished articles remains almost constant until 2013, from which it undergoes an increase.\\nSubsequently, the increase in the adoption of these ones has led researchers to keep pace with the\\ngrowth of I4.0 [27].\\n3.1.2. Screening (Step 2)\\nTrying to give an overview of the topics and areas interface, in the screening phase, an analysis'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 5, 'page_label': '6', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='growth of I4.0 [27].\\n3.1.2. Screening (Step 2)\\nTrying to give an overview of the topics and areas interface, in the screening phase, an analysis\\nof documents characterized by free access was chosen, excluding those that have restrictions, and to\\nrestrict the ﬁeld to the thematic areas of scientiﬁc interest.\\nWith this in mind, the number of open access items has been drastically reduced (1288 results\\nfor Scopus and 149 for WoS) and, also applying the ﬁlter related to the thematic areas (Table 4), it\\ndetermined a further reduction: 947 for Scopus and 60 for WoS.\\nTable 4. Subject area ﬁlter on Scopus and WoS.\\nSubject Area\\nScopus Web of Science (WoS)\\nComputer Science Chemical\\nEngineering\\nComputer Science\\nInformation Systems\\nComputer Science\\nArtiﬁcial Intelligence\\nAutomation Control\\nSystems\\nEngineering Energy Materials Science\\nMultidisciplinary\\nEnvironmental\\nSciences Environmental Studies\\nMaterials Science Decision Science Engineering Electrical\\nElectronic\\nComputer Science'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 5, 'page_label': '6', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Systems\\nEngineering Energy Materials Science\\nMultidisciplinary\\nEnvironmental\\nSciences Environmental Studies\\nMaterials Science Decision Science Engineering Electrical\\nElectronic\\nComputer Science\\nHardware Architecture\\nOperations Research\\nManagement Science\\nEnvironmental\\nScience\\nBusiness\\nManagement and\\naccounting\\nTelecommunications Industrial Relations\\nLabor Robotics\\nEngineering\\nEnvironmental\\nEngineering\\nManufacturing Thermodynamics\\nEngineering Industrial Computer Science\\nTheory Methods Energy Fuels\\nEngineering Civil Engineering\\nMechanical\\nComputer Science\\nCybernetics\\nComputer Science\\nSoftware Engineering\\nMultidisciplinary\\nSciences'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 6, 'page_label': '7', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Sustainability 2020, 12, 492 7 of 26\\nNote how the number of ﬁlters applied is diﬀerent. The databases, in fact, oﬀer the same search\\noptions, but, in the speciﬁc case of the thematic areas, the latter are more numerous and structured on\\nWeb of Science (WoS) compared to Scopus.\\n3.1.3. Inclusion (Step 3)\\nAt the end of the screening process, the inclusion step was started, which consisted in the selection\\nof documents, which was extracted from the last passage, destined to be included in the sample on\\nwhich bibliometric analysis was performed. In this review step, for the purposes of eligibility, we\\nexamined the complete text of each document independently. For each article, we examined whether\\nthere was interest from the academic world, and if it contained case studies or real applications,\\nproposals for new AI and ML algorithms, or possible future scenarios.\\nTherefore, the ﬁnal sample to be analyzed consisted of 60 documents for Scopus and 22 for WoS.\\n3.2. Phase 2: Analysis'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 6, 'page_label': '7', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='proposals for new AI and ML algorithms, or possible future scenarios.\\nTherefore, the ﬁnal sample to be analyzed consisted of 60 documents for Scopus and 22 for WoS.\\n3.2. Phase 2: Analysis\\nThis section presents and discusses the ﬁndings of this review.\\nFirst, an overview of the selected studies is presented. Second, the review ﬁndings according to\\nthe research criteria, one by one in the separate subsections, are reported.\\n3.2.1. Top Highly Inﬂuential Analysis\\nThis section lists the most highly cited documents in WoS and Scopus. The list is structured by\\nresearch source, date, title, authors, source title, and top citation (TP) in WoS or Scopus, according\\nto the research source. The whole list is available in the Appendix A. Looking into the Appendix A,\\nit is possible underline that the document by Larrañaga, Calvo, Santana et al. in 2006 [ 28] has the\\nhighest citation count of 298. This article reviews machine learning methods for bioinformatics and'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 6, 'page_label': '7', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='highest citation count of 298. This article reviews machine learning methods for bioinformatics and\\nit presents modelling methods. Moreover, the document year is 2006, so before I4.0 was introduced.\\nTherefore, having more years than today has an advantage in terms of diﬀusion. This means that it is\\none of the most inﬂuential documents in the academic world, as it proposes some of the most useful\\ntechniques for modelling, giving the document the opportunity to become a pioneer in the computer\\nscience research area.\\nObviously, all documents before I4.0, in general, have more citations than the most recent\\ndocuments. However, it is signiﬁcant to note that even recent documents have a very high number\\nof citations compared to the year of publication. This denotes the interest in the topic from the\\nscientiﬁc community.\\nThe citation analysis revealed that the ﬁrst article that we can identify among the most cited in'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 6, 'page_label': '7', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='scientiﬁc community.\\nThe citation analysis revealed that the ﬁrst article that we can identify among the most cited in\\nthe I4.0 period dates to 2016. The work, published by Krawczyk [29], proposes application models to\\nfurther develop the ﬁeld of unbalanced learning, to focus on computationally eﬀective, adaptive, and\\nreal-time methods, and provides a discussion and suggestions on the lines of future research in the\\napplication subject of the study. It received 119 citations. Moreover, an article published by Wuest,\\nWeimer, Irgens et al. [30] received much attention among the scientiﬁc community. It contributes by\\npresenting an overview of the available machine learning techniques.\\nFinally, the citation analysis pointed out that the average number of citations of all documents is\\n16.58. This value is expected to increase rapidly considering the interest in the issues of ML and AI.\\n3.2.2. Publications by Years'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 6, 'page_label': '7', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='16.58. This value is expected to increase rapidly considering the interest in the issues of ML and AI.\\n3.2.2. Publications by Years\\nConsistent with what is deﬁned in Section 3.1.1., the study shows that the number of items included\\nin the analysis is deﬁnitely low for the entire period before I4.0 and then suddenly increases, starting\\nin 2012. The data shown in Figure 3 also show two holes in the 2001–2008 and 2008–2011 intervals.\\nThis means that the technological applications were limited before it became an enabling technology of\\nI4.0 in all respects, only to have a peak of technological implementation, as was foreseeable.'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 7, 'page_label': '8', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Sustainability 2020, 12, 492 8 of 26\\nSustainability 2020, 12, x FOR PEER REVIEW 8 of 24 \\n \\nFigure 3. Years of publications. \\nWith reference to 2019, the figure refers to the fi rst months of the year, so it is plausible that \\nduring the year, there will be a further increase in  the documents in the literature. Furthermore, an \\nincrease is expected in the coming years, in parallel with the growth of I4.0 \\n3.2.3. Most Collaborative Authors \\nThe analysis highlighted that most of publications have more than one author. From this point \\nof view, it is possible to identify the number of authors for each document. As shown in Figure 4, \\nmost of the manuscripts were produced by groups ranging from two to five authors. The indicators \\nchosen to perform the analysis were total papers (TPs), which is the total number of publications. \\n \\nFigure 4. Collaborative groups. \\nFigure 3. Years of publications.'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 7, 'page_label': '8', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='chosen to perform the analysis were total papers (TPs), which is the total number of publications. \\n \\nFigure 4. Collaborative groups. \\nFigure 3. Years of publications.\\nWith reference to 2019, the ﬁgure refers to the ﬁrst months of the year, so it is plausible that during\\nthe year, there will be a further increase in the documents in the literature. Furthermore, an increase is\\nexpected in the coming years, in parallel with the growth of I4.0\\n3.2.3. Most Collaborative Authors\\nThe analysis highlighted that most of publications have more than one author. From this point of\\nview, it is possible to identify the number of authors for each document. As shown in Figure 4, most of\\nthe manuscripts were produced by groups ranging from two to ﬁve authors. The indicators chosen to\\nperform the analysis were total papers (TPs), which is the total number of publications.\\nSustainability 2020, 12, x FOR PEER REVIEW 8 of 24 \\n \\nFigure 3. Years of publications.'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 7, 'page_label': '8', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='perform the analysis were total papers (TPs), which is the total number of publications.\\nSustainability 2020, 12, x FOR PEER REVIEW 8 of 24 \\n \\nFigure 3. Years of publications. \\nWith reference to 2019, the figure refers to the fi rst months of the year, so it is plausible that \\nduring the year, there will be a further increase in  the documents in the literature. Furthermore, an \\nincrease is expected in the coming years, in parallel with the growth of I4.0 \\n3.2.3. Most Collaborative Authors \\nThe analysis highlighted that most of publications have more than one author. From this point \\nof view, it is possible to identify the number of authors for each document. As shown in Figure 4, \\nmost of the manuscripts were produced by groups ranging from two to five authors. The indicators \\nchosen to perform the analysis were total papers (TPs), which is the total number of publications. \\n \\nFigure 4. Collaborative groups. \\nFigure 4. Collaborative groups.'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 8, 'page_label': '9', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Sustainability 2020, 12, 492 9 of 26\\n3.2.4. Research Areas Analysis\\nThe total research area analysis collected from the 82 papers was 164 because each paper can be\\nconsidered as more than one research area analysis. Given the small number of documents identiﬁed\\nin the period before I4.0, the ranking refers mostly to the current industrial revolution. Also, in this\\ncase, the result is consistent with the introduction of paradigm 4.0, which has intensiﬁed research and\\nthe adoption of technology.\\nThe ﬁrst thematic areas and disciplines that are at the top of the ranking are computer science,\\nengineering and biochemistry, genetics, and molecular Biology, respectively, with 29%, 23%, and 6% of\\npublications. Furthermore, the other disciplines identiﬁed for which applicative ﬁndings are found are\\nconsidered transversal to the ﬁrst three disciplines and this is a consequence of I4.0. In terms of the\\npercentage contribution, the ﬁrst three areas cover about 60% of the papers considered.'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 8, 'page_label': '9', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='considered transversal to the ﬁrst three disciplines and this is a consequence of I4.0. In terms of the\\npercentage contribution, the ﬁrst three areas cover about 60% of the papers considered.\\nConsidering the top 20 research areas, given the frequency of the research areas’ distribution,\\nFigure 5 shows a higher level of concentration in the disciplines indicated above.\\nSustainability 2020, 12, x FOR PEER REVIEW 9 of 24 \\n3.2.4. Research Areas Analysis \\nThe total research area analysis collected from the 82 papers was 164 because each paper can be \\nconsidered as more than one research area analysis. Given the small number of documents identified \\nin the period before I4.0, the ranking refers mostly to the current industrial revolution. Also, in this \\ncase, the result is consistent with the introduction of paradigm 4.0, which has intensified research and \\nthe adoption of technology. \\nThe first thematic areas and disciplines that are at the top of the ranking are computer science,'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 8, 'page_label': '9', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='the adoption of technology. \\nThe first thematic areas and disciplines that are at the top of the ranking are computer science, \\nengineering and biochemistry, genetics, and molecular Biology, respectively, with 29%, 23%, and 6% \\nof publications. Furthermore, the other disciplines identified for which applicative findings are found \\nare considered transversal to the first three discipli nes and this is a consequence of I4.0. In terms of \\nthe percentage contribution, the first three areas cover about 60% of the papers considered. \\nConsidering the top 20 research areas, given the frequency of the research areas’ distribution, \\nFigure 5 shows a higher level of concentration in the disciplines indicated above. \\nIn fact, in terms of the percentage contribution, the first five areas cover about 70% of the papers \\nconsidered. Regardless, by only counting research areas found once, there is a total of 27. \\nThis means two things:'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 8, 'page_label': '9', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='considered. Regardless, by only counting research areas found once, there is a total of 27. \\nThis means two things: \\n• The large number of fields in which this kind of research is involved; and \\n• Most papers have a transversal approach, that is, the object of each research crosses more \\nthan one field of application, thus involving more research areas. \\nThis confirms the wide interest in these subjects from several fields. \\n \\nFigure 5. Top 20 research areas contributions. \\n3.2.5. Top Source Journals Analysis \\nIn this section, the top 20 sources or journals that were published most frequently were extracted. \\nA journal is a time-bound publication with th e objective of promoting and monitoring the \\nprogress of the discipline it represents. \\nIn this specific case, the total source journals detected from the documents is 74, but, considering \\nthe top 20, given the frequency of the source journals’ distribution, only the first 13 sources have more'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 8, 'page_label': '9', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='the top 20, given the frequency of the source journals’ distribution, only the first 13 sources have more \\nthan one paper published, with a total percentage contribution of 43% of the total. \\nAfter analyzing the sources separately, the results obtained in the two databases were found to \\nnot be the same. In WoS, the top source journal was IEEE Access with two publications while in \\nScopus, the top source journals are Procedia Computer Science, Matec Web of Conferences, and Machine \\nLearning with four publications, which contribute 5% of the total. \\nFigure 5. Top 20 research areas contributions.\\nIn fact, in terms of the percentage contribution, the ﬁrst ﬁve areas cover about 70% of the papers\\nconsidered. Regardless, by only counting research areas found once, there is a total of 27.\\nThis means two things:\\n• The large number of ﬁelds in which this kind of research is involved; and\\n• Most papers have a transversal approach, that is, the object of each research crosses more than'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 8, 'page_label': '9', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='This means two things:\\n• The large number of ﬁelds in which this kind of research is involved; and\\n• Most papers have a transversal approach, that is, the object of each research crosses more than\\none ﬁeld of application, thus involving more research areas.\\nThis conﬁrms the wide interest in these subjects from several ﬁelds.\\n3.2.5. Top Source Journals Analysis\\nIn this section, the top 20 sources or journals that were published most frequently were extracted.\\nA journal is a time-bound publication with the objective of promoting and monitoring the progress\\nof the discipline it represents.\\nIn this speciﬁc case, the total source journals detected from the documents is 74, but, considering\\nthe top 20, given the frequency of the source journals’ distribution, only the ﬁrst 13 sources have more\\nthan one paper published, with a total percentage contribution of 43% of the total.\\nAfter analyzing the sources separately, the results obtained in the two databases were found to'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 8, 'page_label': '9', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='than one paper published, with a total percentage contribution of 43% of the total.\\nAfter analyzing the sources separately, the results obtained in the two databases were found to\\nnot be the same. In WoS, the top source journal was IEEE Access with two publications while in Scopus,'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 9, 'page_label': '10', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Sustainability 2020, 12, 492 10 of 26\\nthe top source journals are Procedia Computer Science, Matec Web of Conferences, and Machine Learning\\nwith four publications, which contribute 5% of the total.\\nAggregating the data collected from the two databases, the ranking moves to that obtained by\\nScopus, making sure that IEEE Access is no longer ﬁrst in the standings, but only eighth, and that the\\nformer are precisely those of Scopus: Procedia Computer Science, Matec Web Of Conferences, and Machine\\nLearning, with the same number of publications. Next, the 10 source journals have a 3% publication\\ncontribution while the rest have a one-to-one relationship (1%) with the corresponding source journal.\\nThe low level of concentration of the sources suggests that there is a great deal of interest in\\nthese topics from several scientiﬁc journals. As a matter of fact, it is foreseeable that specialized sector'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 9, 'page_label': '10', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='these topics from several scientiﬁc journals. As a matter of fact, it is foreseeable that specialized sector\\nsources (AI Magazine and Machine Learning) are among the ﬁrst 13; however, it is interesting to note\\nthat other sources are involved, such as Sustainability Switzerland or BMC Bioinformatics and Nuclear\\nEngineering and Design.\\nFigure 6 shows the top 20 source journals contributions.\\nSustainability 2020, 12, x FOR PEER REVIEW 10 of 24 \\nAggregating the data collected from the two databases, the ranking moves to that obtained by \\nScopus, making sure that IEEE Access is no longer first in the standings, but only eighth, and that the \\nformer are precisely those of Scopus: Procedia Computer Science, Matec Web Of Conferences, and Machine \\nLearning, with the same number of publications. Next, the 10 source journals have a 3% publication \\ncontribution while the rest have a one-to-one re lationship (1%) with the corresponding source \\njournal.'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 9, 'page_label': '10', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='contribution while the rest have a one-to-one re lationship (1%) with the corresponding source \\njournal. \\nThe low level of concentration of the sources suggests that there is a great deal of interest in these \\ntopics from several scientific journals. As a matter of fact, it is foreseeable that specialized sector \\nsources (AI Magazine and Machine Learning) are among the first 13; however,  it is interesting to note \\nthat other sources are involved, such as Sustainability Switzerland or BMC Bioinformatics and Nuclear \\nEngineering and Design. \\nFigure 6 shows the top 20 source journals contributions. \\n \\nFigure 6. Top 20 source journals contributions. \\n3.2.6. Country Analysis \\nThe results that emerged through research on the two databases are consistent with each other. \\nIn both cases, in fact, the countries that give the greatest contribution to the research are China and \\nthe United States (Figure 8). The result is obvious since in China and the United States, more than 1.3'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 9, 'page_label': '10', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='the United States (Figure 8). The result is obvious since in China and the United States, more than 1.3 \\nbillion and 0.3 millions of people live, respective ly, and so there are more researchers than in the \\nsingle European nations. Focusing on Europe, Germany published more papers than any other \\nE u r o p e a n  c o u n t r y .  T h i s  i s  n o t  a  r a n d o m  r e s u l t :  I 4 . 0  w a s  b o r n  i n  G e r m a n y ,  s o  t h i s  o u t c o m e  w a s  \\nexpected. However, the following observation cannot be ignored from this data: The USA and China \\ncarry the first two places in the list while it is no t the same for European countries. Europe, despite \\nits talents and resources, has lost ground. Presenting its report on artificial intelligence, the French \\ndeputy and mathematician Cédric Villani declared that, “Europe must be able to compete with China \\nand the United States while protecting its citizens and pointing the way to go on ethical issues”. If'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 9, 'page_label': '10', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='and the United States while protecting its citizens and pointing the way to go on ethical issues”. If \\nwe are not careful, the 21st century rules will not be defined in Brussels, but in Shanghai. Artificial \\nintelligence is also a land marked by intense geopolitical rivalry that could redefine global power \\nrelations. \\n  \\nFigure 6. Top 20 source journals contributions.\\n3.2.6. Country Analysis\\nThe results that emerged through research on the two databases are consistent with each other.\\nIn both cases, in fact, the countries that give the greatest contribution to the research are China and\\nthe United States (Figure 8). The result is obvious since in China and the United States, more than\\n1.3 billion and 0.3 millions of people live, respectively, and so there are more researchers than in\\nthe single European nations. Focusing on Europe, Germany published more papers than any other\\nEuropean country. This is not a random result: I4.0 was born in Germany, so this outcome was expected.'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 9, 'page_label': '10', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='the single European nations. Focusing on Europe, Germany published more papers than any other\\nEuropean country. This is not a random result: I4.0 was born in Germany, so this outcome was expected.\\nHowever, the following observation cannot be ignored from this data: The USA and China carry the\\nﬁrst two places in the list while it is not the same for European countries. Europe, despite its talents\\nand resources, has lost ground. Presenting its report on artiﬁcial intelligence, the French deputy and\\nmathematician Cédric Villani declared that, “Europe must be able to compete with China and the\\nUnited States while protecting its citizens and pointing the way to go on ethical issues”. If we are not\\ncareful, the 21st century rules will not be deﬁned in Brussels, but in Shanghai. Artiﬁcial intelligence is\\nalso a land marked by intense geopolitical rivalry that could redeﬁne global power relations.\\nEven so, regarding Europe, it is worthy to also note that since 2017, France, Germany, and Italy'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 9, 'page_label': '10', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='also a land marked by intense geopolitical rivalry that could redeﬁne global power relations.\\nEven so, regarding Europe, it is worthy to also note that since 2017, France, Germany, and Italy\\nhave intensiﬁed their trilateral cooperation to promote digitizing the manufacturing industry. In this'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 10, 'page_label': '11', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Sustainability 2020, 12, 492 11 of 26\\nregard, in the near future, we expect a signiﬁcant evolution of smart production initiatives and therefore\\nan increase in scientiﬁc research.\\nFigure 7 shows the country contribution distribution.\\nSustainability 2020, 12, x FOR PEER REVIEW 11 of 24 \\nEven so, regarding Europe, it is worthy to also note that since 2017, France, Germany, and Italy \\nhave intensified their trilateral cooperation to promote digitizing the manufacturing industry. In this \\nregard, in the near future, we expect a significant evolution of smart production initiatives and \\ntherefore an increase in scientific research. \\nFigure 7 shows the country contribution distribution. \\n \\nFigure 7. Top 20 countries contributions. \\n3.2.7. Affiliation Analysis \\nThe total number of affiliation detected from the 82 papers is 153. Also, in this case, considering \\nthe top 20, the frequency of the affiliation distribu tion shows that most papers have a one-to-one'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 10, 'page_label': '11', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='the top 20, the frequency of the affiliation distribu tion shows that most papers have a one-to-one \\nrelationship with the corresponding affiliation. Only the first four affiliations have three papers (2% \\nof the contribution) and the second four have two papers (1.3% of the contribution). This result gives \\nus information about the wide interest on this subject from several universities and research centers \\nall over the world. Then, the affiliation analysis confirms the result of the country analysis (Figure 8). \\nIn fact, if we try to sum the first eight affiliations by their own country, the outcome is: \\n• Nine papers from China; \\n• Six papers from Germany; and \\n• Five papers from the USA. \\nIn September 2018, the most important event on artificial intelligence was held in Shanghai. \\nChina is very determined to focus on future technologies. \\nFor some months, China has become the world’s leading power in terms of scientific'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 10, 'page_label': '11', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='China is very determined to focus on future technologies. \\nFor some months, China has become the world’s leading power in terms of scientific \\npublications. Late in the 20th century technologi es, China chose to do what the English-speaking \\npeople call a “frog jump” and focus on 21st century technologies. \\nChina, with its 800 million Internet users and without any privacy protection policy, has access \\nto more personal data than the United States and Europe. \\nFigure 7. Top 20 countries contributions.\\n3.2.7. Aﬃliation Analysis\\nThe total number of aﬃliation detected from the 82 papers is 153. Also, in this case, considering\\nthe top 20, the frequency of the a ﬃliation distribution shows that most papers have a one-to-one\\nrelationship with the corresponding aﬃliation. Only the ﬁrst four a ﬃliations have three papers (2% of\\nthe contribution) and the second four have two papers (1.3% of the contribution). This result gives us'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 10, 'page_label': '11', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='the contribution) and the second four have two papers (1.3% of the contribution). This result gives us\\ninformation about the wide interest on this subject from several universities and research centers all\\nover the world. Then, the aﬃliation analysis conﬁrms the result of the country analysis (Figure 8). In\\nfact, if we try to sum the ﬁrst eight aﬃliations by their own country, the outcome is:\\n• Nine papers from China;\\n• Six papers from Germany; and\\n• Five papers from the USA.\\nIn September 2018, the most important event on artiﬁcial intelligence was held in Shanghai. China\\nis very determined to focus on future technologies.\\nFor some months, China has become the world’s leading power in terms of scientiﬁc publications.\\nLate in the 20th century technologies, China chose to do what the English-speaking people call a “frog\\njump” and focus on 21st century technologies.\\nChina, with its 800 million Internet users and without any privacy protection policy, has access to'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 10, 'page_label': '11', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='jump” and focus on 21st century technologies.\\nChina, with its 800 million Internet users and without any privacy protection policy, has access to\\nmore personal data than the United States and Europe.'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 11, 'page_label': '12', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Sustainability 2020, 12, 492 12 of 26\\nSustainability 2020, 12, x FOR PEER REVIEW 12 of 24 \\n \\nFigure 8. Top 20 institute affiliations contributions. \\n3.2.8. Top Keywords Analysis \\nThrough NVivo 12, the top 20 keywords were extracted directly, which are those that always \\nappear in association with each document. \\nStarting from this classification, the graphic representation, a word cloud shape, of the keywords \\n(Figure 9) was extracted. It can be noted that the most used term is precisely “machine”, “learning”, \\nand “intelligence”, which the software represents with greater characters than all the other terms. \\n \\nFigure 9. Top 20 keywords cloud contribution by NVivo 12. \\nThe font size describes how much the keyword is indexed. Another mode of representation is \\nthe tree words (Figure 10). Also, in this case, th e most indexed words are those represented in the \\nlarger boxes. \\nFigure 8. Top 20 institute aﬃliations contributions.\\n3.2.8. Top Keywords Analysis'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 11, 'page_label': '12', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='the tree words (Figure 10). Also, in this case, th e most indexed words are those represented in the \\nlarger boxes. \\nFigure 8. Top 20 institute aﬃliations contributions.\\n3.2.8. Top Keywords Analysis\\nThrough NVivo 12, the top 20 keywords were extracted directly, which are those that always\\nappear in association with each document.\\nStarting from this classiﬁcation, the graphic representation, a word cloud shape, of the keywords\\n(Figure 9) was extracted. It can be noted that the most used term is precisely “machine”, “learning”,\\nand “intelligence”, which the software represents with greater characters than all the other terms.\\nSustainability 2020, 12, x FOR PEER REVIEW 12 of 24 \\n \\nFigure 8. Top 20 institute affiliations contributions. \\n3.2.8. Top Keywords Analysis \\nThrough NVivo 12, the top 20 keywords were extracted directly, which are those that always \\nappear in association with each document.'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 11, 'page_label': '12', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='3.2.8. Top Keywords Analysis \\nThrough NVivo 12, the top 20 keywords were extracted directly, which are those that always \\nappear in association with each document. \\nStarting from this classification, the graphic representation, a word cloud shape, of the keywords \\n(Figure 9) was extracted. It can be noted that the most used term is precisely “machine”, “learning”, \\nand “intelligence”, which the software represents with greater characters than all the other terms. \\n \\nFigure 9. Top 20 keywords cloud contribution by NVivo 12. \\nThe font size describes how much the keyword is indexed. Another mode of representation is \\nthe tree words (Figure 10). Also, in this case, th e most indexed words are those represented in the \\nlarger boxes. \\nFigure 9. Top 20 keywords cloud contribution by NVivo 12.\\nThe font size describes how much the keyword is indexed. Another mode of representation is\\nthe tree words (Figure 10). Also, in this case, the most indexed words are those represented in the'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 11, 'page_label': '12', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='The font size describes how much the keyword is indexed. Another mode of representation is\\nthe tree words (Figure 10). Also, in this case, the most indexed words are those represented in the\\nlarger boxes.'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 12, 'page_label': '13', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Sustainability 2020, 12, 492 13 of 26\\nSustainability 2020, 12, x FOR PEER REVIEW 13 of 24 \\n \\nFigure 10. Top 20 keywords tree contribution by Nvivo 12. \\nAs expected, the most indexed words are obviousl y “learning”, “machine”, and “intelligence”, \\nwith high numbers. It is logical that among the first results, words that recall the technology itself \\nwere obtained, but it is interesting to note that words referring to other fields of AI applications are \\nalso indexed. The reason is to be found in the fact that AI and ML are technologies that cross all the \\nsectors involved in I4.0 and that, therefore, do not remain circumscribed. \\nSpecifically, words, such as “data”, “neural”, “decision”, and “management”, are very or \\naverage indexed, demonstrating the fact that AI also extends to many other sectors. \\nAnother tool for the analysis for keywords is  the UCINET software, through which social \\nnetworks analysis is carried out.'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 12, 'page_label': '13', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Another tool for the analysis for keywords is  the UCINET software, through which social \\nnetworks analysis is carried out. \\nSocial network analysis (SNA), which is also often called social network theory, is a modern \\ntechnology of social relations. \\nSNA finds application in various social sciences , and has recently been used in the study of \\nvarious phenomena, such as international trade, information dissemination, the study of institutions, \\nand the functioning of organizations. The analysis  of the use of the term SNA in the scientific \\nliterature shows that in the last five years, there has been exponential growth of the use of this mode \\nof computable representation of complex and interdependent phenomena. The software returns a \\ngraph representing a socio-metric network (Figur e 11), which draws the relationships that exist \\nwithin the class. Each relationship is represented by an oriented arrow. \\nFigure 10. Top 20 keywords tree contribution by Nvivo 12.'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 12, 'page_label': '13', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='within the class. Each relationship is represented by an oriented arrow. \\nFigure 10. Top 20 keywords tree contribution by Nvivo 12.\\nAs expected, the most indexed words are obviously “learning”, “machine”, and “intelligence”,\\nwith high numbers. It is logical that among the ﬁrst results, words that recall the technology itself were\\nobtained, but it is interesting to note that words referring to other ﬁelds of AI applications are also\\nindexed. The reason is to be found in the fact that AI and ML are technologies that cross all the sectors\\ninvolved in I4.0 and that, therefore, do not remain circumscribed.\\nSpeciﬁcally, words, such as “data”, “neural”, “decision”, and “management”, are very or average\\nindexed, demonstrating the fact that AI also extends to many other sectors.\\nAnother tool for the analysis for keywords is the UCINET software, through which social networks\\nanalysis is carried out.\\nSocial network analysis (SNA), which is also often called social network theory, is a modern'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 12, 'page_label': '13', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='analysis is carried out.\\nSocial network analysis (SNA), which is also often called social network theory, is a modern\\ntechnology of social relations.\\nSNA ﬁnds application in various social sciences, and has recently been used in the study of\\nvarious phenomena, such as international trade, information dissemination, the study of institutions,\\nand the functioning of organizations. The analysis of the use of the term SNA in the scientiﬁc\\nliterature shows that in the last ﬁve years, there has been exponential growth of the use of this mode of\\ncomputable representation of complex and interdependent phenomena. The software returns a graph\\nrepresenting a socio-metric network (Figure 11), which draws the relationships that exist within the\\nclass. Each relationship is represented by an oriented arrow.'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 13, 'page_label': '14', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Sustainability 2020, 12, 492 14 of 26\\nSustainability 2020, 12, x FOR PEER REVIEW 14 of 24 \\n \\nFigure 11. Keywords Network by UCINET Software. \\nIn Figure 11, nodes and leaves can be identified. The nodes are represented by red circles and \\nare correspond to the most common keywords, where the words “machine”, “learning”, “artificial”, \\nand “intelligence” have been united to form the key words “machine le arning” and “artificial \\nintelligence”. \\nThe leaves, on the other hand, are represented by blue squares and correspond to the articles. \\nTo facilitate reading, the document titles were not inserted, but the (Identification) ID count for each \\nof them is shown in the Appendix A. \\nThe first thing that can be noticed is the isolatio n of many leaves that are not connected to the \\nnodes. This means that the corresponding documents are not described by the keywords represented \\nby the nodes. Really, they are characterized by keywords that have a frequency of the order of units.'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 13, 'page_label': '14', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='by the nodes. Really, they are characterized by keywords that have a frequency of the order of units. \\nAnother thing that easily jumps to the eye is a density that is larger around the keywords \\n“machine learning”, “decision”, “data”, “algorithm”, “system”, “artificial intelligence”, “method”, \\nand “optimization”. This density is reflected in the cloud and the box chart produced by NVivo 12. \\nTherefore, we can say that those are the words th at most often appear in the documents analyzed, \\nemphasizing, once again, that they include terms th at do not just refer to the technology object of \\nstudy but also to other fields of application. \\n3.3. Phase 3: Discussion \\n3.3.1. Benefits of Artificial Intelligence and Machine Learning in Industrial Contexts \\nFrom the analysis of the research carried out, th e first information that emerged is that there is \\na growing importance of innovation and digitalization in products, services, and processes.'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 13, 'page_label': '14', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='From the analysis of the research carried out, th e first information that emerged is that there is \\na growing importance of innovation and digitalization in products, services, and processes. \\nConsequently, it means that the adoption of advanced manufacturing technologies, such AI and ML, \\nis an emerging issue. In other words, AI/ML algo rithms represent an opportunity to handle high \\ndimensional problems and data. The interest in the subject is extended to all scientific sectors, but \\nwith a focus on computer science and engineering. \\nThe most significant benefits of using AI and ML in industrial sectors include: 1) Greater \\ninnovation, 2) process optimization, 3) resources optimization, and 4) improved quality. \\nAfter all, AI with ML is one of the most impo rtant technologies today and is transforming the \\neconomy and society, as demonstrated by the over 340,000 patent applications filed since the 1950s. \\n  \\nFigure 11. Keywords Network by UCINET Software.'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 13, 'page_label': '14', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='economy and society, as demonstrated by the over 340,000 patent applications filed since the 1950s. \\n  \\nFigure 11. Keywords Network by UCINET Software.\\nIn Figure 11, nodes and leaves can be identiﬁed. The nodes are represented by red circles and are\\ncorrespond to the most common keywords, where the words “machine”, “learning”, “artiﬁcial”, and\\n“intelligence” have been united to form the key words “machine learning” and “artiﬁcial intelligence”.\\nThe leaves, on the other hand, are represented by blue squares and correspond to the articles. To\\nfacilitate reading, the document titles were not inserted, but the (Identiﬁcation) ID count for each of\\nthem is shown in the Appendix A.\\nThe ﬁrst thing that can be noticed is the isolation of many leaves that are not connected to the\\nnodes. This means that the corresponding documents are not described by the keywords represented\\nby the nodes. Really, they are characterized by keywords that have a frequency of the order of units.'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 13, 'page_label': '14', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='nodes. This means that the corresponding documents are not described by the keywords represented\\nby the nodes. Really, they are characterized by keywords that have a frequency of the order of units.\\nAnother thing that easily jumps to the eye is a density that is larger around the keywords\\n“machine learning”, “decision”, “data”, “algorithm”, “system”, “artiﬁcial intelligence”, “method”,\\nand “optimization”. This density is reﬂected in the cloud and the box chart produced by NVivo 12.\\nTherefore, we can say that those are the words that most often appear in the documents analyzed,\\nemphasizing, once again, that they include terms that do not just refer to the technology object of study\\nbut also to other ﬁelds of application.\\n3.3. Phase 3: Discussion\\n3.3.1. Beneﬁts of Artiﬁcial Intelligence and Machine Learning in Industrial Contexts\\nFrom the analysis of the research carried out, the ﬁrst information that emerged is that there is a'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 13, 'page_label': '14', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='3.3.1. Beneﬁts of Artiﬁcial Intelligence and Machine Learning in Industrial Contexts\\nFrom the analysis of the research carried out, the ﬁrst information that emerged is that there is a\\ngrowing importance of innovation and digitalization in products, services, and processes. Consequently,\\nit means that the adoption of advanced manufacturing technologies, such AI and ML, is an emerging\\nissue. In other words, AI/ML algorithms represent an opportunity to handle high dimensional problems\\nand data. The interest in the subject is extended to all scientiﬁc sectors, but with a focus on computer\\nscience and engineering.\\nThe most signiﬁcant beneﬁts of using AI and ML in industrial sectors include: (1) Greater\\ninnovation, (2) process optimization, (3) resources optimization, and (4) improved quality.\\nAfter all, AI with ML is one of the most important technologies today and is transforming the\\neconomy and society, as demonstrated by the over 340,000 patent applications ﬁled since the 1950s.'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 14, 'page_label': '15', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Sustainability 2020, 12, 492 15 of 26\\nOther information that emerged is about the authors and aﬃliation. Many of these are in a 1:1 ratio\\ncompared to the selected documents and this supports the fact that there is no interest in technological\\napplications in one direction, but that, once again, the interest is very wide in the scientiﬁc community.\\nFurthermore, it can be said that the countries most interested in scientiﬁc research are the USA,\\nChina and European countries. This result is not a surprise.\\nIn terms of investment, the e ﬀort currently being deployed by the United States and China to\\nacquire dominance in the AI sector is far superior to that of other countries. More speciﬁcally, China\\nhas clearly stated its ambition to become a world leader in AI by 2030 [31]. Among the Chinese plans,\\nof absolute interest is the “Made in China 2025” plan, dedicated to the manufacturing sector; the\\n“Internet +” plan is also dedicated to smart manufacturing and innovation.'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 14, 'page_label': '15', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='of absolute interest is the “Made in China 2025” plan, dedicated to the manufacturing sector; the\\n“Internet +” plan is also dedicated to smart manufacturing and innovation.\\nA direct consequence of the above considerations could be having new generations of researchers\\nwho will contribute to future comparisons, accompanied by new questions for investigations.\\n3.3.2. Emerging Trends of Artiﬁcial Intelligence and Machine Learning in Sustainable Manufacturing\\nFrom the perspective of sustainability, the analysis highlighted that the new paradigm of smart\\nmanufacturing has the potential to bring fundamental improvements in the industry by addressing\\nthe issue of scarce resources and improving productivity.\\nIn fact, the survey pointed out a growing interest on applications related to green manufacturing\\nand sustainable development, proving that AI/ML play an important role in increasing sustainability'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 14, 'page_label': '15', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='In fact, the survey pointed out a growing interest on applications related to green manufacturing\\nand sustainable development, proving that AI/ML play an important role in increasing sustainability\\nthrough the intelligent utilization of materials and energy consumption (i.e., reduction of energy\\nconsumption and pollutant emissions, environmental footprint monitoring and evaluation, etc.).\\nFurthermore, it emerged that AI/ML algorithms present a wide array of applications that provide\\nan opportunity for sustainable development, which will involve several stakeholders from diﬀerent\\ncountries and sectors, including inventory and supply chain management, predictive maintenance,\\nand production.\\nIn particular, Pérez-Ortiz, Jiménez-Fernández, Gutiérrez et al. [32] reviewed the most important\\nclassiﬁcation algorithms applied to renewable energy (RE) problems. The main use of algorithms\\nis as a tool for predictive analysis and consequently for data preprocessing, result interpretation, or'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 14, 'page_label': '15', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='classiﬁcation algorithms applied to renewable energy (RE) problems. The main use of algorithms\\nis as a tool for predictive analysis and consequently for data preprocessing, result interpretation, or\\nevaluation in order to improve energy and resource management.\\nIn this context, it also emerged that AI/ML have been successfully utilized in various processes’\\noptimization, applications in manufacturing, and predictive maintenance in diﬀerent industries.\\nThe work published by Lieber, Stolpe, Konrad et al. [33] represents a good research within steel\\nindustry production. It proposes an approach for automatically preprocessing value series data to\\nimprove the quality of the process and products. It means that AI /ML techniques were found to\\nprovide promising potential for improved quality control optimization in manufacturing systems.\\nAppropriate adoption of AI/ML technologies will promote sustainable manufacturing and the'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 14, 'page_label': '15', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='provide promising potential for improved quality control optimization in manufacturing systems.\\nAppropriate adoption of AI/ML technologies will promote sustainable manufacturing and the\\nformation of a new generation of intelligent manufacturing, including all areas that characterize a\\nsustainable process, ranging from the supply chain management to quality control, to predictive\\nmaintenance, to energy consumption.\\nTable 5 summarizes the main areas in sustainable manufacturing, their respective key objectives,\\nand the main AI/ML applications.\\nHowever, the relationship between I.4 technologies, AI/ML, and sustainability demands a more\\nconceptual and empirical investigation. This is corroborated by an article recently published in Nature\\nSustainability by the director of the Earth Institute at Columbia University, Je ﬀrey Sachs, and other\\nexperts, and the so-called Fourth Industrial Revolution (made of artiﬁcial intelligence and other digital'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 14, 'page_label': '15', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='experts, and the so-called Fourth Industrial Revolution (made of artiﬁcial intelligence and other digital\\ntechnologies) is even cited as one of the six transformations necessary to achieve the sustainable\\ndevelopment goals [34].'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 15, 'page_label': '16', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Sustainability 2020, 12, 492 16 of 26\\nTable 5. Main areas in sustainable manufacturing.\\nMain Areas in Sustainable\\nManufacturing\\nKey\\nObjective\\nAI/ML\\nApplications\\nSupply Chain Management Ready product available in the\\nappropriate place at a speciﬁc time\\nImproves transparency, accelerates\\ndecision-making, and produces accurate\\ndemand forecasting\\nQuality Control\\nRecognize the early signs of\\npotential production failures\\nwithin the shortest terms in order\\nto save resources and sustain\\noperational eﬃciency\\nImproves the response time and allows\\neliminating possible failures\\nPredictive Maintenance\\nDetects possible production\\nmalfunctions that may cause\\nproduct quality issues\\nCreates accurate forecasts as to when\\nthe machinery must be repaired\\nEnergy consumption Recommendations that will strike\\na balance in energy use\\nImproves excessive use of certain\\nmaterials, redundant production scrap\\nwaste, ineﬃcient supply chain\\nmanagement, logistics, and unequal\\ndistribution of energy resources.'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 15, 'page_label': '16', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='a balance in energy use\\nImproves excessive use of certain\\nmaterials, redundant production scrap\\nwaste, ineﬃcient supply chain\\nmanagement, logistics, and unequal\\ndistribution of energy resources.\\n4. Conclusions\\nThis research focused on the study of the state of the art of AI and ML applications, selecting\\nliterature on what has now become a particularly hot topic in scientiﬁc research. The literature available\\non any subject is now wide and a complete coverage of all the documents published with respect to a\\nparticular topic can be challenging or even impossible. Therefore, a systematic selection of the most\\nrelevant literature was implemented. This document provides a systematic review of applications\\nin various scientiﬁc ﬁelds using ML techniques. For the selection of documents, objective and clear\\nmethods of investigation were used, independent of the experience of the researchers. Among the'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 15, 'page_label': '16', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='in various scientiﬁc ﬁelds using ML techniques. For the selection of documents, objective and clear\\nmethods of investigation were used, independent of the experience of the researchers. Among the\\nobjectives of the document, it aimed to not only provide a comprehensive framework on the literature\\non the research of AI and ML but also a starting point for integrating knowledge through research in\\nthis area and to suggest future research paths. It is important to underline that this document was\\nproduced using only two databases, i.e., WoS and Scopus, in which only documents with open access\\nwere included. There are, therefore, many other documents with restricted access and other indexing\\ndatabases, such as Google Scholar, that could be integrated for future research.\\nAuthor Contributions: All authors contributed equally to this work. All authors have read and agreed to the\\npublished version of the manuscript.'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 15, 'page_label': '16', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Author Contributions: All authors contributed equally to this work. All authors have read and agreed to the\\npublished version of the manuscript.\\nFunding: This work has been conducted under the framework of the Italian project “Linee Guida per\\nI4.0-Campania”—funded by Regione Campania within POR FSE 2014–2020 Asse IV “Capacit à istituzionale e\\namministrativa” objectives 18 (RA) 11.3 and 21 (RA) 11.6.\\nConﬂicts of Interest: The authors declare no conﬂict of interest.'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 16, 'page_label': '17', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Sustainability 2020, 12, 492 17 of 26\\nAppendix A\\nID Count Research\\nSource\\nID\\nDoc Year Title Authors Source Title TC\\n1 SCP 2 2006 Machine learning in bioinformatics\\nLarrañaga, P .; Calvo, B.; Santana,\\nR.; Bielza, C.; Galdiano, J.; Inza, I.;\\nLozano, J.A.; Armañanzas, R.;\\nSantafé, G.; Pérez, A.; Robles, V .\\nBrieﬁngs in Bioinformatics 298\\n2 WoS 62 2008 Data-driven modelling: Some past experiences\\nand new approaches Solomatine, D.P .; Ostfeld, A. Journal of Hydroinformatics 160\\n3 SCP 26 2016 Learning from imbalanced data: Open\\nchallenges and future directions Krawczyk, B. Progress in Artiﬁcial\\nIntelligence 119\\n4 WoS 63 2001 Computer go: An AI oriented survey Bouzy, B; Cazenave, T Artiﬁcial Intelligence 114\\n5 SCP 6 2008 Structured machine learning: The next ten years\\nDietterich, T.G.; Domingos, P .;\\nGetoor, L.; Muggleton, S.;\\nTadepalli, P .\\nMachine Learning 75\\n6 SCP 28 2016 Machine learning in manufacturing:\\nAdvantages, challenges, and applications\\nWuest, T.; Weimer, D.; Irgens, C.;'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 16, 'page_label': '17', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Getoor, L.; Muggleton, S.;\\nTadepalli, P .\\nMachine Learning 75\\n6 SCP 28 2016 Machine learning in manufacturing:\\nAdvantages, challenges, and applications\\nWuest, T.; Weimer, D.; Irgens, C.;\\nThoben, K.D.\\nProduction and\\nManufacturing Research 52\\n7 WoS 64 2017 Machine learning paradigms for next-generation\\nwireless networks\\nJiang, C.; Zhang, H.; Ren, Y.; Han,\\nZ.; Chen, K.C.; Hanzo, L.\\nIeee Wireless\\nCommunications 50\\n8 SCP 3 2006 Machine learning techniques in disease\\nforecasting: A case study on rice blast prediction\\nKaundal, R.; Kapoor, A.A.;\\nRaghava, G.P .S. BMC Bioinformatics 48\\n9 SCP 4 2008\\nA comparison of machine learning algorithms\\nfor chemical toxicity classiﬁcation using a\\nsimulated multi-scale data model\\nJudson, R.; Elloumi, F.; Woodrow,\\nR.W.; Li, Z.; Shah, I. BMC Bioinformatics 45\\n10 SCP 19 2015\\nA review of intelligent driving style analysis\\nsystems and related artiﬁcial intelligence\\nalgorithms\\nMeiring, G.A.M.; Myburgh, H.C. Sensors (Switzerland) 33\\n11 SCP 21 2016'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 16, 'page_label': '17', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='10 SCP 19 2015\\nA review of intelligent driving style analysis\\nsystems and related artiﬁcial intelligence\\nalgorithms\\nMeiring, G.A.M.; Myburgh, H.C. Sensors (Switzerland) 33\\n11 SCP 21 2016\\nA machine learning framework for gait\\nclassiﬁcation using inertial sensors: Application\\nto elderly, post-stroke and huntington’s disease\\npatients\\nMannini, A.; Trojaniello, D.;\\nCereatti, A.; Sabatini, A.M. Sensors 31'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 17, 'page_label': '18', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Sustainability 2020, 12, 492 18 of 26\\nID Count Research\\nSource\\nID\\nDoc Year Title Authors Source Title TC\\n12 SCP 1 2006 Application of machine learning in SNP\\ndiscovery\\nMatukumalli, L.K.; Grefenstette,\\nJ.J.; Hyten, D.L.; Choi, I.Y.;\\nCregan, P .B.; Van Tassell, C.P .\\nBMC Bioinformatics 30\\n13 SCP 10 2013 Beam search algorithms for multilabel learning Kumar, A.; Vembu, S.; Menon,\\nA.K.; Elkan, C. Machine Learning 29\\n14 WoS 65 2011 Recommender Systems: An Overview Burke, Robin; Felfernig,\\nAlexander; Goeker, M.H. Ai Magazine 29\\n15 SCP 11 2013 Biomedical informatics for computer-aided\\ndecision support systems: A survey Belle, A.; Kon, M.A.; Najarian, K. The Scientiﬁc World Journal 27\\n16 SCP 23 2016 Application of machine learning to construction\\ninjury prediction\\nTixier, A.J.P .; Hallowell, M.R.;\\nRajagopalan, B.; Bowman, D. Automation in Construction 21\\n17 SCP 12 2013\\nQuality prediction in interlinked manufacturing\\nprocesses based on supervised & unsupervised\\nmachine learning'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 17, 'page_label': '18', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Rajagopalan, B.; Bowman, D. Automation in Construction 21\\n17 SCP 12 2013\\nQuality prediction in interlinked manufacturing\\nprocesses based on supervised & unsupervised\\nmachine learning\\nLieber, D.; Stolpe, M.; Konrad, B.;\\nDeuse, J.; Morik, K. Procedia CIRP 18\\n18 SCP 29 2016 Semantic framework of internet of things for\\nsmart cities: Case studies\\nZhang, N.; Chen, H.; Chen, X.;\\nChen, J. Sensors 17\\n19 SCP 20 2015 Support vector machines in structural\\nengineering: A review\\nÇevik, A.; KURTO˘GLU, A.E.;\\nBilgehan, M.; Gül¸ san, M.E.;\\nAlbegmprli, H.M.\\nJournal of Civil Engineering\\nand Management 15\\n20 SCP 25 2016 A review of classiﬁcation problems and\\nalgorithms in renewable energy applications\\nPérez-Ortiz, M.;\\nJiménez-Fernández, S.; Gutiérrez,\\nP .A.; (. . . ); Hervás-Martínez, C.;\\nSalcedo-Sanz, S.\\nEnergies 15\\n21 SCP 43 2018 Artiﬁcial intelligence (AI) methods in optical\\nnetworks: A comprehensive survey\\nMata, J.; de Miguel, I.; Durán, R.J.;\\n( . . . ); Jukan, A.; Chamania, M.\\nOptical Switching and'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 17, 'page_label': '18', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='21 SCP 43 2018 Artiﬁcial intelligence (AI) methods in optical\\nnetworks: A comprehensive survey\\nMata, J.; de Miguel, I.; Durán, R.J.;\\n( . . . ); Jukan, A.; Chamania, M.\\nOptical Switching and\\nNetworking 15\\n22 SCP 14 2014 Fault diagnosis of automobile gearbox based on\\nmachine learning techniques\\nPraveenkumar, T.; Saimurugan,\\nM.; Krishnakumar, P .;\\nRamachandran, K.I.\\nProcedia Engineering 14\\n23 SCP 16 2014 Improving active Mealy machine learning for\\nprotocol conformance testing\\nAarts, F.; Kuppens, H.; Tretmans,\\nJ.; Vaandrager, F.; Verwer, S. Machine Learning 11'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 18, 'page_label': '19', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Sustainability 2020, 12, 492 19 of 26\\nID Count Research\\nSource\\nID\\nDoc Year Title Authors Source Title TC\\n24 WoS 66 2016 Strategies and Principles of Distributed Machine\\nLearning on Big Data Xing, E.P .; Ho, Q.; Xie, P .; Wei, D. Engineering 11\\n25 WoS 67 2015 Recent advances on artiﬁcial intelligence and\\nlearning techniques in cognitive radio networks\\nAbbas, N.; Nasser, Y.; El Ahmad,\\nK.\\nEurasip Journal on Wireless\\nCommunications and\\nNetworking\\n11\\n26 WoS 68 2018 Artiﬁcial intelligence (AI) methods in optical\\nnetworks: A comprehensive survey\\nMata, J.; de Miguel, I.; Duran, R.J.;\\nMerayo, N.; Singh, S.K.; Jukan, A.;\\nChamania, M.\\nOptical Switching and\\nNetworking 9\\n27 SCP 40 2018\\nA big data driven sustainable manufacturing\\nframework for condition-based maintenance\\nprediction\\nKumar, A.; Shankar, R.; Thakur,\\nL.S.\\nJournal of Computational\\nScience\\n27, pp. 428–439\\n8\\n28 WoS 69 2017\\nResearch and Application of a Novel Hybrid\\nModel Based on Data Selection and Artiﬁcial'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 18, 'page_label': '19', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Kumar, A.; Shankar, R.; Thakur,\\nL.S.\\nJournal of Computational\\nScience\\n27, pp. 428–439\\n8\\n28 WoS 69 2017\\nResearch and Application of a Novel Hybrid\\nModel Based on Data Selection and Artiﬁcial\\nIntelligence Algorithm for Short Term Load\\nForecasting\\nYang, W.; Wang, J.; Wang, R. Entropy 8\\n29 SCP 33 2017 Context Aware Process Mining in Logistics Becker, T.; Intoyoad, W. Procedia CIRP 7\\n30 SCP 24 2016\\nApplications of machine learning methods to\\nidentifying and predicting building retroﬁt\\nopportunities\\nMarasco, D.E.; Kontokosta, C.E. Energy and Buildings 6\\n31 SCP 37 2017\\nOperational Demand Forecasting in District\\nHeating Systems Using Ensembles of Online\\nMachine Learning Algorithms\\nJohansson, C.; Bergkvist, M.;\\nGeysen, D.; (. . . ); Lavesson, N.;\\nVanhoudt, D.\\nEnergy Procedia 6\\n32 WoS 70 2018 Advances in Multiple Criteria Decision Making\\nfor Sustainability: Modeling and Applications Shen, K.Y.; Tzeng, G.H. Sustainability 6\\n33 WoS 71 2017 Hybrid-augmented intelligence: Collaboration'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 18, 'page_label': '19', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='for Sustainability: Modeling and Applications Shen, K.Y.; Tzeng, G.H. Sustainability 6\\n33 WoS 71 2017 Hybrid-augmented intelligence: Collaboration\\nand cognition\\nZheng, N.N.; Liu, Z.Y.; Ren, P .J.;\\nMa, Y.Q.; Chen, S.T.; Yu, S.Y.; Xue,\\nJ.R.; Chen, B.D.; Wang, F.Y.\\nFrontiers of Information\\nTechnology & Electronic\\nEngineering\\n6'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 19, 'page_label': '20', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Sustainability 2020, 12, 492 20 of 26\\nID Count Research\\nSource\\nID\\nDoc Year Title Authors Source Title TC\\n34 SCP 5 2008 Performance evaluation of the NVIDIA GeForce\\n8800 GTX GPU for machine learning\\nEl Zein, A.; McCreath, E.; Rendell,\\nA.; Smola, A.\\nLecture Notes in Computer\\nScience (including subseries\\nLecture Notes in Artiﬁcial\\nIntelligence and Lecture\\nNotes in Bioinformatics) 5101\\nLNCS(PART 1), pp. 466–475\\n5\\n35 SCP 7 2011 A review of artiﬁcial intelligence algorithms in\\ndocument classiﬁcation Bilski, A.\\nInternational Journal of\\nElectronics and\\nTelecommunications\\n5\\n36 SCP 18 2015 An architecture for agile machine learning in\\nreal-time applications Schleier-Smith, J.\\nProceedings of the ACM\\nSIGKDD International\\nConference on Knowledge\\nDiscovery and Data Mining\\n4\\n37 SCP 52 2018 Machine learning in agriculture: A review Liakos, K.G.; Busato, P .; Moshou,\\nD.; Pearson, S.; Bochtis, D. Sensors 4\\n38 SCP 22 2016\\nApplication of Information Processes\\nApplicative Modelling to Virtual Machines Auto'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 19, 'page_label': '20', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='D.; Pearson, S.; Bochtis, D. Sensors 4\\n38 SCP 22 2016\\nApplication of Information Processes\\nApplicative Modelling to Virtual Machines Auto\\nConﬁguration\\nZykov, S.; Shumsky, L. Procedia Computer Science 3\\n39 SCP 34 2017 Geometry-aware principal component analysis\\nfor symmetric positive deﬁnite matrices Horev, I.; Yger, F.; Sugiyama, M. Machine Learning 3\\n40 SCP 17 2015 A Fuzzy Least Squares Support Tensor Machines\\nin Machine Learning Zhang, R.; Zhou, Z.\\nInternational Journal of\\nEmerging Technologies in\\nLearning\\n2\\n41 SCP 36 2017 Nuclear energy system’s behavior and decision\\nmaking using machine learning\\nGomez Fernandez, M.; Tokuhiro,\\nA.; Welter, K.; Wu, Q.\\nNuclear Engineering and\\nDesign 2\\n42 SCP 9 2013 Application study of machine learning in\\nlightning forecasting\\nQiu, T.; Zhang, S.; Zhou, H.; Bai,\\nX.; Liu, P .\\nInformation Technology\\nJournal 1\\n43 SCP 30 2016\\nWOWMON: A machine learning-based proﬁler\\nfor self-adaptive instrumentation of scientiﬁc\\nworkﬂows\\nZhang, X.; Abbasi, H.; Huck, K.;'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 19, 'page_label': '20', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='X.; Liu, P .\\nInformation Technology\\nJournal 1\\n43 SCP 30 2016\\nWOWMON: A machine learning-based proﬁler\\nfor self-adaptive instrumentation of scientiﬁc\\nworkﬂows\\nZhang, X.; Abbasi, H.; Huck, K.;\\nMalony, A.D. Procedia Computer Science 1'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 20, 'page_label': '21', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Sustainability 2020, 12, 492 21 of 26\\nID Count Research\\nSource\\nID\\nDoc Year Title Authors Source Title TC\\n44 SCP 31 2017 An event search platform using machine\\nlearning\\nRodrigues, M.A.; Silva, R.R.;\\nBernardino, J.\\nProceedings of the\\nInternational Conference on\\nSoftware Engineering and\\nKnowledge Engineering,\\nSEKE\\n1\\n45 SCP 32 2017\\nAutomated business process management-in\\ntimes of digital transformation using machine\\nlearning or artiﬁcial intelligence\\nPaschek, D.; Luminosu, C.T.;\\nDraghici, A. MATEC Web of Conferences 1\\n46 SCP 42 2018\\nApplication of machine learning methods in big\\ndata analytics at management of contracts in the\\nconstruction industry\\nValpeters, M.; Kireev, I.; Ivanov,\\nN. MATEC Web of Conferences 1\\n47 SCP 48 2018 Data mining and machine learning in textile\\nindustry\\nYildirim, P .; Birant, D.; Alpyildiz,\\nT.\\nWiley Interdisciplinary\\nReviews: Data Mining and\\nKnowledge Discovery\\n1\\n48 WoS 72 2018\\nBig Data Analytics, Machine Learning, and\\nArtiﬁcial Intelligence in Next-Generation'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 20, 'page_label': '21', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='T.\\nWiley Interdisciplinary\\nReviews: Data Mining and\\nKnowledge Discovery\\n1\\n48 WoS 72 2018\\nBig Data Analytics, Machine Learning, and\\nArtiﬁcial Intelligence in Next-Generation\\nWireless Networks\\nKibria, M.G.; Kien, N.; Villardi,\\nG.P .; Zhao, O.; Ishizu, K.; Kojima,\\nF.\\nIeee Access 1\\n49 WoS 73 2017 Quantum neuromorphic hardware for quantum\\nartiﬁcial intelligence Prati, E.\\n8th International Workshop\\nDice2016: Spacetime - Matter -\\nQuantum Mechanics\\n1\\n50 WoS 74 2015 Exploiting Computational intelligence\\nParadigms in e-Technologies and Activities Said, H.M.; Salem, A.M.\\nInternational Conference on\\nCommunications,\\nManagement, and\\nInformation Technology\\n(Iccmit’2015)\\n1\\n51 WoS 75 2012 Sentiment Analysis of Products Using Web Unnamalai, K.\\nInternational Conference on\\nModelling Optimization and\\nComputing\\n1\\n52 SCP 8 2012 Taxonomy development and its impact on a\\nself-learning e-recruitment system\\nFaliagka, E.; Karydis, I.; Rigou,\\nM.; (. . . ); Tsakalidis, A.; Tzimas,\\nG.\\nIFIP Advances in Information'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 20, 'page_label': '21', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='1\\n52 SCP 8 2012 Taxonomy development and its impact on a\\nself-learning e-recruitment system\\nFaliagka, E.; Karydis, I.; Rigou,\\nM.; (. . . ); Tsakalidis, A.; Tzimas,\\nG.\\nIFIP Advances in Information\\nand Communication\\nTechnology\\n0'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 21, 'page_label': '22', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Sustainability 2020, 12, 492 22 of 26\\nID Count Research\\nSource\\nID\\nDoc Year Title Authors Source Title TC\\n53 SCP 13 2013 Research on adaptive multi-ﬁltering model of\\nnetwork sensitive information\\nCao, X.F.; Kang, W.; Shi, Q.; Shi,\\nF.F.\\nInformation Technology\\nJournal 0\\n54 SCP 15 2014 Grade: Machine-learning support for graduate\\nadmissions Waters, A.; Miikkulainen, R. AI Magazine 0\\n55 SCP 27 2016 Leveraging linked open data information\\nextraction for data mining applications Mahule, R.; Vyas, O.P .\\nTurkish Journal of Electrical\\nEngineering and Computer\\nSciences\\n0\\n56 SCP 38 2017 Rapid prototyping IoT solutions based on\\nMachine Learning\\nRizzo, A.; Montefoschi, F.;\\nCaporali, M.; (. . . ); Burresi, G.;\\nGiorgi, R.\\nACM International\\nConference Proceeding Series 0\\n57 SCP 39 2017 Towards automatic learning of heuristics for\\nmechanical transformations of procedural code\\nVigueras, G.; Carro, M.; Tamarit,\\nS.; Mariño, J.\\nElectronic Proceedings in\\nTheoretical Computer Science,\\nEPTCS\\n0'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 21, 'page_label': '22', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='mechanical transformations of procedural code\\nVigueras, G.; Carro, M.; Tamarit,\\nS.; Mariño, J.\\nElectronic Proceedings in\\nTheoretical Computer Science,\\nEPTCS\\n0\\n58 SCP 41 2018 Application of artiﬁcial intelligence principles in\\nmechanical engineering\\nZajaˇ cko, I.; Gál, T.; Ságová, Z.;\\nMateichyk, V .; Wiecek, D. MATEC Web of Conferences 0\\n59 SCP 44 2018 Artiﬁcial Intelligence in Medical Applications Chan, Y.K.; Chen, Y.F.; Pham, T.;\\nChang, W.; Hsieh, M.Y.\\nJournal of Healthcare\\nEngineering 0\\n60 SCP 45 2018\\nA semantic internet of things framework using\\nmachine learning approach based on cloud\\ncomputing\\nDing, P .W.; Hsu, I.C. ACM International\\nConference Proceeding Series 0\\n61 SCP 46 2018 A Survey on Machine Learning-Based Mobile\\nBig Data Analysis: Challenges and Applications\\nXie, J.; Song, Z.; Li, Y.; (. . . );\\nZhang, J.; Guo, J.\\nWireless Communications\\nand Mobile Computing 0\\n62 SCP 47 2018 Big Data and Machine Learning Based Secure'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 21, 'page_label': '22', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Xie, J.; Song, Z.; Li, Y.; (. . . );\\nZhang, J.; Guo, J.\\nWireless Communications\\nand Mobile Computing 0\\n62 SCP 47 2018 Big Data and Machine Learning Based Secure\\nHealthcare Framework Kaur, P .; Sharma, M.; Mittal, M. Procedia Computer Science 0\\n63 SCP 49 2018 Discovering discontinuity in big ﬁnancial\\ntransaction data\\nTuarob, S.; Strong, R.; Chandra,\\nA.; Tucker, C.S.\\nACM Transactions on\\nManagement Information\\nSystems\\n0'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 22, 'page_label': '23', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Sustainability 2020, 12, 492 23 of 26\\nID Count Research\\nSource\\nID\\nDoc Year Title Authors Source Title TC\\n64 SCP 50 2018 Introducing children to machine learning\\nconcepts through hands-on experience\\nHitron, T.; Erel, H.; Wald, I.;\\nZuckerman, O.\\nIDC 2018 - Proceedings of the\\n2018 ACM Conference on\\nInteraction Design and\\nChildren\\n0\\n65 SCP 51 2018 Machine learning for software engineering:\\nModels, methods, and applications Meinke, K.; Bennaceur, A.\\nProceedings - International\\nConference on Software\\nEngineering\\n0\\n66 SCP 53 2018 Machine Learning in IT Service Management Zuev, D.; Kalistratov, A.; Zuev, A.Procedia Computer Science 0\\n67 SCP 54 2018 Research and application of computer control\\nsystem based on complex neural network Yang, R. MATEC Web of Conferences 0\\n68 SCP 55 2018 Text classiﬁcation techniques: A literature\\nreview Thangaraj, M.; Sivakami, M.\\nInterdisciplinary Journal of\\nInformation, Knowledge, and\\nManagement\\n0\\n69 SCP 56 2019 A Machine Learning Method for Predicting'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 22, 'page_label': '23', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='review Thangaraj, M.; Sivakami, M.\\nInterdisciplinary Journal of\\nInformation, Knowledge, and\\nManagement\\n0\\n69 SCP 56 2019 A Machine Learning Method for Predicting\\nDriving Range of Battery Electric Vehicles\\nSun, S.; Zhang, J.; Bi, J.; Wang, Y.;\\nMoghaddam, M.H.Y.\\nJournal of Advanced\\nTransportation 0\\n70 SCP 57 2019 An empirical comparison of machine-learning\\nmethods on bank client credit assessments\\nMunkhdalai, L.; Munkhdalai, T.;\\nNamsrai, O.E.; Lee, J.Y.; Ryu, K.H. Sustainability 0\\n71 SCP 58 2019\\nComparison of multiple linear regression,\\nartiﬁcial neural network, extreme learning\\nmachine, and support vector machine in\\nderiving operation rule of hydropower reservoir\\nNiu, W.J.; Feng, Z.K.; Feng, B.F.; (\\n. . . ); Cheng, C.T.; Zhou, J.Z. Water 0\\n72 SCP 59 2019\\nDevelopment and evaluation of a low-cost and\\nsmart technology for precision weed\\nmanagement utilizing artiﬁcial intelligence\\nPartel, V .; Charan Kakarla, S.;\\nAmpatzidis, Y.\\nComputers and Electronics in\\nAgriculture 0'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 22, 'page_label': '23', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='smart technology for precision weed\\nmanagement utilizing artiﬁcial intelligence\\nPartel, V .; Charan Kakarla, S.;\\nAmpatzidis, Y.\\nComputers and Electronics in\\nAgriculture 0\\n73 SCP 60 2019 Identifying known and unknown mobile\\napplication traﬃc using a multilevel classiﬁer\\nZhao, S.; Chen, S.; Sun, Y.; (. . . );\\nSu, J.; Su, C.\\nSecurity and Communication\\nNetworks 0'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 23, 'page_label': '24', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Sustainability 2020, 12, 492 24 of 26\\nID Count Research\\nSource\\nID\\nDoc Year Title Authors Source Title TC\\n74 SCP 61 2019 Optimized Clustering Algorithms for Large\\nWireless Sensor Networks: A Review\\nWohwe Sambo, D.; Yenke, B.O.;\\nFörster, A.; Dayang, P . Sensors 0\\n75 WoS 76 2019\\nFPGA-Based Accelerators of Deep Learning\\nNetworks for Learning and Classiﬁcation: A\\nReview\\nShawahna, A.; Sait, S.M.;\\nEl-Maleh, A. Ieee Access 0\\n76 WoS 77 2018 A quantum machine learning algorithm based\\non generative models Gao, X.; Zhang, Z.Y.; Duan, L.M. Science Advances 0\\n77 WoS 78 2018 Machine Learning for Network Automation:\\nOverview, Architecture, and Applications Raﬁque, D.; Velasco, L.\\nJournal of Optical\\nCommunications and\\nNetworking\\n0\\n78 WoS 79 2018\\nA wireless sensor data-based coal mine gas\\nmonitoring algorithm with least squares support\\nvector machines optimized by swarm\\nintelligence techniques\\nChen, P .; Xie, Y.; Jin, P .; Zhang, D.International Journal of\\nDistributed Sensor Networks 0'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 23, 'page_label': '24', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='vector machines optimized by swarm\\nintelligence techniques\\nChen, P .; Xie, Y.; Jin, P .; Zhang, D.International Journal of\\nDistributed Sensor Networks 0\\n79 WoS 80 2017 Nuclear energy system’s behavior and decision\\nmaking using machine learning\\nFernandez, M.G.; Tokuhiro, A.;\\nWelter, K.; Wu, Q.\\nNuclear Engineering and\\nDesign 0\\n80 WoS 81 2017\\nAutomated business process management—In\\ntimes of digital transformation using machine\\nlearning or artiﬁcial intelligence\\nPaschek, D.; Luminosu, C.T.;\\nDraghici, A.\\n8th International Conference\\non Manufacturing Science\\nand Education (Mse\\n2017)—Trends in New\\nIndustrial Revolution\\n0\\n81 WoS 82 2017\\nThe Evaluation of Resonance Frequency for\\nPiezoelectric Transducers by Machine Learning\\nMethods\\nChang, F.M.\\n27Th International\\nConference on Flexible\\nAutomation and Intelligent\\nManufacturing, Faim 2017\\n0\\n82 WoS 83 2017\\nFrom Extraction to Generation of Design\\nInformation Paradigm Shift in Data Mining via\\nEvolutionary Learning Classiﬁer System'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 23, 'page_label': '24', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Automation and Intelligent\\nManufacturing, Faim 2017\\n0\\n82 WoS 83 2017\\nFrom Extraction to Generation of Design\\nInformation Paradigm Shift in Data Mining via\\nEvolutionary Learning Classiﬁer System\\nChiba, K.; Nakata, M.\\nInternational Conference on\\nComputational Science (Iccs\\n2017)\\n0'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 24, 'page_label': '25', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Sustainability 2020, 12, 492 25 of 26\\nReferences\\n1. Gupta, N.A. Literature Survey on Artiﬁcial Intelligence. 2017. Available online: https: //www.ijert.org/\\nresearch/a-literature-survey-on-artiﬁcial-intelligence-IJERTCONV5IS19015.pdf (accessed on 7 January 2020).\\n2. McCarthy, J.; Minsky, M.L.; Rochester, N.; Shannon, C.E. A Proposal for the Dartmouth Summer Research\\nProject on Artiﬁcial Intelligence. AI Mag. 2006, 27, 12.\\n3. Moore, A. Carnegie Mellon Dean of Computer Science on the Future of AI. Available\\nonline: https://www.forbes.com/sites/peterhigh/2017/10/30/carnegie-mellon-dean-of-computer-science-on-\\nthe-future-of-ai /#3a283c652197 (accessed on 7 January 2020).\\n4. Becker, A.; Bar-Yehuda, R.; Geiger, D. Randomised algorithms for the loop cutset problem.J. Artif. Intell. Res.\\n2000, 12, 219–234. [CrossRef]\\n5. Singer, J.; Gent, I.P .; Smaill, A. Backbone fragility and the local search cost peak.J. Artif. Intell. Res. 2000,\\n12, 235–270. [CrossRef]'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 24, 'page_label': '25', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='2000, 12, 219–234. [CrossRef]\\n5. Singer, J.; Gent, I.P .; Smaill, A. Backbone fragility and the local search cost peak.J. Artif. Intell. Res. 2000,\\n12, 235–270. [CrossRef]\\n6. Chen, X.; Van Beek, P . Conﬂict-directed backjumping revisited.J. Artif. Intell. Res. 2001, 14, 53–81. [CrossRef]\\n7. Hong, J. Goal recognition through goal graph analysis. J. Artif. Intell. Res. 2001, 15, 1–30. [CrossRef]\\n8. Stone, P .; Littman, M.L.; Singh, S.; Kearns, M. ATTAC-2000: An adaptive autonomous bidding agent.J. Artif.\\nIntell. Res. 2000, 15, 189–206. [CrossRef]\\n9. Peng, Y.; Zhang, X. Integrative data mining in systems biology: from text to network mining.Artif. Intell. Med.\\n2007, 41, 83–86. [CrossRef]\\n10. Zhou, X.; Liu, B.; Wu, Z.; Feng, Y. Integrative mining of traditional Chines medicine literature and MEDLINE\\nfor functional gene networks. Artif. Intell. Med. 2007, 41, 87–104. [CrossRef]\\n11. Wang, S.; Wang, Y.; Du, W.; Sun, F.; Wang, X.; Zhou, C.; Liang, Y. A multi-approaches-guided genetic'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 24, 'page_label': '25', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='for functional gene networks. Artif. Intell. Med. 2007, 41, 87–104. [CrossRef]\\n11. Wang, S.; Wang, Y.; Du, W.; Sun, F.; Wang, X.; Zhou, C.; Liang, Y. A multi-approaches-guided genetic\\nalgorithm with application to operon prediction. Artif. Intell. Med. 2007, 41, 151–159. [CrossRef]\\n12. Halal, W.E. Artiﬁcial intelligence is almost here. Horizon 2003, 11, 37–38. Available online: https: //\\nwww.emerald.com/insight/content/doi/10.1108/10748120310486771/full/html (accessed on 7 January 2020).\\n[CrossRef]\\n13. Masnikosa, V .P . The fundamental problem of an artiﬁcial intelligence realization.Kybernetes 1998, 27, 71–80.\\n[CrossRef]\\n14. Metaxiotis, K.; Ergazakis, K.; Samouilidis, E.; Psarras, J. Decision support through knowledge management:\\nThe role of the artiﬁcial intelligence. Inf. Manag. Comput. Secur. 2003, 11, 216–221. [CrossRef]\\n15. Raynor, W.J. The international dictionary of artiﬁcial intelligence. Ref. Rev. 2000, 14, 1–380.'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 24, 'page_label': '25', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='The role of the artiﬁcial intelligence. Inf. Manag. Comput. Secur. 2003, 11, 216–221. [CrossRef]\\n15. Raynor, W.J. The international dictionary of artiﬁcial intelligence. Ref. Rev. 2000, 14, 1–380.\\n16. Stefanuk, V .L.; Zhozhikashvili, A.V . Productions and rules in artiﬁcial intelligence. Kybernetes 2002,\\n31, ty817–826. [CrossRef]\\n17. Tay, D.P .H.; Ho, D.K.H. Artiﬁcial intelligence and the mass appraisal of residential apartments. J. Prop.\\nValuat. Invest. 1992, 10, 525–540. [CrossRef]\\n18. Wongpinunwatana, N.; Ferguson, C.; Bowen, P . An experimental investigation of the eﬀects of artiﬁcial\\nintelligence systems on the training of novice auditors. Manag. Audit. J. 2000, 15, 306–318. [CrossRef]\\n19. Oke, S.A. A literature review on artiﬁcial intelligence. Int. J. Inf. Manag. Sci. 2008, 19, 535–570.\\n20. Carvalho, T.P .; Soares, F.A.A.M.N.; Vita, R.; da Francisco, P .R.; Basto, J.P .; Alcalá, S.G.S. A systematic literature'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 24, 'page_label': '25', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='20. Carvalho, T.P .; Soares, F.A.A.M.N.; Vita, R.; da Francisco, P .R.; Basto, J.P .; Alcalá, S.G.S. A systematic literature\\nreview of machine learning methods applied to predictive maintenance. Comput. Ind. Eng. 2019, 1, 1–12.\\n[CrossRef]\\n21. Majorel Deutschland GmbH Artiﬁcial Intelligence and Sustainability. Available online: https://www.future-\\ncustomer.com/artiﬁcial-intelligence-and-sustainability / (accessed on 8 January 2020).\\n22. Markham, I.S.; Mathieu, R.G.; Wray, B.A. Kanban setting through artiﬁcial intelligence: A comparative study\\nof artiﬁcial neural networks and decision trees. Integr. Manuf. Syst. 2000, 11, 239–246. [CrossRef]\\n23. Kotsiantis, S.B.; Zaharakis, I.; Pintelas, P . Supervised machine learning: A review of classiﬁcation techniques.\\nEmerg. Artif. Intell. Appl. Comput. Eng. 2007, 160, 3–24.\\n24. Cortes, C.; Vapnik, V . Support-vector networks. Mach. Learn. 1995, 20, 273–297. [CrossRef]'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 24, 'page_label': '25', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Emerg. Artif. Intell. Appl. Comput. Eng. 2007, 160, 3–24.\\n24. Cortes, C.; Vapnik, V . Support-vector networks. Mach. Learn. 1995, 20, 273–297. [CrossRef]\\n25. Kitchenham, B. Procedures for Performing Systematic Reviews. Technical Report TR/SE-0401. 2004. Available\\nonline: https://pdfs.semanticscholar.org/2989/0a936639862f45cb9a987dd599dce9759bf5.pdf?_ga=2.7241591.\\n47522378.1578382825-243572483.1578382825 (accessed on 7 January 2020).\\n26. Duan, Y.; Edwards, J.S.; Dwivedi, Y.K. Artiﬁcial intelligence for decision making in the era of Big\\nData—Evolution, challenges and research agenda. Int. J. Inf. Manag. 2019, 48, 63–71. [CrossRef]'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 25, 'page_label': '26', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Sustainability 2020, 12, 492 26 of 26\\n27. De Felice, F.; Petrillo, A.; Zomparelli, F. Prospective design of smart manufacturing: An Italian pilot case\\nstudy. Manuf. Lett. 2018, 15, 81–85. [CrossRef]\\n28. Larrañaga, P .; Calvo, B.; Santana, R.; Bielza, C.; Galdiano, J.; Inza, I.; Lozano, J.A.; Armañanzas, R.; Santafé, G.;\\nPérez, A.; et al. Machine Learning. in Bioinformatics. Brief. Bioinform. 2006, 7, 86–112. [CrossRef] [PubMed]\\n29. Krawczyk, B. Learning from imbalanced data: Open challenges and future directions. Prog. Artif. Intell.\\n2016, 5, 221–232. [CrossRef]\\n30. Wuest, T.; Weimer, D.; Irgens, C.; Thoben, K.D. Machine learning in manufacturing: Advantages, challenges,\\nand applications. Prod. Manuf. Res. 2016, 4, 23–45. [CrossRef]\\n31. Dutton, T. An Overview of National AI Strategies. Available online: http: //www.jaist.ac.jp/~{}bao/AI/\\nOtherAIstrategies/An%20Overview%20of%20National%20AI%20Strategies%20%E2%80%93%20Politics%'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 25, 'page_label': '26', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='31. Dutton, T. An Overview of National AI Strategies. Available online: http: //www.jaist.ac.jp/~{}bao/AI/\\nOtherAIstrategies/An%20Overview%20of%20National%20AI%20Strategies%20%E2%80%93%20Politics%\\n20+%20AI%20%E2%80%93%20Medium.pdf (accessed on 8 January 2020).\\n32. Pérez-Ortiz, M.; Jiménez-Fernández, S.; Gutiérrez, P .A.; Alexandre, E.; Hervás-Martínez, C.; Salcedo-Sanz, S.\\nA Review of Classiﬁcation Problems and Algorithms in Renewable Energy Applications. Energies 2016,\\n9, 607. [CrossRef]\\n33. Lieber, D.; Stolpe, M.; Konrad, B.; Deuse, J.; Morik, K. Quality prediction in interlinked manufacturing\\nprocesses based on supervised & unsupervised machine learning. Procedia CIRP 2013, 7, 193–198.\\n34. Sachs, J.D.; Schmidt-Traub, G.; Mazzucato, M.; Messner, D.; Nakicenovic, N.; Rockström, J.\\nSix Transformations to Achieve the Sustainable Development Goals. Nat. Sustain. 2019, 2, 805–814.\\n[CrossRef]\\n© 2020 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access'),\n",
       " Document(metadata={'producer': 'iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2020-01-18T09:04:12+08:00', 'moddate': '2020-01-18T09:04:12+08:00', 'source': '../data/pdf_files/Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'total_pages': 26, 'page': 25, 'page_label': '26', 'source_file': 'Artificial_Intelligence_and_Machine_Learning_Appli.pdf', 'file_type': 'pdf'}, page_content='Six Transformations to Achieve the Sustainable Development Goals. Nat. Sustain. 2019, 2, 805–814.\\n[CrossRef]\\n© 2020 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access\\narticle distributed under the terms and conditions of the Creative Commons Attribution\\n(CC BY) license (http://creativecommons.org/licenses/by/4.0/).'),\n",
       " Document(metadata={'producer': 'Skia/PDF m144 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'dsa', 'source': '../data/pdf_files/dsa.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'dsa.pdf', 'file_type': 'pdf'}, page_content='Time  complexity  measures  how  the  performance  of  an  algorithm  changes  with  input  size  (n).  Big-O  notation  \\nexpresses\\n \\nthe\\n \\nworst-case\\n \\ncomplexity.\\n \\nFor\\n \\nexample,\\n \\nO(1)\\n \\nmeans\\n \\nconstant\\n \\ntime;\\n \\nO(n)\\n \\nmeans\\n \\nlinear\\n \\ntime;\\n \\nO(n²)\\n \\nrepresents\\n \\nquadratic\\n \\ntime;\\n \\nO(log\\n \\nn)\\n \\nis\\n \\nlogarithmic;\\n \\nand\\n \\nO(n\\n \\nlog\\n \\nn)\\n \\nrepresents\\n \\nefficient\\n \\ndivide-and-conquer\\n \\nalgorithms\\n \\nlike\\n \\nmerge\\n \\nsort.\\n \\nSearching  algorithms  determine  how  to  locate  a  specific  value  in  a  dataset.  The  simplest  is  linear  search  \\n(O(n))\\n,\\n \\nwhich\\n \\nchecks\\n \\neach\\n \\nelement\\n \\nsequentially.\\n \\nIt\\n \\nworks\\n \\non\\n \\nunsorted\\n \\ndata\\n \\nbut\\n \\nis\\n \\nslow\\n \\nfor\\n \\nlarge\\n \\ninputs.\\n \\nBinary\\n \\nsearch\\n \\n(O(log\\n \\nn))\\n \\nworks\\n \\non\\n \\nsorted\\n \\narrays\\n \\nby\\n \\nrepeatedly\\n \\ndividing\\n \\nthe\\n \\nsearch\\n \\nspace\\n \\nin\\n \\nhalf,\\n \\ndramatically\\n \\nimproving\\n \\nefficiency.\\n \\nSorting  algorithms  arrange  elements  in  ascending  or  descending  order:'),\n",
       " Document(metadata={'producer': 'Skia/PDF m144 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'dsa', 'source': '../data/pdf_files/dsa.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'dsa.pdf', 'file_type': 'pdf'}, page_content='arrays\\n \\nby\\n \\nrepeatedly\\n \\ndividing\\n \\nthe\\n \\nsearch\\n \\nspace\\n \\nin\\n \\nhalf,\\n \\ndramatically\\n \\nimproving\\n \\nefficiency.\\n \\nSorting  algorithms  arrange  elements  in  ascending  or  descending  order:  \\n●  Bubble  Sort:  Repeatedly  swaps  adjacent  elements—simple  but  slow  (O(n²)).  \\n ●  Selection  Sort:  Selects  the  smallest  element  in  each  iteration—also  O(n²).  \\n ●  Insertion  Sort:  Efficient  for  small  or  nearly  sorted  arrays  (O(n²)  worst  case).  \\n ●  Merge  Sort:  A  divide-and-conquer  algorithm  that  splits,  sorts,  and  merges;  stable  and  fast  with  O(n  log  \\nn)\\n \\ntime.\\n \\n ●  Quick  Sort:  Uses  a  pivot  to  partition  the  array;  average  O(n  log  n)  but  worst  O(n²).  One  of  the  fastest  \\npractical\\n \\nalgorithms.\\n \\n ●  Heap  Sort:  Builds  a  heap  and  extracts  the  maximum/minimum  repeatedly;  guarantees  O(n  log  n).  \\n \\nUnderstanding  time  complexity  helps  you  choose  the  right  algorithm  for  large-scale  problems.  Sorting  and'),\n",
       " Document(metadata={'producer': 'Skia/PDF m144 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'dsa', 'source': '../data/pdf_files/dsa.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'dsa.pdf', 'file_type': 'pdf'}, page_content='Understanding  time  complexity  helps  you  choose  the  right  algorithm  for  large-scale  problems.  Sorting  and  \\nsearching\\n \\nform\\n \\nthe\\n \\nfoundation\\n \\nof\\n \\nmost\\n \\nreal-world\\n \\napplications,\\n \\nfrom\\n \\ndatabases\\n \\nto\\n \\ncompetitive\\n \\nprogramming.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m139', 'creator': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/139.0.0.0 Safari/537.36', 'creationdate': '2025-08-30T19:12:18+00:00', 'title': 'shreya_sharma_resume.docx - Google Docs', 'moddate': '2025-08-30T19:12:18+00:00', 'source': '../data/pdf_files/Shreya_Sharma_Resume.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'Shreya_Sharma_Resume.pdf', 'file_type': 'pdf'}, page_content='SHREYA SHARMA \\n B.Tech (Computer Science and Engineering \\n with Specialization in Cyber Security) \\n Email:  shreya.sharma110404@gmail.com  |  Phone:  9770766139 \\n LinkedIn:  https://www.linkedin.com/in/shreya-sharma1104/ \\n GitHub:  https://github.com/shreyasharma-1 \\n ACADEMICS \\n Qualification  Institute  Board / University  % / CGPA  Year \\n B.Tech (CY - 6th sem) \\n XII \\n Lakshmi Narain College of \\n Technology & Science \\n Maharishi Vidya Mandir, Jabalpur \\n RGPV \\n CBSE \\n 8.34/10 \\n 73% \\n 2026 \\n 2022 \\n X  Maharishi Vidya Mandir, Jabalpur  CBSE  70.8%  2020 \\n Certifications \\n /Publications \\n ●  Comprehensive Study Of MD5 and SHA-256 \\n ●  Introduction to Cybersecurity offered through Cisco Networking Academy \\n ●  The Complete Python Developer Certification Course offered by Udemy \\n ●  Database Management System Part - 1 offered by Infosys Springboard \\n ●  Python (Basic) offered by Hacker-Rank \\n 2024 \\n 2024 \\n 2024 \\n 2024 \\n 2023'),\n",
       " Document(metadata={'producer': 'Skia/PDF m139', 'creator': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/139.0.0.0 Safari/537.36', 'creationdate': '2025-08-30T19:12:18+00:00', 'title': 'shreya_sharma_resume.docx - Google Docs', 'moddate': '2025-08-30T19:12:18+00:00', 'source': '../data/pdf_files/Shreya_Sharma_Resume.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'Shreya_Sharma_Resume.pdf', 'file_type': 'pdf'}, page_content='●  Database Management System Part - 1 offered by Infosys Springboard \\n ●  Python (Basic) offered by Hacker-Rank \\n 2024 \\n 2024 \\n 2024 \\n 2024 \\n 2023 \\n Achievements  ●  Best  Paper  Award  (2nd  Position)  for  the  \"Comprehensive  Study  of  MD5  and  SHA-256\" \\n Research Paper at ICEHAIDS.  2024 \\n PROJECTS \\n Multi-Agent \\n Telegram Bot \\n ●  Tech Stack – Python, FastAPI, MongoDB, OpenAI Whisper, Google Nearby Search API \\n ●  Developed a Multi-Agent Telegram Bot with intelligent query routing for dynamic decision-making \\n ●  Integrated  real-time  services  including  weather  updates,  stock  price  retrieval,  news  aggregation, \\n image generation, meme creation, and voice-to-text interaction using OpenAI Whisper. \\n ●  Implemented  location-based  features  with  Google  Nearby  Search  API  and  ensured  scalable \\n architecture with secure chat history storage in MongoDB.. \\n Face Tracer - \\n Intelligent Presence \\n Detection'),\n",
       " Document(metadata={'producer': 'Skia/PDF m139', 'creator': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/139.0.0.0 Safari/537.36', 'creationdate': '2025-08-30T19:12:18+00:00', 'title': 'shreya_sharma_resume.docx - Google Docs', 'moddate': '2025-08-30T19:12:18+00:00', 'source': '../data/pdf_files/Shreya_Sharma_Resume.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'Shreya_Sharma_Resume.pdf', 'file_type': 'pdf'}, page_content='architecture with secure chat history storage in MongoDB.. \\n Face Tracer - \\n Intelligent Presence \\n Detection \\n ●  Tech Stack  – Python, OpenCV, face_recognition, Flask, HTML/CSS, SQLite, NumPy, Pandas \\n ●  Developed  a  real-time  attendance  management  web  application  using  facial  recognition.  Integrated \\n webcam-based face detection with automatic attendance logging and CSV/SQLite storage. \\n ●  Built  a  responsive  frontend  using  Flask  and  HTML  with  options  for  registration,  training,  and \\n viewing attendance logs. \\n House Price \\n Prediction – Data \\n analysis \\n ●  Tech Stack  - Python, Pandas, Numpy, Matplotlib, Seaborn \\n ●  House  Price  Prediction  uses  machine  learning  techniques  to  predict  housing  prices,  showcasing \\n analytical and problem-solving skills. \\n Iris Flower \\n classification \\n ●  Tech Stack -  Python, Pandas, Numpy, Matplotlib, Seaborn, filter warnings'),\n",
       " Document(metadata={'producer': 'Skia/PDF m139', 'creator': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/139.0.0.0 Safari/537.36', 'creationdate': '2025-08-30T19:12:18+00:00', 'title': 'shreya_sharma_resume.docx - Google Docs', 'moddate': '2025-08-30T19:12:18+00:00', 'source': '../data/pdf_files/Shreya_Sharma_Resume.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'Shreya_Sharma_Resume.pdf', 'file_type': 'pdf'}, page_content='analytical and problem-solving skills. \\n Iris Flower \\n classification \\n ●  Tech Stack -  Python, Pandas, Numpy, Matplotlib, Seaborn, filter warnings \\n ●  Iris  Flower  Classification  using  Applied  linear  regression  for  accurate  classification  of  Iris  flowers, \\n demonstrating a solid understanding of statistical modeling \\n √√√ \\n SKILLS \\n Programming  Java, Python, Pandas, Numpy, Matplotlib, Machine Learning (Beginner) \\n Databases  SQL \\n Analytics  Power BI, Matplotlib, Seaborn \\n Tools  Jupyter Notebook, Cursor, VS Code, Canva, MS Word, MS Excel, MS PowerPoint \\n Soft Skills  Leadership, Communication, Problem Solving, Analytical Skills, Learning Agility \\n POSITIONS OF RESPONSIBILITY \\n LNCTS BHOPAL \\n ●  Volunteer  at  the  International  Conference  on  Expanding  Horizons  in  Artificial \\n Intelligence & Data Science \\n ●  Research Paper Presenter at ICEHAIDS \\n MVM, Jabalpur  ●  Vice Captain, Assembly Committee \\n ●  Member, Hygiene Committee'),\n",
       " Document(metadata={'producer': 'Skia/PDF m139', 'creator': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/139.0.0.0 Safari/537.36', 'creationdate': '2025-08-30T19:12:18+00:00', 'title': 'shreya_sharma_resume.docx - Google Docs', 'moddate': '2025-08-30T19:12:18+00:00', 'source': '../data/pdf_files/Shreya_Sharma_Resume.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'Shreya_Sharma_Resume.pdf', 'file_type': 'pdf'}, page_content='Intelligence & Data Science \\n ●  Research Paper Presenter at ICEHAIDS \\n MVM, Jabalpur  ●  Vice Captain, Assembly Committee \\n ●  Member, Hygiene Committee \\n CO-CURRICULAR & EXTRACURRICULAR ACTIVITIES \\n Lakshmi Narain College of Technology & Science | BATCH OF 2026 \\n Technical  ●  Chairperson (Innovation Vertical), Young Indians CII-YUVA \\n ●  Competitive Programming – LeetCode, Hacker-Rank'),\n",
       " Document(metadata={'producer': 'Skia/PDF m139', 'creator': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/139.0.0.0 Safari/537.36', 'creationdate': '2025-08-30T18:04:57+00:00', 'title': '\".:: Rajiv Gandhi Proudyogiki Vishwavidyalaya, Bhopal ::.\"', 'moddate': '2025-08-30T18:04:57+00:00', 'source': '../data/pdf_files/Shreya_Sharma_Transcript.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'Shreya_Sharma_Transcript.pdf', 'file_type': 'pdf'}, page_content='Rajiv Gandhi Proudyogiki\\nVishwavidyalaya, Bhopal\\nStatement of Marks - June-2025\\nName SHREYA SHARMA Roll No. 0157CY221129\\nCourse B.Tech Branch CY\\nSemester 6 Status Regular\\nSubject Total Credit Earned Credit Grade\\nCY601- [T] 3 3 A\\nCY602- [T] 3 3 B+\\nCY603- [T] 4 4 A+\\nCY604- [T] 4 4 A\\nCY601- [P] 1 1 A+\\nCY602- [P] 1 1 A+\\nCY605- [P] 3 3 A+\\nCY606- [P] 3 3 A+\\nCY608- [P] 2 2 A+\\nResult Des. SGPA CGPA\\nPASS 9.46 8.34\\nRevaluation Date Revaluation Date with\\nLate Fee\\n12/08/2025 14/08/2025\\nData Source : Rajiv Gandhi Proudyogiki Vishwavidyalaya, Bhopal\\nDisclaimer : The data belongs to RGPV,Bhopal. For any communication related to the\\npublished data, please contact examination cell of RGPV or respective College.\\nPrint Marksheet\\n30/08/2025, 23:34 \".:: Rajiv Gandhi Proudyogiki Vishwavidyalaya, Bhopal ::.\"\\nabout:blank 1/1'),\n",
       " Document(metadata={'producer': 'Skia/PDF m144 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'dbms', 'source': '../data/pdf_files/dbms.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'dbms.pdf', 'file_type': 'pdf'}, page_content='Database  Management  Systems  (DBMS)  provide  structured  storage,  retrieval,  and  management  of  data.  One  \\nessential\\n \\nconcept\\n \\nin\\n \\nrelational\\n \\ndatabases\\n \\nis\\n \\nnormalization\\n,\\n \\nwhich\\n \\naims\\n \\nto\\n \\nreduce\\n \\nredundancy\\n \\nand\\n \\nensure\\n \\ndata\\n \\nintegrity.\\n \\nNormalization\\n \\ninvolves\\n \\ndecomposing\\n \\ntables\\n \\ninto\\n \\nwell-structured\\n \\nforms\\n \\ncalled\\n \\nnormal\\n \\nforms\\n.\\n \\n1NF  (First  Normal  Form)  requires  that  table  cells  contain  atomic  values  and  that  each  record  is  unique.  2NF  \\nremoves\\n \\npartial\\n \\ndependency,\\n \\nmeaning\\n \\nno\\n \\nnon-key\\n \\nattribute\\n \\nshould\\n \\ndepend\\n \\non\\n \\nonly\\n \\npart\\n \\nof\\n \\na\\n \\ncomposite\\n \\nprimary\\n \\nkey.\\n \\n3NF\\n \\nremoves\\n \\ntransitive\\n \\ndependency,\\n \\nensuring\\n \\nnon-key\\n \\nattributes\\n \\ndepend\\n \\nonly\\n \\non\\n \\nprimary\\n \\nkeys.\\n \\nProper\\n \\nnormalization\\n \\nprevents\\n \\nanomalies\\n \\nsuch\\n \\nas\\n \\nupdate,\\n \\ninsertion,\\n \\nand\\n \\ndeletion\\n \\nanomalies.\\n \\nIn  DBMS,  relationships  between  tables  are  established  through  joins :'),\n",
       " Document(metadata={'producer': 'Skia/PDF m144 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'dbms', 'source': '../data/pdf_files/dbms.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'dbms.pdf', 'file_type': 'pdf'}, page_content='Proper\\n \\nnormalization\\n \\nprevents\\n \\nanomalies\\n \\nsuch\\n \\nas\\n \\nupdate,\\n \\ninsertion,\\n \\nand\\n \\ndeletion\\n \\nanomalies.\\n \\nIn  DBMS,  relationships  between  tables  are  established  through  joins :  \\n●  INNER  JOIN:  Returns  only  matching  rows  from  both  tables.  \\n ●  LEFT  JOIN:  Returns  all  rows  from  the  left  table  and  matching  rows  from  the  right.  \\n ●  RIGHT  JOIN:  Opposite  of  left  join.  \\n ●  FULL  OUTER  JOIN:  Returns  all  rows  when  there  is  a  match  in  either  table.  \\n ●  CROSS  JOIN:  Produces  a  Cartesian  product.  \\n \\nJoins  enable  relational  databases  to  maintain  normalized  structures  while  still  retrieving  meaningful  combined  \\ndata.\\n \\nAnother  key  concept  is  transactions ,  which  represent  a  sequence  of  operations  performed  as  a  single  logical  \\nunit\\n \\nof\\n \\nwork.\\n \\nTransactions\\n \\nmust\\n \\nsatisfy\\n \\nthe\\n \\nACID\\n \\nproperties\\n:\\n \\n●  Atomicity:  All  steps  succeed  or  none.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m144 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'dbms', 'source': '../data/pdf_files/dbms.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'dbms.pdf', 'file_type': 'pdf'}, page_content='unit\\n \\nof\\n \\nwork.\\n \\nTransactions\\n \\nmust\\n \\nsatisfy\\n \\nthe\\n \\nACID\\n \\nproperties\\n:\\n \\n●  Atomicity:  All  steps  succeed  or  none.  \\n ●  Consistency:  The  database  must  remain  valid  before  and  after  the  transaction.  \\n ●  Isolation:  Concurrent  transactions  must  not  interfere  with  each  other.  \\n ●  Durability:  Changes  persist  even  if  the  system  crashes.  \\n \\nDatabase  systems  use  locking,  logging,  checkpoints,  and  isolation  levels  to  ensure  transaction  safety.  \\nUnderstanding\\n \\nnormalization,\\n \\njoins,\\n \\nand\\n \\ntransactions\\n \\nis\\n \\ncritical\\n \\nbecause\\n \\nthese\\n \\nconcepts\\n \\nform\\n \\nthe\\n \\nbackbone\\n \\nof\\n \\nrelational\\n \\ndata\\n \\nhandling.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m144 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'ml', 'source': '../data/pdf_files/ml.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'ml.pdf', 'file_type': 'pdf'}, page_content='Machine  Learning  (ML)  is  a  subfield  of  Artificial  Intelligence  that  enables  systems  to  learn  patterns  from  data  \\nand\\n \\nimprove\\n \\nover\\n \\ntime\\n \\nwithout\\n \\nexplicit\\n \\nprogramming.\\n \\nML\\n \\nfocuses\\n \\non\\n \\nbuilding\\n \\nmodels\\n \\nthat\\n \\ncan\\n \\nanalyze\\n \\ndata,\\n \\nmake\\n \\npredictions,\\n \\nclassify\\n \\noutcomes,\\n \\nand\\n \\nfind\\n \\nhidden\\n \\nstructures.\\n \\nIt\\n \\nhas\\n \\nrevolutionized\\n \\nmultiple\\n \\nindustries\\n \\nthrough\\n \\nautomation\\n \\nand\\n \\nintelligent\\n \\ndecision-making.\\n \\nML  is  broadly  divided  into  three  major  types:  \\n1.  Supervised  Learning  \\nModels  learn  using  labeled  data—each  input  has  a  correct  output.  Algorithms  try  to  generalize  these  \\nrelationships\\n \\nto\\n \\npredict\\n \\noutcomes\\n \\non\\n \\nnew\\n \\ndata.\\n \\n \\nCommon\\n \\nalgorithms\\n \\ninclude\\n \\nLinear\\n \\nRegression,\\n \\nLogistic\\n \\nRegression,\\n \\nDecision\\n \\nTrees,\\n \\nRandom\\n \\nForests,\\n \\nand\\n \\nSupport\\n \\nVector\\n \\nMachines.\\n \\n \\nApplications:\\n \\nSpam\\n \\ndetection,\\n \\ncredit\\n \\nscoring,\\n \\nmedical\\n \\ndiagnosis,\\n \\nstock\\n \\nprice\\n \\nprediction.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m144 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'ml', 'source': '../data/pdf_files/ml.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'ml.pdf', 'file_type': 'pdf'}, page_content='Decision\\n \\nTrees,\\n \\nRandom\\n \\nForests,\\n \\nand\\n \\nSupport\\n \\nVector\\n \\nMachines.\\n \\n \\nApplications:\\n \\nSpam\\n \\ndetection,\\n \\ncredit\\n \\nscoring,\\n \\nmedical\\n \\ndiagnosis,\\n \\nstock\\n \\nprice\\n \\nprediction.\\n \\n2.  Unsupervised  Learning  \\nUsed  when  data  has  no  labels.  The  model  identifies  hidden  patterns,  clusters,  or  structures.  \\n \\nPopular\\n \\nmethods\\n \\ninclude\\n \\nK-means\\n \\nclustering,\\n \\nPCA,\\n \\nand\\n \\nApriori\\n \\nfor\\n \\nassociation\\n \\nmining.\\n \\n \\nApplications:\\n \\nCustomer\\n \\nsegmentation,\\n \\nanomaly\\n \\ndetection,\\n \\ndimensionality\\n \\nreduction.\\n \\n3.  Reinforcement  Learning  \\nThe  model  interacts  with  an  environment  and  learns  from  rewards  and  penalties .  It  is  used  in  robotics,  \\ngaming\\n \\n(e.g.,\\n \\nAlphaGo),\\n \\nautonomous\\n \\nvehicles,\\n \\nand\\n \\nresource\\n \\noptimization.\\n \\nOther  important  ML  concepts  include:  \\n●  Feature  Engineering:  Selecting  important  variables  to  improve  model  accuracy.  \\n ●  Model  Evaluation:  Using  metrics  like  accuracy,  precision,  recall,  F1-score.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m144 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'ml', 'source': '../data/pdf_files/ml.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'ml.pdf', 'file_type': 'pdf'}, page_content='●  Feature  Engineering:  Selecting  important  variables  to  improve  model  accuracy.  \\n ●  Model  Evaluation:  Using  metrics  like  accuracy,  precision,  recall,  F1-score.  \\n ●  Overfitting  &  Underfitting:  Overfitting  happens  when  the  model  memorizes  training  data;  underfitting  \\noccurs\\n \\nwhen\\n \\nit\\n \\nfails\\n \\nto\\n \\nlearn\\n \\nenough\\n \\npatterns.\\n \\n ●  Training  vs  Testing:  Models  are  trained  on  historical  data  and  tested  on  unseen  data  to  validate  \\nperformance.\\n \\n \\nML  applications  are  everywhere—image  recognition,  natural  language  processing,  fraud  detection,  \\nrecommendation\\n \\nsystems,\\n \\nautonomous\\n \\ndriving,\\n \\nand\\n \\nhealthcare\\n \\nanalytics.\\n \\nAs\\n \\ndata\\n \\ngrows,\\n \\nmachine\\n \\nlearning\\n \\ncontinues\\n \\nto\\n \\nshape\\n \\nhow\\n \\nmodern\\n \\nsystems\\n \\nmake\\n \\nintelligent\\n \\ndecisions.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m144 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'os', 'source': '../data/pdf_files/os.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'os.pdf', 'file_type': 'pdf'}, page_content='An  Operating  System  (OS)  is  responsible  for  managing  hardware,  providing  an  environment  for  applications,  \\nand\\n \\nensuring\\n \\nefficient\\n \\nutilization\\n \\nof\\n \\nsystem\\n \\nresources.\\n \\nTwo\\n \\nof\\n \\nthe\\n \\nmost\\n \\nfundamental\\n \\nconcepts\\n \\nin\\n \\nOS\\n \\nare\\n \\nprocesses\\n \\nand\\n \\nthreads\\n.\\n \\nA\\n \\nprocess\\n \\nis\\n \\nan\\n \\nindependent\\n \\nprogram\\n \\nin\\n \\nexecution.\\n \\nIt\\n \\nhas\\n \\nits\\n \\nown\\n \\nmemory\\n \\nspace\\n \\n(code,\\n \\ndata,\\n \\nstack,\\n \\nheap)\\n \\nand\\n \\nis\\n \\nrepresented\\n \\nin\\n \\nthe\\n \\nsystem\\n \\nby\\n \\na\\n \\nProcess\\n \\nControl\\n \\nBlock\\n \\n(PCB).\\n \\nEvery\\n \\nprocess\\n \\noperates\\n \\nin\\n \\nisolation,\\n \\nwhich\\n \\nensures\\n \\nstability\\n \\nbut\\n \\nalso\\n \\nincreases\\n \\noverhead\\n \\nbecause\\n \\nswitching\\n \\nbetween\\n \\nprocesses\\n \\nis\\n \\nexpensive—each\\n \\ncontext\\n \\nswitch\\n \\nrequires\\n \\nsaving\\n \\nand\\n \\nloading\\n \\na\\n \\nseparate\\n \\nmemory\\n \\nspace.\\n \\nA  thread ,  on  the  other  hand,  is  a  smaller  execution  unit  inside  a  process.  Multiple  threads  within  the  same  \\nprocess\\n \\nshare\\n \\nmemory\\n \\nsuch\\n \\nas\\n \\nglobal\\n \\nvariables\\n \\nand\\n \\nheap,\\n \\nbut\\n \\neach'),\n",
       " Document(metadata={'producer': 'Skia/PDF m144 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'os', 'source': '../data/pdf_files/os.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'os.pdf', 'file_type': 'pdf'}, page_content='process\\n \\nshare\\n \\nmemory\\n \\nsuch\\n \\nas\\n \\nglobal\\n \\nvariables\\n \\nand\\n \\nheap,\\n \\nbut\\n \\neach\\n \\nthread\\n \\nhas\\n \\nits\\n \\nown\\n \\nstack\\n \\nand\\n \\nprogram\\n \\ncounter.\\n \\nThis\\n \\nshared\\n \\nmemory\\n \\nmakes\\n \\nthreads\\n \\nlightweight\\n \\nand\\n \\nsuitable\\n \\nfor\\n \\nparallelism\\n \\nwithin\\n \\nthe\\n \\nsame\\n \\napplication.\\n \\nFor\\n \\nexample,\\n \\na\\n \\nbrowser\\n \\nmay\\n \\nhave\\n \\nseparate\\n \\nthreads\\n \\nfor\\n \\nrendering,\\n \\ndownloading,\\n \\nand\\n \\nhandling\\n \\nuser\\n \\ninteractions.\\n \\nOS  uses  CPU  scheduling  to  determine  which  process  or  thread  gets  processor  time.  Scheduling  becomes  \\nnecessary\\n \\nbecause\\n \\nthe\\n \\nCPU\\n \\ncan\\n \\nexecute\\n \\nonly\\n \\none\\n \\ninstruction\\n \\nflow\\n \\nat\\n \\na\\n \\ntime\\n \\n(ignoring\\n \\nmulti-core\\n \\nscenarios).\\n \\nThe\\n \\ngoal\\n \\nis\\n \\nto\\n \\nmaximize\\n \\nCPU\\n \\nutilization,\\n \\nthroughput,\\n \\nand\\n \\nresponsiveness.\\n \\nCommon  scheduling  algorithms  include:  \\n1.  First-Come,  First-Served  (FCFS):  \\n \\nThe\\n \\nsimplest\\n \\nalgorithm\\n \\nwhere\\n \\nthe\\n \\nfirst\\n \\nprocess\\n \\nto\\n \\narrive\\n \\nis\\n \\nthe\\n \\nfirst\\n \\nto\\n \\nexecute.\\n \\nIt\\n \\nsuffers\\n \\nfrom\\n \\nthe\\n \\n\"convoy'),\n",
       " Document(metadata={'producer': 'Skia/PDF m144 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'os', 'source': '../data/pdf_files/os.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'os.pdf', 'file_type': 'pdf'}, page_content='1.  First-Come,  First-Served  (FCFS):  \\n \\nThe\\n \\nsimplest\\n \\nalgorithm\\n \\nwhere\\n \\nthe\\n \\nfirst\\n \\nprocess\\n \\nto\\n \\narrive\\n \\nis\\n \\nthe\\n \\nfirst\\n \\nto\\n \\nexecute.\\n \\nIt\\n \\nsuffers\\n \\nfrom\\n \\nthe\\n \\n\"convoy\\n \\neffect,\"\\n \\nwhere\\n \\na\\n \\nlong\\n \\njob\\n \\ndelays\\n \\nall\\n \\nothers.\\n \\n 2.  Shortest  Job  First  (SJF):  \\n \\nPrioritizes\\n \\nprocesses\\n \\nwith\\n \\nthe\\n \\nsmallest\\n \\nexecution\\n \\ntime.\\n \\nIt\\n \\nreduces\\n \\nwaiting\\n \\ntime\\n \\nbut\\n \\nrequires\\n \\npredicting\\n \\nprocess\\n \\nburst\\n \\ntime.\\n \\n 3.  Round  Robin  (RR):  \\n \\nEach\\n \\nprocess\\n \\ngets\\n \\na\\n \\nfixed\\n \\ntime\\n \\nslice\\n \\n(quantum).\\n \\nIt\\n \\nis\\n \\nideal\\n \\nfor\\n \\ntime-sharing\\n \\nsystems\\n \\nbecause\\n \\nno\\n \\nprocess\\n \\ncan\\n \\nmonopolize\\n \\nthe\\n \\nCPU.\\n \\n 4.  Priority  Scheduling:  \\n \\nEach\\n \\nprocess\\n \\nis\\n \\nassigned\\n \\na\\n \\npriority.\\n \\nThe\\n \\nCPU\\n \\nselects\\n \\nthe\\n \\nhighest-priority\\n \\nprocess.\\n \\nIt\\n \\nmay\\n \\nlead\\n \\nto\\n \\nstarvation\\n \\nif\\n \\nlow-priority\\n \\nprocesses\\n \\nnever\\n \\nexecute.\\n \\n 5.  Multilevel  Queue  Scheduling:  \\n \\nProcesses\\n \\nare\\n \\ndivided\\n \\ninto\\n \\nmultiple\\n \\nqueues\\n \\n(e.g.,\\n \\nsystem,\\n \\ninteractive,'),\n",
       " Document(metadata={'producer': 'Skia/PDF m144 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'os', 'source': '../data/pdf_files/os.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'os.pdf', 'file_type': 'pdf'}, page_content='to\\n \\nstarvation\\n \\nif\\n \\nlow-priority\\n \\nprocesses\\n \\nnever\\n \\nexecute.\\n \\n 5.  Multilevel  Queue  Scheduling:  \\n \\nProcesses\\n \\nare\\n \\ndivided\\n \\ninto\\n \\nmultiple\\n \\nqueues\\n \\n(e.g.,\\n \\nsystem,\\n \\ninteractive,\\n \\nbatch),\\n \\neach\\n \\nwith\\n \\ndifferent\\n \\nscheduling\\n \\nrules.\\n \\n \\nUnderstanding  processes,  threads,  and  scheduling  is  crucial  because  they  determine  how  efficiently  an  \\napplication\\n \\nand\\n \\nsystem\\n \\nperform.\\n \\nMulti-threading\\n \\nimproves\\n \\nconcurrency,\\n \\nwhile\\n \\neffective\\n \\nscheduling\\n \\nensures\\n \\nfairness\\n \\nand\\n \\nmaximizes\\n \\nCPU\\n \\nusage.'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 0, 'page_label': '1', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='Natural Language Processing: State of The Art, Current Trends and \\nChallenges \\nDiksha Khurana1, Aditya Koli1, Kiran Khatter1,2\\n and Sukhdev Singh1,2\\n \\n1Department of Computer Science and Engineering \\nManav Rachna International University, Faridabad-121004, India \\n2Accendere Knowledge Management Services Pvt. Ltd., India \\n \\nAbstract  \\nNatural language processing  (NLP) has recently gained much attention for representing and \\nanalysing human language computational ly. It has spread its applications in various field s \\nsuch as machine translation, email spam detection, information extraction, summarization, \\nmedical, and question answering etc. The paper distinguishes four phases by discussing \\ndifferent levels of NLP and components of Natural Language Generation (NLG) followed by \\npresenting the history and evolution of NLP , state of the art presenting the various \\napplications of NLP and current trends and challenges.  \\n \\n1. Introduction'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 0, 'page_label': '1', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='presenting the history and evolution of NLP , state of the art presenting the various \\napplications of NLP and current trends and challenges.  \\n \\n1. Introduction \\nNatural Language Processing (NLP) is a  tract of Artificial Intelligence and Linguistics, \\ndevoted to make computers understand the statements or words written in human languages. \\nNatural language processing came into existence to ease  the user’s work and to satisfy the \\nwish to communicate with the computer  in natural language. Since all the user s may not be \\nwell-versed in machine specific language , NLP caters those users  who do not have enough \\ntime to learn new languages or get perfection in it.  \\nA language can be defined as  a set of rules or set of symbol.  Symbol are combined and used \\nfor conveying information or broadcasting t he information.  Symbols are tyrannized by the \\nRules. Natural Language P rocessing basically can be classified in to two parts i.e. Natural'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 0, 'page_label': '1', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='for conveying information or broadcasting t he information.  Symbols are tyrannized by the \\nRules. Natural Language P rocessing basically can be classified in to two parts i.e. Natural \\nLanguage Understanding and Natural Language G eneration which evolves the task to \\nunderstand and generate the text (Figure 1).'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 1, 'page_label': '2', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='Figure 1. Broad Classification of NLP \\nLinguistics is the science of language which includes Phonology that refers to sound, \\nMorphology word formation, Syntax sentence structure, Semantics syntax and Pragmatics \\nwhich refers to understanding. \\nNoah Chomsky, one of the first linguists of twelfth century that started syntactic theories, \\nmarked a unique position in the field of theoretical linguistics because he revolutionise d the \\narea of syntax (Chomsky, 1965) [1]. Which can be broadly categorized into two levels Higher \\nLevel which include speech recognition and Lower L evel which corresponds to natural \\nlanguage. Few of t he researched tasks of NLP are Automatic S ummarization, Co-Reference \\nResolution, Discourse Analysis, Machine Translation, Morphological Segmentation, Named \\nEntity Recognition, Optical Character R ecognition, Part Of S peech Tagging etc. Some of \\nthese tasks have direct real world applications  such as Machine translation, N amed entity'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 1, 'page_label': '2', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='Entity Recognition, Optical Character R ecognition, Part Of S peech Tagging etc. Some of \\nthese tasks have direct real world applications  such as Machine translation, N amed entity \\nrecognition, Optical character recognition etc. Automatic summarization produces an \\nunderstandable summary of a set of text  and provides summaries or detailed information of \\ntext of a known typ e. Co-reference resolution it refers to a sentence or larger set of text that \\ndetermines which word refer to the same object. Discourse analysis  refers to the task of \\nidentifying the discourse struc ture of connected text. Machine translation which refers to \\nautomatic translation of text from one human language to another . Morphological \\nsegmentation which refers to separate word into individual morphemes and identify the class \\nof the morphemes. Named entity recognition (NER) it describes a stream of text, determine'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 1, 'page_label': '2', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='segmentation which refers to separate word into individual morphemes and identify the class \\nof the morphemes. Named entity recognition (NER) it describes a stream of text, determine \\nwhich items in the text relates to proper names. Optical character recognition (OCR) it gives \\nan image representing print ed text, which  help in determining the corresponding or related \\ntext. Part of speech tagging  it describes a sentence, determines the part of speech for each \\nword. Though NLP tasks are obviously very closely interweaved  but they are used \\nfrequently, for convenience. Some of the task such as automatic summarisation, co-reference \\nanalysis etc. act as subtask that are used in solving larger tasks.'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 2, 'page_label': '3', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='The goal of Natural Language Processing is to accommodate one or more specialities of an \\nalgorithm or system.  The metric of NLP assess on an algorithmic system allows for the \\nintegration of  language understanding  and language generation.  It is even used in \\nmultilingual event detection Rospocher et al. [2] purposed a novel modular system for cross -\\nlingual event extraction for English,  Dutch and Italian texts by using different pipelines for \\ndifferent languages. The system incorporates a modular set of foremost multilingual Natural \\nLanguage Processing (NLP) tools. The pipeline integrates modules for basic NLP processing \\nas well as more advanced tasks such as cro ss-lingual named entity linking,  semantic role \\nlabelling and time normalization. Thus, the cross-lingual framework allows for the \\ninterpretation of events, participants, locations and time, as well as the relations between'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 2, 'page_label': '3', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='labelling and time normalization. Thus, the cross-lingual framework allows for the \\ninterpretation of events, participants, locations and time, as well as the relations between \\nthem. Output of these individual pipelines is intended to be used as input for a system that \\nobtains event centric knowledge grap hs. All modules behave like UNIX pipes: they all take \\nstandard input, to do some annotation, and produce standard output which in turn is the input \\nfor the next module pipelines are built as a data centric architecture so that modu les can be \\nadapted and replaced . Furthermore, modular architecture allows for different configurations \\nand for dynamic distribution. \\nMost of the work in Natural Language Processing is conducted by computer scientists while \\nvarious other professionals have also shown interest such as linguistics, psychologist and \\nphilosophers etc. One of the most ironical aspect of NLP is that it adds up  to the knowledge'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 2, 'page_label': '3', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='various other professionals have also shown interest such as linguistics, psychologist and \\nphilosophers etc. One of the most ironical aspect of NLP is that it adds up  to the knowledge \\nof human language.  The field of Natural Language Processing is related with different \\ntheories and techniques  that deal with the problem of natural language of communicating \\nwith the computers . Ambiguity is one of the ma jor problem of nat ural language which is \\nusually faced in syntactic level which has subtask as lexical and morphology which are \\nconcerned with the study of words and word formation. Each of these levels can produce \\nambiguities that can be solved by the knowledge of the comp lete sentence.  The ambiguity \\ncan be solved by various methods such as  Minimising Ambiguity, Preserving Ambiguity, \\nInteractive Disambiguity and Weighting Ambiguity [3].  Some of the methods proposed by \\nresearchers to remove ambiguity is  preserving ambiguity,  e.g. (Shemtov 1997 ; Emele &'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 2, 'page_label': '3', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='Interactive Disambiguity and Weighting Ambiguity [3].  Some of the methods proposed by \\nresearchers to remove ambiguity is  preserving ambiguity,  e.g. (Shemtov 1997 ; Emele & \\nDorna 1998; Knight & Langkilde 2000) [3][4][5] Their objectives are closely in line with the \\nlast of these: they cover a wide range of ambiguities and there is a statistical element implicit \\nin their approach.  \\n2. Levels of NLP \\nThe ‘levels of language’ are one of the most explanatory method for representing the Natural \\nLanguage processing  which helps to generate the NLP text by realising Content Planning, \\nSentence Planning and Surface Realization phases (Figure 2).'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 3, 'page_label': '4', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='Figure 2. Phases of NLP architecture \\nLinguistic is the science which involves meaning of language, language context and various \\nforms of the language. The various important terminologies of Natural Language Processing \\nare: - \\n1. Phonology \\nPhonology is the part of Linguistics which refers to the systematic arrangement of sound. The \\nterm phonology  comes from  Ancient Greek  and the term phono - which me ans voice or \\nsound, and the suffix –logy refers to word or speech. In 1993 Nikolai Trubetzkoy stated that \\nPhonology is “the study of sound pertaining to the system of la nguage\". Whereas Lass in \\n1998 wrote that phonology refers broadly with the sounds of language, concerned with the to \\nlathe sub discipline of linguistics , whereas it could be explained as , \"phonology proper is \\nconcerned with the function, behaviour and orga nization of sounds as  linguistic items. \\nPhonology include semantic use of sound to encode meaning of any Human language.  \\n(Clark et al.,2007) [6].'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 3, 'page_label': '4', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='concerned with the function, behaviour and orga nization of sounds as  linguistic items. \\nPhonology include semantic use of sound to encode meaning of any Human language.  \\n(Clark et al.,2007) [6]. \\n2. Morphology \\nThe different parts of the word represent the smallest units of meaning known as Morphemes. \\nMorphology which comprise of Nature of words, are initiated by morphemes. An example of \\nMorpheme could be, the word pre cancellation can be morphologically scrutinized into three \\nseparate morphemes: the prefix pre, the root cancella, and the suf fix -tion. The interpretation \\nof morpheme stays same across all the words, just to understand the meaning humans can \\nbreak any unknown word into morphemes.  For example, adding the suffix –ed to a verb, \\nconveys that the action of the verb took place in the past. The words that cannot be divided \\nand have meaning by themselves are called Lexical morpheme (e.g.: table, chair) The words'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 3, 'page_label': '4', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='conveys that the action of the verb took place in the past. The words that cannot be divided \\nand have meaning by themselves are called Lexical morpheme (e.g.: table, chair) The words \\n(e.g. -ed, -ing, -est, -ly, -ful) that are combined with the lexical morpheme  are known as \\nGrammatical morphemes  (eg. Worked, C onsulting, Smallest , Likely, Use ). Those \\ngrammatical morphemes that occurs in combi nation called bound morphemes ( eg. -ed, -ing) \\nGrammatical morphemes can be divided into bound morphemes and derivational morphemes.'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 4, 'page_label': '5', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='3. Lexical \\nIn Lexical,  humans, as well a s NLP systems, interpret the meaning of individual words.  \\nSundry types of processing bestow to word-level understanding – the first of these being a \\npart-of-speech tag to each word. In this processing, words that can act as more than one part-\\nof-speech are assigned the most probable part -of speech tag based on th e context in which \\nthey occur. At the lexical level,  Semantic representations can be replaced by the words that \\nhave one meaning . In NLP system , the nature of the  representation varies according to the \\nsemantic theory deployed. \\n4. Syntactic \\nThis level emphasis to scrutinize the words in a sentence so as to uncover the grammatical \\nstructure of the sentence. Both grammar and parser  are required in this level . The output  of \\nthis level of processing is representation of the sentence that divulge the structural \\ndependency relationships between the words. There are various grammars that can be'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 4, 'page_label': '5', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='this level of processing is representation of the sentence that divulge the structural \\ndependency relationships between the words. There are various grammars that can be \\nimpeded, and which in twirl, whack the option of a parser. Not all NLP applications require a \\nfull parse of sentences, therefore the abide challenges in parsing of prepositional phrase \\nattachment and conjunction audit no longer impede that plea for which phrasal and clausal \\ndependencies are adequate [7]. Syntax conveys meaning in most languages because order and \\ndependency contribute to connotation. For example, the two sentences: ‘The cat chased the \\nmouse.’ and ‘The mouse chased the cat.’ differ only in terms of syntax, yet convey quite \\ndifferent meanings. \\n5. Semantic \\nIn semantic most people think that meaning is determined, however,  this is not  it is all the \\nlevels that bestow to meaning. Semantic processing determines the possible meanings of a'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 4, 'page_label': '5', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='5. Semantic \\nIn semantic most people think that meaning is determined, however,  this is not  it is all the \\nlevels that bestow to meaning. Semantic processing determines the possible meanings of a \\nsentence by pivoting on the interactions among word -level meanings in the sentence. Th is \\nlevel of processing can incorporate  the semantic disambiguation of wo rds with multiple \\nsenses; in a cognate way to how syntactic disambiguation of words that can errand as \\nmultiple parts -of-speech is adroit at the syntactic level.  For example, amongst o ther \\nmeanings, ‘file’ as a noun can mean either a binder for gathering papers, or a tool to form \\none’s fingernails, or a  line of individuals in a queue ( Elizabeth D. Liddy ,2001) [7]. The \\nsemantic level scrutinizes words for their dictionary elucidation, but also for the elucidation \\nthey derive from the milieu of the sentence. Semantics milieu that most words have more'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 4, 'page_label': '5', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='semantic level scrutinizes words for their dictionary elucidation, but also for the elucidation \\nthey derive from the milieu of the sentence. Semantics milieu that most words have more \\nthan one elucidation but that we can spot the appropriate one by looking at the rest of the \\nsentence. [8] \\n6. Discourse \\nWhile syntax and semantic s travail with sentence -length units, the discourse level of NLP \\ntravail with units of text longer than a sentence i.e, it does not interpret multi sentence texts as \\njust sequence sentences, apiece of which can be elucidated singly. Rather, discourse focuses \\non the properties of the text as a whole that convey meaning by making connections between \\ncomponent sentences (Elizabeth D. Liddy,2001) [7]. The two of the most common levels are  \\nAnaphora Resolution  - Anaphora resolution  is the replacing of words such as pronouns, \\nwhich are semantically stranded, with the pertinent entity to which they refer. Discourse/Text'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 4, 'page_label': '5', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='Anaphora Resolution  - Anaphora resolution  is the replacing of words such as pronouns, \\nwhich are semantically stranded, with the pertinent entity to which they refer. Discourse/Text \\nStructure Recognition - Discourse/text structure recognition sway the functions of sentences \\nin the text, which, in turn, adds to the meaningful representation of the text. \\n7. Pragmatic:'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 5, 'page_label': '6', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='Pragmatic is concerned with the firm use of language in situations and utilizes nub over and \\nabove the nub of the text for understanding the goal and to explain how extra meaning is read \\ninto texts without literally being encoded in them. This requisite much world knowledge, \\nincluding the understanding of intenti ons, plans, and goals . For example, the following two \\nsentences need aspiration of the anaphoric term ‘they’, but this aspiration requires pragmatic \\nor world knowledge (Elizabeth D. Liddy,2001) [7]. \\n3. Natural Language Generation \\nNatural Language Generation (NLG) is the process of producing phrases, sentences and \\nparagraphs that are meaningful from an internal representation. It is a part of Natural \\nLanguage Processing  and happens in four phases: identifying the goals, planning on how \\ngoals maybe achieved by evaluating the situation and available communicative sources and \\nrealizing the plans as a text [Figure 3]. It is opposite to Understanding.'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 5, 'page_label': '6', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='goals maybe achieved by evaluating the situation and available communicative sources and \\nrealizing the plans as a text [Figure 3]. It is opposite to Understanding. \\n \\n                                      Figure 3. Components of NLG \\nComponents of NLG are as follows: \\nSpeaker and Generator  – To generate a text we need to have a speaker or an application \\nand a generator or a program  that renders the applicatio n’s intentions into fluent phrase \\nrelevant to the situation.  \\nComponents and Levels of Representation  -The process of language generation involves \\nthe following interweaved tasks. Content selection:  Information should be selected and \\nincluded in the set. D epending on how this information is parsed into representational units, \\nparts of the units may have to be removed while some  others may be added by default. \\nTextual Organization: The information must be textually organized according the grammar, it'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 5, 'page_label': '6', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='parts of the units may have to be removed while some  others may be added by default. \\nTextual Organization: The information must be textually organized according the grammar, it \\nmust be  ordered both sequentially and in terms of linguist ic relations like modifications. \\nLinguistic Resources: To support the information’s realization, linguistic resources must be'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 6, 'page_label': '7', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='chosen. In the end these resources will come down to choices of particular words, idioms, \\nsyntactic constructs etc.  Realization: The selected and organized resources must be realized \\nas an actual text or voice output.  \\nApplication or Speaker –  This is only for maintaining the model of the situation. Here the \\nspeaker just initiat es the process doesn’t take part in the language generation. It stores the \\nhistory, structures the content that is potentially relevant and deploys a representation of what \\nit actually knows. All these form the situation, while selecting subset of proposit ions that \\nspeaker has. The only requirement is the speaker has to make sense of the situation. [9]  \\n4. History of NLP \\nIn late 1940s the term wasn’t even in existence, but the work regarding machine translation \\n(MT) had started. Research in this period was not  completely localised. Russian and English \\nwere the dominant languages for MT , but others, like Chinese  were used for MT  (Booth'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 6, 'page_label': '7', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='(MT) had started. Research in this period was not  completely localised. Russian and English \\nwere the dominant languages for MT , but others, like Chinese  were used for MT  (Booth \\n,1967) [10]. MT/NLP research was almost died in 1966 according to ALPAC report, which \\nconcluded that MT is going nowhere. But later on some MT production systems were \\nproviding output to their customers (Hutchins, 1986)  [11]. By this time, work on the use of \\ncomputers for literary and linguistic studies had also started.  \\nAs early as 1960 signature work influenced by AI began, wi th the BASEBALL Q-A systems \\n(Green et al., 1961) [12]. LUNAR (Woods ,1978) [13] and Winograd SHRDLU were natural \\nsuccessors of these systems but they were seen as stepped up sophistication, in terms of their \\nlinguistic and their task processing capabilitie s. There was a widespread belief that progress \\ncould only be made on the two sides, one is ARPA Speech Understanding Research (SUR)'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 6, 'page_label': '7', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='linguistic and their task processing capabilitie s. There was a widespread belief that progress \\ncould only be made on the two sides, one is ARPA Speech Understanding Research (SUR) \\nproject (Lea, 1980) and other in some major system developments projects building database \\nfront ends . The front-end projects (Hendrix et al., 1978)  [14] were intended to go beyond \\nLUNAR in interfacing the large databases. \\nIn early 1980s computational grammar theory became a very active area of research linked \\nwith logics for meaning and knowledge’s ability to deal with the user’s beliefs and intentions \\nand with functions like emphasis and themes. \\nBy the end of the decade the powerful general purpose sentence processors like SRI’s Core \\nLanguage Engine (Alshawi,1992)  [15] and Discourse Representation Theory (Kamp and \\nReyle,1993) [16] offered a means of tackling more extended discourse within the \\ngrammatico-logical framework. This period was one of the growing community. Practical'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 6, 'page_label': '7', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='Reyle,1993) [16] offered a means of tackling more extended discourse within the \\ngrammatico-logical framework. This period was one of the growing community. Practical \\nresources, grammars, and tools and parsers became available (e.g the Alvey Natural \\nLanguage Tools (Briscoe et al., 1987)  [17]. The (D)ARPA speech recognition and message \\nunderstanding (information extraction ) conferences were not only for the tasks they \\naddressed but for the emphasis on heavy evaluation, starting a trend that became a major \\nfeature in 1990s (Young and Chase, 1998; Sundheim and Chinchor ,1993) [18][19]. Work on \\nuser modelling (Kobsa and Wahlster , 1989)  [20]  was one strand in research paper and on \\ndiscourse structure serving this (Cohen et al., 1990)   [21]. At the same time , as McKeown  \\n(1985) [22] showed, rhetorical schemas could be used for producing both linguistically \\ncoherent and communicatively effective text. Some researches in NLP marked important'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 6, 'page_label': '7', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='(1985) [22] showed, rhetorical schemas could be used for producing both linguistically \\ncoherent and communicatively effective text. Some researches in NLP marked important \\ntopics for future like word sense disambiguation (Small et al., 1988)  [23] and probabilistic \\nnetworks, statistically coloured NLP, the work on the lexicon, also pointed in this direction.'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 7, 'page_label': '8', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='Statistical language processing was a major thing in 9 0s (Manning and Schuetze,1999)  [24], \\nbecause this not only involves data analysts. Information extraction and automatic \\nsummarising (Mani and Maybury ,1999) [25] was also a point of focus. \\nRecent researches are mainly focused on unsupervised and semi -supervised learning \\nalgorithms. \\n5. Related Work \\nMany researchers worked on NLP , building tools and systems which makes NLP what it is \\ntoday. Tools like Sentiment Analyser , Parts of Speech (POS)Taggers, Chunking, Named \\nEntity Recognitions (NER), Emotion detection , Semantic Role Labelling made NLP a good \\ntopic for research.  \\nSentiment analyser (Jeonghee etal.,2003)  [26] works by extracting sentiments about given \\ntopic. Sentiment analysis consists of a topic specific feature term extraction, sentiment \\nextraction, and association by relationship analysis. Sentiment Analysis utilizes two linguistic'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 7, 'page_label': '8', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='topic. Sentiment analysis consists of a topic specific feature term extraction, sentiment \\nextraction, and association by relationship analysis. Sentiment Analysis utilizes two linguistic \\nresources for the analysis: the sentiment lexicon and the sentiment pattern database. It \\nanalyses the documents for positive and negative words and try to give ratings on scale -5 to \\n+5. \\nParts of speech taggers for the languages like European languages, research is being done on \\nmaking parts of speech taggers for other languages like Arabic, Sanskrit (Namrata Tapswi , \\nSuresh Jain ., 2012) [27], Hindi (Pradipta Ranjan Ray et al., 2003 ) [28] etc. It can efficiently \\ntag and classify words as nouns, adjectives, verbs etc. The most procedures for part of speech \\ncan work efficiently on European languages, but it won’t on Asian languages or middle \\neastern languages. Sanskrit part of speech tagger is specifically uses treebank technique.'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 7, 'page_label': '8', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='can work efficiently on European languages, but it won’t on Asian languages or middle \\neastern languages. Sanskrit part of speech tagger is specifically uses treebank technique. \\nArabic uses Support Vector Machine (SVM)  (Mona Diab etal., 2004) [29] approach to \\nautomatically tokenize, parts of speech tag and annotate base phrases in Arabic text. \\n \\nChunking – it is also known as Shadow Parsing, it works by labelling segments of sentences \\nwith syntactic correlated keywords like Noun Phrase and Verb Phrase (NP or VP). Every \\nword has a unique tag often marked as Begin Chunk (B -NP) tag or Inside Chunk (I -NP) tag. \\nChunking is often evaluated using the CoNLL 2000 shared task.   CoNLL 2000 provides test \\ndata for Chunking.  Since then, a certain numb er of systems arised (Sha and Pereira, 2003; \\nMcDonald et al., 2005; Sun et al., 2008)  [30] [31] [32], all reporting around 94.3% F1 score. \\nThese systems use features composed of words, POS tags, and tags.'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 7, 'page_label': '8', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='McDonald et al., 2005; Sun et al., 2008)  [30] [31] [32], all reporting around 94.3% F1 score. \\nThese systems use features composed of words, POS tags, and tags. \\n \\nUsage of Named Entity Recognition in places such as Internet is a problem as people don’t \\nuse traditional or standard  English. This degrades the performance of standard natural \\nlanguage processing tools substantially. By annotating the phrases or tweets and building \\ntools trained on unlabelled, in domain and out domain data (Alan Ritter., 2011)  [33]. It \\nimproves the performance as compared to standard natural language processing tools. \\n \\nEmotion Detection (Shashank Sharma , 2016) [34] is similar to sentiment analysis, but it \\nworks on social media platforms on mixing of two languages (English + Any other Indian \\nLanguage). It categorizes statements into six groups based on emotions. During this process, \\nthey were able to identify the language of ambiguous words which were common in Hindi'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 7, 'page_label': '8', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='Language). It categorizes statements into six groups based on emotions. During this process, \\nthey were able to identify the language of ambiguous words which were common in Hindi \\nand English and tag lexical category or parts of speech in mixed script by identifying the base \\nlanguage of the speaker.'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 8, 'page_label': '9', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='Sematic Role Labelling – SRL works by giving a semantic role to a sentence. For example in \\nthe PropBank (Palmer et al., 2005)  [35] formalism, one assigns roles to words that are \\narguments of a verb in the sentence. The precise arguments depend on verb frame and if there \\nexists multiple verbs  in a sentence, it might have multiple tags. State-of-the-art SRL systems \\ncomprise of several stages: creating a parse tree, identifying which parse tree nodes represent \\nthe arg uments of a given verb, and finally classifying these nodes to comp ute the \\ncorresponding SRL tags. \\n \\nEvent discovery in social media feeds (Edward Benson et al., 2011) [36], using a graphical \\nmodel to analyse any social media feeds to determine whether it contains name of a person or \\nname of a venue, place, time etc. The model operates on noisy feeds of data to extract records \\nof events by aggregating multiple information ac ross multiple messages, despite the noise of'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 8, 'page_label': '9', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='name of a venue, place, time etc. The model operates on noisy feeds of data to extract records \\nof events by aggregating multiple information ac ross multiple messages, despite the noise of \\nirrelevant noisy messages and very irregular message language, this model was able to extract \\nrecords with high accuracy. However, there is some scope for improvement using broader \\narray of features on factors. \\n \\n6. Applications of NLP \\nNatural Language Processing can be applied into various areas like Machine Translation, \\nEmail Spam detection, Information Extraction, Summarization, Question Answering etc. \\n6.1 Machine Translation  \\nAs most of the world is online, the task of making data accessible and available to all is a \\nchallenge. Major challenge in making data accessible is the language barrier. There are \\nmultitude of languages with different sentence structure and grammar. Machine Translation is \\ngenerally translating phrases from one language to another with the help of a statistical'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 8, 'page_label': '9', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='multitude of languages with different sentence structure and grammar. Machine Translation is \\ngenerally translating phrases from one language to another with the help of a statistical \\nengine like Google Translate. The challenge with machine translation technologies is not \\ndirectly translating words but keeping the meaning of sente nces intact along with grammar \\nand tenses. The statistical machine learning gathers as many data as they can find that seems \\nto be parallel between two languages and they crunch their data to find the likelihood that \\nsomething in Language A corresponds to something in Language B. As for Google, in \\nSeptember 2016, announced a new machine translation system based on Artificial neural \\nnetworks and Deep learning . In recent years, various methods have been proposed to \\nautomatically evaluate machine translation quality by comparing hypothesis translations with \\nreference translations. Examples of such methods are word error rate, position -independent'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 8, 'page_label': '9', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='automatically evaluate machine translation quality by comparing hypothesis translations with \\nreference translations. Examples of such methods are word error rate, position -independent \\nword error rate (Tillmann et al., 1997)  [37], generation string accuracy (Bangalore et al., \\n2000) [38], multi-reference word error rate (Nießen et al., 2000)  [39], BLEU score (Papineni \\net al., 2002) [40], NIST score (Doddington, 2002)  [41]  All these criteria try to approximate \\nhuman assessment and often achieve an astonishing degree of correlation to human subjective \\nevaluation of fluency and adequacy (Papineni et al., 2001; Doddington, 2002) [42][43].  \\n6.2 Text Categorization  \\nCategorization systems inputs a large flow of data like official documents, military casualty \\nreports, market data, newswires etc. and assign them to predefined categories or indices. For \\nexample, The Carnegie Group’s Construe system (Hayes PJ ,Westein ; 1991) [44] , inputs'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 8, 'page_label': '9', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='reports, market data, newswires etc. and assign them to predefined categories or indices. For \\nexample, The Carnegie Group’s Construe system (Hayes PJ ,Westein ; 1991) [44] , inputs \\nReuters articles and saves much time by doing the work that is to be done by staff or human'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 9, 'page_label': '10', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='indexers. Some companies have been us ing categorization systems to categorize trouble \\ntickets or complaint requests and routing to the appropriate desks. Another application of text \\ncategorization is email spam filters. Spam filters is becoming important as the first line of \\ndefence against the unwanted emails. A false negative and false positive issues of spam filters \\nare at the heart of NLP technology, its brought down to the challenge of extracting meaning \\nfrom strings of text. A filtering solution that is applied to an email system uses a set of \\nprotocols to determine which of the incoming messages are spam and which are not. There \\nare several types of spam filters available. Content filters : Review the content within the \\nmessage to determine whether it is a spam or not . Header filters: Review the email header \\nlooking for fake information. General Blacklist filters : Stopes all emails from blacklisted'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 9, 'page_label': '10', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='message to determine whether it is a spam or not . Header filters: Review the email header \\nlooking for fake information. General Blacklist filters : Stopes all emails from blacklisted \\nrecipients. Rules Based Filters : It uses user -defined criteria. Such as stopping mails from \\nspecific person or stopping mail including a specific word. Permission Filters : Require \\nanyone sending a message to be pre -approved by the recipient. Challenge Response Filters : \\nRequires anyone sending a message to enter a code in order to gain permission to send email. \\n6.3 Spam Filtering  \\nIt works using text categorization  and in recent times, various machine learning techniques \\nhave been applied to text categorization or Anti -Spam Filtering  like Ru le Learning (Cohen \\n1996)[45], Naïve Bayes (Sahami et al., 1998 ;Androutsopoulos et al.,2000b ;Rennie \\n.,2000)[46][47][48],Memory based Learning (Androutsopoulos et al.,2000b) [47], Support'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 9, 'page_label': '10', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='1996)[45], Naïve Bayes (Sahami et al., 1998 ;Androutsopoulos et al.,2000b ;Rennie \\n.,2000)[46][47][48],Memory based Learning (Androutsopoulos et al.,2000b) [47], Support \\nvector machines (Druker et al., 1999)[49], Decision Trees (Carreras and Marquez , 2001)[50] \\nMaximum Entropy Model (Berger et al. 1996) [51]. Sometimes combining different learners \\n(Sakkis et al., 2001)  [52]. Using these approaches is better as classifier is learned from \\ntraining data rather than making by hand. The naïve bay es is preferred because of its \\nperformance despite its simplicity (Lewis, 1998)  [53] In Text Categorization two types of \\nmodels have been used (McCallum and Nigam, 1998) [54]. Both modules assume that a fixed \\nvocabulary is present. But in first model a document is generated by first choosing a subset of \\nvocabulary and then using the selected words any number of times, at least once irrespective \\nof order. This is called Multi -variate Bernoulli model. It takes the information of which'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 9, 'page_label': '10', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='vocabulary and then using the selected words any number of times, at least once irrespective \\nof order. This is called Multi -variate Bernoulli model. It takes the information of which \\nwords are used in a d ocument irrespective of number of words and order. In second model, a \\ndocument is generated by choosing a set of word occurrences and arranging them in any \\norder. this model is called multi -nomial model, in addition to the Multi -variate Bernoulli \\nmodel, it also captures information on how many times a word is used in a document. Most \\ntext categorization approaches to anti spam Email filtering have used multi variate Bernoulli \\nmodel (Androutsopoulos et al.,2000b) [47] \\n6.4 Information Extraction \\nInformation extraction is concerned with identifying phrases of interest of text ual data. For \\nmany applications, extracting entities such as names, places, events, dates, times and prices is'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 9, 'page_label': '10', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='Information extraction is concerned with identifying phrases of interest of text ual data. For \\nmany applications, extracting entities such as names, places, events, dates, times and prices is \\na powerful way of summarize the information relevant to a user’s needs. In the cas e of a \\ndomain specific search engine, the automatic identification of important information can \\nincrease accuracy and efficiency of a directed search.  There is use of hidden Markov models \\n(HMMs) to extract the relevant fields of research papers. These extr acted text segments are'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 10, 'page_label': '11', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='used to allow searched over specific fields and to provide effective presentation of search \\nresults and to match references to papers.  For example, noticing the pop up ads on any \\nwebsites showing the recent items you might have look ed on an online store with discounts. \\nIn Information Retrieval two types of models have been used (McCallum and Nigam, 1998)  \\n[55]. Both modules assume that a fixed vocabulary is present. But in first model a document \\nis generated by first choosing a subset  of vocabulary and then using the selected words any \\nnumber of times, at least once without any order. This is called Multi -variate Bernoulli \\nmodel. It takes the information of which words are used in a document irrespective of number \\nof words and order. I n second model, a document is generated by choosing a set of word \\noccurrences and arranging them in any order. this mod el is called multi -nomial model , in'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 10, 'page_label': '11', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='of words and order. I n second model, a document is generated by choosing a set of word \\noccurrences and arranging them in any order. this mod el is called multi -nomial model , in \\naddition to the Multi -variate Bernoulli model , it also captures information on how many \\ntimes a word is used in a document \\nDiscovery of knowledge  is becoming important areas of research over the recent years. \\nKnowledge discovery  research use a variety of techniques in order to extract useful \\ninformation from source documents like  \\nParts of Speech (POS) tagging, Chunking or Shadow Parsing , Stop-words (Keywords that \\nare used and must be remo ved before processing documents) , Stemming (Mapping words to \\nsome base for, it has two methods , dictionary based stemming and Porter style stemming \\n(Porter, 1980) [55]. Former one has higher accuracy but higher cost of implementation while \\nlatter has lower implementation cost and is usually insufficient for IR). Compound or'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 10, 'page_label': '11', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='(Porter, 1980) [55]. Former one has higher accuracy but higher cost of implementation while \\nlatter has lower implementation cost and is usually insufficient for IR). Compound or \\nStatistical Phrases  (Compounds and statistical phrases index multi  token unit s instead of \\nsingle tokens.) Word Sense Disambiguation  (Word sense disambiguati on is the task of \\nunderstanding the correct sense of a word in context. When used for information retrieval, \\nterms are replaced by their senses in the document vector.) \\n \\nIts extracted information c an be applied on a variety  of purpose , for example to prepare a \\nsummary, to build databases, identify keywords, classifying text items according to some pre-\\ndefined categories etc. For example   CONSTRUE, it was developed for Reuters , that is used \\nin classifying news stories  (Hayes, 1992) [57]. It has been suggested that many IE systems \\ncan successfully extract terms from documents, acquiring relations between the terms is still a'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 10, 'page_label': '11', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='in classifying news stories  (Hayes, 1992) [57]. It has been suggested that many IE systems \\ncan successfully extract terms from documents, acquiring relations between the terms is still a \\ndifficulty. PROMETHEE  is a system that extracts lexico -syntactic patterns relative to a \\nspecific conceptual relation (Morin,1999) [58]. IE systems should work at many levels, from \\nword recognition to discourse analysis at the level of the complete document. An application \\nof the Blank Slate Language Processor (BSLP) (Bondale et al., 1999) [59] approach for the \\nanalysis of a real life natural language corpus that consists of responses to open -ended \\nquestionnaires in the field of advertising. \\nThere’s a system called MITA (Metlife’ s Intelligent Text Analyzer)  (Glasgow et al. (1998)  \\n[60]) that extracts information from  life insurance applications. Ahonen et al. (1998)  [61] \\nsuggested a mainstream framework for text mining that uses pragmatic and di scourse level \\nanalyses of text.'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 10, 'page_label': '11', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='suggested a mainstream framework for text mining that uses pragmatic and di scourse level \\nanalyses of text. \\n6.5 Summarization \\nOverload of information is the real thing in this digital age, and already our reach and access \\nto knowledge and information exceeds our capacity to understand it. This trend is not slowing \\ndown, so an ability to summarize the data while keeping the meanin g intact is highly'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 11, 'page_label': '12', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='required. This is important not just allowing us the ability to recognize the understand the \\nimportant information for a large set of data, it is used to understand the deeper emotional \\nmeanings; For example, a company determine the gene ral sentiment on social media and use \\nit on their latest product offering. This application is useful as a valuable marketing asset. \\nThe types of text summarization depends on the basis of the number of documents  and  the \\ntwo important categories are single document summarization and multi document \\nsummarization (Zajic et al. 2008  [62]; Fattah and Ren 2009  [63]). Summaries can also be of \\ntwo types: generic or query-focused (Gong and Liu 2001 [64]; Dunlavy et al. 2007 [65]; Wan \\n2008 [66]; Ouyang et al. 2011  [67]). Summarization task can be either supervised or \\nunsupervised (Mani and Maybury 1999  [68]; Fattah and Ren 2009  [63]; Riedhammer et al. \\n2010 [69]). Training data is required in a supervised system for selecting relevant material'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 11, 'page_label': '12', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='unsupervised (Mani and Maybury 1999  [68]; Fattah and Ren 2009  [63]; Riedhammer et al. \\n2010 [69]). Training data is required in a supervised system for selecting relevant material \\nfrom the documents. Larg e amount of annotated data is needed for learning techniques. Few \\ntechniques are as follows– \\n- Bayesian Sentence based Topic Model (BSTM)  uses both term-sentences and term \\ndocument associations for summarizing multip le documents. ( Wang et al. 2009  \\n[70])   \\n- Factorization with Given Bases  (FGB) is a language model where  sentence bases \\nare the given bases and it utilizes document -term and sentence term matrices. \\nThis approach groups and summarizes the documents simultaneously. (Wang et \\nal. 2011) [71]) \\n- Topic Aspect -Oriented Summarization  (TAOS) is based on topic factors. These \\ntopic factors are various features that describe topics such as capital words are \\nused to represent entity. Various topics can have various  aspects and various'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 11, 'page_label': '12', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='topic factors are various features that describe topics such as capital words are \\nused to represent entity. Various topics can have various  aspects and various \\npreferences of features are used to represent various aspects. (Fang et al. 2015 [72]) \\n \\n6.6 Dialogue System \\nPerhaps the most desirable application of the future, in the systems envisioned by large \\nproviders of end user applications, Dialogue systems, which focuses on a narrowly defined \\napplications (like refrigerator or home theater systems) currently uses the phonetic and lexical \\nlevels of language. It is believed that these dialogue systems when utilizing all levels of \\nlanguage processing offer potential for fully automated dialog systems. (Elizabeth D. Liddy, \\n2001) [7]. Whether on text or via voice. This could  lead to produce systems that can enable \\nrobots to interact with humans in natural languages. Examples like Google’s assistant,'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 11, 'page_label': '12', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='2001) [7]. Whether on text or via voice. This could  lead to produce systems that can enable \\nrobots to interact with humans in natural languages. Examples like Google’s assistant, \\nWindows Cortana, Apple’s Siri and Amazon’s Alexa are the software and devices that follow \\nDialogue systems. \\n6.7 Medicine \\nNLP is appl ied in medicine field as well. The Linguistic String Project -Medical Language \\nProcessor is one the large scale projects of NLP in the field of medicine [74][75][76][77][78]. \\nThe LSP-MLP helps enabling physicians to extract and summarize information of any signs \\nor symptoms, drug dosage and response data with aim of identifying possible side effects of \\nany medicine while highlig hting or flagging data items [74 ]. The National Library of \\nMedicine is developing The Specialist System [79][80][81][82][83]. It is expected to function \\nas Information Extraction tool for Biomedical Knowledge Bases, particularly Medline'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 12, 'page_label': '13', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='abstracts. The lexicon was created using MeSH  (Medical Subject Headings), Dorland’s \\nIllustrated Medical Dictionary and general English Dictionaries. Th e Centre d’Informatique \\nHospitaliere of the Hopital Cantonal de Geneve is working on an electronic archiving \\nenvironment with NLP features [8 4][85]. In first phase , patient records were archived . At \\nlater stage the LSP-MLP has been adapted for French [86][87][88][89] , and finally , a proper \\nNLP syste m called RECIT  [90 ][91][92][93] has been developed using a method called \\nProximity Processing [ 94]. It’s task was to implement a robust and multilingual system able \\nto analyze/comprehend medical sentences, an d to preserve a knowledge of free text into a \\nlanguage independent knowledge representation [ 95][96]. The Columbia university of New \\nYork has developed an NLP system called MEDLEE (MEDical Language Extraction and \\nEncoding System) that identifies clinical i nformation in narrative reports and transforms the'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 12, 'page_label': '13', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='York has developed an NLP system called MEDLEE (MEDical Language Extraction and \\nEncoding System) that identifies clinical i nformation in narrative reports and transforms the \\ntextual information into structured representation [97]. \\n7. Approaches \\nRationalist approach or symbolic approach assume that crucial part of the knowledge in the \\nhuman mind is not derived by the sense but is firm in advance, probably by genetic in \\nheritance. Noam Chomsky was the strongest advocate of this approach. It was trusted that \\nmachine can be  made to function like human brain by giving some fundamental knowledge \\nand reasoning mechanism linguistics  knowledge is directly encoded in rule or other forms of \\nrepresentation. This helps automatic process of natural languages. [ 98] Statistical and \\nmachine learning entail evolution of algorithms that allow a program to infer patterns. An \\niterative process is use d to characterize a given algorithm’s underlying algorithm that are'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 12, 'page_label': '13', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='machine learning entail evolution of algorithms that allow a program to infer patterns. An \\niterative process is use d to characterize a given algorithm’s underlying algorithm that are \\noptimised by a numerical measure that characterize numerical pa rameters and learning phase. \\nMachine-learning models can be predominantly categorized as either generative or \\ndiscriminative. Generative methods can generate synthetic data because of which they create \\nrich models of probability distributions. Discriminative methods are more functional and \\nhave right estimating posterior probabilities and are based on observations.  \\nSrihari [99] explains the different generative models as one with a resemblance that is used to \\nspot an unknown speaker’s language and would bid the deep knowledge of numerous \\nlanguage to perform the match. Whereas discriminative methods rely on a less knowledge -\\nintensive approach and using distinction between language.  Whereas generative models, can'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 12, 'page_label': '13', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='language to perform the match. Whereas discriminative methods rely on a less knowledge -\\nintensive approach and using distinction between language.  Whereas generative models, can \\nbecome troublesome when many features are used and discriminative models allow use of \\nmore features. [ 100] Few of the examples of discriminative methods are Logistic regr ession \\nand conditional random fields (CRFs), generative methods are Naive Bayes classifiers and \\nhidden Markov models (HMMs). \\n7.1 Hidden Markov Model (HMM) \\nAn HMM is a system where a shifting takes place between several states, generating feasible \\noutput symbols with each switch. The sets of viable states and unique symbols may be large, \\nbut finite and known. We can descry the outputs, but the system’s intern als are hidden. Few \\nof the problem could be solved are by Inference A certain sequence of output symbols, \\ncompute the probabilities of one or more candidate states with sequences. Pattern matching'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 12, 'page_label': '13', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='of the problem could be solved are by Inference A certain sequence of output symbols, \\ncompute the probabilities of one or more candidate states with sequences. Pattern matching \\nthe state -switch sequence is realised are most likely to ha ve generated a particular output -'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 13, 'page_label': '14', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='symbol sequence.  Training the output -symbol chain data, reckon the state -switch/output \\nprobabilities that fit this data best. \\nHidden Markov Models are extensively used for speech recognition, where the output \\nsequence is matched to the sequence of individual phonemes. Frederick Jelinek, a statistical -\\nNLP advocate who first instigated HMMs at IBM’s Speech Recognition Group, reportedly \\njoked, every time a linguist leaves my group, the speech recognizer’s performance improves.  \\n[101] HMM is not restricted to this application it has several others such as bioinformatics \\nproblems, for example, multiple sequence a lignment [10 2]. Sonnhammer mentioned that \\nPfam hold multiple alignments and hidden Markov model based profiles (HMM -profiles) of \\nentire protein domains. The cue of domain boundaries, family members and alignment is \\ndone semi -automatically found on expert knowledge, sequence similarity, other protein'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 13, 'page_label': '14', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='entire protein domains. The cue of domain boundaries, family members and alignment is \\ndone semi -automatically found on expert knowledge, sequence similarity, other protein \\nfamily databases and the capability of HMM -profiles to correctly identify an d align the \\nmembers. [103]  \\n7.2 Naive Bayes Classifiers \\n The choice of area is wide ranging covering usual items like word segmentation and \\ntranslation but also unusual areas like segmentation for infant learning and identifying \\ndocuments for opinions and facts. In addition, exclusive article was selected for its use of \\nBayesian methods to aid the research in designing algorithms for their investigation. \\n8. NLP in Talk \\nThis section discuss es the recent developments in the NLP projects implemented by various \\ncompanies and these are as follows: \\n8.1 ACE Powered GDPR Robot Launched by RAVN Systems [104] \\nRAVN Systems,  an leading expert in Artificial Intelligence (AI),  Search and Knowledge'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 13, 'page_label': '14', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='companies and these are as follows: \\n8.1 ACE Powered GDPR Robot Launched by RAVN Systems [104] \\nRAVN Systems,  an leading expert in Artificial Intelligence (AI),  Search and Knowledge \\nManagement Solutions, announced the launch of a RAVN (\"Applied Cognitive Engine\") i.e \\npowered software Robot to help and facilitate the GDPR  (\"General Data Protection \\nRegulation\") compliance. \\nThe Robot uses AI techniques to automatically analyse documents and other types of data in \\nany business system which is subject to GDPR rules.  It allows users to quickly and easily \\nsearch, retrieve, flag, classify and report on data mediated to be supersensitive under GDPR. \\nUsers also have the ability to identify personal data from documents, view feeds on the latest \\npersonal data that requires attention and provide reports on the data suggested to be deleted or \\nsecured.  RAVN\\'s GDPR Robot is also abl e to hasten requests for information (Data Subject'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 13, 'page_label': '14', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='personal data that requires attention and provide reports on the data suggested to be deleted or \\nsecured.  RAVN\\'s GDPR Robot is also abl e to hasten requests for information (Data Subject \\nAccess Requests - \"DSAR\") in a simple and efficient way, removing the need for a physical \\napproach to these requests which tends to be very labour thorough.  Peter Wallqvist, CSO at \\nRAVN Systems commented, \"GDPR compliance is of universal paramountcy as it will \\nexploit to any organisation that control and process data concerning EU citizens. \\nLINK:http://markets.financialcontent.com/stocks/news/read/33888795/RAVN_Systems_Launch_the_ACE_Po\\nwered_GDPR_Robot \\n8.2 Eno A Natural Language Chatbot Launched by Capital One [105]'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 14, 'page_label': '15', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='Capital one announces chatbot for customers called Eno.  Eno is a natural language chatbot \\nthat people socialize through texting.  Capital one claims that Eno  is First natural language \\nSMS chatbot from a U.S. bank that allows customer to ask questions using natural language.  \\nCustomers can interact with Eno asking  questions about their savings and others using a text \\ninterface. Eno makes such an environment that it feels that a human is interacting.  Ken \\nDodelin, Capital One’s vice president of digital product development, said “We kind of \\nlaunched a chatbot and didn’t know it.”  \\nThis provides a different platform than other brands that launch chatbots like Facebook \\nMessenger and Skype.  They believed that Facebook  has too much access of private \\ninformation of a person, which could get them into trouble with privacy laws of U.S. \\nfinancial institutions work under.  Like any Facebook Page admin can access full transcripts'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 14, 'page_label': '15', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='information of a person, which could get them into trouble with privacy laws of U.S. \\nfinancial institutions work under.  Like any Facebook Page admin can access full transcripts \\nof the bot’s conversations.  If that would be the case then the admins could easily view the \\npersonal banking information of customers with is not correct \\n LINK: https://www.macobserver.com/analysis/capital-one-natural-language-chatbot-eno/ \\n8.3  Future of BI in Natural Language Processing [106] \\nSeveral companies in Bi spaces are trying to get with the trend and trying hard to ensure that \\ndata becomes more friendly and easily accessible.  But still there is long way for this.BI will \\nalso make it easier to access as GUI is not needed.  Because now a days the queries are made \\nby text or voice command on smartphones.one of the most common example is Google might \\ntell you today what will be the tomorrows  weather. But soon enough, we will be able to  ask'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 14, 'page_label': '15', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='by text or voice command on smartphones.one of the most common example is Google might \\ntell you today what will be the tomorrows  weather. But soon enough, we will be able to  ask \\nour personal data chatbot about customer sentiment today, and how do we feel about their \\nbrand next week; all while walking down the street. Today, NLP tends to be based on turning \\nnatural language into mac hine language. But with time the technology matures – especially \\nthe AI component –the computer will get better at “understanding” the query and start to \\ndeliver answers rather than search results. \\n Initially, the data chatbot will probably ask the questio n as how have revenues changed over \\nthe last three -quarters?’ and then return pages of data for you to analyse.  But once it learns \\nthe semantic relations and inferences of the question, it will be able to automatically perform \\nthe filtering and formulation necessary to provide an intelligible answer, rather than simply \\nshowing you data.'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 14, 'page_label': '15', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='the filtering and formulation necessary to provide an intelligible answer, rather than simply \\nshowing you data. \\nLink: http://www.smartdatacollective.com/eran-levy/489410/here-s-why-natural-language-processing-future-bi \\n8.4 Using Natural Language Processing and Network Analysis to \\nDevelop a Conceptual Framework for Medication  Therapy \\nManagement Research [107] \\nNatural Language Processing and Network Analysis to Develop a Conceptual Framework for \\nMedication Therapy Management Research describes a theory derivation  process that is used \\nto develop conceptual framework for medication therapy management (MTM) research.  The \\nMTM service model and chronic care model are selected a s parent theories.  Review article'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 15, 'page_label': '16', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='abstracts target medication therapy management in chronic disease care that were retrieved \\nfrom Ovid Medline (2000-2016). \\nUnique concepts in each abstract are extracted using Meta  Map and their pairwise \\ncooccurrence are de termined. Then the information is used to construct a network graph of \\nconcept co -occurrence that is further analysed to identify  content for the new conceptual \\nmodel. 142 abstracts are analysed. Medication adherence is the most studied drug therapy \\nproblem and co-occurred with concepts related to patient -centred interventions targeting self-\\nmanagement. The enhanced model consists of 65 concepts clustered into 14 constructs. The \\nframework requires additional refinement and evaluation to determine its releva nce and \\napplicability across a broad audience including underserved settings. \\nLink: https://www.ncbi.nlm.nih.gov/pubmed/28269895?dopt=Abstract \\n8.5 Meet the Pilot, world’s first language translating earbuds [108]'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 15, 'page_label': '16', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='Link: https://www.ncbi.nlm.nih.gov/pubmed/28269895?dopt=Abstract \\n8.5 Meet the Pilot, world’s first language translating earbuds [108] \\nThe world’s first smart earpiece Pilot will soon be transcribed over 15 languages.  According \\nto Spring wise, Waverly Labs’ Pilot can already transliterate five spoken languages, English, \\nFrench, Italian, Portuguese and Spanish, and seven written affixed languages, German, Hindi, \\nRussian, Japanese, Arabic, Korean and Mandarin Chinese. The Pilot earpiece is connected \\nvia Bluetooth to the Pilot speech translation app, which uses speech recognitio n, machine \\ntranslation and machine learning and speech synthesis technology. \\nSimultaneously, the user will hear the translated version of the speech on the second earpiece. \\nMoreover, it is not necessary that conversation would be taking place between two p eople \\nonly the users can join in and discuss as a group. As if now the user may experience a few'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 15, 'page_label': '16', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='Moreover, it is not necessary that conversation would be taking place between two p eople \\nonly the users can join in and discuss as a group. As if now the user may experience a few \\nsecond lag interpolated the speech and translation, which Waverly Labs pursue to reduce. \\nThe Pilot earpiece will be available from September, but can be pre -ordered now for $249. \\nThe earpieces can also be used for streaming music, answering voice calls and getting audio \\nnotifications. \\nLink:https://www.indiegogo.com/projects/meet-the-pilot-smart-earpiece-language-translator-\\nheadphones-travel#/ \\n \\nREFRENCES \\n[1] Chomsky, Noam, 1965, Aspects of the Theory of Syntax, Cambridge, Massachusetts: \\nMIT Press.  \\n [2] Rospocher, M., van Erp, M., Vossen, P., Fokkens, A., Aldabe,I., Rigau, G., Soroa, A., \\nPloeger, T., and Bogaard, T.(2016). Building event -centric knowledge graphs from news. \\nWeb Semantics: Science, Services and Agents on the World Wide Web, In Press.'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 15, 'page_label': '16', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='Ploeger, T., and Bogaard, T.(2016). Building event -centric knowledge graphs from news. \\nWeb Semantics: Science, Services and Agents on the World Wide Web, In Press. \\n[3] Shemtov, H. (1997).  Ambiguity manageme nt in natural language generation. Stanford \\nUniversity.  \\n[4] Emele, M. C., & Dorna, M. (1998, August). Ambiguity preserving machine translation \\nusing packed representations. In  Proceedings of the 36th Annual Meeting of the Association'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 16, 'page_label': '17', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='for Computational Lin guistics and 17th International Conference on Computational \\nLinguistics-Volume 1 (pp. 365-371). Association for Computational Linguistics. \\n[5] Knight, K., & Langkilde, I. (2000, July). Preserving ambiguities in generation via \\nautomata intersection. In AAAI/IAAI (pp. 697-702). \\n[6] Nation, K., Snowling, M. J., & Clarke, P. (2007). Dissecting the relationship between \\nlanguage skills and learning to read: Semantic and phonological contributions to new \\nvocabulary learning in children with poor reading compre hension. Advances in Speech \\nLanguage Pathology, 9(2), 131-139. \\n[7] Liddy, E. D. (2001). Natural language processing. \\n[8] Feldman, S. (1999). NLP Meets the Jabberwocky: Natural Language Processing in \\nInformation Retrieval. ONLINE-WESTON THEN WILTON-, 23, 62-73. \\n[9] \"Natural Language Processing.\"  Natural Language Processing RSS. N.p., n.d. Web. 25 \\nMar. 2017 \\n[10] Hutchins, W. J. (1986).  Machine translation: past, present, future  (p. 66). Chichester:'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 16, 'page_label': '17', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='[9] \"Natural Language Processing.\"  Natural Language Processing RSS. N.p., n.d. Web. 25 \\nMar. 2017 \\n[10] Hutchins, W. J. (1986).  Machine translation: past, present, future  (p. 66). Chichester: \\nEllis Horwood. \\n[11] Hutchins, W. J. (Ed.). (2000).  Early years in machine translation: memoirs and \\nbiographies of pioneers (Vol. 97). John Benjamins Publishing. \\n[12] Green Jr, B. F., Wolf, A. K., Chomsky, C., & Laughery, K. (1961, May). Baseball: an \\nautomatic question-answerer. In Papers presented at the May 9 -11, 1961, western joint IRE -\\nAIEE-ACM computer conference (pp. 219-224). ACM. \\n[13] Woods, W. A. (1978). Semantics and quantification in natural language question \\nanswering. Advances in computers, 17, 1-87. \\n[14] Hendrix, G. G., Sacerdoti, E. D., Sagalowicz, D., & Slocum, J. (1978). Developing a \\nnatural language interface to complex data.  ACM Transactions on Database Systems \\n(TODS), 3(2), 105-147. \\n[15] Alshawi, H. (1992). The core language engine. MIT press.'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 16, 'page_label': '17', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='natural language interface to complex data.  ACM Transactions on Database Systems \\n(TODS), 3(2), 105-147. \\n[15] Alshawi, H. (1992). The core language engine. MIT press. \\n[16] Kamp, H., & Reyle, U. (1993). Tense and Aspect.  In From Discourse to Logic (pp. 483-\\n689). Springer Netherlands. \\n[17] Lea , W.A Trends in speech recognition , Englewoods Cliffs , NJ: Prentice Hall , 1980. \\n[18] Young, S. J., & Chase, L. L. (1998). Speech recognition evaluation: a review of the US \\nCSR and LVCSR programmes. Computer Speech & Language, 12(4), 263-279. \\n[19] Sundheim, B. M., & Chinchor, N. A. (1993, March). Survey of the message \\nunderstanding conferences. In  Proceedings of the workshop on Human Language \\nTechnology (pp. 56-60). Association for Computational Linguistics.'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 17, 'page_label': '18', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='[20] Wahlster, W., & Kobsa, A. (1989). User models in dialog systems. In  User models in \\ndialog systems (pp. 4-34). Springer Berlin Heidelberg. \\n[21] McKeown, K.R. Text generation , Cambridge: Cambridge University Press , 1985. \\n[22] Small S.L., Cortell G.W., and Tanenhaus , M.K. Lexical Ambiguity Resolutions , San \\nMateo , CA : Morgan Kauffman, 1988. \\n[23] Manning, C. D., & Schütze, H. (1999).  Foundations of statistical natural language \\nprocessing (Vol. 999). Cambridge: MIT press. \\n[24] Mani, I., & Maybury, M. T. (Eds.). (1999).  Advances in automatic text \\nsummarization (Vol. 293). Cambridge, MA: MIT press. \\n[25] Yi, J., Nasukawa, T., Bunescu, R., & Niblack, W. (2003, November). Sentiment \\nanalyzer: Extracting sentiments about a given topi c using natural language processing \\ntechniques. In Data Mining, 2003. ICDM 2003. Third IEEE International Conference on  (pp. \\n427-434). IEEE. \\n[26] Yi, J., Nasukawa, T., Bunescu, R., & Niblack , W. (2003, November). Sentiment'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 17, 'page_label': '18', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='techniques. In Data Mining, 2003. ICDM 2003. Third IEEE International Conference on  (pp. \\n427-434). IEEE. \\n[26] Yi, J., Nasukawa, T., Bunescu, R., & Niblack , W. (2003, November). Sentiment \\nanalyzer: Extracting sentiments about a given topic using natural language processing \\ntechniques. In Data Mining, 2003. ICDM 2003. Third IEEE International Conference on  (pp. \\n427-434). IEEE. \\n[27] Tapaswi, N., & Jain, S. (20 12, September). Treebank based deep grammar acquisition \\nand Part -Of-Speech Tagging for Sanskrit sentences. In  Software Engineering (CONSEG), \\n2012 CSI Sixth International Conference on (pp. 1-4). IEEE. \\n[28] Ranjan, P., & Basu, H. V. S. S. A. (2003). Part of  speech tagging and local word \\ngrouping techniques for natural language parsing in Hindi. In  Proceedings of the 1st \\nInternational Conference on Natural Language Processing (ICON 2003). \\n[29] Diab, M., Hacioglu, K., & Jurafsky, D. (2004, May). Automatic tagg ing of Arabic text:'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 17, 'page_label': '18', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='International Conference on Natural Language Processing (ICON 2003). \\n[29] Diab, M., Hacioglu, K., & Jurafsky, D. (2004, May). Automatic tagg ing of Arabic text: \\nFrom raw text to base phrase chunks. In  Proceedings of HLT -NAACL 2004: Short \\npapers (pp. 149-152). Association for Computational Linguistics. \\n[30] Sha, F., & Pereira, F. (2003, May). Shallow parsing with conditional random fields. \\nIn Proceedings of the 2003 Conference of the North American Chapter of the Association for \\nComputational Linguistics on Human Language Technology -Volume 1  (pp. 134 -141). \\nAssociation for Computational Linguistics. \\n[31] McDonald, R., Crammer, K., & Pereira, F. (2 005, October). Flexible text segmentation \\nwith structured multilabel classification. In  Proceedings of the conference on Human \\nLanguage Technology and Empirical Methods in Natural Language Processing  (pp. 987 -\\n994). Association for Computational Linguistics.'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 17, 'page_label': '18', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='Language Technology and Empirical Methods in Natural Language Processing  (pp. 987 -\\n994). Association for Computational Linguistics. \\n[32] Sun, X., Morency, L. P., Okanohara, D., & Tsujii, J. I. (2008, August). Modeling latent -\\ndynamic in shallow parsing: a latent conditional model with improved inference.'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 18, 'page_label': '19', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='In Proceedings of the 22nd International Conference on Computational Linguistics-Volume \\n1 (pp. 841-848). Association for Computational Linguistics. \\n[33] Ritter, A., Clark, S., & Etzioni, O. (2011, July). Named entity recognition in tweets: an \\nexperimental study. In  Proceedings of the Conference on Empirical Methods in Natur al \\nLanguage Processing (pp. 1524-1534). Association for Computational Linguistics. \\n[34] Sharma, S. , Srinivas,  PYKL, &  Balabantaray, RC (2016). Emotion Detection using \\nOnline Machine Learning Method and TLBO on Mixed Script. In Proceedings of Language \\nResources and Evaluation Conference 2016 (pp. 47-51). \\n[35] Palmer, M., Gildea, D., & Kingsbury, P. (2005). The proposition bank: An annotated \\ncorpus of semantic roles. Computational linguistics, 31(1), 71-106. \\n[36] Benson, E., Haghighi, A., & Barzilay, R. (2011, June). Event discovery in social media \\nfeeds. In  Proceedings of the 49th Annual Meeting of the Association for Computational'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 18, 'page_label': '19', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='[36] Benson, E., Haghighi, A., & Barzilay, R. (2011, June). Event discovery in social media \\nfeeds. In  Proceedings of the 49th Annual Meeting of the Association for Computational \\nLinguistics: Human Language Technologies -Volume 1  (pp. 389 -398). Association for \\nComputational Linguistics. \\n[37] Tillmann, C ., Vogel, S., Ney, H., Zubiaga, A., & Sawaf, H. (1997, September). \\nAccelerated DP based search for statistical translation. In Eurospeech. \\n[38] Bangalore, S., Rambow, O., & Whittaker, S. (2000, June). Evaluation metrics for \\ngeneration. In  Proceedings of the first international conference on Natural language \\ngeneration-Volume 14 (pp. 1-8). Association for Computational Linguistics \\n[39] Nießen, S., Och, F. J., Leusch, G., & Ney, H. (2000, May). An Evaluation Tool for \\nMachine Translation: Fast Evaluation for MT Research. In LREC \\n[40] Papineni, K., Roukos, S., Ward, T., & Zhu, W. J. (2002, July). BLEU: a method for'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 18, 'page_label': '19', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='Machine Translation: Fast Evaluation for MT Research. In LREC \\n[40] Papineni, K., Roukos, S., Ward, T., & Zhu, W. J. (2002, July). BLEU: a method for \\nautomatic evaluation of machine translation. In  Proceedings of the 40th annual meeting on \\nassociation for computational linguistics  (pp. 311 -318). Association for Computational \\nLinguistics \\n[41] Doddington, G. (2002, March). Automatic evaluation of machine translation quality \\nusing n-gram co-occurrence statistics. In  Proceedings of the second international conference \\non Human Language Technology Research (pp. 138-145). Morgan Kaufmann Publishers Inc  \\n[42] Papineni, K., Roukos, S., Ward, T., & Zhu, W. J. (2002, July). BLEU: a method for \\nautomatic evaluation of machine translation. In  Proceedings of the 40th annual meeting on \\nassociation for computationa l linguistics  (pp. 311 -318). Association for Computational \\nLinguistics \\n[43] Doddington, G. (2002, March). Automatic evaluation of machine translation quality'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 18, 'page_label': '19', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='association for computationa l linguistics  (pp. 311 -318). Association for Computational \\nLinguistics \\n[43] Doddington, G. (2002, March). Automatic evaluation of machine translation quality \\nusing n-gram co-occurrence statistics. In  Proceedings of the second international conference \\non Human Language Technology Research (pp. 138-145). Morgan Kaufmann Publishers Inc'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 19, 'page_label': '20', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='[44] Hayes, P. J. (1992). Intelligent high -volume text processing using shallow, domain -\\nspecific techniques.  Text-based intelligent systems: Current research and practice in \\ninformation extraction and retrieval, 227-242. \\n[45] Cohen, W. W. (1996, March). Learning rules that classify e -mail. In  AAAI spring \\nsymposium on machine learning in information access (Vol. 18, p. 25). \\n[46] Sahami, M., Dumais, S., Heckerman, D., &  Horvitz, E. (1998, July). A Bayesian \\napproach to filtering junk e -mail. In Learning for Text Categorization: Papers from the 1998 \\nworkshop (Vol. 62, pp. 98-105). \\n[47] Androutsopoulos, I., Paliouras, G., Karkaletsis, V., Sakkis, G., Spyropoulos, C. D., & \\nStamatopoulos, P. (2000). Learning to filter spam e -mail: A comparison of a naive bayesian \\nand a memory-based approach. arXiv preprint cs/0009009. \\n[48] Rennie, J. (2000, August). ifile: An application of machine learning to e -mail filtering. \\nIn Proc. KDD 2000 Workshop on Text Mining, Boston, MA'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 19, 'page_label': '20', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='[48] Rennie, J. (2000, August). ifile: An application of machine learning to e -mail filtering. \\nIn Proc. KDD 2000 Workshop on Text Mining, Boston, MA \\n[49] Drucker, H., Wu, D., & Vapnik, V. N. (1999). Support vector machines for spam \\ncategorization. IEEE Transactions on Neural networks, 10(5), 1048-1054 \\n[50] Carreras, X., & Marquez, L. (2001). Boosting trees for ant i-spam email filtering.  arXiv \\npreprint cs/0109015 \\n[51] BERGER, A. L., DELLA PIETRA, S. A., AND DELLA PIETRA, V. J. 1996. A \\nmaximum entropy approach to natural language processing. Computational Linguistics 22, 1, \\n39–71 \\n[52] Sakkis, G., Androutsopoulos, I.,  Paliouras, G., Karkaletsis, V., Spyropoulos, C. D., & \\nStamatopoulos, P. (2001). Stacking classifiers for anti-spam filtering of e-mail. arXiv preprint \\ncs/0106040.. \\n[53] Lewis, D. D. (1998, April). Naive (Bayes) at forty: The independence assumption in \\ninformation retrieval. In  European conference on machine learning  (pp. 4 -15). Springer'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 19, 'page_label': '20', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='cs/0106040.. \\n[53] Lewis, D. D. (1998, April). Naive (Bayes) at forty: The independence assumption in \\ninformation retrieval. In  European conference on machine learning  (pp. 4 -15). Springer \\nBerlin Heidelberg \\n[54] McCallum, A., & Nigam, K. (1998, July). A comparison of event models for naive bayes \\ntext classification. In  AAAI-98 workshop on learning for text ca tegorization (Vol. 752, pp. \\n41-48). \\n[55] McCallum, A., & Nigam, K. (1998, July). A comparison of event models for naive bayes \\ntext classification. In  AAAI-98 workshop on learning for text categorization  (Vol. 752, pp. \\n41-48). \\n[56] Porter, M. F. (1980). An algorithm for suffix stripping. Program, 14(3), 130-137'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 20, 'page_label': '21', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='[57] Hayes, P. J. (1992). Intelligent high -volume text processing using shallow, domain -\\nspecific techniques.  Text-based intelligent systems: Current research and practice in \\ninformation extraction and retrieval, 227-242 \\n[58] Morin, E. (1999, August). Automatic acquisition of semantic relations between terms \\nfrom technical corpora. In  Proc. of the Fifth International Congress on Terminology and \\nKnowledge Engineering-TKE’99. \\n[59] Bondale, N., Maloor, P.,  Vaidyanathan, A., Sengupta, S., & Rao, P. V. (1999). \\nExtraction of information from open -ended questionnaires using natural language processing \\ntechniques. Computer Science and Informatics, 29(2), 15-22 \\n[60] Glasgow, B., Mandell, A., Binney, D., Ghemri, L ., & Fisher, D. (1998). MITA: An \\ninformation-extraction approach to the analysis of free -form text in life insurance \\napplications. AI magazine, 19(1), 59. \\n[61] Ahonen, H., Heinonen, O., Klemettinen, M., & Verkamo, A. I. (1998, April). Applying'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 20, 'page_label': '21', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='applications. AI magazine, 19(1), 59. \\n[61] Ahonen, H., Heinonen, O., Klemettinen, M., & Verkamo, A. I. (1998, April). Applying \\ndata mining techniques for descriptive phrase extraction in digital document collections. \\nIn Research and Technology Advances in Digital Libraries, 1998. ADL 98. Proceedings. \\nIEEE International Forum on (pp. 2-11). IEEE. \\n[62] Zajic, D. M., Dorr, B. J., & Lin, J. (2008 ). Single -document and multi -document \\nsummarization techniques for email threads using sentence compression.  Information \\nProcessing & Management, 44(4), 1600-1610. \\n[63] Fattah, M. A., & Ren, F. (2009). GA, MR, FFNN, PNN and GMM based models for \\nautomatic text summarization. Computer Speech & Language, 23(1), 126-144. \\n[64] Gong, Y., & Liu, X. (2001, September). Generic text summarization using relevance \\nmeasure and latent semantic analysis. In  Proceedings of the 24th annual international ACM \\nSIGIR conference on Research and development in information retrieval (pp. 19-25). ACM.'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 20, 'page_label': '21', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='measure and latent semantic analysis. In  Proceedings of the 24th annual international ACM \\nSIGIR conference on Research and development in information retrieval (pp. 19-25). ACM. \\n[65] Dunlavy, D. M., O’Leary, D. P., Conroy, J. M., & Schlesinger, J. D. (2007). QCS: A \\nsystem for querying, clustering and summarizing documents.  Information processing & \\nmanagement, 43(6), 1588-1605. \\n[66] Wan, X. (2008). Using only cross -document relationships for both generic and topic -\\nfocused multi-document summarizations. Information Retrieval, 11(1), 25-49. \\n[67] Ouyang, Y., Li, W., Li, S., & Lu, Q. (2011). Applying regression models to query -\\nfocused multi-document summarization. Information Processing & Management,  47(2), 227-\\n237. \\n[68] Mani, I., & Maybury, M. T. (Eds.). (1999).  Advances in automatic text \\nsummarization (Vol. 293). Cambridge, MA: MIT press.'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 21, 'page_label': '22', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='[69] Riedhammer, K., F avre, B., & Hakkani -Tür, D. (2010). Long story short –global \\nunsupervised models for keyphrase based meeting summarization.  Speech \\nCommunication, 52(10), 801-815. \\n[70] Wang, D., Zhu, S., Li, T., & Gong, Y. (2009, August). Multi -document summarization \\nusing sentence-based topic models. In  Proceedings of the ACL -IJCNLP 2009 Conference \\nShort Papers (pp. 297-300). Association for Computational Linguistics. \\n[71] Wang, D., Zhu, S., Li, T., Chi, Y., & Gong, Y. (2011). Integrating document clustering \\nand multidocument summarization. ACM Transactions on Knowledge Discovery from Data \\n(TKDD), 5(3), 14. \\n[72] Fang, H., Lu, W., Wu, F., Zhang, Y., Shang, X., Shao, J., & Zhuang, Y. (2015). Topic \\naspect-oriented summarization via group selection. Neurocomputing, 149, 1613-1619. \\n[73] Sager, N., Lyman, M., Nhan, N. T., & Tick, L. J. (1995). Medical language processing: \\napplications to patient data representation and automatic encoding. Methods of information in'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 21, 'page_label': '22', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='[73] Sager, N., Lyman, M., Nhan, N. T., & Tick, L. J. (1995). Medical language processing: \\napplications to patient data representation and automatic encoding. Methods of information in \\nmedicine, 34(1-2), 140-146. \\n[74] Chi, E. C., Lyman, M. S. , Sager, N., Friedman, C., & Macleod, C. (1985, November). A \\ndatabase of computer -structured narrative: methods of computing complex relations. \\nIn Proceedings of the Annual Symposium on Computer Application in Medical Care (p. 221). \\nAmerican Medical Informatics Association. \\n[75] Grishman, R., Sager, N., Raze, C., & Bookchin, B. (1973, June). The linguistic string \\nparser. In  Proceedings of the June 4 -8, 1973, national computer conference and \\nexposition (pp. 427-434). ACM. \\n[76] Hirschman, L., Grishman, R., & Sager, N. (1976, June). From text to structured \\ninformation: automatic processing of medical reports. In  Proceedings of the June 7 -10, 1976, \\nnational computer conference and exposition (pp. 267-275). ACM.'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 21, 'page_label': '22', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='information: automatic processing of medical reports. In  Proceedings of the June 7 -10, 1976, \\nnational computer conference and exposition (pp. 267-275). ACM. \\n[77] Sager, N. (1981). Natural language information processing. Addison-Wesley Publishing \\nCompany, Advanced Book Program. \\n[78] Lyman, M., Sager, N., Friedman, C., & Chi, E. (1985, November). Computer -structured \\nnarrative in ambulatory care: its use in longitudinal review of clinical data. In  Proceedings of \\nthe Annual Symposium on Computer Application in Medical Care (p. 82). American Medical \\nInformatics Association. \\n[79] McCray, A. T., & Nelson, S. J. (1995). The representation of meaning in the \\nUMLS. Methods of information in medicine, 34(1-2), 193-201. \\n[80] McGray, A. T., Sponsler, J. L., Brylawski, B., & Browne, A. C. (1987, November). The \\nrole of lexical knowledge in biomedical text understanding. In  Proceedings of the Annual \\nSymposium on Computer Application in Medical Care  (p. 103). American Medical'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 21, 'page_label': '22', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='role of lexical knowledge in biomedical text understanding. In  Proceedings of the Annual \\nSymposium on Computer Application in Medical Care  (p. 103). American Medical \\nInformatics Association.'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 22, 'page_label': '23', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='[81] McCray, A. T. (1991). Natural language processing for intelligent information retrieval. \\nIn Engineering in Medicine and Biology Society, 1991. Vol. 13: 1991., Proceedings of the \\nAnnual International Conference of the IEEE (pp. 1160-1161). IEEE. \\n[82] McCray, A. T. (1991). Extending a natural language parser with UMLS knowledge. \\nIn Proceedings of the Annual Symposium on Computer Application in Medical Care (p. 194). \\nAmerican Medical Informatics Association. \\n[83] McCray, A. T., Srin ivasan, S., & Browne, A. C. (1994). Lexical methods for managing \\nvariation in biomedical terminologies. In  Proceedings of the Annual Symposium on \\nComputer Application in Medical Care (p. 235). American Medical Informatics Association. \\n[84] McCray, A. T., &  Razi, A. (1994). The UMLS Knowledge Source server.  Medinfo. \\nMEDINFO, 8, 144-147. \\n[85] Scherrer, J. R., Revillard, C., Borst, F., Berthoud, M., & Lovis, C. (1994). Medical office'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 22, 'page_label': '23', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='MEDINFO, 8, 144-147. \\n[85] Scherrer, J. R., Revillard, C., Borst, F., Berthoud, M., & Lovis, C. (1994). Medical office \\nautomation integrated into the distributed architecture of a hospital informa tion \\nsystem. Methods of information in medicine, 33(2), 174-179. \\n[86] Baud, R. H., Rassinoux, A. M., & Scherrer, J. R. (1992). Natural language processing \\nand semantical representation of medical texts.  Methods of information in medicine,  31(2), \\n117-125. \\n[87] Lyman, M., Sager, N., Chi, E. C., Tick, L. J., Nhan, N. T., Su, Y., ... & Scherrer, J. \\n(1989, November). Medical Language Processing for Knowledge Representation and \\nRetrievals. In Proceedings. Symposium on Computer Applications in Medical Care  (pp. 548-\\n553). American Medical Informatics Association. \\n[88] Nhàn, N. T., Sager, N., Lyman, M., Tick, L. J., Borst, F., & Su, Y. (1989, November). A \\nMedical Language Processor for Two Indo -European Languages. In  Proceedings.'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 22, 'page_label': '23', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content=\"[88] Nhàn, N. T., Sager, N., Lyman, M., Tick, L. J., Borst, F., & Su, Y. (1989, November). A \\nMedical Language Processor for Two Indo -European Languages. In  Proceedings. \\nSymposium on Computer Applications i n Medical Care  (pp. 554 -558). American Medical \\nInformatics Association. \\n[89] Sager, N., Lyman, M., Tick, L. J., Borst, F., Nhan, N. T., Revillard, C., ... & Scherrer, J. \\nR. (1989). Adapting a medical language processor from English to French.  Medinfo, 89, 795-\\n799. \\n[90] Borst, F., Sager, N., Nhàn, N. T., Su, Y., Lyman, M., Tick, L. J., ... & Scherrer, J. R. \\n(1989). Analyse automatique de comptes rendus d'hospitalisation. In  Degoulet P, Stephan JC, \\nVenot A, Yvon PJ, rédacteurs. Informatique et Santé, Informat ique et Gestion des Unités de \\nSoins, Comptes Rendus du Colloque AIM-IF, Paris (pp. 246-56). [5] \\n[91] Baud, R. H., Rassinoux, A. M., & Scherrer, J. R. (1991). Knowledge representation of \\ndischarge summaries. In AIME 91 (pp. 173-182). Springer Berlin Heidelberg.\"),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 22, 'page_label': '23', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='[91] Baud, R. H., Rassinoux, A. M., & Scherrer, J. R. (1991). Knowledge representation of \\ndischarge summaries. In AIME 91 (pp. 173-182). Springer Berlin Heidelberg. \\n[92] Baud, R. H., Alpay, L., & Lovis, C. (1994). Let’s Meet the Users with Natural Language \\nUnderstanding. Knowledge and Decisions in Health Telematics: The Next Decade, 12, 103.'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 23, 'page_label': '24', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='[93] Rassinoux, A. M., Baud, R. H., & Scherrer, J. R. (1992). Conceptual  graphs model \\nextension for knowledge representation of medical texts. MEDINFO, 92, 1368-1374. \\n[94] Morel-Guillemaz, A. M., Baud, R. H., & Scherrer, J. R. (1990). Proximity Processing of \\nMedical Text. In Medical Informatics Europe’90 (pp. 625-630). Springer Berlin Heidelberg. \\n[95] Rassinoux, A. M., Michel, P. A., Juge, C., Baud, R., & Scherrer, J. R. (1994). Natural \\nlanguage processing of medical texts within the HELIOS environment.  Computer methods \\nand programs in biomedicine, 45, S79-96. \\n[96] Rassinoux, A. M., Juge, C., Michel, P. A., Baud, R. H., Lemaitre, D., Jean, F. C., ... & \\nScherrer, J. R. (1995, June). Analysis of medical jargon: The RECIT system. In  Conference \\non Artificial Intelligence in Medicine in Europe (pp. 42-52). Springer Berlin Heidelberg. \\n[97] Friedman, C., Cimino, J. J., & Johnson, S. B. (1993). A conceptual model for clinical'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 23, 'page_label': '24', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='on Artificial Intelligence in Medicine in Europe (pp. 42-52). Springer Berlin Heidelberg. \\n[97] Friedman, C., Cimino, J. J., & Johnson, S. B. (1993). A conceptual model for clinical \\nradiology reports. In  Proceedings of the Annual Symposium on Computer Application in \\nMedical Care (p. 829). American Medical Informatics Association. \\n[98] \"Natural Language Processing.\"  Natural Language Processing RSS. N.p., n.d. Web. 23 \\nMar. 2017.   \\n[99] [Srihari S. Machine Learning: Generative and Discriminative Models. 2010. http:// \\nwww.cedar.buffalo.edu/wsrihari/CSE574/Discriminative-Generative.pdf (access ed 31 May \\n2011).] \\n[100] [Elkan C. Log -Linear Models and Conditional Random Fields. 2008. http://cseweb. \\nucsd.edu/welkan/250B/cikmtutorial.pdf (accessed 28 Jun 2011). 62. Hearst MA, Dumais ST, \\nOsman E, et al. Support vector machines] \\n[101] [Jurafsky D, Martin JH. Speech and Language Processing. 2nd edn. Englewood Cliffs, \\nNJ: Prentice-Hall, 2008.]'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 23, 'page_label': '24', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='Osman E, et al. Support vector machines] \\n[101] [Jurafsky D, Martin JH. Speech and Language Processing. 2nd edn. Englewood Cliffs, \\nNJ: Prentice-Hall, 2008.] \\n[102] [Sonnhammer ELL, Eddy SR, Birney E, et al. Pfam: Multiple sequence alignments and \\nHMM-profiles of protein domains. Nucleic Acids Res 1998;26:320] \\n[103] [Sonnhammer, E. L., Eddy, S. R., Birney, E., Bateman, A., & Durbin, R. (1998). Pfam: \\nmultiple sequence alignments and HMM -profiles of protein domains.  Nucleic acids \\nresearch, 26(1), 320-322] \\n[104] Systems, RAVN. \"RAVN Systems Launch the ACE Powered GDPR Rob ot - Artificial \\nIntelligence to Expedite GDPR Compliance.\"  Stock Market. PR Newswire, n.d. Web. 19 \\nMar. 2017. \\n [105] \"Here\\'s Why Natural Language Processing is the Future of BI.\"  SmartData Collective. \\nN.p., n.d. Web. 19 Mar. 2017'),\n",
       " Document(metadata={'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2017-08-17T12:10:59+05:30', 'author': 'Diksha Khurana', 'moddate': '2017-08-17T12:10:59+05:30', 'source': '../data/pdf_files/Natural_language_processing_state_of_the_art_curre.pdf', 'total_pages': 25, 'page': 24, 'page_label': '25', 'source_file': 'Natural_language_processing_state_of_the_art_curre.pdf', 'file_type': 'pdf'}, page_content='[106] \"Using Natural Langu age Processing and Network Analysis to Develop a Conceptual \\nFramework for Medication Therapy Management Research.\"  AMIA ... Annual Symposium \\nproceedings. AMIA Symposium. U.S. National Library of Medicine, n.d. Web. 19 Mar. 2017 \\n[107] Ogallo, W., & Kanter , A. S. (2017, February 10). Using Natural Language Processing \\nand Network Analysis to Develop a Conceptual Framework for Medication Therapy \\nManagement Research. Retrieved April 10, 2017, from \\nhttps://www.ncbi.nlm.nih.gov/pubmed/28269895?dopt=Abstract \\n[108] Ochoa, A. (2016, May 25). Meet the Pilot: Smart Earpiece Language Translator. \\nRetrieved April 10, 2017, from https://www.indiegogo.com/projects/meet -the-pilot-smart-\\nearpiece-language-translator-headphones-travel'),\n",
       " Document(metadata={'producer': 'Skia/PDF m144 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'Siddhant_Kochhar_Resume', 'source': '../data/pdf_files/Siddhant_Kochhar_Resume.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'Siddhant_Kochhar_Resume.pdf', 'file_type': 'pdf'}, page_content='SIDDHANT  KOCHHAR  (22BCE11684)  B.Tech  (Computer  Science  and  Engineering)   Email:  siddhantkochhar2022@vitbhopal.ac.in  |  Phone:  8965897560  LinkedIn:  https://www.linkedin.com/in/siddhant-kochhar/ LeetCode:   https://leetcode.com/u/Siddhant_Kochhar/  GitHub:  https://github.com/Siddhant-kochhar  \\n  \\n \\nACADEMICS  \\n \\nQualification  Institute  Board  /  University  %  /  CGPA  Year  B.Tech  (CSE  -  7th  sem)  XII  \\nVellore  Institute  of  Technology  Maharishi  Vidya  Mandir,  Jabalpur  \\nVIT  University  CBSE  \\n8.81/10  78.6%  \\n2026  2022  X  Maharishi  Vidya  Mandir,  Jabalpur  CBSE  79.2%  2020  \\n \\nCertifications   \\n●  AWS  Academy  Graduate  -  AWS  Academy  Cloud  Architecting ●  Cloud  Computing  by  IIT  Kharagpur  offered  through  NPTEL  ●  The  Bits  and  Bytes  of  Computer  Networks  by  Google  offered  through  Coursera  ●  Python  A-Z™:  Python  For  Data  Science offered  by  Udemy  \\n2025  2024  2023  2023  \\n \\nAchievements'),\n",
       " Document(metadata={'producer': 'Skia/PDF m144 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'Siddhant_Kochhar_Resume', 'source': '../data/pdf_files/Siddhant_Kochhar_Resume.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'Siddhant_Kochhar_Resume.pdf', 'file_type': 'pdf'}, page_content='2025  2024  2023  2023  \\n \\nAchievements  \\n●  Selected  among  top  500  students  globally  for  the  Ericsson  Academic  Training  Program  ●  Awarded  a  scholarship  under  Deen  Dayal  SPARSH  Yojana  by  India  Post  \\n2024  2017  \\n  \\nINTERNSHIP                                                                                                                                                              2  MONTHS  \\n  \\nMagicPin  (Hybrid)  Gen  AI  Intern   May  2025  -  June  2025  \\nRoles  and  Responsibilities  \\nGen  AI  &  Conversational  Interfaces  ●  Developed  a  WhatsApp-based  GenAI  chatbot  enabling  users  to  search  for  food,  fashion,  etc.  ●  Integrated  personalised  food  recommendation  engine  using  user  context  and  historical  data  ●  Enhanced  Magicpin’s  personal  support  bot  with  conversational  AI  capabilities  ●  Collaborated  with  tech  and  product  teams  to  ensure  scalable  integration  across  key  user  workflows   \\n \\n \\nPROJECTS'),\n",
       " Document(metadata={'producer': 'Skia/PDF m144 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'Siddhant_Kochhar_Resume', 'source': '../data/pdf_files/Siddhant_Kochhar_Resume.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'Siddhant_Kochhar_Resume.pdf', 'file_type': 'pdf'}, page_content='PROJECTS  \\n \\nGet.Fit  \\n●  Tech  Stack  -  Python,  FastAPI,  Google  Gemini,  Google  Fit,  MongoDB,  HTML,  CSS  ●  Developed  a  smart  health  tracking  app  integrated  with  Google  Fit  for  vitals  monitoring  ●  Added  a  feature  to  send  regular  summaries  and  real-time  alerts  for  proactive  health  management  \\nAI  Tutor  \\n●  Tech  Stack  -  Python,  FastAPI,  MongoDB,  OpenAI  ●  Developed  an  AI  tutor  that  assesses  the  user’s  proficiency  to  generate  personalized  responses  ●  Developed  a  YouTube  video  summarizer,  transforming  lengthy  video  content  into  concise  notes  \\nEventGenie \\n●  Tech  Stack  -  Python,  FastAPI,  Google  Gemini,  MongoDB,  MCP,  Redis,  Google  Places,  HTML   ●  Developed  EventGenie,  an  AI  event  planner  with  venues,  budgeting,  restaurants,  and  activities.  ●  Integrated  Google  Gemini  and  Google  Places  API  for  intelligent  venues,  budgeting,  and  scheduling.  \\nNote-Taking  App'),\n",
       " Document(metadata={'producer': 'Skia/PDF m144 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'Siddhant_Kochhar_Resume', 'source': '../data/pdf_files/Siddhant_Kochhar_Resume.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'Siddhant_Kochhar_Resume.pdf', 'file_type': 'pdf'}, page_content='Note-Taking  App  \\n●  Tech  Stack  -  Python,  FastAPI,  MongoDB,  Bootstrap  ●  Developed  a  basic  note-taking  application  using  CRUD  APIs  to  learn  the  FastAPI  framework  \\n \\nCORE  COMPETENCIES  \\n \\nData  Structure  and  Algorithm,  Operating  Systems,  Database  Management,  GenAI,  Cloud  Computing,  Computer  Networking  Programming  Python,  FastAPI,  Flask,  Pandas,  Numpy,  HTML,  CSS,  Bootstrap,  Java  Databases/Cache  MongoDB,  SQL,  Redis  Cloud  AWS,  GCP  AI/Tools  OpenAI  APIs,  Gemini,  MCP  server,  GitHub,  Cursor,  Postman,  MS  Office,  Canva  Soft  Skills  Leadership,  Communication,  Teamwork,  Problem  Solving,  Analytical  Skills,  Learning  Agility  \\n \\nPOSITIONS  OF  RESPONSIBILITY  \\n \\nMVM,  Jabalpur  \\n●  Vice  Captain,  Assembly  Committee  ●  Junior  Prefect  of  Parashar  House  \\n \\n \\nCO-CURRICULAR  &  EXTRACURRICULAR  ACTIVITIES  \\n \\nTechnical'),\n",
       " Document(metadata={'producer': 'Skia/PDF m144 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'Siddhant_Kochhar_Resume', 'source': '../data/pdf_files/Siddhant_Kochhar_Resume.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'Siddhant_Kochhar_Resume.pdf', 'file_type': 'pdf'}, page_content='POSITIONS  OF  RESPONSIBILITY  \\n \\nMVM,  Jabalpur  \\n●  Vice  Captain,  Assembly  Committee  ●  Junior  Prefect  of  Parashar  House  \\n \\n \\nCO-CURRICULAR  &  EXTRACURRICULAR  ACTIVITIES  \\n \\nTechnical  \\n●  Member,  Google  Developers  Group  ●  Competitive  Programming  -  LeetCode,  HackerRank,  Code  Chef  \\n \\nSocial/Sports  \\n●  Karate  -  Yellow  belt   Interests  /  Hobbies  ●  Travelling,  Cooking,  Gaming     VIT  UNIVERSITY  |  BATCH  OF  2026'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 0, 'page_label': '1', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='Natural Language Processing Journal 7 (2024) 100062\\nContents lists available at ScienceDirect\\nNatural Language Processing Journal\\njournal homepage: www.elsevier.com/locate/nlp\\nUnderstanding latent affective bias in large pre-trained neural language\\nmodels\\nAnoop Kadana,∗, Deepak P.b, Sahely Bhadrac, Manjary P. Gangand, Lajish V.L.d\\na School of Psychology, Queen’s University Belfast, UK\\nb School of Electronics, Electrical Engineering and Computer Science, Queen’s University Belfast, UK\\nc Computer Science and Engineering, IIT Palakkad, India\\nd Department of Computer Science, University of Calicut, India\\nA R T I C L E I N F O\\nKeywords:\\nAffective bias in NLP\\nFairness in NLP\\nPre-trained language models\\nTextual emotion detection\\nDeep learning\\nA B S T R A C T\\nGroundbreaking inventions and highly significant performance improvements in deep learning based Natural\\nLanguage Processing are witnessed through the development of transformer based large Pre-trained Language'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 0, 'page_label': '1', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='Language Processing are witnessed through the development of transformer based large Pre-trained Language\\nModels (PLMs). The wide availability of unlabeled data within human generated data deluge along with self-\\nsupervised learning strategy helps to accelerate the success of large PLMs in language generation, language\\nunderstanding, etc. But at the same time, latent historical bias/unfairness in human minds towards a particular\\ngender, race, etc., encoded unintentionally/intentionally into the corpora harms and questions the utility and\\nefficacy of large PLMs in many real-world applications, particularly for the protected groups. In this paper,\\nwe present an extensive investigation towards understanding the existence of ‘‘Affective Bias’’ in large PLMs\\nto unveil any biased association of emotions such as anger, fear, joy, etc., towards a particular gender, race\\nor religion with respect to the downstream task of textual emotion detection. We conduct our exploration of'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 0, 'page_label': '1', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='or religion with respect to the downstream task of textual emotion detection. We conduct our exploration of\\naffective bias from the very initial stage of corpus level affective bias analysis by searching for imbalanced\\ndistribution of affective words within a domain, in large scale corpora that are used to pre-train and fine-tune\\nPLMs. Later, to quantify affective bias in model predictions, we perform an extensive set of class-based and\\nintensity-based evaluations using various bias evaluation corpora. Our results show the existence of statistically\\nsignificant affective bias in the PLM based emotion detection systems, indicating biased association of certain\\nemotions towards a particular gender, race, and religion.\\n1. Introduction\\nRecently, large scale Natural Language Processing (NLP) models are\\nbeing increasingly deployed in many real-world applications within\\nalmost all domains such as health-care, business, legal systems, etc.,'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 0, 'page_label': '1', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='being increasingly deployed in many real-world applications within\\nalmost all domains such as health-care, business, legal systems, etc.,\\nVelupillai et al. (2018), Soni and Roberts (2020), Mishev et al. (2020),\\nDale (2019), Rahman and Siddiqui (2019) and Rahman and Siddiqui\\n(2021) due to its efficacy to make data-driven decisions and capability\\nof natural language understanding even better than humans1 (He et al.,\\n2021). Transformer based large Pre-trained Language Models (PLMs)\\nhave been hugely influential in NLP due to their capability to gener-\\nate powerful contextual representations. PLMs are mostly built based\\non a self-supervised learning strategy that highly relies on unlabeled\\ndata abundantly available from the human generated data deluge (He\\net al., 2021). But, since this historical data of textual write-ups has its\\nroots within human thought, they often reflect latent social stereotypes\\n(Suresh and Guttag, 2021; Garg et al., 2018). For example, the Social'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 0, 'page_label': '1', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='roots within human thought, they often reflect latent social stereotypes\\n(Suresh and Guttag, 2021; Garg et al., 2018). For example, the Social\\n∗ Correspondence to: School of Psychology, Queen’s University Belfast, Northern Ireland, UK.\\nE-mail addresses: a.kadan@qub.ac.uk (A. Kadan), deepaksp@acm.org (Deepak P.), sahely@iitpkd.ac.in (S. Bhadra), manjaryp_dcs@uoc.ac.in\\n(M. P. Gangan), lajish@uoc.ac.in (Lajish V.L.).\\n1 https://www.infoq.com/news/2021/01/google-microsoft-superhuman/.\\nRole Theory by Eagly and Steffen (1984) demonstrates that the idea of\\ngender stereotype develops from perceivers’ observations, associating\\nthe capabilities and personality attributes of different genders with the\\nactivities in which they engage in their day-to-day lives over time,\\nbuilding rigid stereotypes in human minds and their writings, on how\\nthese genders behave (e.g. women are highly emotional), where they\\nwork (e.g. women preferred in children’s daycare), etc. Hence the data'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 0, 'page_label': '1', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='these genders behave (e.g. women are highly emotional), where they\\nwork (e.g. women preferred in children’s daycare), etc. Hence the data\\nfrom such human generated data repositories eventually convey these\\nstereotypes as linguistic biases through the NLP algorithms (Raza et al.,\\n2024), especially those built on large PLMs that utilize huge amounts\\nof data (Suresh and Guttag, 2021).\\nIn this direction, investigation of ‘‘Affective Bias’’ in NLP is a re-\\ncent stream of research to study the existence of any unfair/biased\\nassociation of emotions (anger, fear, joy, etc.) or sentiments (positive,\\nnegative, etc.) towards underrepresented or protected groups in a\\ndomain, that may lead affective computing systems such as sentiment\\nor emotion detection systems to deliver unfavorable outcomes for these\\nhttps://doi.org/10.1016/j.nlp.2024.100062\\nReceived 5 November 2023; Received in revised form 6 January 2024; Accepted 1 March 2024'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 0, 'page_label': '1', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='https://doi.org/10.1016/j.nlp.2024.100062\\nReceived 5 November 2023; Received in revised form 6 January 2024; Accepted 1 March 2024\\n2949-7191/© 2024 The Author(s). Published by Elsevier B.V. This is an open access article under the CC BY-NC license\\n(http://creativecommons.org/licenses/by-nc/4.0/).'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 1, 'page_label': '2', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='A. Kadan, Deepak P., S. Bhadra et al. Natural Language Processing Journal 7 (2024) 100062\\nTable 1\\nDifferences in predicted emotion classes/intensities between sentences that differ only on a target term\\nrepresenting various social groups, indicating existence of ‘Affective Bias’.\\nSentence Emotion prediction\\nMen know how to drive Joy\\nWomen know how to drive Fear\\nWhite people are very ambitious as a whole Joy\\nBlack people are very ambitious as a whole Anger\\nTasha fell in love with the Christian man’s looks Joy\\nTasha fell in love with the Muslim man’s looks Fear\\nHe eventually wants to become a doctor Joy: 0.700\\nShe eventually wants to become a doctor Joy: 0.506\\nMy man friend made me feel alarmed Fear: 0.694\\nMy woman friend made me feel alarmed Fear: 0.750\\nMy queer friend made me feel alarmed Fear: 0.940\\nBlack people can dance very well Joy: 0.491\\nWhite people can dance very well Joy: 0.746\\nIt is always the Christian people who think their films are the best Joy: 0.996'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 1, 'page_label': '2', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='Black people can dance very well Joy: 0.491\\nWhite people can dance very well Joy: 0.746\\nIt is always the Christian people who think their films are the best Joy: 0.996\\nIt is always the Muslim people who think their films are the best Joy: 0.488\\nprotected groups (Anoop et al., 2022). For instance, a model consis-\\ntently associating women with a different class of emotion or same\\nemotion differing in emotion intensities vis-a-vis predictions for male\\n(Shields, 2002) could be seen as a manifestation of affective bias.\\nSimilarly, association of a particular religion always with a specific\\nemotion (Abid et al., 2021a) represents affective bias too. A real world\\nscenario of affective bias is the case of Google sentiment analyzer\\njudging that being gay is bad by assigning high negative sentiments\\nto sentences such as ‘ I’m a gay black woman’, ‘I’m a homosexual’, etc.,.2\\nFor better understandability of affective bias, we illustrate in Table 1,'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 1, 'page_label': '2', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='to sentences such as ‘ I’m a gay black woman’, ‘I’m a homosexual’, etc.,.2\\nFor better understandability of affective bias, we illustrate in Table 1,\\na sample set of affectively biased emotion predictions from PLM based\\ntextual emotion detection models constructed in this study for affective\\nbias analysis (detailed explanation of the models are provided in Sec-\\ntion 4.1). The first set in the table demonstrates affective bias due to\\ndifferences in predicted emotion classes, whereas the second set shows\\naffective bias due to differences in predicted emotion intensities.\\nSimilar to other general algorithmic biases like gender bias, racial\\nbias, etc., a possible stimuli to affective biases are the latent emotion\\nbased stereotypes about different social groups in the data. Studies\\nreport that such emotion based stereotyping influence socialization\\nof emotions leading to propagation of stereotypes such as associating\\nwomen’s (or men’s) experiences and expressions being aligned with'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 1, 'page_label': '2', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='of emotions leading to propagation of stereotypes such as associating\\nwomen’s (or men’s) experiences and expressions being aligned with\\nfear and sadness (or anger and pride) (Plant et al., 2000). Similarly,\\naffective bias within systems could facilitate a higher association of\\nblack women to the emotion anger when considering emotions with\\nthe domains race and gender (Ashley, 2014). In addition to biased\\ndata, another reason for bias is based on how the model/algorithmic\\ndesign considers or treats the underrepresented or protected attributes\\nconcerning a domain (Hooker, 2021). Similar to any other general\\nsocial biases, the existence of these affective biases make textual af-\\nfective computing systems generate unfair or biased decisions that can\\nharm its utility towards socially marginalized populations by denying\\nopportunities/resources or by false portrayal of these groups when\\ndeployed in the real-world. Hence, understanding affective bias in NLP'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 1, 'page_label': '2', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='opportunities/resources or by false portrayal of these groups when\\ndeployed in the real-world. Hence, understanding affective bias in NLP\\n2 https://www.vice.com/en/article/j5jmj8/google-artificial-intelligence-\\nbias.\\nplays a vital role in achieving algorithmic fairness, by protecting the\\nsocio-political and moral equality of marginalized groups.\\nIn this context, we present an extensive experimental analysis to\\nunderstand and illustrate the existence of latent ‘‘Affective Bias’’ in\\ntransformer based large PLMs 3 with respect to the downstream task\\nof textual emotion detection. Hence, we set our research question: Do\\npredictions made by large PLM based textual emotion detection sys-\\ntems systematically or consistently exemplify ‘Affective Bias’ towards\\ndemographic groups?Our investigation of affective bias in large PLMs\\nprimarily aims to identify the existence of gender, racial, and religious\\naffective biases and set aside the task of affective bias mitigation in'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 1, 'page_label': '2', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='primarily aims to identify the existence of gender, racial, and religious\\naffective biases and set aside the task of affective bias mitigation in\\nthe scope for future work. We start with an exploration of corpus level\\naffective bias or affect imbalance in corpus to find out any biased emo-\\ntion associations in the large scale corpora that are used to pre-train and\\nfine-tune the PLMs, by analyzing the distribution of emotions or their\\nassociations with demographic target terms (e.g., Islam, Quran) related\\nto a social group (e.g., Muslim) concerning a domain (e.g., Religion).\\nLater, we explore the prediction level affective bias in four popular\\ntransformer based PLMs, BERT (Bidirectional Encoder Representation\\nfrom Transformers) (Devlin et al., 2019), OpenAI GPT-2 (Generative\\nPre-trained Transformer) (Radford et al., 2019), XLNet (Yang et al.,\\n2019), and T5 (Text-to-Text Transfer Transformer) (Raffel et al., 2020),\\nthat are fine-tuned using a popular corpora SemEval-2018 EI-oc (Mo-'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 1, 'page_label': '2', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='2019), and T5 (Text-to-Text Transfer Transformer) (Raffel et al., 2020),\\nthat are fine-tuned using a popular corpora SemEval-2018 EI-oc (Mo-\\nhammad et al., 2018) for the task of textual emotion detection. To\\nquantify prediction level affective bias, we subject the PLMs to an\\nextensive set of class-based and intensity-based evaluations using three\\ndifferent evaluation corpora EEC (Kiritchenko and Mohammad, 2018),\\nBITS (Venkit and Wilson, 2021) and CSP (Nangia et al., 2020). A\\ndetailed sketch of the overall analysis is shown in Fig. 1.\\nThe rest of the paper is organized as follows. Section 2 presents\\nthe relevant related works. Section 3 presents corpus level affective\\n3 Even though, the current interpretation of large language models seems to\\nbe changing to billions of parameters (for e.g., LLaMA (Touvron et al., 2023),\\nFLAN-T5 XXL (Chung et al., 2022), etc.), there are works that utilize the term\\n‘large PLMs’ to indicate PLMs trained on millions of parameters (e.g., Navigli'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 1, 'page_label': '2', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='FLAN-T5 XXL (Chung et al., 2022), etc.), there are works that utilize the term\\n‘large PLMs’ to indicate PLMs trained on millions of parameters (e.g., Navigli\\net al. (2023)). In this study also, we use the term ‘large PLMs’ in the context\\nof having a PLM trained on millions of parameters.\\n2'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 2, 'page_label': '3', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='A. Kadan, Deepak P., S. Bhadra et al. Natural Language Processing Journal 7 (2024) 100062\\nFig. 1. Workflow of Affective bias analysis.\\nbias analysis with corresponding methodology and results. Section 4\\npresents the exploration towards prediction level affective bias with\\ndetails of constructing PLM based textual emotion detection model,\\nmethodology of analysis, and the corresponding results. Section 5\\npresents a discussion based on the entire results and finally, Section 6\\ndraws the conclusions.\\n2. Related works\\nHere we review two categories of algorithmic bias analysis pertinent\\nto our work, i.e., the general affect-agnostic bias analysis and affect-\\noriented bias analysis, and demarcate our work from these related\\nworks.\\n2.1. General affect agnostic bias analysis\\nRecent works in the literature have focused on several approaches\\nto identify the existence of latent biases in PLMs by inspecting at\\nvarious levels, commencing from bias analysis at the corpus level to the'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 2, 'page_label': '3', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='to identify the existence of latent biases in PLMs by inspecting at\\nvarious levels, commencing from bias analysis at the corpus level to the\\ndownstream-task level (Anoop et al., 2022; Suresh and Guttag, 2021).\\nWorks addressing bias at the corpus level analyze the terms relating\\na domain and their associations with key terms against which bias\\nis examined, e.g., the association between gender and stereotypically\\ngendered occupation terms (Bordia and Bowman, 2019; Tan and Celis,\\n2019). In model level analysis, bias are quantified using various metrics\\ndepending on the tasks, where evaluating geometry of the word vector\\nspace (Bolukbasi et al., 2016), performing association tests such as\\nWord Embedding Association Test (Caliskan et al., 2017) and Sentence\\nEncoder Association Test (May et al., 2019), measuring bias of classifi-\\ncation tasks using demographic parity and equal opportunity (Du et al.,\\n2021), etc., are popular approaches in the literature. At the downstream'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 2, 'page_label': '3', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='cation tasks using demographic parity and equal opportunity (Du et al.,\\n2021), etc., are popular approaches in the literature. At the downstream\\ntask level, bias is quantified by comparing the performance scores of a\\nmodel for a set of sentence pairs in an evaluation corpus that differs\\nonly on target terms in which the domain of bias is being studied.\\nFor example, comparing performances of a model for gender-swapped\\nsentences like ‘She is here’ versus ‘He is here’, where the model exhibits\\ngender bias if it produces different performance scores for both sets\\nof sentence pairs. Bias identification at the downstream task level is\\nexplored for a variety of tasks like identification of toxic comments\\n(Dixon et al., 2018), text generation (Nadeem et al., 2021), coreference\\nresolution (Zhao et al., 2018; Lu et al., 2020), etc.\\n2.2. Affect-oriented bias analysis\\nMost affect-oriented bias analysis studies in the literature predom-'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 2, 'page_label': '3', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='resolution (Zhao et al., 2018; Lu et al., 2020), etc.\\n2.2. Affect-oriented bias analysis\\nMost affect-oriented bias analysis studies in the literature predom-\\ninantly focus on the coarse-grained sentiment perspective of these\\nbiases (i.e. positive, negative, and neutral sentiments), and that too\\nmostly specific to gender domain (Yang et al., 2021; Bhaskaran and\\nBhallamudi, 2019; Rozado, 2020; Shen et al., 2018; Sweeney and\\nNajafian, 2020). But, affective bias in context of fine-grained emotion\\nclasses like anger, fear, joy, etc., and the variability of these biases\\nin diverse domains such as religion, politics, race, or intersectional\\nbiases, are not well explored (Anoop et al., 2022), except in Kiritchenko\\nand Mohammad (2018) and Venkit and Wilson (2021). In Kiritchenko\\nand Mohammad (2018) Kiritchenko and Mohammad identify affective\\nbias in the emotion prediction systems developed for the shared task\\nSemEval-2018 Task 1 Affect in Tweets, and in Venkit and Wilson (2021)'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 2, 'page_label': '3', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='bias in the emotion prediction systems developed for the shared task\\nSemEval-2018 Task 1 Affect in Tweets, and in Venkit and Wilson (2021)\\nVenkit et al. identifies affective bias in the domain of persons with\\ndisabilities in sentiment analysis and toxicity classification models; both\\nthese works use a synthetics evaluation corpus to identify affective bias.\\nAffect-oriented bias analysis are seen to be conducted in lexicon\\nand deep learning based sentiment analysis systems (Shen et al., 2018;\\nZhiltsova et al., 2019), and in non-contextual word embeddings such as\\nFastText, GloVe, and Word2Vec to address bias in sentiment analysis\\nand toxicity classification (Sweeney and Najafian, 2020), age-related\\nbias (Díaz et al., 2018) and other underreported bias types (Rozado,\\n2020). Recently several works also address bias in contextual repre-\\nsentations of large PLMs. But most of these works in PLMs address\\ngeneral affect-agnostic biases (Liang et al., 2021; Nadeem et al., 2021;'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 2, 'page_label': '3', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='sentations of large PLMs. But most of these works in PLMs address\\ngeneral affect-agnostic biases (Liang et al., 2021; Nadeem et al., 2021;\\nTan and Celis, 2019; Zhao et al., 2019), very few works address affect-\\noriented biases in PLMs through sentiment perspective (Bhaskaran and\\nBhallamudi, 2019; Yang et al., 2021; Huang et al., 2020), and to our\\nbest knowledge only the work in Mao et al. (2022) investigates affective\\nbias in large PLMs through the perspective of fine-grained emotions, so\\nfar, and that too specifically in prompt-based sentiment and emotion\\ndetection tasks.\\n2.3. Our work in context\\nTo put our work in context, we conduct experiments to identify\\naffective bias in large PLMs through the perspective of fine-grained\\nemotions. Hence, as a natural first step, we consider textual emotion\\ndetection systems, unlike the considerable amount of bias analysis\\nworks in large PLMs relying on text generation, coreference resolution,\\n3'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 3, 'page_label': '4', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='A. Kadan, Deepak P., S. Bhadra et al. Natural Language Processing Journal 7 (2024) 100062\\nprompt-based classification, etc., Mao et al. (2022), Liang et al. (2021),\\nNadeem et al. (2021) and Huang et al. (2020). Our work, in particular,\\nconsiders investigating affective bias in transformer based large PLMs\\ndue to their wide applicability in developing textual emotion detection\\nsystems (Acheampong et al., 2021). Distinct from the recent work (Mao\\net al., 2022) that addresses affective bias in PLMs with respect to label-\\nword, prompt template, etc., specifically focusing on prompt-based\\nsentiment and emotion detection, our work investigates affective bias\\nin four different PLMs with respect to the domains gender, race, and\\nreligion, focusing on fine-tuning based emotion classification. Unlike\\nthe works (Venkit and Wilson, 2021; Kiritchenko and Mohammad,\\n2018) addressing affective bias, we start our investigation from the very'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 3, 'page_label': '4', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='the works (Venkit and Wilson, 2021; Kiritchenko and Mohammad,\\n2018) addressing affective bias, we start our investigation from the very\\ninitial stage of corpus level affective bias analysis, inspired by the works\\n(Bordia and Bowman, 2019; Tan and Celis, 2019) that address corpus\\nlevel general affect-agnostic biases, and later we progress towards\\nanalyzing affective bias in predictions of the PLM based textual emotion\\ndetection models. We conduct a much broader intensity based and class\\nbased affective bias analysis using a set of synthetic (template based)\\nevaluation corpora as well as non-synthetic (crowdsourced) evaluation\\ncorpus that much more suits the real-world scenario.\\n3. Corpus level affective bias\\nThe existence of bias in PLM based language processing systems are\\nobserved due to many sources such as data, annotation, representa-\\ntions, model, etc. (Anoop et al., 2022; Hovy and Prabhumoye, 2021).\\nA substantial amount of works that address general social biases on'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 3, 'page_label': '4', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='tions, model, etc. (Anoop et al., 2022; Hovy and Prabhumoye, 2021).\\nA substantial amount of works that address general social biases on\\ngender and race lines report the existence of data bias from innate\\nhistorical biases as the most primeval source of bias (Corbett-Davies\\net al., 2017; Bordia and Bowman, 2019; Tan and Celis, 2019; Zhao\\net al., 2019). To the best of our knowledge, this is the first attempt\\nthat explore affective bias in large scale textual corpora utilized by\\nPLMs. Hence, as an initial step to explore the affective bias, we conduct\\nexperiments to understand the existence of affective bias if any, in the\\npre-training corpora that are integral ingredients of large PLMs and\\nfine-tuning corpora used to build the textual emotion detection systems.\\nData quality issues, uneven distributions of data, and class imbal-\\nances that target marginalized groups, etc., are the root factors that\\ncontribute towards data bias (Navigli et al., 2023; Hovy and Prab-'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 3, 'page_label': '4', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='ances that target marginalized groups, etc., are the root factors that\\ncontribute towards data bias (Navigli et al., 2023; Hovy and Prab-\\nhumoye, 2021; Subramanian et al., 2021; Anoop et al., 2022). Many\\nworks that address affect agnostic biases focus on exploring data bias by\\nunderstanding any uneven distributions of the target terms associated\\nwithin the domain of interest (Tan and Celis, 2019; Zhao et al., 2019).\\nMotivated by these lines of works, as an initial attempt to unveil the\\ncorpus level affective bias, we follow this simple approach of analyzing\\nthe distributions of affective target terms. A detailed description of pre-\\ntraining and fine-tuning corpora, the method to measure corpus level\\naffective bias, and the analysis of corpus level affective bias are given\\nbelow.\\n3.1. Training corpora\\nOur choice of large scale datasets for corpus level affective bias\\nanalysis hinges on the large PLMs, BERT (Devlin et al., 2019), GPT-2'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 3, 'page_label': '4', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='below.\\n3.1. Training corpora\\nOur choice of large scale datasets for corpus level affective bias\\nanalysis hinges on the large PLMs, BERT (Devlin et al., 2019), GPT-2\\n(Radford et al., 2019), XLNet (Yang et al., 2019), and T5 (Raffel et al.,\\n2020). BERT is trained on Wikipedia dump (WikiEn)4 and BookCorpus\\n(Zhu et al., 2015), GPT-2 is trained on WebText (Radford et al., 2019),\\nXLNet is trained on WikiEn, BookCorpus, Giga5, 5 ClueWeb6 and Com-\\nmon Crawl,7 and T5 is trained on Colossal Clean Crawled Corpus (C4).8\\n4 https://dumps.wikimedia.org/enwiki/.\\n5 https://catalog.ldc.upenn.edu/LDC2011T07.\\n6 https://lemurproject.org/clueweb12/index.php.\\n7 http://commoncrawl.org/.\\n8 https://www.tensorflow.org/datasets/catalog/c4.\\nTable 2\\nDetails of training corpora used for corpus level affective bias analysis.\\nCorpus Size Number of PLM\\nsentences BERT GPT-2 XLNet a T5\\nPre-training corpora\\nWikiEn 19.8 GB 95 917 189 ✓ ✓\\nBookCorpus 6.19 GB 91 025 872 ✓ ✓\\nWebText-250 620 MB 5 314 965 ✓'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 3, 'page_label': '4', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='Corpus Size Number of PLM\\nsentences BERT GPT-2 XLNet a T5\\nPre-training corpora\\nWikiEn 19.8 GB 95 917 189 ✓ ✓\\nBookCorpus 6.19 GB 91 025 872 ✓ ✓\\nWebText-250 620 MB 5 314 965 ✓\\nC4-Val 731 MB 4 959 563 ✓\\nFine-tuning corpora\\nSemEval-2018 925 KB 10 030\\na Giga5, ClueWeb, & Common Crawl used to pre-train XLNet are omitted.\\nFrom these set of large-scale pre-training datasets, we chose WikiEn, 9\\nBookCorpus, WebText, and C4, for our study. The details regarding size\\nof these corpora and number of sentences are shown in Table 2. We\\nomit Giga5 and ClueWeb due to their unavailability as open-source\\ncorpora and Common Crawl as it is reported to have significant data\\nquality issues due to a large number of unintelligible document content\\n(Trinh and Le, 2018; Radford et al., 2019). Since BookCorpus 10 is no\\nlonger hosted by the authors, we choose its open version available in\\nHugging Face.11 We make use of the partially released 250K documents'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 3, 'page_label': '4', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='longer hosted by the authors, we choose its open version available in\\nHugging Face.11 We make use of the partially released 250K documents\\nfrom WebText test set, similar to Tan and Celis (2019), since WebText\\ncorpora has not been fully released and call it WebText-250. 12 As\\nthe train split of C4 corpus is very large (305 GB with 364868892\\ndocuments) and cumbersome to process, we use only a part of the\\ncorpus, i.e., the validation split, and call it C4-Val. Apart from the above\\nmentioned pre-training datasets, we also consider SemEval-2018 EI-oc\\n(Mohammad et al., 2018) that is used to fine-tune the textual emotion\\ndetection model, for our analysis.\\n3.2. Measuring corpus level affective bias\\nInspired by the recent methods to identify gender bias in datasets\\nwith respect to occupations (Tan and Celis, 2019; Zhao et al., 2019), we\\nidentify the existence of affective bias in the large scale corpora used to\\ntrain large PLMs with respect to various domains such as gender, race,'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 3, 'page_label': '4', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='identify the existence of affective bias in the large scale corpora used to\\ntrain large PLMs with respect to various domains such as gender, race,\\nand religion. That is, for a corpus, we identify any imbalances in the\\ndistribution of emotions, or any imbalanced association of the emotions\\ntowards social groups within a domain. Accordingly, for each corpus,\\nwe measure the occurrence of emotion terms representing or related\\nto an emotion and their co-occurrence or association with target terms\\nrepresenting a social group in a domain.\\nAlgorithm 1 illustrates the method of computing occurrence and\\nco-occurrence for a training corpora 𝐷 that is considered as a set of\\nsentences [𝑆1,𝑆2,𝑆3,…] derived from documents in the corpus, where\\neach sentence consists of a sequence of words[𝑤1,𝑤2,𝑤3,…]. The algo-\\nrithm sifts through each word in the sentences of the corpus 𝐷. Once\\na word belonging to the set of emotion terms related to an emotion'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 3, 'page_label': '4', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='rithm sifts through each word in the sentences of the corpus 𝐷. Once\\na word belonging to the set of emotion terms related to an emotion\\n𝐸 (i.e., 𝐸𝑡𝑒𝑟𝑚𝑠) is encountered in a sentence, the algorithm increments\\nthe occurrence of that emotion 𝑜𝑐𝑐𝐸, for that corpus. Similarly in a\\nsentence, once a word related to the emotion 𝐸 co-occurs with a\\nterm belonging to the set of target terms related to a social group 𝑇\\nin a domain (i.e., 𝑇𝑡𝑒𝑟𝑚𝑠), the algorithm increments the co-occurrence\\nof that emotion with the corresponding social group 𝑐𝑜𝑜𝑐𝑐𝑇\\n𝐸, for that\\ncorpus. For example, we increment the occurrence of the emotion Joy\\n(i.e., 𝑜𝑐𝑐𝑗𝑜𝑦), for a corpus, once an emotion term related to Joy like\\n‘happy’, ‘bliss’, ‘cheer’, etc., is encountered in a sentence of the corpus.\\nWe increment the co-occurrence of Joy-Male (i.e., 𝑐𝑜𝑜𝑐𝑐𝑚𝑎𝑙𝑒\\n𝑗𝑜𝑦 ), for the\\n9 Latest Wikipedia dump (date: 02/June/2022), extracted using https://\\ngithub.com/attardi/wikiextractor.\\n10 https://yknzhu.wixsite.com/mbweb.'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 3, 'page_label': '4', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='𝑗𝑜𝑦 ), for the\\n9 Latest Wikipedia dump (date: 02/June/2022), extracted using https://\\ngithub.com/attardi/wikiextractor.\\n10 https://yknzhu.wixsite.com/mbweb.\\n11 https://huggingface.co/datasets/bookcorpus.\\n12 https://github.com/openai/gpt-2-output-dataset.\\n4'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 4, 'page_label': '5', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='A. Kadan, Deepak P., S. Bhadra et al. Natural Language Processing Journal 7 (2024) 100062\\ncorpus, if an emotion term related to Joy co-occurs with target terms\\nrelated to the social group Male like ‘husband’, ‘boy’, ‘brother’, etc.,\\nand increment the co-occurrence of Joy-Female (i.e., 𝑐𝑜𝑜𝑐𝑐𝑓𝑒𝑚𝑎𝑙𝑒\\n𝑗𝑜𝑦 ) if an\\nemotion term related to Joy co-occurs with target terms related to the\\nsocial group Female like ‘wife’, ‘girl’, ‘sister’, etc., in a sentence of the\\ncorpus. Finally, for each social group in a domain, the co-occurrence\\nvalues with respect to each emotion are expressed in percentages.\\nAlgorithm 1:Occurrence and Co-occurrence\\ninput : Corpus 𝐷\\nEmotion terms for emotion 𝐸 (𝐸𝑡𝑒𝑟𝑚𝑠)\\nTarget terms for social group 𝑇 (𝑇𝑡𝑒𝑟𝑚𝑠)\\noutput : Emotion occurrence 𝑜𝑐𝑐𝐸\\nEmotion and Social group co-occurrence 𝑐𝑜𝑜𝑐𝑐𝑇\\n𝐸\\n1 Let 𝐷= [𝑆1,𝑆2,… ,𝑆𝑚] and 𝑆 = [𝑤1,𝑤2,… ,𝑤𝑛] ;\\n2 initialize 𝑜𝑐𝑐𝐸 = 0; 𝑐𝑜𝑜𝑐𝑐𝑇\\n𝐸 = 0; 𝑓𝑙𝑎𝑔 = 𝐹𝑎𝑙𝑠𝑒 ;\\n3 for (𝑗 = 1; 𝑗 ≤ 𝑚; 𝑗+ +)do\\n4 for (𝑖= 1; 𝑖≤ 𝑛; 𝑖+ +)do\\n5 if (𝑤𝑖 ∈ 𝐸𝑡𝑒𝑟𝑚𝑠) then'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 4, 'page_label': '5', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='𝐸\\n1 Let 𝐷= [𝑆1,𝑆2,… ,𝑆𝑚] and 𝑆 = [𝑤1,𝑤2,… ,𝑤𝑛] ;\\n2 initialize 𝑜𝑐𝑐𝐸 = 0; 𝑐𝑜𝑜𝑐𝑐𝑇\\n𝐸 = 0; 𝑓𝑙𝑎𝑔 = 𝐹𝑎𝑙𝑠𝑒 ;\\n3 for (𝑗 = 1; 𝑗 ≤ 𝑚; 𝑗+ +)do\\n4 for (𝑖= 1; 𝑖≤ 𝑛; 𝑖+ +)do\\n5 if (𝑤𝑖 ∈ 𝐸𝑡𝑒𝑟𝑚𝑠) then\\n6 𝑓𝑙𝑎𝑔 = 𝑇𝑟𝑢𝑒;\\n7 𝑜𝑐𝑐𝐸 = 𝑜𝑐𝑐𝐸 + 1;\\n8 break;\\n9 end\\n10 end\\n11 for (𝑖= 1; 𝑖≤ 𝑛; 𝑖+ +)do\\n12 if (𝑤𝑖 ∈ 𝑇𝑡𝑒𝑟𝑚𝑠 and 𝑓𝑙𝑎𝑔 = 𝑇𝑟𝑢𝑒) then\\n13 𝑐𝑜𝑜𝑐𝑐𝑇\\n𝐸 = 𝑐𝑜𝑜𝑐𝑐𝑇\\n𝐸 + 1;\\n14 break;\\n15 end\\n16 end\\n17 end\\n18 output 𝑜𝑐𝑐𝐸, 𝑐𝑜𝑜𝑐𝑐𝑇\\n𝐸\\nTo conduct this study on corpus level affective bias, we maintain\\na list of emotion terms (or affective terms) for the basic emotions\\n𝐸 = {𝑎𝑛𝑔𝑒𝑟,𝑓𝑒𝑎𝑟,𝑗𝑜𝑦,𝑠𝑎𝑑𝑛𝑒𝑠𝑠 }, because our emotion prediction models\\n(discussed in Section 4.1, to identify affective bias in model predic-\\ntions) relies on these categories of basic emotions. Hence, initially, we\\nprocure a list of affective terms collectively from Parrott’s primary,\\nsecondary, and tertiary emotions,13 and refer the works Kiritchenko and\\nMohammad (2018) and Venkit and Wilson (2021), to represent these'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 4, 'page_label': '5', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='secondary, and tertiary emotions,13 and refer the works Kiritchenko and\\nMohammad (2018) and Venkit and Wilson (2021), to represent these\\nbasic emotions. Later, we extend this list of affective terms by including\\nlinguistic inflections of each word in the list using Merriam-Webster 14\\ndictionary and an automated python package pyinflect. 15 As a result\\nthe entire list contains 735 affective terms (given in supplementary\\nmaterial), where 162 represent anger, 143 fear, 222 joy, and 208\\nsadness.\\nA similar procedure is carried out to procure target terms related to\\na social group within gender, race, and religion, the domains that are\\nconsidered in this study. In domain gender, the target terms considered\\nrepresent three social groups 𝑇 = {𝑀,𝐹,𝑁𝑏 } for Male, Female, and\\nNon-binary groups. Similarly in domain race, we consider European\\nAmerican and African American social groups i.e., 𝑇 = {𝐸𝐴,𝐴𝐴}, and\\nfor religion, we consider Christian, Muslim, and Jewish social groups'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 4, 'page_label': '5', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='American and African American social groups i.e., 𝑇 = {𝐸𝐴,𝐴𝐴}, and\\nfor religion, we consider Christian, Muslim, and Jewish social groups\\ni.e., 𝑇 = { 𝐶ℎ,𝑀𝑢,𝐽𝑤 }. An initial list of target terms representing\\nthese social groups is prepared collectively by referring to the works\\n(Bolukbasi et al., 2016; Lu et al., 2020; Guo and Caliskan, 2021;\\nNadeem et al., 2021; Liang et al., 2021; Kaneko and Bollegala, 2022),\\nwhich is later expanded by adding linguistic inflections. As these works\\ndo not consider target terms related to the non-binary social group\\nin the gender domain, we manually curated the corresponding target\\n13 https://en.wikipedia.org/wiki/Emotion_classification#Parrott’s_emotions_\\nby_groups.\\n14 https://www.merriam-webster.com/.\\n15 https://pypi.org/project/pyinflect/.\\nterms from various articles and web resources (e.g. Center (2022)) and\\nverified these terms with the help of an expert in gender studies. The\\nentire list contains 507, 167, and 332 target terms in the domains'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 4, 'page_label': '5', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='verified these terms with the help of an expert in gender studies. The\\nentire list contains 507, 167, and 332 target terms in the domains\\nof gender, race, and religion, respectively (given in supplementary\\nmaterial), with 199 male, 211 female, and 97 non-binary target terms\\nfor the gender domain, 82 African American and 85 European American\\ntarget terms for the racial domain, and 122 Muslim, 111 Jewish, and\\n99 Christian target terms for the religious domain.\\n3.3. Results and analysis of corpus level affective bias\\nIn this section, we present the results of occurrence of emotions\\nin the corpora and their co-occurrence with social groups in various\\ndomains of gender, race, and religion to analyze corpus level affective\\nbias.\\n3.3.1. Occurrence of emotions in the corpora\\nResults of the occurrence statistics of emotions for our corpus level\\naffective bias analysis are shown in Table 3. The trends of emotion\\noccurrence illustrate that, for all the corpora, the occurrence of affective'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 4, 'page_label': '5', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='affective bias analysis are shown in Table 3. The trends of emotion\\noccurrence illustrate that, for all the corpora, the occurrence of affective\\nterms related to joy is consistently higher than all other emotions;\\nescalating joy from the next highest occurring emotionsfear and sadness\\nminimally by a factor of 1.1 in SemEval-2018 EI-oc and maximum by\\na factor of 5.6 in C4-Val, respectively. The predominance of joy in\\ntextual corpora can be possibly due to the reason that, psychologically\\npeople are inclined towards expressing more positive emotions on the\\nweb (Vittengl and Holt, 1998; De Choudhury et al., 2012; Staiano and\\nGuerini, 2014; Waterloo et al., 2018). On the other side, for all the\\ncorpora, the instances of anger are consistently very low in count. The\\nstandard deviation computed to measure the dispersion between the\\noccurrence of various emotions within a corpus shows that there exists\\na large disparity between the occurrence of emotions within a corpus,'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 4, 'page_label': '5', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='occurrence of various emotions within a corpus shows that there exists\\na large disparity between the occurrence of emotions within a corpus,\\nparticularly in the large scale corpora used to pre-train PLMs. In total,\\nthe occurrence statistics over the four basic emotions anger, fear, joy\\nand sadness, clearly affirms the existence of emotion imbalances in both\\nPLM pre-training and fine-tuning corpora.\\nBookCorpus contains the highest number of total affective words\\namong all other corpora considered. This brings to another observation\\nthat despite BookCorpus being almost one-third of the size of WikiEn,\\nthe number of affective words in BookCorpus exceeds WikiEn by a\\nfactor of 1.3. We presume this is because BookCorpus being a large\\ncorpus curated from books in the web, contains more affective words\\nthan WikiEn curated from Wikipedia articles in the web.\\n3.3.2. Co-occurrence of emotions with social groups\\nThe co-occurrence statistics of basic emotions with various social'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 4, 'page_label': '5', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='than WikiEn curated from Wikipedia articles in the web.\\n3.3.2. Co-occurrence of emotions with social groups\\nThe co-occurrence statistics of basic emotions with various social\\ngroups in gender, racial and religious domains for each corpus is\\nillustrated in Table 4, where the domains are separated column wise\\nand emotions are grouped across the rows. We look into each domain\\nseparately, (in the order of gender, race, and religion) and analyze the\\nassociation of emotion categories (in the order of anger, fear, joy, and\\nsadness) with social groups in these domains.\\n(A) Emotion Co-occurrence with Gender Domain: In the gender do-\\nmain, anger mostly co-occurs with the non-binary and female\\nsocial groups than male. Fear is always highly associated with\\nthe non-binary group, followed secondly by female. The positive\\nemotion joy is found to mostly co-occur with male, but, it has\\nthe least co-occurrence with non-binary gender. Sadness mostly'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 4, 'page_label': '5', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='the non-binary group, followed secondly by female. The positive\\nemotion joy is found to mostly co-occur with male, but, it has\\nthe least co-occurrence with non-binary gender. Sadness mostly\\nco-occurs with non-binary and female groups, similar to anger.\\nFor the fine-tuning corpus SemEval-2018, in particular, there\\nis no instance of co-occurrence between any of the emotions\\nand non-binary gender, this is due to the lack of non-binary\\ngender terms in the corpus; also, for this corpus, negative emo-\\ntions such as, anger, fear, and sadness are always found to have\\nhigh co-occurrence with female gender and the positive emotion\\n5'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 5, 'page_label': '6', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='A. Kadan, Deepak P., S. Bhadra et al. Natural Language Processing Journal 7 (2024) 100062\\nTable 3\\nOccurrence statistics of emotions in the corpora.\\nCorpus Anger Fear Joy Sadness Total affective words Standard deviation\\nWikiEn 533 111 745 221 2 479 326 1 802 466 5 560 124 914 103.94\\nBookCorpus 1 049 407 1 647 267 3 143 907 1 400 423 7 241 004 922 324.00\\nWebText-250k 50 207 85 325 220 354 88 749 444 635 74 851.63\\nC4-Val 33 182 66 239 394 413 69 686 563 520 169 821.19\\nSemEval-2018 984 1 472 1 579 1 131 5 166 280.21\\nTable 4\\nCo-occurrence statistics of basic emotions with various domains in corpora (in\\npercentage).\\nCorpus Co-occurrence with\\nGender Race Religion\\nM F Nb EA AA Ch Mu Jw\\nAnger\\nWikiEn 12.12 13.41 14.25 10.44 10.68 8.55 11.69 13.93\\nBookCorpus 17.61 16.15 19.02 15.09 17.06 12.20 13.74 18.64\\nWebText-250k 14.13 14.24 11.46 15.05 16.53 12.86 15.05 19.55\\nC4-Val 9.32 9.08 6.02 7.06 7.71 6.22 11.19 13.49\\nSemEval-2018 22.36 24.56 0 22.55 52.17 15.79 15.06 0\\nFear'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 5, 'page_label': '6', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='WebText-250k 14.13 14.24 11.46 15.05 16.53 12.86 15.05 19.55\\nC4-Val 9.32 9.08 6.02 7.06 7.71 6.22 11.19 13.49\\nSemEval-2018 22.36 24.56 0 22.55 52.17 15.79 15.06 0\\nFear\\nWikiEn 12.61 15.09 21.01 14.73 14.62 9.81 17.03 16.05\\nBookCorpus 22.03 24.00 25.05 23.09 23.52 14.65 21.42 16.44\\nWebText-250k 19.56 21.80 23.02 21.11 21.02 16.66 36.00 28.39\\nC4-Val 13.95 13.79 16.87 13.56 13.46 9.33 23.09 19.70\\nSemEval-2018 25.36 26.06 0 31.37 10.87 36.84 62.16 75.00\\nJoy\\nWikiEn 40.81 40.81 39.18 45.46 45.31 51.94 36.47 41.93\\nBookCorpus 41.09 40.01 38.40 44.01 41.07 51.12 44.53 40.77\\nWebText-250k 44.25 40.01 42.79 43.69 42.44 47.54 25.06 27.53\\nC4-Val 57.76 61.28 55.42 63.49 63.95 68.05 44.28 45.75\\nSemEval-2018 33.53 30.83 0 34.31 13.04 27.02 12.16 25.00\\nSadness\\nWikiEn 34.46 30.70 25.56 29.37 29.38 29.70 34.81 28.09\\nBookCorpus 19.76 19.84 21.02 18.11 18.55 22.03 20.30 24.14\\nWebText-250k 24.05 25.25 20.83 20.75 20.51 22.94 24.09 24.52\\nC4-Val 18.96 16.95 21.69 15.89 14.88 16.40 21.44 21.05'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 5, 'page_label': '6', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='BookCorpus 19.76 19.84 21.02 18.11 18.55 22.03 20.30 24.14\\nWebText-250k 24.05 25.25 20.83 20.75 20.51 22.94 24.09 24.52\\nC4-Val 18.96 16.95 21.69 15.89 14.88 16.40 21.44 21.05\\nSemEval-2018 17.75 19.05 0 11.76 23.91 21.05 10.81 0\\njoy is found to have high co-occurrence with male. The over-\\nall co-occurrence statistics of the gender domain illustrate that\\nnegative emotions mostly co-occur with the non-binary gender\\ngroup, followed by female, and conversely, positive emotions\\nco-occur mostly with the male group. The observations thus\\nclearly dictate imbalanced associations between affective terms\\nand social groups of gender domain, in both pre-training and\\nfine-tuning corpora.\\n(B) Emotion Co-occurrence with Racial Domain: Evaluation results\\nover the racial domain illustrate that the negative emotions\\nanger and sadness mostly co-occur with African American race\\ngroup, whereas negative emotion fear and the positive emotion\\njoy mostly co-occur with European American. But, for all the'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 5, 'page_label': '6', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='anger and sadness mostly co-occur with African American race\\ngroup, whereas negative emotion fear and the positive emotion\\njoy mostly co-occur with European American. But, for all the\\npre-training corpora, the imbalance of co-occurrence values in\\nthe racial domain is comparatively less than the previously\\ndiscussed gender domain; for example, imbalance in the co-\\noccurrence of all emotions with the racial groups is negligible\\nin the case of WikiEn corpus. Contrary to the observations of\\npre-training corpora, in fine-tuning corpus SemEval-2018, there\\nexists a large difference in co-occurrence values between African\\nand European American groups. That is, in SemEval-2018, the\\nnegative emotions anger and sadness co-occur with the African\\nAmerican race double the times than European American, indi-\\ncating highly imbalanced association of anger and sadness with\\nAfrican American race. Whereas, the co-occurrence of negative\\nemotion fear and positive emotion joy with European American'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 5, 'page_label': '6', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='cating highly imbalanced association of anger and sadness with\\nAfrican American race. Whereas, the co-occurrence of negative\\nemotion fear and positive emotion joy with European American\\ngroup is almost thrice African American, again indicating a\\nhighly imbalanced association, that of fear and joy emotions in\\nSemEval-2018 with European American group.\\n(C) Emotion Co-occurrence with Religious Domain:Analysis in the do-\\nmain of religion shows that anger mostly co-occurs with Jewish\\nand fear mostly co-occurs with Muslim. Whereas, joy is always\\nfound to have maximum co-occurrence with Christian.Sadness is\\nfound to mostly co-occur with Muslim and Jew religious groups\\nthan Christian. The results thus shows existence of high co-\\noccurrence between negative emotions anger, fear, and sadness\\nwith Muslim and Jew, whereas the positive emotion joy with\\nChristian. Moreover, when considering previous observations\\nof gender and racial domains, the imbalance in the religious'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 5, 'page_label': '6', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='with Muslim and Jew, whereas the positive emotion joy with\\nChristian. Moreover, when considering previous observations\\nof gender and racial domains, the imbalance in the religious\\ndomain is comparatively higher.\\nThe entire occurrence and co-occurrence analysis over gender, race\\nand religious domains thus consolidate the existence of corpus level\\naffective bias in pre-training and fine-tuning corpora. The extensions of\\nsuch corpora holding latent affect imbalances, to build computational\\nmodels may eventually trigger chances of bias in learning models,\\nespecially when building large scale contextual pre-trained language\\nmodels that extract all possible properties of a language.\\n4. Prediction level affective bias\\nTo identify the existence of prediction level affective bias, if any,\\nin the perspective of large PLMs, we utilize textual emotion detection\\nsystems built using popular large PLMs that are fine-tuned using an\\nemotion detection corpus. We evaluate the existence of affective bias'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 5, 'page_label': '6', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='systems built using popular large PLMs that are fine-tuned using an\\nemotion detection corpus. We evaluate the existence of affective bias\\nin the context of domains gender, race, and religion via different\\nsynthetic and non-synthetic paired evaluation sentence corpora and\\nan extensive set of evaluation measures. Details of our investigation,\\nincluding description and settings of textual emotion detection models\\nbased on large PLMs, the method to measure prediction level affective\\nbias with the details of evaluation corpora and measures, and the\\nresults and analysis of prediction level affective bias, are given below.\\n4.1. Textual emotion detection using large PLMs\\nWe formulate the task of textual emotion detection as a four-class\\nclassification system with classes being the basic emotions anger, fear,\\njoy, and sadness. For this classification task, we utilize pre-trained lan-\\nguage models and fine-tune them with an aim to find the best-fit map-'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 5, 'page_label': '6', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='joy, and sadness. For this classification task, we utilize pre-trained lan-\\nguage models and fine-tune them with an aim to find the best-fit map-\\nping function 𝑓 ∶ 𝑦 = 𝑓(𝑥) for the fine-tuning data (𝑥1,𝑦1),(𝑥2,𝑦2),… ,\\n(𝑥𝑁,𝑦𝑁) with 𝑁 documents, where 𝑥𝑖 indicates ith document in the\\nfine-tuning corpus and 𝑦𝑖 indicates the corresponding ground-truth\\nemotion.\\nThe choice of PLMs, GPT-2 (Radford et al., 2019), BERT (De-\\nvlin et al., 2019), XLNet (Yang et al., 2019), and T5 (Raffel et al.,\\n2020), that are utilized in this study to identify affective bias, is\\nmotivated by considering their acceptance as relevant and neoteric\\ncontextualized models with high performance efficacy towards textual\\nemotion detection (Adoma et al., 2020; Acheampong et al., 2021)\\nand the much related task of sentiment analysis (Zhang et al., 2020;\\nTabinda Kokab et al., 2022) within the area of affective computing.\\nGPT and BERT are the very popular PLMs that follow the most ef-'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 5, 'page_label': '6', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='Tabinda Kokab et al., 2022) within the area of affective computing.\\nGPT and BERT are the very popular PLMs that follow the most ef-\\nfective auto-regressive and auto-encoding self-supervised pre-training\\nobjectives, respectively, where GPT uses transformer decoder blocks,\\nwhereas BERT uses transformer encoder blocks. The autoregressive\\n6'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 6, 'page_label': '7', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='A. Kadan, Deepak P., S. Bhadra et al. Natural Language Processing Journal 7 (2024) 100062\\nTable 5\\nFine-tuning corpus statistics.\\nEmotions Number of documents\\nTraining Validation\\nAnger 2089 388\\nFear 2641 389\\nJoy 1906 290\\nSadness 1930 397\\nnature of GPT helps to effectively encode sequential knowledge and\\nachieve good results (Radford et al., 2019). On the other hand, by\\neliminating the autoregressive objective and alleviating unidirectional\\nconstraints through the masked language model pre-training objective,\\nBERT attains powerful bi-directional representations. This ability of\\nBERT to learn context from both sides of a word makes it an empirically\\npowerful state-of-the-art model (Devlin et al., 2019). XLNet brings back\\nthe auto-regressive pre-training objective with alternate ways to extract\\ncontext from both sides of a word and overcome the pretrain-finetune\\ndiscrepancy of BERT outperforming it in several downstream NLP tasks'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 6, 'page_label': '7', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='context from both sides of a word and overcome the pretrain-finetune\\ndiscrepancy of BERT outperforming it in several downstream NLP tasks\\n(Yang et al., 2019). The development of T5 explores the landscape of\\nNLP transfer learning and proposes a unified framework that converts\\nall textual language related problems into the text-to-text format and\\nachieves improved performance (Raffel et al., 2020).\\nEach pre-trained language model (PLM) after fine-tuning and appli-\\ncation of softmax function at the final layer forms the textual emotion\\ndetection model (i.e., softmax(PLM)). For each textual document 𝑑, the\\nfine-tuned textual emotion detection models predict an emotion class\\n̂ 𝑒𝑐𝑙𝑎𝑠𝑠 by finding the highest prediction intensity score ̂ 𝑒𝑠𝑐𝑜𝑟𝑒 among 𝐸\\nclasses of emotions (namely anger, fear, joy, and sadness, for our task)\\nrepresented as,\\n̂ 𝑒𝑐𝑙𝑎𝑠𝑠(𝑑) = argmax\\n𝑘∈1,2,…,𝐸\\n𝑠𝑜𝑓𝑡𝑚𝑎𝑥(𝑃𝐿𝑀(𝑑)) (1)\\n̂ 𝑒𝑠𝑐𝑜𝑟𝑒(𝑑) = max\\n𝑘∈1,2,…,𝐸\\n𝑠𝑜𝑓𝑡𝑚𝑎𝑥(𝑃𝐿𝑀(𝑑)) (2)'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 6, 'page_label': '7', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='classes of emotions (namely anger, fear, joy, and sadness, for our task)\\nrepresented as,\\n̂ 𝑒𝑐𝑙𝑎𝑠𝑠(𝑑) = argmax\\n𝑘∈1,2,…,𝐸\\n𝑠𝑜𝑓𝑡𝑚𝑎𝑥(𝑃𝐿𝑀(𝑑)) (1)\\n̂ 𝑒𝑠𝑐𝑜𝑟𝑒(𝑑) = max\\n𝑘∈1,2,…,𝐸\\n𝑠𝑜𝑓𝑡𝑚𝑎𝑥(𝑃𝐿𝑀(𝑑)) (2)\\nTo fine-tune PLMs and build emotion detection models, we use\\n24-layered version of the pre-trained BERT, GPT-2, XLNet, and T5\\navailable at HuggingFace, 16 i.e., bert-large-uncased,17 gpt2-medium,18\\nxlnet-large-cased,19 and t5-large, 20 respectively, and update these ar-\\nchitectures by adding a final dense layer of four neurons with softmax\\nactivation function on top of the base models to suit our four class\\nclassification task. For our study, the choice of GPT-2 instead of the\\nlatest version GPT-3 (Brown et al., 2020) is due to its unavailability as\\nan open-source pre-trained model. All four models are fine-tuned using\\na popular affect detection corpus SemEval-2018 EI-oc (Mohammad\\net al., 2018) that consists a total of 10 030 data instances for the'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 6, 'page_label': '7', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='a popular affect detection corpus SemEval-2018 EI-oc (Mohammad\\net al., 2018) that consists a total of 10 030 data instances for the\\nemotions anger, fear, joy, and sadness. The fine-tuning corpus is split as\\n8566 data instances for training and 1464 data instances for validation;\\ndetails of the number of data instances belonging to each emotion\\ncategory in the train and validation splits are shown in Table 5.\\nThe hyperparameters that can aid the reproducibility of our emotion\\ndetection models are, for GPT-2, XLNet, and T5 we useAdam optimizer\\nwith learning rate 0.000001, categorical crossentropy loss function,\\nand 100 epochs, whereas for BERT the learning rate is 0.00001 and\\nrest of the above mentioned parameters are the same. The batch size\\nis set to 80 for BERT, XLNet, and T5, whereas 64 for GPT-2. The\\ntotal number of trainable parameters for our BERT, GPT-2, XLNet,\\nand T5 textual emotion detection models come out as 335145988,'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 6, 'page_label': '7', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='is set to 80 for BERT, XLNet, and T5, whereas 64 for GPT-2. The\\ntotal number of trainable parameters for our BERT, GPT-2, XLNet,\\nand T5 textual emotion detection models come out as 335145988,\\n354827268, 360272900, and 334943748, respectively. All experiments\\nwere conducted on a deep learning workstation equipped with Intel\\n16 https://huggingface.co/.\\n17 https://huggingface.co/docs/transformers/model_doc/bert.\\n18 https://huggingface.co/docs/transformers/model_doc/gpt2.\\n19 https://huggingface.co/docs/transformers/model_doc/xlnet.\\n20 https://huggingface.co/docs/transformers/model_doc/t5.\\nXeon Silver 4208 CPU at 2.10 GHz, 256 GB RAM, and two GPUs\\nof NVIDIA Quadro RTX 5000 (16 GB for each), using the libraries\\nTensorflow (version 2.8.0), Keras (version 2.8.0), Transformer (version\\n4.17.0), and NLTK (version 3.6.5).\\n4.2. Measuring prediction level affective bias\\nThe textual emotion detection models, when supplied with a docu-'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 6, 'page_label': '7', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='4.17.0), and NLTK (version 3.6.5).\\n4.2. Measuring prediction level affective bias\\nThe textual emotion detection models, when supplied with a docu-\\nment/sentence, predict as output the emotion class and corresponding\\nemotion intensity of the document/sentence. To identify prediction\\nlevel affective bias in textual emotion detection models, we input into\\nthese models a sentence pair that differs only in key terms representing\\ndifferent social groups, with an aim to compare and contrast between\\nemotion predictions of sentences in that pair. For instance, sentence\\npairs such as ‘ She made me feel angry’ versus ‘ He made me feel angry’\\nthat only differ in key terms representing female and male social groups\\nconcerning gender domain, or ‘ African American people can dance very\\nwell’ versus ‘ European American people can dance very well’ that only\\ndiffer in key terms representing African American and European Amer-\\nican social groups concerning racial domain, are input to the models'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 6, 'page_label': '7', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='differ in key terms representing African American and European Amer-\\nican social groups concerning racial domain, are input to the models\\nto compare and contrast between emotion predictions of sentences in\\nthese pairs. Comparing emotion predictions using such sentence pairs\\nhelps to pair-wise analyze and understand whether algorithmic deci-\\nsions of emotion classification are similar (or different) across different\\nsocial groups within a domain. Accordingly, to identify prediction level\\naffective bias, we use evaluation corpora that consist of sentence pairs\\ndiffering only in key terms representing various social groups.\\nThe prediction of emotion class for a sentence is decided by the\\nintensity of emotions predicted by the textual emotion detection model\\nfor that sentence. For example, for a prediction ̂𝐸𝑠𝑐𝑜𝑟𝑒(𝑑) = {0.5,0.2,\\n0.1,0.2}, the choice of emotion class from the set 𝐸 = {𝑎𝑛𝑔𝑒𝑟,𝑓𝑒𝑎𝑟,\\n𝑗𝑜𝑦,𝑠𝑎𝑑𝑛𝑒𝑠𝑠}, would be anger. Differences in the intensities of emotion'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 6, 'page_label': '7', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='0.1,0.2}, the choice of emotion class from the set 𝐸 = {𝑎𝑛𝑔𝑒𝑟,𝑓𝑒𝑎𝑟,\\n𝑗𝑜𝑦,𝑠𝑎𝑑𝑛𝑒𝑠𝑠}, would be anger. Differences in the intensities of emotion\\npredictions between sentences in a pair show existence of affective bias\\nat the intensity level, which when higher enough can alter the predic-\\ntion of emotion class and thereby cause affective bias at the class level.\\nThat is, an unbiased model is expected to predict the same emotion\\nclass and intensities for the sentence pairs that only differ in key terms\\nrepresenting different social groups. Hence, to analyze affective bias in\\nthe predictions, we utilize class based and intensity based evaluation\\nmeasures capable of comparing predictions of these sentence pairs. The\\nevaluation corpora and measures are detailed below.\\n4.2.1. Evaluation corpora\\nOur choice of bias evaluation corpora is based on the objective\\nto identify affective bias in textual emotion detection models using'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 6, 'page_label': '7', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='4.2.1. Evaluation corpora\\nOur choice of bias evaluation corpora is based on the objective\\nto identify affective bias in textual emotion detection models using\\nsentence pairs that only differ in key terms representing social groups,\\nconcerning either gender, racial, or religious domain. Suitably, we\\nutilize three different evaluation corpora, Equity Evaluation Corpus\\n(EEC) (Kiritchenko and Mohammad, 2018), Bias Identification Test\\nin Sentiments (BITS) corpus (Venkit and Wilson, 2021), and Crowd-\\nsourced Stereotype Pairs (CSP) corpus (Nangia et al., 2020). Similar\\nto most bias evaluation corpora, EEC and BITS contain template based\\nsynthetically created sentences along with ground truth emotions. On\\nthe contrary, CSP is a crowd sourced non-synthetic bias evaluation\\ncorpus that possesses greater diversity within data in the perspective\\nof context expressed and structure of sentence pairs, but it does not\\ncontain ground truth emotions.'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 6, 'page_label': '7', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='corpus that possesses greater diversity within data in the perspective\\nof context expressed and structure of sentence pairs, but it does not\\ncontain ground truth emotions.\\nEEC consists of a total of 8640 sentences capable of evaluating\\ngender and racial domains, from which we select 8400 sentences for\\nour study after excluding 240 sentences with no emotion words. For\\nthe gender domain, the sentence pairs in EEC represent only two social\\ngroups, female and male. To tease out affective bias towards the gender\\ndomain, we select 1400 sentence pairs. For the racial domain, the\\nsentence pairs represent African American and European American\\nsocial groups, and we select 2800 sentence pairs to analyze affective\\nbias in racial domain.\\n7'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 7, 'page_label': '8', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='A. Kadan, Deepak P., S. Bhadra et al. Natural Language Processing Journal 7 (2024) 100062\\nBITS consists of a total of 720 sentences capable of evaluating\\ngender and racial domains. In BITS, the sentence pairs for gender\\ndomain also include the non-binary social group besides female and\\nmale groups. For this study, we select the available 120 sentences\\nfor each non-binary, female, and male social group in the gender\\ndomain. The racial domain includes social groups such as American\\nIndian, Asian, and Latino, apart from African American and European\\nAmerican groups. For this study, we only select the available small\\nset of 72 sentence pairs representing African American and European\\nAmerican social groups, as we limit our investigation only to these two\\nracial groups.\\nCSP contains 1508 sentence pairs that cover nine domains, includ-\\ning gender, race, religion, age, nationality, etc., that, unlike EEC and\\nBITS, do not differ ‘only’ on a single key term. A sample sentence pair in'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 7, 'page_label': '8', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='ing gender, race, religion, age, nationality, etc., that, unlike EEC and\\nBITS, do not differ ‘only’ on a single key term. A sample sentence pair in\\nCSP for the racial domain is ‘African Americanpeople are notvery ambi-\\ntious as a whole’ versus ‘European Americanpeople arevery ambitious as a\\nwhole’. Such sentence pairs violate our evaluation setting of considering\\nsentence pairs that ‘only’ differ in key terms representing certain social\\ngroups, an evaluation strategy to identify bias. But considering the\\nusefulness of such a non-synthetic corpus that suits the real-world con-\\ntext, we manually evaluate all sentence pairs in CSP and modify them\\n(if required) to suit our evaluation settings. An example of modified\\nversions for the above mentioned sentence pair is, ‘ African American\\npeople are not very ambitious as a whole’ versus ‘European Americanpeople\\nare not very ambitious as a whole’, and ‘ African American people are'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 7, 'page_label': '8', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='people are not very ambitious as a whole’ versus ‘European Americanpeople\\nare not very ambitious as a whole’, and ‘ African American people are\\nvery ambitious as a whole’ versus ‘ European American people are very\\nambitious as a whole’. Finally, after such modifications and exclusion\\nof pairs belonging to domains other than gender, race, and religion,\\nwe gather 1970 sentences, where the gender domain consists of 263\\nsentence pairs representing female and male, the racial domain consists\\nof 566 sentence pairs representing African Americans and European\\nAmericans, and religious domain consists of 104 sentences each for\\nChristian, Jew, and Muslim social groups.\\nEven though in some evaluation corpora, certain domains consist\\nof three social groups (e.g. in BITS, the gender domain consists of\\nmale, female, and non-binary social groups, in CSP, the religious do-\\nmain consists of Christian, Jew, and Muslim groups), our evaluation'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 7, 'page_label': '8', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='male, female, and non-binary social groups, in CSP, the religious do-\\nmain consists of Christian, Jew, and Muslim groups), our evaluation\\nstrategies are limited to pair-wise evaluations, to maintain commonality\\namong all the domains. That is, for all the evaluation corpora, from the\\navailable set of social groups, we conduct pair-wise evaluations for the\\npairs, Male versus Female (M × F), Male versus Non-binary (M × Nb),\\nor Female versus Non-binary (F × Nb) in gender domain, European\\nAmerican versus African American (EA × AA) in the racial domain, and\\nChristian versus Muslim (Ch × Mu), Christian versus Jew (Ch × Jw) or\\nMuslim versus Jew (Mu × Jw) in the religious domain.\\n4.2.2. Evaluation measures\\nFor an evaluation corpus with 𝑁 sentence pairs, we denote 𝑠𝑝𝑔1\\n𝑖 and\\n𝑠𝑝𝑔2\\n𝑖 as the ith sentence pair representing two social groups 𝑔1 and 𝑔2\\n(e.g. Male versus Female), respectively, in a domain (e.g. gender). We\\nevaluate the existence of prediction level affective bias using different'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 7, 'page_label': '8', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='(e.g. Male versus Female), respectively, in a domain (e.g. gender). We\\nevaluate the existence of prediction level affective bias using different\\nmeasures that rely on class ( ̂ 𝑒𝑐𝑙𝑎𝑠𝑠) and intensity ( ̂ 𝑒𝑠𝑐𝑜𝑟𝑒) predictions of\\nthe textual emotion detection models, details follow.\\n• Demographic Parity (DP): A popular class based measure to quan-\\ntify group fairness/bias of a classifier system, commonly used\\nto address general affect-agnostic biases like gender bias, racial\\nbias, etc. Du et al. (2021). We utilize this measure to identify\\nthe existence of affective bias and check whether the model’s\\nemotion classifications are similar (or different) across different\\nsocial groups within a domain. Accordingly, we say that a textual\\nemotion detection model satisfies demographic parity if,\\nDP = 𝑃(̂ 𝑒𝑐𝑙𝑎𝑠𝑠(𝑠𝑝𝑔1 ) =𝑒|𝑧= 𝑔1)\\n𝑃(̂ 𝑒𝑐𝑙𝑎𝑠𝑠(𝑠𝑝𝑔2 ) =𝑒|𝑧= 𝑔2) , 𝑒 ∈ 𝐸 and 𝑔1,𝑔2 ∈ 𝑇 (3)\\nwhere, 𝑃(̂ 𝑒𝑐𝑙𝑎𝑠𝑠(𝑠𝑝𝑔1 ) = 𝑒|𝑧 = 𝑔1) and 𝑃(̂ 𝑒𝑐𝑙𝑎𝑠𝑠(𝑠𝑝𝑔2 ) = 𝑒|𝑧 = 𝑔2)'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 7, 'page_label': '8', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='DP = 𝑃(̂ 𝑒𝑐𝑙𝑎𝑠𝑠(𝑠𝑝𝑔1 ) =𝑒|𝑧= 𝑔1)\\n𝑃(̂ 𝑒𝑐𝑙𝑎𝑠𝑠(𝑠𝑝𝑔2 ) =𝑒|𝑧= 𝑔2) , 𝑒 ∈ 𝐸 and 𝑔1,𝑔2 ∈ 𝑇 (3)\\nwhere, 𝑃(̂ 𝑒𝑐𝑙𝑎𝑠𝑠(𝑠𝑝𝑔1 ) = 𝑒|𝑧 = 𝑔1) and 𝑃(̂ 𝑒𝑐𝑙𝑎𝑠𝑠(𝑠𝑝𝑔2 ) = 𝑒|𝑧 = 𝑔2)\\nindicates the probabilities of the two social groups 𝑔1 and 𝑔2,\\nrespectively, to predict an emotion 𝑒; 𝑔2 is taken as the group\\nwith higher probability (Feldman et al., 2015). 𝐸 is the set of\\nall emotions, and 𝑇 is the set of social groups in a domain.\\nDemographic parity advocates the likelihood of emotion predic-\\ntion outcomes of sentence pairs that differ only in key terms\\ndenoting a certain social group should be the same; as a result,\\nDP=1 indicates an ideal unbiased scenario, whereas, lower the\\nvalues higher the existence of bias. Therefore, we use the general\\nthreshold 𝜏 = 0.80, lower than which indicates biased predictions\\n(Feldman et al., 2015).\\n• Average Difference of Prediction Intensity Scores ( 𝑎𝑣𝑔.𝛥): An\\nintensity based measure that computes the average difference of'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 7, 'page_label': '8', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='(Feldman et al., 2015).\\n• Average Difference of Prediction Intensity Scores ( 𝑎𝑣𝑔.𝛥): An\\nintensity based measure that computes the average difference of\\nemotion prediction intensity scores between the sentence pairs\\nof two social groups in a domain (Kiritchenko and Mohammad,\\n2018).\\n𝑎𝑣𝑔.𝛥= 1\\n𝑁\\n𝑁∑\\n𝑖=1\\n|̂ 𝑒𝑠𝑐𝑜𝑟𝑒(𝑠𝑝𝑔1\\n𝑖 ) −̂ 𝑒𝑠𝑐𝑜𝑟𝑒(𝑠𝑝𝑔2\\n𝑖 )| (4)\\nwhere, ̂ 𝑒𝑠𝑐𝑜𝑟𝑒(𝑠𝑝𝑔1\\n𝑖 ) and ̂ 𝑒𝑠𝑐𝑜𝑟𝑒(𝑠𝑝𝑔2\\n𝑖 ) indicates emotion prediction\\nintensity scores corresponding to the social groups 𝑔1 and 𝑔2,\\nrespectively, for the ith sentence pair concerning a domain, and\\n𝑁 denotes the total number of sentence pairs. That is, 𝑎𝑣𝑔.𝛥\\nindicates the average dissimilarity in prediction scores between\\na pair of sentences; 0 indicates perfect similarity, and higher the\\nvalues more the dissimilarity.\\n• Prediction Score Significance ( 𝑝-value): A measure that shows\\nwhether dissimilarity in prediction scores between the sentence\\npairs is statistically significant or not. To compute prediction'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 7, 'page_label': '8', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='• Prediction Score Significance ( 𝑝-value): A measure that shows\\nwhether dissimilarity in prediction scores between the sentence\\npairs is statistically significant or not. To compute prediction\\nscore significance, we perform a paired statistical significance\\ntest, 𝑡-Test (Kiritchenko and Mohammad, 2018) over the predic-\\ntion scores of sentence pairs, ̂ 𝑒𝑠𝑐𝑜𝑟𝑒(𝑠𝑝𝑔1\\n𝑖 ) and ̂ 𝑒𝑠𝑐𝑜𝑟𝑒(𝑠𝑝𝑔2\\n𝑖 ), using the\\nconventional significance level, i.e., a 𝑝-value of 0.05.\\n• Average Confidence Score (ACS): A measure that illustrates model\\nbias towards a particular social group using the average ratio\\nbetween prediction intensity scores of sentence pairs (Nangia\\net al., 2020), computed as,\\nACS = 1\\n𝑁\\n𝑁∑\\n𝑖=1\\n1 −\\n̂ 𝑒𝑠𝑐𝑜𝑟𝑒(𝑠𝑝𝑔1\\n𝑖 )\\n̂ 𝑒𝑠𝑐𝑜𝑟𝑒(𝑠𝑝𝑔2\\n𝑖 )\\n(5)\\nACS value of an unbiased model will peak around zero, but if\\nit tends to negative values, then the measure indicates that the\\nmodel prediction intensities of the social group𝑔1 are higher than'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 7, 'page_label': '8', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='(5)\\nACS value of an unbiased model will peak around zero, but if\\nit tends to negative values, then the measure indicates that the\\nmodel prediction intensities of the social group𝑔1 are higher than\\n𝑔2, and if it tends to positive values, it indicates that prediction\\nintensities of the social group 𝑔2 are higher than 𝑔1.\\n4.3. Results and analysis of prediction level affective bias\\nWe examine emotion predictions of each PLM based textual emotion\\ndetection system and could observe the existence of affective bias in\\nthe predicted emotion classes, as well as their intensities, for gender,\\nrace, and religious domains. The sample set of predictions presented in\\nTable 1 is a small subset of these affectively biased emotion predictions\\nfrom the emotion detection models that employ BERT and T5. More sets\\nof affectively biased predictions from the PLM based textual emotion\\ndetection systems, are provided in the supplementary material. In the'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 7, 'page_label': '8', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='of affectively biased predictions from the PLM based textual emotion\\ndetection systems, are provided in the supplementary material. In the\\nfollowing subsections, we evaluate the results of each PLM separately.\\n4.3.1. Affective bias in BERT\\nTable 6 shows evaluation results observed for the textual emotion\\ndetection model built using BERT, analyzing gender, racial and re-\\nligious domains using three different evaluation corpora EEC, BITS,\\nand CSP, and various evaluation measures. The pairs of social groups\\naddressed by the evaluation corpora within each domain are presented\\ncolumn wise, the measures are presented row wise, and the emotions\\nare grouped across the rows.\\n8'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 8, 'page_label': '9', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='A. Kadan, Deepak P., S. Bhadra et al. Natural Language Processing Journal 7 (2024) 100062\\nTable 6\\nResults of BERT (Boldface is used to highlight the values of DP < threshold 𝜏 = 0.80 and p-values <0.05).\\nEvaluation Gender Race Religion\\nmeasures EEC\\nM × F\\nBITS\\nM × F\\nCSP\\nM × F\\nBITS\\nM × Nb\\nBITS\\nF × Nb\\nEEC\\nEA × AA\\nBITS\\nEA × AA\\nCSP\\nEA × AA\\nCSP\\nCh × Mu\\nCSP\\nCh × Jw\\nCSP\\nMu × Jw\\nAnger\\nDP 0.964 1.000 0.836 0.866 0.867 0.996 0.948 1.000 0.923 0.923 1.000\\navg.𝛥 0.018 0.016 0.049 0.038 0.030 0.031 0.012 0.052 0.076 0.078 0.100\\np-value 0.003 0.036 0.037 0.047 0.132 0.417 0.431 0.730 0.038 0.042 2e −04\\nACS 0.010 0.017 0.025 0.036 0.020 −0.005 −0.008 −0.001 0.050 −0.084 −0.148\\nFear\\nDP 0.954 1.000 1.000 0.938 0.938 0.961 1.000 0.743 0.857 0.885 0.968\\navg.𝛥 0.019 0.049 0.086 0.085 0.086 0.049 0.058 0.109 0.076 0.089 0.073\\np-value 9.2e−12 0.864 0.767 0.043 0.063 5.3e−27 0.748 1.2e−6 0.044 0.439 0.001\\nACS 0.019 −0.010 −0.015 −0.094 −0.088 −0.055 −0.016 −0.123 0.031 −0.041 −0.082\\nJoy'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 8, 'page_label': '9', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='p-value 9.2e−12 0.864 0.767 0.043 0.063 5.3e−27 0.748 1.2e−6 0.044 0.439 0.001\\nACS 0.019 −0.010 −0.015 −0.094 −0.088 −0.055 −0.016 −0.123 0.031 −0.041 −0.082\\nJoy\\nDP 0.994 1.000 0.971 1.000 1.000 1.000 1.000 0.797 0.455 0.637 0.713\\navg.𝛥 0.002 9.9e −5 0.072 0.001 0.001 0.005 0.001 0.076 0.148 0.031 0.130\\np-value 0.400 0.061 0.014 0.360 0.394 0.002 0.611 0.001 0.033 0.425 0.021\\nACS −0.001 −5.8e−5 0.064 −0.001 −0.001 −0.004 −1e−4 −0.080 −0.240 −0.022 0.169\\nSadness\\nDP 0.953 1.000 0.872 0.938 0.938 0.977 0.950 0.724 0.666 0.666 1.000\\navg.𝛥 0.027 0.013 0.076 0.024 0.033 0.056 0.012 0.116 0.124 0.100 0.051\\np-value 1.8e−4 0.045 0.019 0.461 0.156 0.600 0.924 1e−12 0.065 0.201 0.146\\nACS −0.020 −0.019 −0.064 0.006 0.022 −0.010 −0.002 0.100 −0.279 −0.169 0.064\\n(A) Affective Gender Bias:Initially, looking into the gender domain,\\nfor class based measure DP, throughout all the emotions, we can\\nobserve that there is almost no affective bias in the predictions'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 8, 'page_label': '9', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='(A) Affective Gender Bias:Initially, looking into the gender domain,\\nfor class based measure DP, throughout all the emotions, we can\\nobserve that there is almost no affective bias in the predictions\\nmade by BERT between male and female groups when evaluated\\nusing the EEC corpus (since, DP > 0.8 in all cases), and ideally\\nno affective bias when evaluated using BITS corpus (since, DP =\\n1 in all cases). This ideal scenario in BITS might be because\\nBITS is a small corpus containing short-length synthetically cre-\\nated sentences with explicit emotion terms that do not suit the\\nreal-world context. When compared to synthetic corpora (EEC\\nand BITS), evaluations using the real-world context and non-\\nsynthetic corpus CSP shows more disparity (lower values of DP)\\nbetween male and female groups for all the emotions except\\nfear. For pairs involving non-binary genders, the values of DP\\nare much less than those involving male and female groups of'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 8, 'page_label': '9', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='between male and female groups for all the emotions except\\nfear. For pairs involving non-binary genders, the values of DP\\nare much less than those involving male and female groups of\\nsynthetic corpora EEC and BITS, for all emotions except joy.\\nThis indicate more disparity of male and female groups with\\nnon-binary gender, with respect to anger, fear and sadness. Since\\nthe evaluation of affective bias in non-binary social groups is\\nonly possible with BITS corpus, it may limit the exploration\\nof affective bias towards this group and also the magnitude of\\naffective bias. For the measure DP, when looking across each\\nemotion, the most disparity (lowest value for DP) is observed\\nfor anger between male versus female when evaluated using CSP\\ncorpus, followed by male versus non-binary, and female versus\\nnon-binary, for the same emotion, when evaluated using BITS\\ncorpus. Whereas, for joy, very less disparity is observed across\\nthe gender groups. In total, even though disparities are shown'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 8, 'page_label': '9', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='non-binary, for the same emotion, when evaluated using BITS\\ncorpus. Whereas, for joy, very less disparity is observed across\\nthe gender groups. In total, even though disparities are shown\\nby DP, any of the gender pairs do not have values of DP less than\\nthe threshold 𝜏 = 0.80. Hence DP does not establish the existence\\nof gender affective bias in the predictions of BERT using these\\nevaluation corpora.\\nComing to the intensity based measure avg. 𝛥 in the gender\\ndomain, similar to DP, more disparity is observed for male\\nversus female pairs when evaluated using CSP corpus and also\\nfor the pairs involving non-binary social groups in BITS, across\\nall the emotions. Different from the measure DP, avg. 𝛥 reports\\nhighest disparity for fear, but similar to DP, avg. 𝛥 shows very\\nless disparity for joy. For the next measure 𝑝-value, at least one\\nof the evaluation corpora reports values less than 0.05 or statisti-\\ncally significant difference between male and female predictions'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 8, 'page_label': '9', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='of the evaluation corpora reports values less than 0.05 or statisti-\\ncally significant difference between male and female predictions\\nacross the emotions, indicating the existence of affective bias.\\nThe 𝑝-value also shows that difference between male and non-\\nbinary predictions for anger and fear are statistically significant.\\nAnalyzing the prediction intensity plots of pairs with statistically\\nsignificant differences (e.g. Figs. 2(a) and 2(b)), shows that their\\nintensity plots also depict more dispersion between data points\\nas well as more disparity between the corresponding mean val-\\nues. Conversely, in the plots of sentence pairs with statistically\\ninsignificant differences in prediction intensities (e.g. Fig. 2(c)),\\nthere is very less dispersion between data points and less dispar-\\nity between the mean values. Therefore𝑝-value evidently reports\\nthe existence of affective bias in emotion prediction intensities\\nof male and female groups with respect to all emotions, and for'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 8, 'page_label': '9', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='ity between the mean values. Therefore𝑝-value evidently reports\\nthe existence of affective bias in emotion prediction intensities\\nof male and female groups with respect to all emotions, and for\\nmale and non-binary groups with respect to anger and fear.\\nIn the case of intensity based measure ACS, for emotion anger,\\nthe positive values in Male versus Female sentence pairs of EEC,\\nBITS, and CSP indicates that prediction intensities for anger are\\nhigher for the Female when compared to Male, and positive\\nvalues in Male versus Non-binary and Female versus Non-binary\\nsentence pairs of BITS indicates that anger prediction intensities\\nare higher for the Non-binary group when compared to Male and\\nFemale. Similarly, when examining across evaluation corpora,\\nprediction intensities of fear and joy are higher for Male and\\nFemale genders, and prediction intensities of sadness are higher\\nfor Male and Non-binary genders. Therefore in the gender do-'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 8, 'page_label': '9', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='prediction intensities of fear and joy are higher for Male and\\nFemale genders, and prediction intensities of sadness are higher\\nfor Male and Non-binary genders. Therefore in the gender do-\\nmain, the measure ACS also indicates affective bias in prediction\\nintensities.\\n(B) Affective Racial Bias:The European and African American racial\\ngroups when evaluated using CSP corpus, for the measure DP,\\nshows the presence of affective bias for all emotions except\\nanger, where EEC and BITS fail to identify it. Similarly, the avg.𝛥\\ndisparities among intensity predictions of these racial groups\\nare also much more visible when evaluated using CSP corpus.\\nEither or both, EEC and CSP corpora shows that the difference\\nin intensity predictions of these racial groups are statistically\\n9'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 9, 'page_label': '10', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='A. Kadan, Deepak P., S. Bhadra et al. Natural Language Processing Journal 7 (2024) 100062\\nFig. 2. Intensity plots of emotion predictions from BERT.\\nsignificant with p-values less than 0.05, for all emotions ex-\\ncept anger, similar to the observations of the measure DP. The\\nmeasure ACS also shows disparities in prediction intensities\\nbetween the racial groups, where, for all emotions, prediction\\nintensities of European American race are mostly higher than\\nAfrican American.\\n(C) Affective Religious Bias: In the religious domain, the measure\\nDP evidently shows affective bias in the emotion joy with very\\nlow values for all three religious pairs and also in sadness for\\nChristian versus Muslim and Christian versus Jew pairs. For\\nall the emotions, the values of DP indicate more bias in the\\nChristian versus Muslim and Christian versus Jew sentence pairs\\nthan in the Muslim versus Jew pairs. The measure avg. 𝛥 shows\\nthat there exist disparities between prediction intensities of reli-'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 9, 'page_label': '10', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='Christian versus Muslim and Christian versus Jew sentence pairs\\nthan in the Muslim versus Jew pairs. The measure avg. 𝛥 shows\\nthat there exist disparities between prediction intensities of reli-\\ngious pairs, and these disparities are found to be comparatively\\nhigher than the pairs of gender and racial domains. The 𝑝-value\\nindicates statistically significant differences in intensity predic-\\ntions of anger between all three religious pairs. Also, Christian\\nversus Muslim and Muslim versus Jew pairs show statistically\\nsignificant differences in intensity predictions of all emotions\\nexcept sadness. The measure ACS shows that for BERT anger and\\nfear prediction intensities are higher for Muslim followed by\\nChristian, and joy and sadness prediction intensities are higher\\nfor Christian followed by Jew.\\n4.3.2. Affective bias in GPT-2\\n(A) Affective Gender Bias:Table 7 shows evaluation results observed\\nfor GPT-2 where similar to BERT, no gender affective bias is'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 9, 'page_label': '10', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='for Christian followed by Jew.\\n4.3.2. Affective bias in GPT-2\\n(A) Affective Gender Bias:Table 7 shows evaluation results observed\\nfor GPT-2 where similar to BERT, no gender affective bias is\\nobserved with the measure DP for any of the emotion class\\npredictions. Whereas intensity based disparities are shown by\\nthe measure avg.𝛥, which is highly visible when evaluated using\\nCSP corpus. The difference in prediction intensities between\\nMale versus Female when evaluated using EEC corpus for all\\nemotions except joy, and Male versus Non-binary and Female\\nversus Non-binary when evaluated using BITS corpus for all\\nemotions except fear, are statistically significant with p-values\\n< 0.05, indicating the existence of affective bias in emotion\\nprediction intensities. The measure ACS indicates that, in GPT-\\n2, anger and joy prediction intensities are higher for Male and\\nFemale genders, fear prediction intensities are higher mainly for\\nFemale, and sadness prediction intensities are higher mainly for'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 9, 'page_label': '10', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='2, anger and joy prediction intensities are higher for Male and\\nFemale genders, fear prediction intensities are higher mainly for\\nFemale, and sadness prediction intensities are higher mainly for\\nMale gender.\\n(B) Affective Racial Bias: In the racial domain, similar to gender,\\nDP does not show racial affective bias for any of the emotion\\nclass predictions, whereas intensity based disparities are shown\\nby the measure avg. 𝛥. Here also, the disparities for class based\\nmeasure DP and intensity based measure avg.𝛥, are more visible\\nwhen evaluated using CSP corpus. Whereas BITS reports an ideal\\nunbiased scenario for DP and very low disparity for avg. 𝛥. The\\nmeasure 𝑝-value reports that the difference in prediction inten-\\nsities of European and African American races are statistically\\nsignificant for all emotions except sadness. The measure ACS\\nshows that, in GPT-2, prediction intensities of anger and sadness\\nare mostly higher for African American race, whereas predic-'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 9, 'page_label': '10', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='significant for all emotions except sadness. The measure ACS\\nshows that, in GPT-2, prediction intensities of anger and sadness\\nare mostly higher for African American race, whereas predic-\\ntion intensities of fear and joy are mostly higher for European\\nAmerican race.\\n(C) Affective Religious Bias:Unlike gender and race, in the religious\\ndomain the class based measure DP reports affective bias (with\\nvalues of DP < 0.8) in the predictions of all emotions except\\nfear. The measure avg. 𝛥 also shows disparities in prediction\\nintensities of religious pairs. The p-values indicate that differ-\\nence in fear prediction intensities for the pairs Christian versus\\nMuslim and Muslim versus Jew are statistically significant. The\\n10'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 10, 'page_label': '11', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='A. Kadan, Deepak P., S. Bhadra et al. Natural Language Processing Journal 7 (2024) 100062\\nTable 7\\nResults of GPT-2 (Boldface is used to highlight the values of DP < threshold 𝜏 = 0.80 and p-values <0.05).\\nEvaluation Gender Race Religion\\nmeasures EEC\\nM × F\\nBITS\\nM × F\\nCSP\\nM × F\\nBITS\\nM × Nb\\nBITS\\nF × Nb\\nEEC\\nEA × AA\\nBITS\\nEA × AA\\nCSP\\nEA × AA\\nCSP\\nCh × Mu\\nCSP\\nCh × Jw\\nCSP\\nMu × Jw\\nAnger\\nDP 0.992 0.926 0.954 0.960 0.889 0.980 1.000 0.920 0.600 0.867 0.692\\navg.𝛥 0.023 0.006 0.039 0.008 0.008 0.038 0.010 0.050 0.059 0.048 0.021\\np-value 2.5e−05 0.103 0.772 0.031 0.004 3.4e −5 0.015 0.037 0.580 0.788 0.626\\nACS 0.013 0.007 −0.005 −0.006 −0.008 0.011 0.012 0.015 −0.044 −0.018 0.010\\nFear\\nDP 1.000 1.000 0.991 0.960 0.960 0.996 1.000 0.901 0.883 0.985 0.870\\navg.𝛥 0.016 0.007 0.058 0.017 0.015 0.030 0.010 0.063 0.139 0.069 0.158\\np-value 0.048 0.372 0.505 0.917 0.787 0.012 0.101 0.183 6.9e−13 0.262 7e−13\\nACS −0.003 0.002 0.001 3.7e −4 −0.001 −0.011 −0.014 0.005 0.159 −0.040 −0.277\\nJoy'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 10, 'page_label': '11', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='p-value 0.048 0.372 0.505 0.917 0.787 0.012 0.101 0.183 6.9e−13 0.262 7e−13\\nACS −0.003 0.002 0.001 3.7e −4 −0.001 −0.011 −0.014 0.005 0.159 −0.040 −0.277\\nJoy\\nDP 0.985 1.000 0.914 1.000 1.000 0.995 1.000 0.936 0.545 0.600 0.909\\navg.𝛥 0.008 3.3e −5 0.073 0.001 0.001 0.017 2e −4 0.101 0.114 0.100 0.089\\np-value 0.640 0.713 0.761 0.018 0.017 0.872 0.204 6.1e−5 0.110 0.944 0.069\\nACS −7.3e−5 5.3e −6 −0.023 −0.001 −0.001 −0.003 −2e−4 −0.108 0.135 −0.011 −0.129\\nSadness\\nDP 0.985 0.951 0.927 1.000 0.951 0.996 1.000 0.938 0.467 0.933 0.502\\navg.𝛥 0.011 0.002 0.047 0.014 0.014 0.018 0.010 0.055 0.039 0.045 0.045\\np-value 4.5e−29 0.262 0.313 0.042 0.042 0.178 0.725 0.283 0.310 0.429 0.343\\nACS −0.012 −0.001 −0.020 −0.013 −0.011 −0.002 0.001 0.006 −0.058 0.028 0.060\\nmeasure ACS shows that for GPT-2 anger prediction intensities\\nare mostly higher for Christian, fear and joy prediction intensi-\\nties are higher for Muslim and Christian, and sadness prediction\\nintensities are mostly higher for Jew groups.'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 10, 'page_label': '11', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='are mostly higher for Christian, fear and joy prediction intensi-\\nties are higher for Muslim and Christian, and sadness prediction\\nintensities are mostly higher for Jew groups.\\n4.3.3. Affective bias in XLNet\\n(A) Affective Gender Bias:Table 8 shows evaluation results of XLNet,\\nwhere the class based measure DP shows negligible affective bias\\n(values of DP is almost one) in emotion predictions of gender\\npairs, whereas avg. 𝛥 shows disparities in emotion prediction\\nintensities of these pairs. The p-values report that differences be-\\ntween intensity predictions are statistically significant for Male\\nversus Female pairs for all emotions, and also for pairs involving\\nthe Non-binary group for emotion anger. The measure ACS indi-\\ncates high anger and fear prediction intensities for Female and\\nMale genders, and high joy and sadness prediction intensities for\\nMale and Non-binary genders.\\n(B) Affective Racial Bias: Similar to the gender domain, the mea-'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 10, 'page_label': '11', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='Male genders, and high joy and sadness prediction intensities for\\nMale and Non-binary genders.\\n(B) Affective Racial Bias: Similar to the gender domain, the mea-\\nsure DP does not confirm class based affective racial bias in\\nXLNet, but avg. 𝛥 shows disparity in intensities of predictions\\nwith 𝑝-value indicating statistically significant differences be-\\ntween prediction intensities of both races, for all emotions. The\\nmeasure ACS shows that anger and sadness prediction intensities\\nare higher for African American, whereasfear and joy prediction\\nintensities are higher for European American race.\\n(C) Affective Religious Bias:In the religious domain, even though the\\nvalues of DP are less compared to gender and racial domains,\\nit is not sufficient to confirm class based affective religious bias\\nin the emotions except sadness whose values are very low and\\nreporting bias. The measure avg.𝛥shows disparity in prediction\\nintensities, with 𝑝-value indicating statistically significant differ-'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 10, 'page_label': '11', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='in the emotions except sadness whose values are very low and\\nreporting bias. The measure avg.𝛥shows disparity in prediction\\nintensities, with 𝑝-value indicating statistically significant differ-\\nences between Christian versus Muslim and Muslim versus Jew\\nreligious pairs, for anger and sadness. The measure ACS indicates\\nthat anger prediction intensities are mostly higher for Muslim\\nreligion followed by Christian, fear mostly higher for Christian\\nfollowed by Muslim, andjoy and sadness higher for Christian and\\nJew.\\n4.3.4. Affective bias in T5\\n(A) Affective Gender Bias: Table 9 shows evaluation results of T5.\\nIn the gender domain, class based measure DP shows affective\\nbias in the predictions of Male versus Female pair for anger and\\nfear when evaluated using CSP corpus. The avg.𝛥measure shows\\ndisparities in prediction intensities, and p-values indicate that\\ndifferences in prediction intensities of Male versus Female pair\\nfor all emotions except fear and in pairs involving Non-binary'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 10, 'page_label': '11', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='disparities in prediction intensities, and p-values indicate that\\ndifferences in prediction intensities of Male versus Female pair\\nfor all emotions except fear and in pairs involving Non-binary\\ngender for emotions anger and fear are statistically significant.\\nThe measure ACS indicates high prediction intensities for anger,\\njoy and sadness mostly by Male gender and high prediction\\nintensities for fear mostly by Female and Non-binary genders.\\n(B) Affective Racial Bias: The measure DP does not confirm class\\nbased affective racial bias in T5 predictions, whereas avg. 𝛥\\nshows intensity based affective racial bias, with statistically\\nsignificant differences in intensity predictions of the racial pairs\\nfor all the emotions. ACS indicates prediction intensities of\\nAfrican American race are higher for anger, whereas prediction\\nintensities of European American are higher for fear, joy and\\nsadness.\\n(C) Affective Religious Bias: In the religious pairs, the measure DP'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 10, 'page_label': '11', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='intensities of European American are higher for fear, joy and\\nsadness.\\n(C) Affective Religious Bias: In the religious pairs, the measure DP\\nindicates affective bias in Muslim versus Jew pairs for all emo-\\ntions, in Muslim versus Christian pairs for all emotions except\\nanger, and in Christian versus Jew pairs for joy. The avg.𝛥shows\\nintensity based disparities in all emotions, and p-values indicate\\nthat the differences in prediction intensities are statistically sig-\\nnificant in the case of Muslim versus Jew pair for all emotions\\nexcept joy and in Christian versus Jew pair for the emotion\\nfear. ACS indicates that anger and joy prediction intensities are\\nhigher for Jew religion followed by Christian, fear prediction\\nintensities are higher for Christian followed by Muslim, and\\nsadness prediction intensities are higher for Christian followed\\nby Jew.\\n5. Discussion\\n5.1. Affective bias - Across the PLMs\\nThis study analyzes affective bias in the predictions of textual'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 10, 'page_label': '11', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='sadness prediction intensities are higher for Christian followed\\nby Jew.\\n5. Discussion\\n5.1. Affective bias - Across the PLMs\\nThis study analyzes affective bias in the predictions of textual\\nemotion detection models at class level and intensity level. In most\\n11'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 11, 'page_label': '12', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='A. Kadan, Deepak P., S. Bhadra et al. Natural Language Processing Journal 7 (2024) 100062\\nTable 8\\nResults of XLNet (Boldface is used to highlight the values of DP < threshold 𝜏 = 0.80 and p-values <0.05).\\nEvaluation Gender Race Religion\\nmeasures EEC\\nM × F\\nBITS\\nM × F\\nCSP\\nM × F\\nBITS\\nM × Nb\\nBITS\\nF × Nb\\nEEC\\nEA × AA\\nBITS\\nEA × AA\\nCSP\\nEA × AA\\nCSP\\nCh × Mu\\nCSP\\nCh × Jw\\nCSP\\nMu × Jw\\nAnger\\nDP 0.983 1.000 1.000 1.000 1.000 0.976 1.000 0.974 0.825 0.869 0.950\\navg.𝛥 0.017 0.005 0.053 0.017 0.019 0.048 0.004 0.061 0.115 0.083 0.110\\np-value 1.7e−6 0.002 0.226 0.035 0.014 0.041 0.561 0.063 0.008 0.842 0.001\\nACS 0.015 0.005 −0.028 −0.015 −0.020 −0.021 0.002 0.015 0.077 −0.032 −0.153\\nFear\\nDP 0.991 1.000 0.989 1.000 1.000 0.988 1.000 0.938 0.810 1.000 0.810\\navg.𝛥 0.012 0.030 0.080 0.060 0.071 0.038 0.036 0.067 0.054 0.070 0.047\\np-value 0.032 0.809 0.680 0.667 0.642 0.228 0.004 0.003 0.561 0.807 0.703\\nACS 0.004 −0.001 −0.003 −0.008 −0.013 −0.007 −0.050 −0.062 −0.029 −0.005 −0.019\\nJoy'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 11, 'page_label': '12', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='p-value 0.032 0.809 0.680 0.667 0.642 0.228 0.004 0.003 0.561 0.807 0.703\\nACS 0.004 −0.001 −0.003 −0.008 −0.013 −0.007 −0.050 −0.062 −0.029 −0.005 −0.019\\nJoy\\nDP 0.993 1.000 0.974 1.000 1.000 0.970 1.000 0.804 0.856 1.000 0.857\\navg.𝛥 0.010 0.013 0.084 0.006 0.018 0.022 0.009 0.084 0.027 0.077 0.086\\np-value 0.457 0.118 0.028 0.158 0.125 0.011 0.573 0.024 0.357 0.410 0.397\\nACS −0.003 −0.018 0.056 0.006 0.019 −0.012 0.004 −0.073 −0.055 0.073 0.133\\nSadness\\nDP 0.998 1.000 0.989 1.000 1.000 0.997 1.000 0.902 0.533 0.833 0.640\\navg.𝛥 0.009 0.003 0.050 0.007 0.008 0.028 0.007 0.083 0.094 0.065 0.104\\np-value 0.013 0.010 0.553 0.203 0.061 0.253 0.075 5.1e−6 0.048 0.637 0.010\\nACS −0.003 −0.003 −0.031 0.002 0.005 −0.004 0.009 0.046 −0.131 0.007 0.124\\nTable 9\\nResults of T5 (Boldface is used to highlight the values of DP < threshold 𝜏 = 0.80 and p-values <0.05).\\nEvaluation Gender Race Religion\\nmeasures EEC\\nM × F\\nBIT\\nM × F\\nCSP\\nM × F\\nBITS\\nM × Nb\\nBITS\\nF × Nb\\nEEC\\nEA × AA\\nBITS\\nEA × AA\\nCSP\\nEA × AA\\nCSP'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 11, 'page_label': '12', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='Evaluation Gender Race Religion\\nmeasures EEC\\nM × F\\nBIT\\nM × F\\nCSP\\nM × F\\nBITS\\nM × Nb\\nBITS\\nF × Nb\\nEEC\\nEA × AA\\nBITS\\nEA × AA\\nCSP\\nEA × AA\\nCSP\\nCh × Mu\\nCSP\\nCh × Jw\\nCSP\\nMu × Jw\\nAnger\\nDP 0.983 0.966 0.765 0.897 0.866 0.933 0.952 0.903 0.968 0.816 0.790\\navg.𝛥 0.039 0.016 0.077 0.021 0.022 0.101 0.004 0.106 0.082 0.113 0.097\\np-value 3.6e−20 0.530 0.385 0.017 0.043 0.001 0.458 6.8e−8 0.118 0.491 0.041\\nACS −0.044 0.006 −0.037 −0.029 −0.032 0.005 0.002 0.070 −0.086 0.014 0.064\\nFear\\nDP 0.994 1.000 0.778 0.897 1.000 0.966 1.000 0.867 0.783 0.915 0.717\\navg.𝛥 0.017 0.029 0.079 0.079 0.068 0.039 0.067 0.099 0.079 0.148 0.145\\np-value 0.309 0.318 0.662 0.003 0.004 3.1e −7 0.022 9.2e −5 0.602 0.001 2.8e −5\\nACS 0.002 0.008 −0.025 0.071 0.063 −0.035 −0.087 −0.111 −0.005 −0.242 −0.263\\nJoy\\nDP 0.990 1.000 0.848 1.000 1.000 0.961 1.000 0.971 0.624 0.375 0.600\\navg.𝛥 0.009 2e −4 0.062 1e −4 2.8e −4 0.029 0.009 0.068 0.183 0.001 0.075\\np-value 0.003 0.025 0.885 0.605 0.115 0.122 0.332 0.001 0.122 0.468 0.423'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 11, 'page_label': '12', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='avg.𝛥 0.009 2e −4 0.062 1e −4 2.8e −4 0.029 0.009 0.068 0.183 0.001 0.075\\np-value 0.003 0.025 0.885 0.605 0.115 0.122 0.332 0.001 0.122 0.468 0.423\\nACS −0.009 −2e−4 −0.025 −1.6e−5 1.8e −4 −0.014 −0.014 −0.078 −0.320 0.001 0.075\\nSadness\\nDP 0.998 0.973 0.952 0.925 0.900 0.998 0.955 0.972 0.500 0.900 0.450\\navg.𝛥 0.023 0.006 0.082 0.009 0.014 0.074 0.007 0.103 0.095 0.118 0.085\\np-value 8.6e−15 0.035 0.689 0.223 0.871 0.002 0.048 0.957 0.121 0.751 0.020\\nACS −0.026 −0.006 −0.027 −0.008 −0.002 −0.040 −0.007 −0.030 −0.150 −0.002 0.099\\ncases, class based measures that are capable of identifying differences\\nin emotion classes predicted for two different social groups, do not\\nshow affective bias, whereas intensity based measures mostly identify\\nthe existence of affective bias in predicted emotion intensities. This\\nis because the differences in predicted emotion intensities between\\nthe social groups might not be that very high to alter the choice of'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 11, 'page_label': '12', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='is because the differences in predicted emotion intensities between\\nthe social groups might not be that very high to alter the choice of\\nemotion class predictions, but even then there exists affective bias due\\nto differences in the predicted emotion intensities. When comparing\\nacross the PLMs, class based affective gender bias is only observed in\\nT5, whereas intensity based affective gender bias is observed in all\\nthe PLMs. Similarly, class based affective racial bias is only observed\\nin BERT, whereas intensity based affective racial bias is observed in\\nall the PLMs. But, in the domain of religion, all four PLMs show\\nhigh magnitudes of class based and intensity based affective bias,\\ni.e., compared to gender and race, the religious domain is observed to have\\nhigh existence of affective bias. We believe this could be a reflection\\nof comparatively high affect imbalance with respect to the religious\\ndomain in the pre-training corpora (from Table 4).'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 11, 'page_label': '12', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='high existence of affective bias. We believe this could be a reflection\\nof comparatively high affect imbalance with respect to the religious\\ndomain in the pre-training corpora (from Table 4).\\nXLNet is observed to have the least class based affective bias, with\\nbias only observed in the case of the religious domain for the emo-\\ntion sadness. XLNet is also observed to have the least intensity based\\naffective bias among all the PLMs when considering the measures avg.𝛥\\n(i.e., the top five values of avg. 𝛥 do not have any instance of XLNet)\\nand 𝑝-value (i.e., the number of instances in XLNet with statistically\\nsignificant differences are also low). Whereas T5 has the maximum\\nclass based biased instances, and also high intensity based affective bias\\namong all the PLMs when considering the measures avg.𝛥(i.e., top five\\nvalues of avg.𝛥have three instances of T5) and𝑝-value (i.e., the number\\nof instances in T5 with statistically significant differences are also high).'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 11, 'page_label': '12', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='values of avg.𝛥have three instances of T5) and𝑝-value (i.e., the number\\nof instances in T5 with statistically significant differences are also high).\\nBERT also shows class based and intensity based affective bias, nearly\\nsimilar but comparatively less than T5, followed by GPT-2.\\n12'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 12, 'page_label': '13', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='A. Kadan, Deepak P., S. Bhadra et al. Natural Language Processing Journal 7 (2024) 100062\\nThis study explores affective bias in large PLMs that are trained on\\nmillions of parameters. However, rapid growth in the data processing\\ntechnology and plenty availability of data has recently, very quickly\\nevolved the category of large PLMs to being trained on billions of\\nparameters, the PLMs such as LLaMA (Touvron et al., 2023), Flan-T5\\nXXL (Chung et al., 2022), PaLM (Chowdhery et al., 2023), LaMDA\\n(Thoppilan et al., 2022), etc. All these PLMs have the benefits of\\nhuge improvements in their performance, capable of performing several\\ndownstream tasks, and supporting multi-lingual and multi-modal data\\nprocessing. All such large PLMs highly rely on the large availability\\nof massive amounts of textual data especially collected from the web,\\nWikipedia, Book Corpus, etc. In most cases, which proportion of data\\nis extracted from a source to train a PLM is not fully transparent.'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 12, 'page_label': '13', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='Wikipedia, Book Corpus, etc. In most cases, which proportion of data\\nis extracted from a source to train a PLM is not fully transparent.\\nFor example, LLaMA uses different data proportions from different\\ncommonly available data deluges such as CommonCrawl (67.0%), C4\\n(15.0%), Wikipedia (4.5%), etc., where which data proportions are\\nextracted from each of the sources is not fully transparent. Also, the\\ntraining data quality is unmanageable and unverifiable by even a large\\ngroup of human crowd (Navigli et al., 2023), where there are chances\\nof the existence of affective biases in these recent large PLMs. For\\nexample, LLaMA is trained on data proportions from several corpora in-\\ncluding C4 and Wikipedia, which are already investigated in this study\\nand identified with the affect imbalances. The large PLMs PaLM and\\nLaMDA are also trained on billions of tokens extracted from web pages,\\nbooks, Wikipedia, and news articles, indicating chances of existence of'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 12, 'page_label': '13', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='LaMDA are also trained on billions of tokens extracted from web pages,\\nbooks, Wikipedia, and news articles, indicating chances of existence of\\naffective bias. Similarly, Flan-T5 is a variant of the T5, and in this study\\nwe observed that T5 has the highest affective bias amongst the PLMs\\nXLNet, BERT, and GPT-2.\\n5.2. Affect imbalance in corpora and affective bias in predictions\\nWhen revisiting the analysis of corpora involved in training PLMs,\\nwe have already observed (in Table 4) that these corpora have imbal-\\nanced co-occurrences of emotions with certain social groups in gender,\\nracial and religious domains. Further at the prediction level, PLMs that\\nutilize these corpora seems to reflect some of these imbalances hinting\\nat the propagation of affect imbalance in data towards affective bias\\nin predictions. For example, in pre-training and fine-tuning corpora\\nof BERT (i.e., WikiEn, BookCorpus, and SemEval-2018), the emotion'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 12, 'page_label': '13', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='in predictions. For example, in pre-training and fine-tuning corpora\\nof BERT (i.e., WikiEn, BookCorpus, and SemEval-2018), the emotion\\nanger has high co-occurrence with Non-binary and Female groups than\\nMale. This seems to reflect in the predictions of BERT, i.e., the measure\\nACS shows that prediction intensities of anger are higher for Non-\\nbinary and Female groups than Male. Some other imbalanced emotion\\nassociations that exist in these corpora like sadness more associated\\nwith Male and Non-binary groups in the gender domain, joy more\\nassociated with European American racial group, fear more associated\\nwith Muslim, joy more associated with Christian, etc., are also seen\\nto be reflected in the predictions of BERT when evaluated using the\\nmeasure ACS. Similar to BERT, we can also observe the reflection of\\ncorpus level affective bias from pre-training and fine-tuning corpora\\nof GPT-2 (i.e., WebText-250k and SemEval-2018) to the predictions'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 12, 'page_label': '13', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='corpus level affective bias from pre-training and fine-tuning corpora\\nof GPT-2 (i.e., WebText-250k and SemEval-2018) to the predictions\\nof GPT-2, e.g., (1) high co-occurrence of fear with Female and Non-\\nbinary genders in the corpora, and high prediction intensities offear for\\nFemale and Non-binary genders, (2) high co-occurrence of anger with\\nAfrican American race in the corpora, and high prediction intensities\\nof anger for African American, (3) high co-occurrence of fear with\\nMuslim religion in the corpora, and high prediction intensities of fear\\nfor Muslim, etc. Such examples of reflection of corpus level affective\\nbias in the predictions of PLMs are also visible in XLNet and T5. These\\ninstances give hints that affect imbalances in the large scale corpora of\\nPLMs may lead to affective bias in the predictions of the models that utilize\\nthese PLMs. Hence, this study further opens the scope for much more\\nnuanced explorations in the direction of affective bias propagation from'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 12, 'page_label': '13', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='these PLMs. Hence, this study further opens the scope for much more\\nnuanced explorations in the direction of affective bias propagation from\\nthe corpus to model prediction.\\n5.3. Societal stereotypes and affective bias\\nThe imbalanced/biased association of emotions with certain so-\\ncial groups within a domain, either at the corpus level or prediction\\nlevel, reflects several affect-oriented societal stereotypes. Patterns in\\nthe training corpora and predictions of PLM based textual emotion\\ndetection models showing high association of African American race\\nwith anger (an example plot of high anger prediction intensities for\\nAfrican American race is presented in Fig. 3(a)) reflect the ‘‘Angry\\nBlack’’ stereotype that misrepresents and victimizes blacks as hostile\\nin mainstream American culture and suppress their emotions (Lozada\\net al., 2022). Another pattern of high association of European American\\nrace with fear (an example plot of high fear prediction intensities for'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 12, 'page_label': '13', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='et al., 2022). Another pattern of high association of European American\\nrace with fear (an example plot of high fear prediction intensities for\\nEuropean American is presented in Fig. 3(b)) reflects the existence of\\nstereotypes such as fear of crime, residential integration, and racial\\nprejudice among the whites (Skogan, 1995). The high association of\\nNon-binary genders with negative emotions especially fear, and very\\nrarely associating with positive emotionjoy, reflects the societal stigmas\\nlike homo-negativity and homophobia against these gender minorities\\n(Hahn et al., 2020). Similarly, the high association of Muslim religion\\nwith fear (an example plot of highfear prediction intensities for Muslim\\nis presented in Fig. 3(c)), which we believe may probably be due to the\\nIslamophobia manifested through text, are inline with the experimental\\nresults in Abid et al. (2021b) that reports language generated by GPT-\\n3 (Brown et al., 2020) in the context of the Muslim religion are more'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 12, 'page_label': '13', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='results in Abid et al. (2021b) that reports language generated by GPT-\\n3 (Brown et al., 2020) in the context of the Muslim religion are more\\nassociated with violence.\\n5.4. Effectiveness of evaluation corpora in unveiling affective bias\\nWhen comparing the capability of the evaluation corpora EEC,\\nBITS, and CSP, we could observe that BITS, with a smaller number of\\nsentence pairs (120 for gender and 72 for race) and explicit emotion\\nterms, is mostly unable to recognize the existence of affective bias in\\nperspective of both class level and intensity level analysis. But even\\nthough EEC also has implicit representation of emotion terms similar\\nto BITS, the availability of a large number of sentence pairs (1400 for\\neach domain) eventually helps EEC to identify the existence of affective\\nbias better than BITS. On the other side, even with a smaller number\\nof sentence pairs (263 for gender, 566 for race, 104 for religion), the'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 12, 'page_label': '13', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='bias better than BITS. On the other side, even with a smaller number\\nof sentence pairs (263 for gender, 566 for race, 104 for religion), the\\nevaluation corpus CSP helps to identify affective bias to a great extent,\\nand it is the only corpus that unveils class based affective bias in the\\ndomains. We believe the non-synthetic and real-world context nature\\nof sentence pairs in CSP could have been advantageous in identifying\\naffective bias. Therefore, upgrading such a corpus with more number\\nof sentence pairs or procuring new evaluation corpora containing non-\\nsynthetic real-world sentences, along with corresponding ground truth\\nemotions could eventually help towards comprehensive and rigorous\\nexplorations in the direction of identifying affective bias and quantify-\\ning its magnitude using ground truth dependent measures like Equal\\nOpportunity (Du et al., 2021).\\n6. Conclusion\\nTextual affective analysis and recognition enable efficient ways to'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 12, 'page_label': '13', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='ing its magnitude using ground truth dependent measures like Equal\\nOpportunity (Du et al., 2021).\\n6. Conclusion\\nTextual affective analysis and recognition enable efficient ways to\\nencode and understand human emotional states from textual data and\\nyield new opportunities to systems such as business, healthcare, and\\neducation by analyzing customers, employees, users, patients, etc., in\\nthe context of affective content. Unfair representations of affect in\\nlanguage, i.e. affective bias in such systems discriminate social groups\\nin a domain on the basis of certain emotions while making algorithmic\\ndecisions. Affective bias in textual emotion detection systems when\\ndeployed in the real world, can harm the ethical trust of these systems\\nand can be potentially threatening to human lives. Hence, analyzing\\nthe existence of affective bias in these systems is crucial to avoid huge\\n13'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 13, 'page_label': '14', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='A. Kadan, Deepak P., S. Bhadra et al. Natural Language Processing Journal 7 (2024) 100062\\nFig. 3. Intensity plots of emotion predictions reflecting societal stereotypes.\\ndisputes and damages in society similar to the adverse effects produced\\nby many other unfair systems such as unfair recidivism prediction. 21\\nIn this work, we for the first time, to the best of our knowledge,\\nattempted to explore and identify any existence of affective bias in\\nlarge PLMs, when utilized for the task of textual emotion detection,\\nwith respect to the domains gender, race, and religion. For the study,\\nwe used BERT, GPT-2, XLNet, and T5 considering their popularity and\\nwide applicability in textual emotion detection and many other related\\ntasks. As algorithmic bias has its roots from data bias, we started our\\nexploration of affective bias by analyzing the imbalanced distribution of\\naffect in the pre-training corpora of these PLMs i.e., WikiEn, BookCor-'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 13, 'page_label': '14', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='exploration of affective bias by analyzing the imbalanced distribution of\\naffect in the pre-training corpora of these PLMs i.e., WikiEn, BookCor-\\npus, WebText-250, and C4-Val, and SemEval-2018 used to fine-tune the\\nemotion detection models. Later, we analyzed the existence of affective\\nbias in the predictions of fine-tuned emotion detection models built\\nusing these large PLMs. Evaluations are performed to analyze affective\\nbias in the predicted emotion classes and corresponding intensities of\\nsocial groups within a domain using three different evaluation corpora\\nand various class based and intensity based evaluation measures. Our\\nwide set of experiments and evaluation strategies confirm the existence\\nof affect imbalance in large scale corpora and affective bias in emotion\\npredictions of the PLMs, with affective bias mostly higher for T5\\ncompared to the other PLMs. The high association of emotion anger\\nwith African American race, joy with European American race, fear'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 13, 'page_label': '14', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='predictions of the PLMs, with affective bias mostly higher for T5\\ncompared to the other PLMs. The high association of emotion anger\\nwith African American race, joy with European American race, fear\\nwith the Muslim religion, etc., are some examples of affective bias.\\nReligious domain reports more biased instances, compared to gender\\nand race, for all the PLMs. Our results also demonstrated that the\\nbiased predictions of the models are inclined with patterns of affect\\n21 https://www.propublica.org/article/machine-bias-risk-assessments-in-\\ncriminal-sentencing?token=nD-X136_tDm0nh1l4Xtv0LbpjY_BSO3u.\\nimbalance in the corpora, and both these reflect certain affect-oriented\\nsocietal stereotypes, hinting at the propagation of affective bias towards\\npredictions of the PLMs. To aid future research, we shall make publicly\\navailable all the relevant materials including the pre-processed pre-\\ntraining and fine-tuning corpora, evaluation corpora modified to suit'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 13, 'page_label': '14', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='available all the relevant materials including the pre-processed pre-\\ntraining and fine-tuning corpora, evaluation corpora modified to suit\\nour task, list of affective terms and target terms for corpus level\\nanalysis, source code, and fine-tuned textual emotion detection models\\nalong with their emotion class and intensity predictions, at https:\\n//github.com/anoopkdcs/affective_bias_in_plm and https://dcs.uoc.ac.\\nin/cida/projects/ac/affective-bias.html along with the publication.\\n6.1. Future work\\nThe proposed study explores corpus level affective bias using a sim-\\nple approach to analyzing the distributions of affective target terms in\\nthe corpora. In the future, we are planning to conduct a more nuanced\\nexploration towards the corpus level affective bias in the context of\\nvarious facets such as the time of creation of corpora, people behind\\ncorpora, languages and cultures (Navigli et al., 2023). Recent affect\\nagnostic bias analysis studies explore bias in the context of causality (Su'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 13, 'page_label': '14', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='corpora, languages and cultures (Navigli et al., 2023). Recent affect\\nagnostic bias analysis studies explore bias in the context of causality (Su\\net al., 2022); therefore to further explore the relationship between the\\ncorpus characteristics and model bias we are also planning to conduct\\ncausality based affective bias analysis.\\nIn context the model predictions, the observations of affective bias\\nand its magnitudes in this study are dependent on the choice of eval-\\nuation corpora and measures, i.e., certain instances of ‘no affective\\nbias’ or marginal magnitudes of affective bias may also be due to the\\nlimited capability of evaluation corpora and measures to unveil the\\nactual latent affective bias that exists in the model. Therefore in the\\nfuture, we are considering extending the study with a set of real-world\\n14'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 14, 'page_label': '15', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='A. Kadan, Deepak P., S. Bhadra et al. Natural Language Processing Journal 7 (2024) 100062\\ncontext evaluation corpora, for example, by expanding CSP in terms of\\nthe number of sentences and also by procuring ground truth emotions\\nthat allow applying other evaluation measures like Equal Opportunity\\n(Du et al., 2021). Beyond analyzing each sentence pair in a domain\\nseparately, we are looking into the ways to simultaneously analyze\\nsentences representing various social groups in a domain, for example,\\nanalyzing sentence triplets like Male versus Female versus Non-binary.\\nA very recent and relevant work that addresses a similar line of\\nthoughts in the context of affect agnostic bias in PLMs from pre-training\\ndata to language models to downstream tasks in the political domain\\nis explained in Feng et al. (2023). In the backdrop of this work, we\\nobserve a wide scope of exploring political affective biasin large PLMs.\\nBecause, there are works in the literature that give hints that emotions'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 14, 'page_label': '15', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='observe a wide scope of exploring political affective biasin large PLMs.\\nBecause, there are works in the literature that give hints that emotions\\nsuch as anger, disgust, or fear are more frequent in the predictions of\\nrepublicans’ (right-leaning) posts, whereas love or sadness are more\\noften predicted for democrats’ (left-leaning) posts (Huguet Cabot et al.,\\n2020).\\nOur initial attempt to identify affective bias in textual emotion\\ndetection models that utilize large PLMs, opens up the vast future scope\\ntowards identifying affective bias in the other very recent large PLMs\\nsuch as LLAMA, Flan-T5 XXL, PaLM, LaMDA, etc. There also exists a\\nwide scope for affective bias mitigation, which we believe, can be better\\nachieved by adopting more convenient solutions that utilize constraints\\nwhile fine-tuning the prediction system (i.e., in-processing) and post-\\nprocessing, rather than retraining or fine-tuning the PLM based affect\\nprediction systems with unbiased corpora which are expensive and'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 14, 'page_label': '15', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='processing, rather than retraining or fine-tuning the PLM based affect\\nprediction systems with unbiased corpora which are expensive and\\ncumbersome (Hooker, 2021).\\nCRediT authorship contribution statement\\nAnoop Kadan: Conceptualization, Data curation, Formal analy-\\nsis, Investigation, Methodology, Resources, Validation, Visualization,\\nWriting – original draft, Writing – review & editing. Deepak P.: Con-\\nceptualization, Formal analysis, Methodology, Supervision, Writing –\\nreview & editing, Validation. Sahely Bhadra:Formal analysis, Method-\\nology, Supervision, Writing – review & editing, Validation. Manjary\\nP. Gangan:Conceptualization, Formal analysis, Methodology, Writing\\n– original draft, Writing – review & editing. Lajish V.L.: Supervision,\\nWriting – review & editing.\\nDeclaration of competing interest\\nThe authors declare that they have no known competing finan-\\ncial interests or personal relationships that could have appeared to\\ninfluence the work reported in this paper.'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 14, 'page_label': '15', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='The authors declare that they have no known competing finan-\\ncial interests or personal relationships that could have appeared to\\ninfluence the work reported in this paper.\\nAcknowledgments\\nThe authors would like to thank the authors of Tan and Celis (2019)\\nfor making their source codes publicly available and the authors of Kir-\\nitchenko and Mohammad (2018), Venkit and Wilson (2021) and Nangia\\net al. (2020) for making their evaluation corpora publicly available.\\nThe authors would like to thank Chanjal V.V., Master’s student (2018–\\n20) of the Department of Women Studies, University of Calicut for her\\ninvolvement and cooperation to create the list of target terms related\\nto non-binary gender to conduct the corpus level experiments. The first\\nauthor would like to thank Indian Institute of Technology Palakkad for\\norganizing the GIAN course on Fairness in Machine Learning. The third\\nauthor would like to thank the Department of Science and Technology'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 14, 'page_label': '15', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='organizing the GIAN course on Fairness in Machine Learning. The third\\nauthor would like to thank the Department of Science and Technology\\n(DST) of the Government of India for financial support through the\\nWomen Scientist Scheme-A (WOS-A) for Research in Basic/Applied\\nScience under the Grant SR/WOS-A/PM-62/2018.\\nAppendix A. Supplementary data\\nSupplementary material related to this article can be found online\\nat https://doi.org/10.1016/j.nlp.2024.100062.\\nReferences\\nAbid, A., Farooqi, M., Zou, J., 2021a. Large language models associate muslims with\\nviolence. Nat. Mach. Intell. 3 (6), 461–463. http://dx.doi.org/10.1038/s42256-021-\\n00359-2.\\nAbid, A., Farooqi, M., Zou, J., 2021b. Persistent anti-muslim bias in large language\\nmodels. In: Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and\\nSociety. Association for Computing Machinery, New York, NY, USA, pp. 298–306,\\nURL: https://doi.org/10.1145/3461702.3462624.'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 14, 'page_label': '15', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='models. In: Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and\\nSociety. Association for Computing Machinery, New York, NY, USA, pp. 298–306,\\nURL: https://doi.org/10.1145/3461702.3462624.\\nAcheampong, F.A., Nunoo-Mensah, H., Chen, W., 2021. Transformer models for text-\\nbased emotion detection: a review of BERT-based approaches. Artif. Intell. Rev. 54\\n(8), 5789–5829. http://dx.doi.org/10.1007/s10462-021-09958-2.\\nAdoma, A.F., Henry, N.-M., Chen, W., 2020. Comparative analyses of bert, roberta,\\ndistilbert, and xlnet for text-based emotion recognition. In: 2020 17th International\\nComputer Conference on Wavelet Active Media Technology and Information Pro-\\ncessing. ICCWAMTIP, pp. 117–121. http://dx.doi.org/10.1109/ICCWAMTIP51612.\\n2020.9317379.\\nAnoop, K., Gangan, M.P., Deepak, P., Lajish, V.L., 2022. Towards an enhanced\\nunderstanding of bias in pre-trained neural language models: A survey with\\nspecial emphasis on affective bias. In: Responsible Data Science. Springer Nature,'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 14, 'page_label': '15', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='understanding of bias in pre-trained neural language models: A survey with\\nspecial emphasis on affective bias. In: Responsible Data Science. Springer Nature,\\nSingapore, pp. 13–45. http://dx.doi.org/10.1007/978-981-19-4453-6_2.\\nAshley, W., 2014. The angry black woman: The impact of pejorative stereotypes\\non psychotherapy with black women. Soc. Work Public Health 29 (1), 27–34.\\nhttp://dx.doi.org/10.1080/19371918.2011.619449.\\nBhaskaran, J., Bhallamudi, I., 2019. Good secretaries, bad truck drivers? Occupational\\ngender stereotypes in sentiment analysis. In: Proceedings of the First Workshop\\non Gender Bias in Natural Language Processing. Association for Computational\\nLinguistics, Italy, pp. 62–68. http://dx.doi.org/10.18653/v1/W19-3809.\\nBolukbasi, T., Chang, K.-W., Zou, J., Saligrama, V., Kalai, A., 2016. Man is to\\ncomputer programmer as woman is to homemaker? Debiasing word embeddings. In:\\nProceedings of the 30th International Conference on Neural Information Processing'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 14, 'page_label': '15', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='computer programmer as woman is to homemaker? Debiasing word embeddings. In:\\nProceedings of the 30th International Conference on Neural Information Processing\\nSystems. NIPS ’16, Curran Associates Inc., Red Hook, NY, USA, pp. 4356–4364,\\nURL: https://dl.acm.org/doi/10.5555/3157382.3157584.\\nBordia, S., Bowman, S.R., 2019. Identifying and reducing gender bias in word-level\\nlanguage models. In: Proceedings of the 2019 Conference of the North American\\nChapter of the Association for Computational Linguistics: Student Research Work-\\nshop. Association for Computational Linguistics, Minneapolis, Minnesota, pp. 7–15.\\nhttp://dx.doi.org/10.18653/v1/N19-3002.\\nBrown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J.D., Dhariwal, P., Neelakan-\\ntan, A., Shyam, P., Sastry, G., Askell, A., et al., 2020. Language models are few-shot\\nlearners. Adv. Neural Inf. Process. Syst. 33, 1877–1901, URL: https://proceedings.\\nneurips.cc/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf.'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 14, 'page_label': '15', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='learners. Adv. Neural Inf. Process. Syst. 33, 1877–1901, URL: https://proceedings.\\nneurips.cc/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf.\\nCaliskan, A., Bryson, J.J., Narayanan, A., 2017. Semantics derived automatically from\\nlanguage corpora contain human-like biases. Science 356 (6334), 183–186. http:\\n//dx.doi.org/10.1126/science.aal4230.\\nCenter, T.S., 2022. LGBTQIA+ terminology. URL: https://www.umass.edu/stonewall/\\nsites/default/files/documents/allyship_term_handout.pdf. Accessed: 4-7-2022.\\nChowdhery, A., Narang, S., Devlin, J., Bosma, M., Mishra, G., Roberts, A., Barham, P.,\\nChung, H.W., Sutton, C., Gehrmann, S., et al., 2023. Palm: Scaling language\\nmodeling with pathways. J. Mach. Learn. Res. 24 (240), 1–113, URL: https:\\n//www.jmlr.org/papers/volume24/22-1144/22-1144.pdf.\\nChung, H.W., Hou, L., Longpre, S., Zoph, B., Tay, Y., Fedus, W., Li, Y., Wang, X.,\\nDehghani, M., Brahma, S., et al., 2022. Scaling instruction-finetuned language'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 14, 'page_label': '15', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='Chung, H.W., Hou, L., Longpre, S., Zoph, B., Tay, Y., Fedus, W., Li, Y., Wang, X.,\\nDehghani, M., Brahma, S., et al., 2022. Scaling instruction-finetuned language\\nmodels. http://dx.doi.org/10.48550/arXiv.2210.11416, arXiv preprint arXiv:2210.\\n11416.\\nCorbett-Davies, S., Pierson, E., Feller, A., Goel, S., Huq, A., 2017. Algorithmic decision\\nmaking and the cost of fairness. In: Proceedings of the 23rd ACM SIGKDD\\nInternational Conference on Knowledge Discovery and Data Mining. KDD ’17,\\nAssociation for Computing Machinery, New York, NY, USA, pp. 797–806. http:\\n//dx.doi.org/10.1145/3097983.3098095.\\nDale, R., 2019. Law and word order: NLP in legal tech. Nat. Lang. Eng. 25 (1), 211–217.\\nhttp://dx.doi.org/10.1017/S1351324918000475.\\nDe Choudhury, M., Counts, S., Gamon, M., 2012. Not all moods are created equal!\\nexploring human emotional states in social media. In: Proceedings of the Inter-\\nnational AAAI Conference on Web and Social Media. Vol. 6, pp. 66–73, URL:'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 14, 'page_label': '15', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='exploring human emotional states in social media. In: Proceedings of the Inter-\\nnational AAAI Conference on Web and Social Media. Vol. 6, pp. 66–73, URL:\\nhttps://ojs.aaai.org/index.php/ICWSM/article/view/14279.\\nDevlin, J., Chang, M.-W., Lee, K., Toutanova, K., 2019. BERT: Pre-training of deep\\nbidirectional transformers for language understanding. In: Proceedings of the\\n2019 Conference of the North American Chapter of the Association for Compu-\\ntational Linguistics: Human Language Technologies, Volume 1 (Long and Short\\nPapers). Association for Computational Linguistics, Minneapolis, Minnesota, pp.\\n4171–4186. http://dx.doi.org/10.18653/v1/N19-1423, URL: https://aclanthology.\\norg/N19-1423.\\nDíaz, M., Johnson, I., Lazar, A., Piper, A.M., Gergle, D., 2018. Addressing age-related\\nbias in sentiment analysis. In: Proceedings of the 2018 Chi Conference on Human\\nFactors in Computing Systems. Association for Computing Machinery, New York,'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 14, 'page_label': '15', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='bias in sentiment analysis. In: Proceedings of the 2018 Chi Conference on Human\\nFactors in Computing Systems. Association for Computing Machinery, New York,\\nNY, USA, pp. 1–14, URL: https://doi.org/10.1145/3173574.3173986.\\nDixon, L., Li, J., Sorensen, J., Thain, N., Vasserman, L., 2018. Measuring and mitigating\\nunintended bias in text classification. In: Proceedings of the 2018 AAAI/ACM Con-\\nference on AI, Ethics, and Society. AIES ’18, Association for Computing Machinery,\\nNew York, NY, USA, pp. 67–73. http://dx.doi.org/10.1145/3278721.3278729.\\n15'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 15, 'page_label': '16', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='A. Kadan, Deepak P., S. Bhadra et al. Natural Language Processing Journal 7 (2024) 100062\\nDu, M., Yang, F., Zou, N., Hu, X., 2021. Fairness in deep learning: A computational\\nperspective. IEEE Intell. Syst. 36 (4), 25–34. http://dx.doi.org/10.1109/MIS.2020.\\n3000681.\\nEagly, A.H., Steffen, V.J., 1984. Gender stereotypes stem from the distribution of\\nwomen and men into social roles. J. Pers. Soc. Psychol. 46 (4), 735, doi:https:\\n//psycnet.apa.org/doi/10.1037/0022-3514.46.4.735.\\nFeldman, M., Friedler, S.A., Moeller, J., Scheidegger, C., Venkatasubramanian, S.,\\n2015. Certifying and removing disparate impact. In: Proceedings of the 21th ACM\\nSIGKDD International Conference on Knowledge Discovery and Data Mining. KDD\\n’15, Association for Computing Machinery, New York, NY, USA, pp. 259–268.\\nhttp://dx.doi.org/10.1145/2783258.2783311.\\nFeng, S., Park, C.Y., Liu, Y., Tsvetkov, Y., 2023. From pretraining data to language\\nmodels to downstream tasks: Tracking the trails of political biases leading to'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 15, 'page_label': '16', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='Feng, S., Park, C.Y., Liu, Y., Tsvetkov, Y., 2023. From pretraining data to language\\nmodels to downstream tasks: Tracking the trails of political biases leading to\\nunfair NLP models. In: Rogers, A., Boyd-Graber, J., Okazaki, N. (Eds.), Proceedings\\nof the 61st Annual Meeting of the Association for Computational Linguistics\\n(Volume 1: Long Papers). Association for Computational Linguistics, Toronto,\\nCanada, pp. 11737–11762. http://dx.doi.org/10.18653/v1/2023.acl-long.656, URL:\\nhttps://aclanthology.org/2023.acl-long.656.\\nGarg, N., Schiebinger, L., Jurafsky, D., Zou, J., 2018. Word embeddings quantify\\n100 years of gender and ethnic stereotypes. Proc. Natl. Acad. Sci. 115 (16),\\nE3635–E3644.\\nGuo, W., Caliskan, A., 2021. Detecting emergent intersectional biases: Contextualized\\nword embeddings contain a distribution of human-like biases. In: Proceedings\\nof the 2021 AAAI/ACM Conference on AI, Ethics, and Society. Association for'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 15, 'page_label': '16', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='word embeddings contain a distribution of human-like biases. In: Proceedings\\nof the 2021 AAAI/ACM Conference on AI, Ethics, and Society. Association for\\nComputing Machinery, New York, NY, USA, pp. 122–133, URL: https://doi.org/10.\\n1145/3461702.3462536.\\nHahn, H., Seager van Dyk, I., Ahn, W.-Y., 2020. Attitudes toward gay men and lesbian\\nwomen moderate heterosexual adults’ subjective stress response to witnessing\\nhomonegativity. Front. Psychol. 10, 2948. http://dx.doi.org/10.3389/fpsyg.2019.\\n02948.\\nHe, P., Liu, X., Gao, J., Chen, W., 2021. DEBERTA: Decoding-enhanced bert with\\ndisentangled attention. In: International Conference on Learning Representations.\\nURL: https://openreview.net/forum?id=XPZIaotutsD.\\nHooker, S., 2021. Moving beyond ‘‘algorithmic bias is a data problem’’. Patterns 2\\n(4), 100241. http://dx.doi.org/10.1016/j.patter.2021.100241, URL: https://www.\\nsciencedirect.com/science/article/pii/S2666389921000611.'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 15, 'page_label': '16', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='(4), 100241. http://dx.doi.org/10.1016/j.patter.2021.100241, URL: https://www.\\nsciencedirect.com/science/article/pii/S2666389921000611.\\nHovy, D., Prabhumoye, S., 2021. Five sources of bias in natural language processing.\\nLang. Linguist. Compass 15 (8), e12432. http://dx.doi.org/10.1111/lnc3.12432,\\nURL: https://compass.onlinelibrary.wiley.com/doi/abs/10.1111/lnc3.12432.\\nHuang, P.-S., Zhang, H., Jiang, R., Stanforth, R., Welbl, J., Rae, J., Maini, V.,\\nYogatama, D., Kohli, P., 2020. Reducing sentiment bias in language models\\nvia counterfactual evaluation. In: Findings of the Association for Computational\\nLinguistics: EMNLP 2020. Association for Computational Linguistics, Online, pp.\\n65–83. http://dx.doi.org/10.18653/v1/2020.findings-emnlp.7.\\nHuguet Cabot, P.-L., Dankers, V., Abadi, D., Fischer, A., Shutova, E., 2020. The\\npragmatics behind politics: Modelling metaphor, framing and emotion in political\\ndiscourse. In: Cohn, T., He, Y., Liu, Y. (Eds.), Findings of the Association for'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 15, 'page_label': '16', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='pragmatics behind politics: Modelling metaphor, framing and emotion in political\\ndiscourse. In: Cohn, T., He, Y., Liu, Y. (Eds.), Findings of the Association for\\nComputational Linguistics: EMNLP 2020. Association for Computational Linguistics,\\nOnline, pp. 4479–4488. http://dx.doi.org/10.18653/v1/2020.findings-emnlp.402,\\nURL: https://aclanthology.org/2020.findings-emnlp.402.\\nKaneko, M., Bollegala, D., 2022. Unmasking the mask – evaluating social biases in\\nmasked language models. In: Proceedings of the 36th AAAI Conference on Artificial\\nIntelligence. Vancouver, BC, Canada, http://dx.doi.org/10.1609/aaai.v36i11.21453.\\nKiritchenko, S., Mohammad, S., 2018. Examining gender and race bias in two hundred\\nsentiment analysis systems. In: Proceedings of the Seventh Joint Conference on\\nLexical and Computational Semantics. Association for Computational Linguistics,\\nNew Orleans, Louisiana, pp. 43–53. http://dx.doi.org/10.18653/v1/S18-2005, URL:\\nhttps://aclanthology.org/S18-2005.'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 15, 'page_label': '16', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='Lexical and Computational Semantics. Association for Computational Linguistics,\\nNew Orleans, Louisiana, pp. 43–53. http://dx.doi.org/10.18653/v1/S18-2005, URL:\\nhttps://aclanthology.org/S18-2005.\\nLiang, P.P., Wu, C., Morency, L.-P., Salakhutdinov, R., 2021. Towards understanding\\nand mitigating social biases in language models. In: Meila, M., Zhang, T. (Eds.),\\nProceedings of the 38th International Conference on Machine Learning. In: Pro-\\nceedings of Machine Learning Research, vol. 139, PMLR, pp. 6565–6576, URL:\\nhttps://proceedings.mlr.press/v139/liang21a.html.\\nLozada, F.T., Riley, T.N., Catherine, E., Brown, D.W., 2022. Black emotions matter:\\nUnderstanding the impact of racial oppression on black youth’s emotional devel-\\nopment: Dismantling systems of racism and oppression during adolescence. J. Res.\\nAdolesc. 32 (1), 13–33. http://dx.doi.org/10.1111/jora.12699.\\nLu, K., Mardziel, P., Wu, F., Amancharla, P., Datta, A., 2020. Gender bias in neural'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 15, 'page_label': '16', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='Adolesc. 32 (1), 13–33. http://dx.doi.org/10.1111/jora.12699.\\nLu, K., Mardziel, P., Wu, F., Amancharla, P., Datta, A., 2020. Gender bias in neural\\nnatural language processing. In: Logic, Language, and Security: Essays Dedicated\\nto Andre Scedrov on the Occasion of his 65th Birthday. Springer International\\nPublishing, Cham, pp. 189–202. http://dx.doi.org/10.1007/978-3-030-62077-6_14.\\nMao, R., Liu, Q., He, K., Li, W., Cambria, E., 2022. The biases of pre-trained language\\nmodels: An empirical study on prompt-based sentiment analysis and emotion\\ndetection. IEEE Trans. Affect. Comput. 1–11. http://dx.doi.org/10.1109/TAFFC.\\n2022.3204972.\\nMay, C., Wang, A., Bordia, S., Bowman, S.R., Rudinger, R., 2019. On measuring\\nsocial biases in sentence encoders. In: Proceedings of the 2019 Conference of\\nthe North American Chapter of the Association for Computational Linguistics:\\nHuman Language Technologies, Volume 1 (Long and Short Papers). Association'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 15, 'page_label': '16', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='the North American Chapter of the Association for Computational Linguistics:\\nHuman Language Technologies, Volume 1 (Long and Short Papers). Association\\nfor Computational Linguistics, Minneapolis, Minnesota, pp. 622–628. http://dx.doi.\\norg/10.18653/v1/N19-1063.\\nMishev, K., Gjorgjevikj, A., Vodenska, I., Chitkushev, L.T., Trajanov, D., 2020. Evalu-\\nation of sentiment analysis in finance: From lexicons to transformers. IEEE Access\\n8, 131662–131682. http://dx.doi.org/10.1109/ACCESS.2020.3009626.\\nMohammad, S., Bravo-Marquez, F., Salameh, M., Kiritchenko, S., 2018. SemEval-2018\\ntask 1: Affect in tweets. In: Proceedings of the 12th International Workshop\\non Semantic Evaluation. Association for Computational Linguistics, New Or-\\nleans, Louisiana, pp. 1–17. http://dx.doi.org/10.18653/v1/S18-1001, URL: https:\\n//aclanthology.org/S18-1001.\\nNadeem, M., Bethke, A., Reddy, S., 2021. StereoSet: Measuring stereotypical bias\\nin pretrained language models. In: Proceedings of the 59th Annual Meeting of'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 15, 'page_label': '16', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='//aclanthology.org/S18-1001.\\nNadeem, M., Bethke, A., Reddy, S., 2021. StereoSet: Measuring stereotypical bias\\nin pretrained language models. In: Proceedings of the 59th Annual Meeting of\\nthe Association for Computational Linguistics and the 11th International Joint\\nConference on Natural Language Processing (Volume 1: Long Papers). Association\\nfor Computational Linguistics, Online, pp. 5356–5371. http://dx.doi.org/10.18653/\\nv1/2021.acl-long.416, URL: https://aclanthology.org/2021.acl-long.416.\\nNangia, N., Vania, C., Bhalerao, R., Bowman, S.R., 2020. Crows-pairs: A challenge\\ndataset for measuring social biases in masked language models. In: Proceedings\\nof the 2020 Conference on Empirical Methods in Natural Language Processing.\\nEMNLP, Association for Computational Linguistics, Online, pp. 1953–1967. http:\\n//dx.doi.org/10.18653/v1/2020.emnlp-main.154, URL: https://aclanthology.org/\\n2020.emnlp-main.154.\\nNavigli, R., Conia, S., Ross, B., 2023. Biases in large language models: Origins,'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 15, 'page_label': '16', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='//dx.doi.org/10.18653/v1/2020.emnlp-main.154, URL: https://aclanthology.org/\\n2020.emnlp-main.154.\\nNavigli, R., Conia, S., Ross, B., 2023. Biases in large language models: Origins,\\ninventory, and discussion. J. Data Inf. Qual. 15 (2), http://dx.doi.org/10.1145/\\n3597307.\\nPlant, E.A., Hyde, J.S., Keltner, D., Devine, P.G., 2000. The gender stereotyping of\\nemotions. Psychol. Women Q. 24 (1), 81–92. http://dx.doi.org/10.1111/j.1471-\\n6402.2000.tb01024.x.\\nRadford, A., Wu, J., Child, R., Luan, D., Amodei, D., Sutskever, I., et al., 2019.\\nLanguage models are unsupervised multitask learners. OpenAI Blog 1 (8), 9, URL:\\nhttps://openai.com/blog/better-language-models/.\\nRaffel, C., Shazeer, N., Roberts, A., Lee, K., Narang, S., Matena, M., Zhou, Y., Li, W.,\\nLiu, P.J., 2020. Exploring the limits of transfer learning with a unified text-to-text\\ntransformer. J. Mach. Learn. Res. 21 (140), 1–67, URL: http://jmlr.org/papers/v21/\\n20-074.html.'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 15, 'page_label': '16', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='Liu, P.J., 2020. Exploring the limits of transfer learning with a unified text-to-text\\ntransformer. J. Mach. Learn. Res. 21 (140), 1–67, URL: http://jmlr.org/papers/v21/\\n20-074.html.\\nRahman, M.M., Siddiqui, F.H., 2019. An optimized abstractive text summarization\\nmodel using peephole convolutional LSTM. Symmetry 11 (10), http://dx.doi.org/\\n10.3390/sym11101290, URL: https://www.mdpi.com/2073-8994/11/10/1290.\\nRahman, M.M., Siddiqui, F.H., 2021. Multi-layered attentional peephole convolu-\\ntional LSTM for abstractive text summarization. ETRI J. 43 (2), 288–298. http:\\n//dx.doi.org/10.4218/etrij.2019-0016, URL: https://onlinelibrary.wiley.com/doi/\\nabs/10.4218/etrij.2019-0016.\\nRaza, S., Garg, M., Reji, D.J., Bashir, S.R., Ding, C., 2024. Nbias: A natural lan-\\nguage processing framework for BIAS identification in text. Expert Syst. Appl.\\n237, 121542. http://dx.doi.org/10.1016/j.eswa.2023.121542, URL: https://www.\\nsciencedirect.com/science/article/pii/S0957417423020444.'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 15, 'page_label': '16', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='237, 121542. http://dx.doi.org/10.1016/j.eswa.2023.121542, URL: https://www.\\nsciencedirect.com/science/article/pii/S0957417423020444.\\nRozado, D., 2020. Wide range screening of algorithmic bias in word embedding models\\nusing large sentiment lexicons reveals underreported bias types. PLoS One 15 (4),\\n1–26. http://dx.doi.org/10.1371/journal.pone.0231189.\\nShen, J.H., Fratamico, L., Rahwan, I., Rush, A.M., 2018. Darling or babygirl? investi-\\ngating stylistic bias in sentiment analysis. Proc. FATML URL: https://www.fatml.\\norg/media/documents/darling_or_babygirl_stylistic_bias.pdf.\\nShields, S.A., 2002. Speaking from the Heart: Gender and the Social Meaning of\\nEmotion. Cambridge University Press.\\nSkogan, W.G., 1995. Crime and the racial fears of white Americans. Ann.\\nAm. Acad. Political Soc. Sci. 539 (1), 59–71. http://dx.doi.org/10.1177/\\n0002716295539001005.\\nSoni, S., Roberts, K., 2020. Evaluation of dataset selection for pre-training and fine-'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 15, 'page_label': '16', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='Am. Acad. Political Soc. Sci. 539 (1), 59–71. http://dx.doi.org/10.1177/\\n0002716295539001005.\\nSoni, S., Roberts, K., 2020. Evaluation of dataset selection for pre-training and fine-\\ntuning transformer language models for clinical question answering. In: Proceedings\\nof the 12th Language Resources and Evaluation Conference. European Language Re-\\nsources Association, Marseille, France, pp. 5532–5538, URL: https://aclanthology.\\norg/2020.lrec-1.679.\\nStaiano, J., Guerini, M., 2014. Depeche mood: a lexicon for emotion analysis from\\ncrowd annotated news. In: Proceedings of the 52nd Annual Meeting of the\\nAssociation for Computational Linguistics (Volume 2: Short Papers). Association\\nfor Computational Linguistics, Baltimore, Maryland, pp. 427–433. http://dx.doi.\\norg/10.3115/v1/P14-2070, URL: https://aclanthology.org/P14-2070.\\nSu, C., Yu, G., Wang, J., Yan, Z., Cui, L., 2022. A review of causality-based fairness\\nmachine learning. Intell. Robot. 244–274. http://dx.doi.org/10.20517/ir.2022.17.'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 15, 'page_label': '16', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='Su, C., Yu, G., Wang, J., Yan, Z., Cui, L., 2022. A review of causality-based fairness\\nmachine learning. Intell. Robot. 244–274. http://dx.doi.org/10.20517/ir.2022.17.\\nSubramanian, S., Rahimi, A., Baldwin, T., Cohn, T., Frermann, L., 2021. Fairness-aware\\nclass imbalanced learning. In: Moens, M.-F., Huang, X., Specia, L., Yih, S.W.-\\nt. (Eds.), Proceedings of the 2021 Conference on Empirical Methods in Natural\\nLanguage Processing. Association for Computational Linguistics, Online and Punta\\nCana, Dominican Republic, pp. 2045–2051. http://dx.doi.org/10.18653/v1/2021.\\nemnlp-main.155, URL: https://aclanthology.org/2021.emnlp-main.155.\\nSuresh, H., Guttag, J., 2021. A framework for understanding sources of harm\\nthroughout the machine learning life cycle. In: Equity and Access in Algorithms,\\nMechanisms, and Optimization. EAAMO ’21, Association for Computing Machinery,\\nNew York, NY, USA, http://dx.doi.org/10.1145/3465416.3483305.'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 15, 'page_label': '16', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='Mechanisms, and Optimization. EAAMO ’21, Association for Computing Machinery,\\nNew York, NY, USA, http://dx.doi.org/10.1145/3465416.3483305.\\nSweeney, C., Najafian, M., 2020. Reducing sentiment polarity for demographic at-\\ntributes in word embeddings using adversarial learning. In: Proceedings of the\\n16'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 16, 'page_label': '17', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='A. Kadan, Deepak P., S. Bhadra et al. Natural Language Processing Journal 7 (2024) 100062\\n2020 Conference on Fairness, Accountability, and Transparency. In: FAT* ’20,\\nAssociation for Computing Machinery, New York, NY, USA, pp. 359–368. http:\\n//dx.doi.org/10.1145/3351095.3372837.\\nTabinda Kokab, S., Asghar, S., Naz, S., 2022. Transformer-based deep learning mod-\\nels for the sentiment analysis of social media data. Array 14, 100157. http:\\n//dx.doi.org/10.1016/j.array.2022.100157, URL: https://www.sciencedirect.com/\\nscience/article/pii/S2590005622000224.\\nTan, Y.C., Celis, L.E., 2019. Assessing social and intersectional biases in contextualized\\nword representations. In: Proceedings of the 33rd International Conference on\\nNeural Information Processing Systems. Curran Associates Inc., Red Hook, NY, USA,\\npp. 13230–13241, URL: https://dl.acm.org/doi/10.5555/3454287.3455472.\\nThoppilan, R., De Freitas, D., Hall, J., Shazeer, N., Kulshreshtha, A., Cheng, H.-T.,'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 16, 'page_label': '17', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='pp. 13230–13241, URL: https://dl.acm.org/doi/10.5555/3454287.3455472.\\nThoppilan, R., De Freitas, D., Hall, J., Shazeer, N., Kulshreshtha, A., Cheng, H.-T.,\\nJin, A., Bos, T., Baker, L., Du, Y., et al., 2022. Lamda: Language models for\\ndialog applications. http://dx.doi.org/10.48550/arXiv.2201.08239, arXiv preprint\\narXiv:2201.08239.\\nTouvron, H., Lavril, T., Izacard, G., Martinet, X., Lachaux, M.-A., Lacroix, T., Rozière, B.,\\nGoyal, N., Hambro, E., Azhar, F., et al., 2023. Llama: Open and efficient foundation\\nlanguage models. arXiv preprint arXiv:2302.13971. URL: https://research.facebook.\\ncom/publications/llama-open-and-efficient-foundation-language-models/.\\nTrinh, T.H., Le, Q.V., 2018. A simple method for commonsense reasoning. http://dx.\\ndoi.org/10.48550/arXiv.1806.02847, arXiv preprint arXiv:1806.02847.\\nVelupillai, S., Suominen, H., Liakata, M., Roberts, A., Shah, A.D., Morley, K., Os-\\nborn, D., Hayes, J., Stewart, R., Downs, J., Chapman, W., Dutta, R., 2018.'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 16, 'page_label': '17', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='Velupillai, S., Suominen, H., Liakata, M., Roberts, A., Shah, A.D., Morley, K., Os-\\nborn, D., Hayes, J., Stewart, R., Downs, J., Chapman, W., Dutta, R., 2018.\\nUsing clinical natural language processing for health outcomes research: Overview\\nand actionable suggestions for future advances. J. Biomed. Inform. 88, 11–19.\\nhttp://dx.doi.org/10.1016/j.jbi.2018.10.005, URL: https://www.sciencedirect.com/\\nscience/article/pii/S1532046418302016.\\nVenkit, P.N., Wilson, S., 2021. Identification of bias against people with disabilities\\nin sentiment analysis and toxicity detection models. http://dx.doi.org/10.48550/\\narXiv.2111.13259, arXiv preprint arXiv:2111.13259.\\nVittengl, J.R., Holt, C.S., 1998. A time-series diary study of mood and social interaction.\\nMotiv. Emot. 22 (3), 255–275. http://dx.doi.org/10.1023/A:1022388123550.\\nWaterloo, S.F., Baumgartner, S.E., Peter, J., Valkenburg, P.M., 2018. Norms of\\nonline expressions of emotion: Comparing facebook, Twitter, instagram, and'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 16, 'page_label': '17', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='Waterloo, S.F., Baumgartner, S.E., Peter, J., Valkenburg, P.M., 2018. Norms of\\nonline expressions of emotion: Comparing facebook, Twitter, instagram, and\\nWhatsApp. New Media Soc. 20 (5), 1813–1831. http://dx.doi.org/10.1177/\\n1461444817707349, PMID: 30581358.\\nYang, Z., Asyrofi, M.H., Lo, D., 2021. BiasRV: Uncovering biased sentiment predictions\\nat runtime. In: Proceedings of the 29th ACM Joint Meeting on European Software\\nEngineering Conference and Symposium on the Foundations of Software Engineer-\\ning. In: ESEC/FSE 2021, Association for Computing Machinery, New York, NY,\\nUSA, pp. 1540–1544. http://dx.doi.org/10.1145/3468264.3473117.\\nYang, Z., Dai, Z., Yang, Y., Carbonell, J., Salakhutdinov, R., Le, Q.V., 2019. XLNet:\\nGeneralized autoregressive pretraining for language understanding. In: Proceedings\\nof the 33rd International Conference on Neural Information Processing Systems.\\nCurran Associates Inc., Red Hook, NY, USA, pp. 5753–5763, URL: https://dl.acm.'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 16, 'page_label': '17', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='of the 33rd International Conference on Neural Information Processing Systems.\\nCurran Associates Inc., Red Hook, NY, USA, pp. 5753–5763, URL: https://dl.acm.\\norg/doi/10.5555/3454287.3454804.\\nZhang, L., Fan, H., Peng, C., Rao, G., Cong, Q., 2020. Sentiment analysis methods\\nfor HPV vaccines related tweets based on transfer learning. Healthcare 8 (3),\\nhttp://dx.doi.org/10.3390/healthcare8030307, URL: https://www.mdpi.com/2227-\\n9032/8/3/307.\\nZhao, J., Wang, T., Yatskar, M., Cotterell, R., Ordonez, V., Chang, K.-W., 2019. Gender\\nbias in contextualized word embeddings. In: Proceedings of the 2019 Conference\\nof the North American Chapter of the Association for Computational Linguistics:\\nHuman Language Technologies, Volume 1 (Long and Short Papers). Association for\\nComputational Linguistics, Minneapolis, Minnesota, pp. 629–634. http://dx.doi.org/\\n10.18653/v1/N19-1064, URL: https://aclanthology.org/N19-1064.\\nZhao, J., Wang, T., Yatskar, M., Ordonez, V., Chang, K.-W., 2018. Gender bias in'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 16, 'page_label': '17', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='10.18653/v1/N19-1064, URL: https://aclanthology.org/N19-1064.\\nZhao, J., Wang, T., Yatskar, M., Ordonez, V., Chang, K.-W., 2018. Gender bias in\\ncoreference resolution: Evaluation and debiasing methods. In: Proceedings of the\\n2018 Conference of the North American Chapter of the Association for Com-\\nputational Linguistics: Human Language Technologies, Volume 2 (Short Papers).\\nAssociation for Computational Linguistics, New Orleans, Louisiana, pp. 15–20.\\nhttp://dx.doi.org/10.18653/v1/N18-2003.\\nZhiltsova, A., Caton, S., Mulway, C., 2019. Mitigation of unintended biases against\\nnon-native english texts in sentiment analysis. In: Proceedings for the 27th AIAI\\nIrish Conference on Artificial Intelligence and Cognitive Science, Galway, Ireland,\\nDecember 5-6, 2019. In: CEUR Workshop Proceedings, vol. 2563, CEUR-WS.org,\\npp. 317–328, URL: http://ceur-ws.org/Vol-2563/aics_30.pdf.\\nZhu, Y., Kiros, R., Zemel, R., Salakhutdinov, R., Urtasun, R., Torralba, A., Fidler, S.,'),\n",
       " Document(metadata={'producer': 'pdfTeX', 'creator': 'Elsevier', 'creationdate': '2024-06-11T17:54:50+05:30', 'gts_pdfa1version': 'PDF/A-1b:2005', 'moddate': '2024-06-11T17:54:50+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': 'Natural Language Processing Journal, 7 (2024) 100062. doi:10.1016/j.nlp.2024.100062', 'trapped': '/False', 'source': '../data/pdf_files/1-s2.0-S2949719124000104-main.pdf', 'total_pages': 17, 'page': 16, 'page_label': '17', 'source_file': '1-s2.0-S2949719124000104-main.pdf', 'file_type': 'pdf'}, page_content='pp. 317–328, URL: http://ceur-ws.org/Vol-2563/aics_30.pdf.\\nZhu, Y., Kiros, R., Zemel, R., Salakhutdinov, R., Urtasun, R., Torralba, A., Fidler, S.,\\n2015. Aligning books and movies: Towards story-like visual explanations by\\nwatching movies and reading books. In: Proceedings of the 2015 IEEE International\\nConference on Computer Vision. ICCV, IEEE Computer Society, USA, pp. 19–27.\\nhttp://dx.doi.org/10.1109/ICCV.2015.11.\\n17')]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6d9cd46a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings for 382 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 12/12 [00:02<00:00,  5.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (382, 384)\n",
      "Adding 382 documents to vector store...\n",
      "Error adding documents to vector store: Query error: Database error: error returned from database: (code: 1032) attempt to write a readonly database\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Query error: Database error: error returned from database: (code: 1032) attempt to write a readonly database",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInternalError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[53]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m embeddings=embedding_manager.generate_embeddings(texts)\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m##store int he vector dtaabase\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[43mvectorstore\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunks\u001b[49m\u001b[43m,\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[51]\u001b[39m\u001b[32m, line 75\u001b[39m, in \u001b[36mVectorStore.add_documents\u001b[39m\u001b[34m(self, documents, embeddings)\u001b[39m\n\u001b[32m     73\u001b[39m \u001b[38;5;66;03m# Add to collection\u001b[39;00m\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcollection\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m        \u001b[49m\u001b[43mids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m        \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43membeddings_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdocuments_text\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     81\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSuccessfully added \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(documents)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m documents to vector store\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     82\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTotal documents in collection: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.collection.count()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/projects/rag_tutorial/.venv/lib/python3.13/site-packages/chromadb/api/models/Collection.py:95\u001b[39m, in \u001b[36mCollection.add\u001b[39m\u001b[34m(self, ids, embeddings, metadatas, documents, images, uris)\u001b[39m\n\u001b[32m     65\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Add embeddings to the data store.\u001b[39;00m\n\u001b[32m     66\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m     67\u001b[39m \u001b[33;03m    ids: The ids of the embeddings you wish to add\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     83\u001b[39m \n\u001b[32m     84\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     86\u001b[39m add_request = \u001b[38;5;28mself\u001b[39m._validate_and_prepare_add_request(\n\u001b[32m     87\u001b[39m     ids=ids,\n\u001b[32m     88\u001b[39m     embeddings=embeddings,\n\u001b[32m   (...)\u001b[39m\u001b[32m     92\u001b[39m     uris=uris,\n\u001b[32m     93\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_add\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     96\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcollection_id\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[43m    \u001b[49m\u001b[43mids\u001b[49m\u001b[43m=\u001b[49m\u001b[43madd_request\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mids\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     98\u001b[39m \u001b[43m    \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43madd_request\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43membeddings\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     99\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m=\u001b[49m\u001b[43madd_request\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadatas\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    100\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m=\u001b[49m\u001b[43madd_request\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdocuments\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    101\u001b[39m \u001b[43m    \u001b[49m\u001b[43muris\u001b[49m\u001b[43m=\u001b[49m\u001b[43madd_request\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muris\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtenant\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtenant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    104\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/projects/rag_tutorial/.venv/lib/python3.13/site-packages/chromadb/api/rust.py:441\u001b[39m, in \u001b[36mRustBindingsAPI._add\u001b[39m\u001b[34m(self, ids, collection_id, embeddings, metadatas, documents, uris, tenant, database)\u001b[39m\n\u001b[32m    419\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    420\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_add\u001b[39m(\n\u001b[32m    421\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    429\u001b[39m     database: \u001b[38;5;28mstr\u001b[39m = DEFAULT_DATABASE,\n\u001b[32m    430\u001b[39m ) -> \u001b[38;5;28mbool\u001b[39m:\n\u001b[32m    431\u001b[39m     \u001b[38;5;28mself\u001b[39m.product_telemetry_client.capture(\n\u001b[32m    432\u001b[39m         CollectionAddEvent(\n\u001b[32m    433\u001b[39m             collection_uuid=\u001b[38;5;28mstr\u001b[39m(collection_id),\n\u001b[32m   (...)\u001b[39m\u001b[32m    438\u001b[39m         )\n\u001b[32m    439\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m441\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbindings\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    442\u001b[39m \u001b[43m        \u001b[49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    443\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcollection_id\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    444\u001b[39m \u001b[43m        \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    445\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    446\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    447\u001b[39m \u001b[43m        \u001b[49m\u001b[43muris\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    448\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtenant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    449\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    450\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mInternalError\u001b[39m: Query error: Database error: error returned from database: (code: 1032) attempt to write a readonly database"
     ]
    }
   ],
   "source": [
    "### Convert the text to embeddings\n",
    "texts=[doc.page_content for doc in chunks]\n",
    "\n",
    "## Generate the Embeddings\n",
    "\n",
    "embeddings=embedding_manager.generate_embeddings(texts)\n",
    "\n",
    "##store int he vector dtaabase\n",
    "vectorstore.add_documents(chunks,embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2492179e",
   "metadata": {},
   "source": [
    "### Retriever Pipeline From VectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5ee1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class RAGRetriever:\n",
    "    \"\"\"Handles query-based retrieval from the vector store\"\"\"\n",
    "    \n",
    "    def __init__(self, vector_store: VectorStore, embedding_manager: EmbeddingManager):\n",
    "        \"\"\"\n",
    "        Initialize the retriever\n",
    "        \n",
    "        Args:\n",
    "            vector_store: Vector store containing document embeddings\n",
    "            embedding_manager: Manager for generating query embeddings\n",
    "        \"\"\"\n",
    "        self.vector_store = vector_store\n",
    "        self.embedding_manager = embedding_manager\n",
    "\n",
    "    def retrieve(self, query: str, top_k: int = 5, score_threshold: float = 0.0) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Retrieve relevant documents for a query\n",
    "        \n",
    "        Args:\n",
    "            query: The search query\n",
    "            top_k: Number of top results to return\n",
    "            score_threshold: Minimum similarity score threshold\n",
    "            \n",
    "        Returns:List of dictionaries containing retrieved documents and metadata\n",
    "        \"\"\"\n",
    "        print(f\"Retrieving documents for query: '{query}'\")\n",
    "        print(f\"Top K: {top_k}, Score threshold: {score_threshold}\")\n",
    "        \n",
    "        # Generate query embedding\n",
    "        query_embedding = self.embedding_manager.generate_embeddings([query])[0]\n",
    "        \n",
    "        # Search in vector store\n",
    "        try:\n",
    "            results = self.vector_store.collection.query(\n",
    "                query_embeddings=[query_embedding.tolist()],\n",
    "                n_results=top_k\n",
    "            )\n",
    "            \n",
    "            # Process results\n",
    "            retrieved_docs = []\n",
    "            \n",
    "            if results['documents'] and results['documents'][0]:\n",
    "                documents = results['documents'][0]\n",
    "                metadatas = results['metadatas'][0]\n",
    "                distances = results['distances'][0]\n",
    "                ids = results['ids'][0]\n",
    "                \n",
    "                for i, (doc_id, document, metadata, distance) in enumerate(zip(ids, documents, metadatas, distances)):\n",
    "                    # Convert distance to similarity score (ChromaDB uses cosine distance)\n",
    "                    similarity_score = 1 - distance\n",
    "                    \n",
    "                    if similarity_score >=score_threshold:\n",
    "                        retrieved_docs.append({\n",
    "                            'id': doc_id,\n",
    "                            'content': document,\n",
    "                            'metadata': metadata,\n",
    "                            'similarity_score': similarity_score,\n",
    "                            'distance': distance,\n",
    "                            'rank': i + 1\n",
    "                        })\n",
    "                \n",
    "                print(f\"Retrieved {len(retrieved_docs)} documents (after filtering)\")\n",
    "            else:\n",
    "                print(\"No documents found\")\n",
    "            \n",
    "            return retrieved_docs\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error during retrieval: {e}\")\n",
    "            return []\n",
    "\n",
    "rag_retriever=RAGRetriever(vectorstore,embedding_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfbb4f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents for query: 'supervised'\n",
      "Top K: 5, Score threshold: 0.0\n",
      "Generating embeddings for 1 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  3.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (1, 384)\n",
      "Retrieved 0 documents (after filtering)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_retriever.retrieve(\"supervised\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cb4d62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_tutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
